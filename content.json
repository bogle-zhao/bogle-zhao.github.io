{"meta":{"title":"个人博客","subtitle":null,"description":null,"author":"bogle","url":"http://blog.shagle.cn"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2018-12-24T02:48:54.000Z","updated":"2018-12-21T08:11:19.000Z","comments":false,"path":"/404.html","permalink":"http://blog.shagle.cn//404.html","excerpt":"","text":""},{"title":"关于","date":"2018-12-24T02:48:54.000Z","updated":"2018-12-21T08:11:19.000Z","comments":false,"path":"about/index.html","permalink":"http://blog.shagle.cn/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"分类","date":"2018-12-24T02:48:54.000Z","updated":"2018-12-21T08:11:19.000Z","comments":false,"path":"categories/index.html","permalink":"http://blog.shagle.cn/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2018-12-24T02:48:54.000Z","updated":"2018-12-21T08:11:19.000Z","comments":false,"path":"books/index.html","permalink":"http://blog.shagle.cn/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-12-24T02:48:54.000Z","updated":"2018-12-21T08:11:19.000Z","comments":true,"path":"links/index.html","permalink":"http://blog.shagle.cn/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2018-12-24T02:48:54.000Z","updated":"2018-12-21T08:11:19.000Z","comments":false,"path":"repository/index.html","permalink":"http://blog.shagle.cn/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-12-24T02:48:54.000Z","updated":"2018-12-21T08:11:19.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.shagle.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"并发包中ThreadLocalRandom类原理剖析","slug":"并发包中ThreadLocalRandom类原理剖析","date":"2019-03-22T07:13:26.000Z","updated":"2019-03-22T07:21:19.000Z","comments":true,"path":"2019/03/22/并发包中ThreadLocalRandom类原理剖析/","link":"","permalink":"http://blog.shagle.cn/2019/03/22/并发包中ThreadLocalRandom类原理剖析/","excerpt":"","text":"1. 并发包中ThreadLocalRandom类原理剖析ThreadLocalRandom类是JDK7在JUC包下新增的随机数生成器，它解决了Random类在多线程下多个线程竞争内部唯一的原子性种子变量而导致大量线程自旋重试的不足。本节首先讲解下Random类的实现原理已经它在多线程下使用的局限性，然后引入ThreadLocalRandom类，通过讲解ThreadLocalRandom的实现原理来说明ThreadLocalRandom是如何解决的Random类的不足。 1.1 Random类及其局限性在JDK7之前包括现在java.util.Random应该是使用比较广泛的随机数生成工具类，另外java.lang.Math中的随机数生成也是使用的java.util.Random的实例。下面先看看java.util.Random的使用： 1234567891011public class RandomTest &#123; public static void main(String[] args) &#123; //(1)创建一个默认种子的随机数生成器 Random random = new Random(); //(2)输出10个在0-5（包含0，不包含5）之间的随机数 for (int i = 0; i &lt; 10; ++i) &#123; System.out.println(random.nextInt(5)); &#125; &#125;&#125; 代码（1）创建一个默认随机数生成器，使用默认的种子。 代码（2）输出输出10个在0-5（包含0，不包含5）之间的随机数。 这里提下随机数的生成需要一个默认的种子，这个种子其实是一个long类型的数字,这个种子要么在Random的时候通过构造函数指定，那么默认构造函数内部会生成一个默认的值，有了默认的种子后，如何生成随机数那？ 12345678910public int nextInt(int bound) &#123; //(3)参数检查 if (bound &lt;= 0) throw new IllegalArgumentException(BadBound); //(4)根据老的种子生成新的种子 int r = next(31); //(5)根据新的种子计算随机数 ... return r;&#125; 如上代码可知新的随机数的生成需要两个步骤 首先需要根据老的种子生成新的种子。 然后根据新的种子来计算新的随机数。 其中步骤（4）我们可以抽象为seed=f(seed),其中f是一个固定的函数，比如seed= f(seed)=aseed+b;步骤（5）也可以抽象为g(seed,bound)，其中g是一个固定的函数，比如g(seed,bound)=(int)((bound (long)seed) &gt;&gt; 31);在单线程情况下每次调用nextInt都是根据老的种子计算出来新的种子，这是可以保证随机数产生的随机性的。但是在多线程下多个线程可能都拿同一个老的种子去执行步骤（4）计算新的种子，这会导致多个线程产生的新种子是一样的，由于步骤（5）算法是固定的，所以会导致多个线程产生相同的随机值，这并不是我们想要的。所以步骤（4）要保证原子性，也就是说多个线程在根据同一个老种子计算新种子时候，第一个线程的新种子计算出来后，第二个线程要丢弃自己老的种子，要使用第一个线程的新种子来计算自己的新种子，依次类推，只有保证了这个，才能保证多线程下产生的随机数是随机的。Random函数使用一个原子变量达到了这个效果，在创建Random对象时候初始化的种子就保存到了种子原子变量里面，下面看下next()代码： 12345678910111213protected int next(int bits) &#123; long oldseed, nextseed; AtomicLong seed = this.seed; do &#123; //(6) oldseed = seed.get(); //(7) nextseed = (oldseed * multiplier + addend) &amp; mask; //(8) &#125; while (!seed.compareAndSet(oldseed, nextseed)); //(9) return (int)(nextseed &gt;&gt;&gt; (48 - bits));&#125; 代码（6）获取当前原子变量种子的值 代码（7）根据当前种子值计算新的种子 代码（8）使用CAS操作，使用新的种子去更新老的种子，多线程下可能多个线程都同时执行到了代码（6）那么可能多个线程都拿到的当前种子的值是同一个，然后执行步骤（7）计算的新种子也都是一样的，但是步骤（8）的CAS操作会保证只有一个线程可以更新老的种子为新的，失败的线程会通过循环从新获取更新后的种子作为当前种子去计算老的种子，可见这里解决了上面提到的问题，也就保证了随机数的随机性。 代码（9）则使用固定算法根据新的种子计算随机数。 总结下：每个Random实例里面有一个原子性的种子变量用来记录当前的种子的值，当要生成新的随机数时候要根据当前种子计算新的种子并更新回原子变量。多线程下使用单个Random实例生成随机数时候，多个线程同时计算随机数计算新的种子时候多个线程会竞争同一个原子变量的更新操作，由于原子变量的更新是CAS操作，同时只有一个线程会成功，所以会造成大量线程进行自旋重试，这是会降低并发性能的，所以ThreadLocalRandom应运而生。 1.2. ThreadLocalRandom为了解决多线程高并发下Random的缺陷，JUC包下新增了ThreadLocalRandom类，下面首先看下它如何使用：123456789101112public class RandomTest &#123; public static void main(String[] args) &#123; //(10)获取一个随机数生成器 ThreadLocalRandom random = ThreadLocalRandom.current(); //(11)输出10个在0-5（包含0，不包含5）之间的随机数 for (int i = 0; i &lt; 10; ++i) &#123; System.out.println(random.nextInt(5)); &#125; &#125;&#125; 如上代码（10）调用ThreadLocalRandom.current()来获取当前线程的随机数生成器。下面来分析下ThreadLocalRandom的实现原理。从名字看会让我们联想到基础篇讲解的ThreadLocal，ThreadLocal的出现就是为了解决多线程访问一个变量时候需要进行同步的问题，让每一个线程拷贝一份变量，每个线程对变量进行操作时候实际是操作自己本地内存里面的拷贝，从而避免了对共享变量进行同步。实际上ThreadLocalRandom的实现也是这个原理，Random的缺点是多个线程会使用原子性种子变量，会导致对原子变量更新的竞争，如下图： 那么如果每个线程维护自己的一个种子变量，每个线程生成随机数时候根据自己老的种子计算新的种子，并使用新种子更新老的种子，然后根据新种子计算随机数，就不会存在竞争问题，这会大大提高并发性能，如下图ThreadLocalRandom原理： 1.3 源码分析首先看下ThreadLocalRandom的类图结构： 可知ThreadLocalRandom继承了Random并重写了nextInt方法，ThreadLocalRandom中并没有使用继承自Random的原子性种子变量。ThreadLocalRandom中并没有具体存放种子，具体的种子是存放到具体的调用线程的threadLocalRandomSeed变量里面的，ThreadLocalRandom类似于ThreadLocal类就是个工具类。当线程调用ThreadLocalRandom的current方法时候ThreadLocalRandom负责初始化调用线程的threadLocalRandomSeed变量，也就是初始化种子。当调用ThreadLocalRandom的nextInt方法时候，实际上是获取当前线程的threadLocalRandomSeed变量作为当前种子来计算新的种子，然后更新新的种子到当前线程的threadLocalRandomSeed变量，然后在根据新种子和具体算法计算随机数。这里需要注意的是threadLocalRandomSeed变量就是Thread类里面的一个普通long变量，并不是原子性变量，其实道理很简单，因为这个变量是线程级别的，根本不需要使用原子性变量，如果还是不理解可以思考下ThreadLocal的原理。 其中变量seeder和probeGenerator是两个原子性变量，在初始化调用线程的种子和探针变量时候用到，每个线程只会使用一次。 另外变量instance是个ThreadLocalRandom的一个实例，该变量是static的，当多线程通过ThreadLocalRandom的current方法获取ThreadLocalRandom的实例时候其实获取的是同一个，但是由于具体的种子是存放到线程里面的，所以ThreadLocalRandom的实例里面只是与线程无关的通用算法，所以是线程安全的。 下面看看ThreadLocalRandom的主要代码实现逻辑 Unsafe 机制的使用 12345678910111213141516171819202122private static final sun.misc.Unsafe UNSAFE; private static final long SEED; private static final long PROBE; private static final long SECONDARY; static &#123; try &#123; //获取unsafe实例 UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; tk = Thread.class; //获取Thread类里面threadLocalRandomSeed变量在Thread实例里面偏移量 SEED = UNSAFE.objectFieldOffset (tk.getDeclaredField(\"threadLocalRandomSeed\")); //获取Thread类里面threadLocalRandomProbe变量在Thread实例里面偏移量 PROBE = UNSAFE.objectFieldOffset (tk.getDeclaredField(\"threadLocalRandomProbe\")); //获取Thread类里面threadLocalRandomProbe变量在Thread实例里面偏移量 SECONDARY = UNSAFE.objectFieldOffset (tk.getDeclaredField(\"threadLocalRandomSecondarySeed\")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; ThreadLocalRandom current()方法：该方法获取ThreadLocalRandom实例，并初始化调用线程中threadLocalRandomSeed和threadLocalRandomProbe变量。 123456789static final ThreadLocalRandom instance = new ThreadLocalRandom(); public static ThreadLocalRandom current() &#123; //(12) if (UNSAFE.getInt(Thread.currentThread(), PROBE) == 0) //(13) localInit(); //(14) return instance; &#125; 12345678static final void localInit() &#123; int p = probeGenerator.addAndGet(PROBE_INCREMENT); int probe = (p == 0) ? 1 : p; // skip 0 long seed = mix64(seeder.getAndAdd(SEEDER_INCREMENT)); Thread t = Thread.currentThread(); UNSAFE.putLong(t, SEED, seed); UNSAFE.putInt(t, PROBE, probe);&#125; 如上代码（12）如果当前线程中threadLocalRandomProbe变量值为0（默认情况下线程的这个变量为0），说明当前线程第一次调用ThreadLocalRandom的current方法，那么就需要调用localInit方法计算当前线程的初始化种子变量。这里设计为了延迟初始化，不需要使用随机数功能时候Thread类中的种子变量就不需要被初始化，这是一种优化。 代码（13）首先计算根据probeGenerator计算当前线程中threadLocalRandomProbe的初始化值，然后根据seeder计算当前线程的初始化种子，然后把这两个变量设置到当前线程。代码（14）返回ThreadLocalRandom的实例，需要注意的是这个方法是静态方法，多个线程返回的是同一个ThreadLocalRandom实例。 int nextInt(int bound)方法：计算当前线程的下一个随机数 123456789101112131415161718 public int nextInt(int bound) &#123; //(15)参数校验 if (bound &lt;= 0) throw new IllegalArgumentException(BadBound); //(16) 根据当前线程中种子计算新种子 int r = mix32(nextSeed()); //(17)根据新种子和bound计算随机数 int m = bound - 1; if ((bound &amp; m) == 0) // power of two r &amp;= m; else &#123; // reject over-represented candidates for (int u = r &gt;&gt;&gt; 1; u + m - (r = u % bound) &lt; 0; u = mix32(nextSeed()) &gt;&gt;&gt; 1) ; &#125; return r;&#125; 如上代码逻辑步骤与Random相似，我们重点看下nextSeed()方法： 123456final long nextSeed() &#123; Thread t; long r; // UNSAFE.putLong(t = Thread.currentThread(), SEED, r = UNSAFE.getLong(t, SEED) + GAMMA); return r;&#125; 如上代码首先使用 r = UNSAFE.getLong(t, SEED)获取当前线程中threadLocalRandomSeed变量的值，然后在种子的基础上累加GAMMA值作为新种子，然后使用UNSAFE的putLong方法把新种子放入当前线程的threadLocalRandomSeed变量。 1.4 总结本节首先讲解了Random的实现原理以及介绍了Random在多线程下存在竞争种子原子变量更新操作失败后自旋等待的缺点，从而引出ThreadLocalRandom类，ThreadLocalRandom使用ThreadLocal的原理，让每个线程内持有一个本地的种子变量，该种子变量只有在使用随机数时候才会被初始化，多线程下计算新种子时候是根据自己线程内维护的种子变量进行更新，从而避免了竞争","categories":[{"name":"ThreadLocalRandom","slug":"ThreadLocalRandom","permalink":"http://blog.shagle.cn/categories/ThreadLocalRandom/"}],"tags":[]},{"title":"String和StringBuffer和StringBuilder","slug":"String和StringBuffer和StringBuilder","date":"2019-03-22T06:13:28.000Z","updated":"2019-03-22T06:20:18.000Z","comments":true,"path":"2019/03/22/String和StringBuffer和StringBuilder/","link":"","permalink":"http://blog.shagle.cn/2019/03/22/String和StringBuffer和StringBuilder/","excerpt":"","text":"1. 从是否可变的角度String类中使用字符数组保存字符串，因为有“final”修饰符，所以String对象是不可变的。 12/** The value is used for character storage. */private final char value[]; StringBuffer和StringBuilder都继承自AbstractStringBuilder类，在AbstractStringBuilder中也是使用字符数组保存字符串，但没有“final”修饰符，所以两种对象都是可变的。 123AbstractStringBuilder (java.lang) StringBuffer (java.lang) StringBuilder (java.lang) 使用该字符数组保存内容1234/** * The value is used for character storage. */char[] value; 2. 是否多线程安全tring中的对象是不可变的，也就可以理解为常量，所以是线程安全的。AbstractStringBuilder是StringBuffer和StringBuilder的公共父类，定义了一些字符串的基本操作，如append、、indexOf等公共方法。StringBuffer对方法加了同步锁(synchronized) ，所以是线程安全的。看如下源码： StringBuffer123456@Overridepublic synchronized StringBuffer append(CharSequence s) &#123; toStringCache = null; super.append(s); return this;&#125; StringBuilder并没有对方法进行加同步锁，所以是非线程安全的。如下源码： StringBuilder 12345@Overridepublic StringBuilder append(CharSequence s) &#123; super.append(s); return this;&#125; 3. StringBuffer和StringBuilder的共同点StringBuffer和StringBuilder有公共父类AbstractStringBuilder(抽象类)。StringBuffer、StringBuilder的方法都会调用AbstractStringBuilder中的公共方法，如上面的两段源码中都调用了super.append(str); 只是StringBuffer会在方法上加synchronized关键字，进行同步。","categories":[{"name":"Java中String、StringBuffer、StringBuilder的区别","slug":"Java中String、StringBuffer、StringBuilder的区别","permalink":"http://blog.shagle.cn/categories/Java中String、StringBuffer、StringBuilder的区别/"}],"tags":[]},{"title":"Protocol buffers翻译","slug":"Protocol-buffers翻译","date":"2019-03-12T13:11:05.000Z","updated":"2019-03-13T08:09:49.000Z","comments":true,"path":"2019/03/12/Protocol-buffers翻译/","link":"","permalink":"http://blog.shagle.cn/2019/03/12/Protocol-buffers翻译/","excerpt":"RPC:Remote Procedure Call,远程过程调用，很多RPC框架是夸语言的 定义一个接口说明文件：描述了对象(结构图体)，对象成员，接口方法等一系列信息 通过RPC框架所提供的编码器，将接口说明文件编译成集体的语言文件 在客户端和服务端分别引入RPC编译器所生成的文件，即可像调用本地方法一样调用远程方法","text":"RPC:Remote Procedure Call,远程过程调用，很多RPC框架是夸语言的 定义一个接口说明文件：描述了对象(结构图体)，对象成员，接口方法等一系列信息 通过RPC框架所提供的编码器，将接口说明文件编译成集体的语言文件 在客户端和服务端分别引入RPC编译器所生成的文件，即可像调用本地方法一样调用远程方法 1. Protocol buffersProtocol buffers 是语言中立的，平台无关的，可扩展的用于序列化结构化数据 1.1. What are protocol buffers? 12345message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3;&#125; Protocol buffers是google提供的语言中立，平台中立，用于数据结构化，可扩展化的结构化数据–就像xml，但是它的提交更小，速度更快，更加简单。你只需要定义一次你的数据结构，然后使用特殊生成的源代码轻松地将结构化数据写入和读取各种数据流，并使用各种语言。 1.2. Pick your favorite language1234567Person john = Person.newBuilder() .setId(1234) .setName(\"John Doe\") .setEmail(\"jdoe@example.com\") .build();output = new FileOutputStream(args[0]);john.writeTo(output); Protocol buffers当前支持生成的代码Java，Python，Objective-C和C++语言。使用我们新的proto3语言版本，您还可以使用Dart，Go，Ruby和C＃，以及更多语言。 1.3 How do I start?1234567Person john;fstream input(argv[1], ios::in | ios::binary);john.ParseFromIstream(&amp;input);id = john.id();name = john.name();email = john.email(); 下载并安装protocol buffer 编译器 阅读指南。 尝试使用您选择的语言的教程。 2. Protocol Buffer Basics: Java本教程提供了一个基本的Java程序员介绍如何使用Protocol buffers。它向您展示如何通过创建一个简单的示例应用程序， 在.proto文件中定义消息格式。 使用protocol buffer编译器 使用Java protocol buffer API来编写和读取消息。 这不是在Java中使用protocol buffer的综合指南。有关更详细的参考信息，请参阅Protocol Buffer Language Guide,Java API Reference, Encoding Reference. 2.1 Why Use Protocol Buffers?我们将要使用的示例是一个非常简单的“address book”应用程序，可以在文件中读取和写入人员的联系人详细信息。address book中的每个人都有姓名，ID，电子邮件地址和联系电话号码。 你如何序列化和检索这样的结构化数据？有几种方法可以解决这个问题： 使用java的序列化:这是默认方法，因为它内置于语言中，但它有许多众所周知的问题(参见Effective Java，作者：Josh Bloch，第213页),并且如果您需要与使用C ++或Python编写的应用程序共享数据，也无法正常工作。 您可以发明一种特殊的方法将数据项编码为单个字符串 - 例如将4个整数编码为“12:3:-23:67”，这是一种简单而灵活的方法，虽然它确实需要编写一次性编码和解析代码，并且解析会产生很小的运行时成本。这最适合编码非常简单的数据。 将数据序列化为XML。这种方法非常有吸引力，因为XML是人类可读的，并且有许多语言的绑定库。如果您想与其他应用程序/项目共享数据，这可能是一个不错的选择。然而，XML是众所周知的空间密集型，并且编码/解码它会对应用程序造成巨大的性能损失。此外，导航XML DOM树比通常在类中导航简单字段要复杂得多。 Protocol Buffers是灵活，高效，自动化的解决方案，可以解决这个问题。使用Protocol Buffers，您可以编写要存储的数据结构的.proto描述。根据这个.proto文件，Protocol Buffers编译器创建一个class，该类使用有效的二进制格式实现Protocol Buffers数据的自动编码和解析。生成的类为构成Protocol Buffers针对字段提供getter和setter，并负责Protocol Buffers作为一个单元读取和写入的细节。重要的是，Protocol Buffers格式支持随着时间的推移扩展格式的想法，使得代码仍然可以读取用旧格式编码的数据。 2.2 Where to Find the Example Code示例代码包含在源代码包中的“examples”目录下。Download it here. 2.3 Defining Your Protocol Format要创建address book应用程序，您需要从.proto文件开始。.proto文件中的定义很简单：为要序列化的每个数据结构添加消息，然后为消息中的每个字段指定名称和类型。这是定义结构消息的.proto文件addressbook.proto。 1234567891011121314151617181920212223242526272829syntax = \"proto2\";package tutorial;option java_package = \"com.example.tutorial\";option java_outer_classname = \"AddressBookProtos\";message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType &#123; MOBILE = 0; HOME = 1; WORK = 2; &#125; message PhoneNumber &#123; required string number = 1; optional PhoneType type = 2 [default = HOME]; &#125; repeated PhoneNumber phones = 4;&#125;message AddressBook &#123; repeated Person people = 1;&#125; 如您所见，语法类似于C ++或Java。接下来让我们浏览文件的每个部分，看看它的作用。 .proto文件以package声明开头，这有助于防止不同项目之间的命名冲突。在Java中，包名称用作Java包，除非您已经明确指定了java_package，就像我们在这里一样。即使你确实提供了java_package，你仍然应该定义一个普通的package，以避免在Protocol Buffers名称空间和非Java语言中发生名称冲突。 在声明package之后，您可以看到两个特定于Java的选项：java_package和java_outer_classname.java_package指定生成的classes应该位于什么Java包中存在。如果没有明确指定它，它只是匹配package声明给出的包名中，但这些名称通常不是合适的Java包名（因为它们通常不以域名开头）。java_outer_classname选项定义应包含此文件中所有类的类名。如果未明确提供java_outer_classname，则将通过将文件名转换为驼峰形式来生成它。例如，默认情况下，“my_proto.proto”将使用“MyProto”作为外部类名。 接下来，您有消息定义。 消息只是包含一组类型字段的聚合。许多标准的简单数据类型都可用作字段类型，包括bool，int32，float，double和string。您还可以使用其他消息类型作为字段类型向消息中添加更多结构 - 在上面的示例中，Person消息包含PhoneNumber消息，而AddressBook消息包含Person消息。您甚至可以定义嵌套在其他消息中的消息类型 -​​ 如您所见，PhoneNumber类型在Person中定义。如果您希望其中一个字段具有预定义的值列表之一，您还可以定义枚举类型 - 此处您要指定电话号码可以是MOBILE，HOME或WORK之一。 每个元素上的“= 1”，“= 2”标记标识该字段在二进制编码中使用的唯一“标记”。标签号1-15需要少于一个字节来编码而不是更高的数字，因此作为优化，您可以决定将这些标签用于常用或重复的元素，将标签16和更高版本留给不太常用的可选元素。重复字段中的每个元素都需要重新编码标记号，因此重复字段特别适合此优化。 必须使用以下修饰符之一注释每个字段： required：必须提供该字段的值，否则该消息将被视为“未初始化”。尝试构建未初始化的消息将抛出RuntimeException。解析未初始化的消息将抛出IOException。除此之外，必填字段的行为与可选字段完全相同。 optional：可以设置也可以不设置字段。如果未设置可选字段值，则使用默认值。对于简单类型，您可以指定自己的默认值，就像我们在示例中为电话号码类型所做的那样。否则，使用系统默认值：数字类型为0，字符串为空字符串，bools为false。对于嵌入式消息，默认值始终是消息的“默认实例”或“原型”，其中没有设置其字段。调用访问器以获取尚未显式设置的可选（或必需）字段的值始终返回该字段的默认值。 repeated：该字段可以重复任意次数（包括0次）。重复值的顺序将保留在protocol buffer中。将重复字段视为动态大小的数组。 必需永远您应该非常小心地将字段标记为required。如果您希望在某个时刻停止写入或不发送必填字段，则将字段更改为optional字段会有问题 - 旧readers会认为没有此字段，可能会无意中拒绝或丢弃它们。您应该考虑为protocol buffer编写特定于应用程序的自定义验证例程。谷歌的一些工程师得出的结论是，使用repeated的弊大于利;他们更喜欢只使用optional和repeated。但是，这种观点并不普遍。 您将在Protocol Buffer Language Guide中找到编写.proto文件的完整指南 - 包括所有可能的字段类型。不要去寻找类继承类似方式，但protocol buffer不支持继承。 2. 4. Compiling Your Protocol Buffers现在你已经有一个.proto，你接下来需要做的下一件事是生成你需要读取和写入AddressBook（以及Person和PhoneNumber）消息所需的类。为此，您需要在.proto上运行Protocol Buffers编译器protoc： 如果尚未安装Protocol Buffers编译器，请下载该软件包并按照自述文件中的说明进行操作。 现在运行编译器，指定source代码目录（应用程序的源代码所在的位置 - 如果不提​​供值，则使用当前目录），目标目录（您希望生成的代码在哪里;通常与$SRC_DIR），以及.proto的路径。在这种情况下，你…： 1protoc -I=$SRC_DIR --java_out=$DST_DIR $SRC_DIR/addressbook.proto 因为您需要Java class，所以使用–java_out选项 - 为其他受支持的语言提供了类似的选项。 这将在指定的目标目录中生成com/example/tutorial/AddressBookProtos.java。 2.5 The Protocol Buffer API让我们看看一些生成的代码，看看编译器为您创建了哪些类和方法。如果你查看AddressBookProtos.java，你会发现它定义了一个名为AddressBookProtos的类，在addressbook.proto中指定的每个消息都嵌套在AddressBookProtos类中。每个类都有自己的Builder类，可用于创建该类的实例。您可以在下面的“Builders vs. Messages”部分中找到有关构建器的更多信息。 消息和构建器都为消息的每个字段都有自动生成的访问器方法;消息只有getter，而构建器有getter和setter。以下是Person类的一些访问器（为简洁起见省略了实现）： 12345678910111213141516// required string name = 1;public boolean hasName();public String getName();// required int32 id = 2;public boolean hasId();public int getId();// optional string email = 3;public boolean hasEmail();public String getEmail();// repeated .tutorial.Person.PhoneNumber phones = 4;public List&lt;PhoneNumber&gt; getPhonesList();public int getPhonesCount();public PhoneNumber getPhones(int index); 同时，Person.Builder拥有相同的getter加setter： 1234567891011121314151617181920212223242526// required string name = 1;public boolean hasName();public java.lang.String getName();public Builder setName(String value);public Builder clearName();// required int32 id = 2;public boolean hasId();public int getId();public Builder setId(int value);public Builder clearId();// optional string email = 3;public boolean hasEmail();public String getEmail();public Builder setEmail(String value);public Builder clearEmail();// repeated .tutorial.Person.PhoneNumber phones = 4;public List&lt;PhoneNumber&gt; getPhonesList();public int getPhonesCount();public PhoneNumber getPhones(int index);public Builder setPhones(int index, PhoneNumber value);public Builder addPhones(PhoneNumber value);public Builder addAllPhones(Iterable&lt;PhoneNumber&gt; value);public Builder clearPhones(); 如您所见，每个字段都有简单的JavaBeans样式的getter和setter。针对每个字段都有getter，如果已设置该字段，则返回true。最后，每个字段都有一个clear方法，将字段取消设置回其空状态。 重复字段有一些额外的方法 - 一个Count方法（它只是列表大小的简写），getter和setter通过索引获取或设置列表的特定元素，add方法将一个新元素附加到列表，以及一个addAll方法，它将整个容器中的元素添加到列表中。 有关protocol编译器为任何特定字段定义生成的确切成员的更多信息，请参阅Java generated code reference。 2.6 Enums and Nested Classes生成的代码包含一个嵌套在Person中的PhoneType枚举： 1234567public static enum PhoneType &#123; MOBILE(0, 0), HOME(1, 1), WORK(2, 2), ; ...&#125; 正如您所期望的那样，生成嵌套类型Person.PhoneNumber，作为Person中的嵌套类。 2.7 Builders vs. MessagesProtocol Buffer编译器生成的消息类都是不可变的。一旦构造了消息对象，就像Java String那样不能修改它。要构造消息，必须首先构造构建器，将要设置的任何字段设置为所选值，然后调用构建器的build()方法。 您可能已经注意到构建器的每个修改消息的方法都会返回另一个构建器。返回的对象实际上是您调用该方法的同一个构建器。为方便起见，它会返回，以便您可以在一行代码中将多个setter串在一起。 这是一个如何创建Person实例的示例： 12345678910Person john = Person.newBuilder() .setId(1234) .setName(\"John Doe\") .setEmail(\"jdoe@example.com\") .addPhones( Person.PhoneNumber.newBuilder() .setNumber(\"555-4321\") .setType(Person.PhoneType.HOME)) .build(); 2.8. Standard Message Methods每个消息和构建器类还包含许多其他方法，可用于检查或操作整个消息，包括： isInitialized(): 检查是否已设置所有必填字段。 toString():返回人类可读消息，对调试特别有用 mergeFrom(Message other):(仅限构建器)将其他内容合并到此消息中，覆盖单个标量字段，合并复合字段以及连接重复字段。 clear():（仅限构建器）将所有字段清除回空状态。 这些方法实现了所有Java消息和构建器共享的Message和Message.Builder接口。有关更多信息，请参阅complete API documentation for Message。 2.9 Parsing and Serialization最后，每个protocol buffer类都有相应的方法使用protocol buffer二进制格式去编写和读取所选类型的消息的方法。这些包括： byte[] toByteArray();: 序列化消息并返回包含其原始字节的字节数组。 static Person parseFrom(byte[] data);: 根据字节数组来解析消息。 void writeTo(OutputStream output);: 序列化消息并将其写入OutputStream。 static Person parseFrom(InputStream input);: 从InputStream读取和解析消息。 这些只是解析和序列化提供的几个选项。再次，请参阅Message API reference以获取完整列表。 Protocol Buffers 和O-O(面向对象)设计Protocol Buffers 类基本上是哑数据持有者（如C中的struct）;他们没有在对象模型中成为优秀的一等公民。如果要为生成的类添加更丰富的行为，最好的方法是将生成的Protocol Buffers 类包装在特定于应用程序的类中。如果您没有对.proto文件进行更好的设计（例如，如果您正在重用另一个项目中的一个消息），那么包装Protocol Buffers 也是一个好主意。在这种情况下，您可以使用包装器类来创建更适合应用程序的独特环境的接口：隐藏一些数据和方法，公开便利功能等。您永远不应该通过继承它们来向生成的类添加行为。这将打破内部机制，无论如何都不是良好的面向对象的实践。 简单理解就是Protocol Buffers 不支持继承 2.10 Writing A Message 这个demo是将一个对象通过Protocol Buffer写入到一个文件中 现在让我们尝试使用您的Protocol Buffer类。首先第一件事使用address book应用程序将个人详细信息写入您的address book文件。为此，您需要创建并填充Protocol Buffer类的实例属性，然后将它们写入输出流。 这是一个从键盘输入中读取到AddressBook的程序，根据用户输入向其添加一个新Person，并将新的AddressBook再次写回文件。直接调用或引用Protocol protocol编译器生成的代码的部分将突出显示。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485import com.example.tutorial.AddressBookProtos.AddressBook;import com.example.tutorial.AddressBookProtos.Person;import java.io.BufferedReader;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.InputStreamReader;import java.io.IOException;import java.io.PrintStream;class AddPerson &#123; // This function fills in a Person message based on user input. static Person PromptForAddress(BufferedReader stdin, PrintStream stdout) throws IOException &#123; Person.Builder person = Person.newBuilder(); stdout.print(\"Enter person ID: \"); person.setId(Integer.valueOf(stdin.readLine())); stdout.print(\"Enter name: \"); person.setName(stdin.readLine()); stdout.print(\"Enter email address (blank for none): \"); String email = stdin.readLine(); if (email.length() &gt; 0) &#123; person.setEmail(email); &#125; while (true) &#123; stdout.print(\"Enter a phone number (or leave blank to finish): \"); String number = stdin.readLine(); if (number.length() == 0) &#123; break; &#125; Person.PhoneNumber.Builder phoneNumber = Person.PhoneNumber.newBuilder().setNumber(number); stdout.print(\"Is this a mobile, home, or work phone? \"); String type = stdin.readLine(); if (type.equals(\"mobile\")) &#123; phoneNumber.setType(Person.PhoneType.MOBILE); &#125; else if (type.equals(\"home\")) &#123; phoneNumber.setType(Person.PhoneType.HOME); &#125; else if (type.equals(\"work\")) &#123; phoneNumber.setType(Person.PhoneType.WORK); &#125; else &#123; stdout.println(\"Unknown phone type. Using default.\"); &#125; person.addPhones(phoneNumber); &#125; return person.build(); &#125; // Main function: Reads the entire address book from a file, // adds one person based on user input, then writes it back out to the same // file. public static void main(String[] args) throws Exception &#123; if (args.length != 1) &#123; System.err.println(\"Usage: AddPerson ADDRESS_BOOK_FILE\"); System.exit(-1); &#125; AddressBook.Builder addressBook = AddressBook.newBuilder(); // Read the existing address book. try &#123; addressBook.mergeFrom(new FileInputStream(args[0])); &#125; catch (FileNotFoundException e) &#123; System.out.println(args[0] + \": File not found. Creating a new file.\"); &#125; // Add an address. addressBook.addPeople( PromptForAddress(new BufferedReader(new InputStreamReader(System.in)), System.out)); // Write the new address book back to disk. FileOutputStream output = new FileOutputStream(args[0]); addressBook.build().writeTo(output); output.close(); &#125;&#125; 2.11 Reading A Message 将2.10 生成的文件反序列化到程序中 当然，如果您无法从中获取任何信息，那么address book就不会有多大用处！此示例读取上面示例创建的文件并打印其中的所有信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import com.example.tutorial.AddressBookProtos.AddressBook;import com.example.tutorial.AddressBookProtos.Person;import java.io.FileInputStream;import java.io.IOException;import java.io.PrintStream;class ListPeople &#123; // Iterates though all people in the AddressBook and prints info about them. static void Print(AddressBook addressBook) &#123; for (Person person: addressBook.getPeopleList()) &#123; System.out.println(\"Person ID: \" + person.getId()); System.out.println(\" Name: \" + person.getName()); if (person.hasEmail()) &#123; System.out.println(\" E-mail address: \" + person.getEmail()); &#125; for (Person.PhoneNumber phoneNumber : person.getPhonesList()) &#123; switch (phoneNumber.getType()) &#123; case MOBILE: System.out.print(\" Mobile phone #: \"); break; case HOME: System.out.print(\" Home phone #: \"); break; case WORK: System.out.print(\" Work phone #: \"); break; &#125; System.out.println(phoneNumber.getNumber()); &#125; &#125; &#125; // Main function: Reads the entire address book from a file and prints all // the information inside. public static void main(String[] args) throws Exception &#123; if (args.length != 1) &#123; System.err.println(\"Usage: ListPeople ADDRESS_BOOK_FILE\"); System.exit(-1); &#125; // Read the existing address book. AddressBook addressBook = AddressBook.parseFrom(new FileInputStream(args[0])); Print(addressBook); &#125;&#125; 2.12 Extending a Protocol Buffer在使用protocol buffer的代码之后，您无疑会想要“改进”protocol buffer的定义。如果你希望你的新buffers向后兼容，并且你的旧buffers是向前兼容的 - 而且你几乎肯定想要这个 - 那么你需要遵循一些规则。在新版本的protocol buffer中： 您不得更改任何现有字段的标记号。 您不得添加或删除任何required字段。 您可以删除optional或repeated的字段。 您可以添加新的optional或repeated字段，但必须使用新的标记号（即从未在此protocol buffer中使用的标记号，甚至不包括已删除的字段）。(这些规则有一些Exceptions，但它们很少使用) 如果您遵循这些规则，旧代码将很乐意阅读新消息并简单地忽略任何新字段。对于旧代码，已删除的可选字段将只具有其默认值，删除的重复字段将为空。新代码也将透明地读取旧消息。但是，请记住旧的消息中不会出现新的可选字段，因此您需要明确检查它们是否设置为has_，或者使用[default = value]在.proto文件中提供合理的默认值。标签号后面。如果未为可选元素指定默认值，则使用特定于类型的默认值：对于字符串，默认值为空字符串。对于布尔值，默认值为false。对于数字类型，默认值为零。另请注意，如果添加了新的重复字段，则新代码将无法判断它是否为空（通过新代码）或从未设置（通过旧代码），因为它没有has_标志。 2.13. Advanced Usageprotocol buffer的用途不仅仅是简单的访问器和序列化。请务必浏览Java API reference，以了解您可以使用它们做些什么。 protocol消息类提供的一个关键特性是反射。您可以迭代消息的字段并在你写的代码中操纵它们的值，而无需针对任何特定的消息类型编写代码。使用反射的一种非常有用的方法是将protocol消息转换为与其他编码（例如XML或JSON）之间的转换。更高级的反射使用可能是找到两个相同类型的消息之间的差异，或者开发一种“protocol消息的正则表达式”，您可以在其中编写与某些消息内容匹配的表达式。如果您运用自己的想象力，可以将protocol buffer应用于比您最初预期更广泛的问题！ Message和Message.Builder接口提供一部分反射信息 3. Developer Guide欢迎开发者来到Protocol buffers文档 – 一种与语言无关，平台无关，可扩展的序列化结构化数据的方法，用于通信协议，数据存储等","categories":[{"name":"RPC","slug":"RPC","permalink":"http://blog.shagle.cn/categories/RPC/"}],"tags":[{"name":"Protocol buffers","slug":"Protocol-buffers","permalink":"http://blog.shagle.cn/tags/Protocol-buffers/"}]},{"title":"socket阻塞与非阻塞，同步与异步、I/O模型，select与poll、epoll比较","slug":"IO复用","date":"2019-03-12T06:48:27.000Z","updated":"2019-03-12T06:49:19.000Z","comments":true,"path":"2019/03/12/IO复用/","link":"","permalink":"http://blog.shagle.cn/2019/03/12/IO复用/","excerpt":"","text":"socket阻塞与非阻塞，同步与异步、I/O模型，select与poll、epoll比较 http://www.cnblogs.com/wujing-hubei/p/6111347.htmlhttps://www.cnblogs.com/bw13/p/6410877.html","categories":[{"name":"rpc","slug":"rpc","permalink":"http://blog.shagle.cn/categories/rpc/"}],"tags":[{"name":"I/O多路复用","slug":"I-O多路复用","permalink":"http://blog.shagle.cn/tags/I-O多路复用/"}]},{"title":"grpc翻译","slug":"grpc翻译","date":"2019-03-10T07:48:49.000Z","updated":"2019-03-13T14:32:30.000Z","comments":true,"path":"2019/03/10/grpc翻译/","link":"","permalink":"http://blog.shagle.cn/2019/03/10/grpc翻译/","excerpt":"","text":"grpc 官网https://grpc.io grpc 是一个高效的，开源的，统一的rpc框架 grpc 的基本特点是： 简单的服务定义：可以使用protocol buffers来定义你的服务，protocol buffers本身是一个强大的，二进制序列化工具集和语言 可以跨越语言和平台：可以为你的服务自动的生成习惯使用的客户端和服务端的stubs语言和平台 快速启动或扩展：通过一个简单的命令安装到开发环境或运行是环境并扩展为百万级别的rpc框架 双向的流并集成授权：基于http 2传输的二进制双向流并完全集成可插拔的身份验证 1. what is grpc这个文档介绍了grpc和protocol buffers，grpc可以使用protocol buffers即作为它的IDL(接口描述语言，接口定义语言)，可以使用它作为它底层的消息交换格式，如果你是一个不了解grpc或protocol buffers的就继续往下读 1.1. Overview在Grpc客户端应用中可以调用各机器上各服务上的各方法，就好像是一个本地对象一样，这使的你可以创建分布式应用与服务。就像很多RPC系统一样，gRPC是基于这样一个想法，定义一个服务，指定好可以远程调用的方法，同时带上参数和返回值，在服务器端，实现接口，然后运行一个gRPC服务器来处理客户端的调用。另外在客户端有一个stub(在某些语言中也叫client)，它提供了可服务器相同的方法 gRPC 客户端和服务端可以在多种环境中运行和交互 - 从 google 内部的服务器到你自己的桌面，并且可以用任何 gRPC 支持的语言来编写。所以，你可以很容易地用 Java 创建一个 gRPC 服务端，用 Go、Python、Ruby 来创建客户端。此外，Google 最新 API 将有 gRPC 版本的接口，使你很容易地将 Google 的功能集成到你的应用里。 1.2. Working with Protocol BuffersgRPC 默认使用 protocol buffers，这是 Google 开源的一套成熟的结构数据序列化机制（当然也可以使用其他数据格式如 JSON）。正如你将在下方例子里所看到的，你用 proto files 创建 gRPC 服务，用 protocol buffers 消息类型来定义方法参数和返回类型。你可以在 Protocol Buffers 文档找到更多关于 Protocol Buffers 的资料。 1.2.1 Protocol buffer versions虽然Protocol buffer对用户已经开源了一段时间了，但是他们的实例使用的Proto3，它提供了稍微简介的语法，新的特效，并支持更多的语言，目前可以使用到Java, C++, Python, Objective-C, C#, a lite-runtime (Android Java), Ruby, and JavaScript，Go 或更多的语言开发。您可以在proto3语言指南和每种语言的参考文档中找到更多信息。参考文档还包括.proto文件格式的正式规范。 一般来说你可以使用proto2(当前Protocol buffer默认版本号)，在使用gRPC中我们建议你使用Proto3，以便于支持更多的功能和特效，以便于出现如下错误，一端使用的Proto2，一边使用的Proto3，版本不一样出现一下兼容性问题， 2. gRPC Concepts本文档通过对于 gRPC 的架构和 RPC 生命周期的概览来介绍 gRPC 的主要概念。本文是在假设你已经读过文档部分的前提下展开的。针对具体语言细节请查看对应语言的快速开始、教程和参考文档（很快就会有完整的文档）。 2.1 Overview2.1.2 Service definition与许多RPC系统一样，gRPC基于定义服务的思想，指定可以使用的参数和返回类型远程调用的方法，默认情况下，gRPC使用Protocol buffer作为接口定义语言（IDL）来描述服务接口和有效负载消息的结构。如果需要，可以使用其他替代方案。 1234567891011service HelloService &#123; rpc SayHello (HelloRequest) returns (HelloResponse);&#125;message HelloRequest &#123; string greeting = 1;&#125;message HelloResponse &#123; string reply = 1;&#125; gRPC可以让我们定义四种方法 客户端向服务器发送单个请求并返回单个响应，就像正常的函数调用一样。 12rpc SayHello(HelloRequest) returns (HelloResponse)&#123;&#125; 服务端流式 RPC，即客户端发送一个请求给服务端，可获取一个数据流用来读取一系列消息。客户端从返回的数据流里一直读取直到没有更多消息为止。 12rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse)&#123;&#125; 客户端流式 RPC，即客户端用提供的一个数据流写入并发送一系列消息给服务端。一旦客户端完成消息写入，就等待服务端读取这些消息并返回应答。 12rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse) &#123;&#125; 双向流式 RPC，即两边都可以分别通过一个读写数据流来发送一系列消息。这两个数据流操作是相互独立的，所以客户端和服务端能按其希望的任意顺序读写，例如：服务端可以在写应答前等待所有的客户端消息，或者它可以先读一个消息再写一个消息，或者是读写相结合的其他方式。每个数据流里消息的顺序会被保持。 12rpc BidiHello(stream HelloRequest) returns (stream HelloResponse)&#123;&#125; 我们将在下面的RPC生命周期部分中更详细地介绍不同类型的RPC。 2.1.3 Using the API surfacegRPC 提供 protocol buffer 编译插件，能够从一个服务定义的 .proto 文件生成客户端和服务端代码。通常 gRPC 用户可以在服务端实现这些API，并从客户端调用它们。 在服务侧，服务端实现服务接口，运行一个 gRPC 服务器来处理客户端调用。gRPC 底层架构会解码传入的请求，执行服务方法，编码服务应答。 在客户侧，客户端有一个stub实现了服务端同样的方法。客户端可以在本地stub调用这些方法，用合适的 protocol buffer 消息类型封装这些参数— gRPC 来负责发送请求给服务端并返回服务端 protocol buffer 响应。 2.1.4 Synchronous vs. asynchronous同步 RPC 调用一直会阻塞直到从服务端获得一个应答，这与 RPC 希望的抽象最为接近。另一方面网络内部是异步的，并且在许多场景下能够在不阻塞当前线程的情况下启动 RPC 是非常有用的。 在多数语言里，gRPC 编程接口同时支持同步和异步的特点。你可以从每个语言教程和参考文档里找到更多内容(很快就会有完整文档)。 2.2. RPC life cycle现在让我们来仔细了解一下当 gRPC 客户端调用 gRPC 服务端的方法时到底发生了什么。我们不究其实现细节，关于实现细节的部分，你可以在我们的特定语言页面里找到更为详尽的内容。 2.2.1 单项 RPC首先我们来了解一下最简单的 RPC 形式：客户端发出单个请求，获得单个响应。 一旦客户端通过stub/client调用一个方法，服务端会得到相关通知 ，通知包括客户端的元数据，方法名，允许的响应期限（如果可以的话） 服务端既可以在任何响应之前直接发送回初始的元数据，也可以等待客户端的请求信息，到底哪个先发生，取决于具体的应用。 一旦服务端获得客户端的请求信息，就会做所需的任何工作来创建或组装对应的响应。如果成功的话，这个响应会和包含状态码以及可选的状态信息等状态明细及可选的追踪信息返回给客户端 。 假如状态是 OK 的话，客户端会得到应答，这将结束客户端的调用。 2.2.2 Server streaming RPC服务端流式 RPC 除了在得到客户端请求信息后发送回一个应答流之外，与我们的简单例子一样。在发送完所有应答后，服务端的状态详情(状态码和可选的状态信息)和可选的跟踪元数据被发送回客户端，以此来完成服务端的工作。客户端在接收到所有服务端的应答后也完成了工作。 2.2.3 Client streaming RPC客户端流式 RPC 也基本与我们的简单例子一样，区别在于客户端通过发送一个请求流给服务端，取代了原先发送的单个请求。服务端通常（但并不必须）会在接收到客户端所有的请求后发送回一个应答，其中附带有它的状态详情和可选的跟踪数据。 2.2.4 Bidirectional streaming RPC双向流式 RPC ，调用由客户端调用方法来初始化，而服务端则接收到客户端的元数据，方法名和截止时间。服务端可以选择发送回它的初始元数据或等待客户端发送请求。 下一步怎样发展取决于应用，因为客户端和服务端能在任意顺序上读写 - 这些流的操作是完全独立的。例如服务端可以一直等直到它接收到所有客户端的消息才写应答，或者服务端和客户端可以像”乒乓球”一样：服务端后得到一个请求就回送一个应答，接着客户端根据应答来发送另一个请求，以此类推。 2.2.5 Deadlines/TimeoutsgRPC 允许客户端在调用一个远程方法前指定一个最后期限值。这个值指定了在客户端可以等待服务端多长时间来应答，超过这个时间值 RPC 将结束并返回DEADLINE_EXCEEDED错误。在服务端可以查询这个期限值来看是否一个特定的方法已经过期，或者还剩多长时间来完成这个方法。 各语言来指定一个截止时间的方式是不同的 - 比如在 Python 里一个截止时间值总是必须的，但并不是所有语言都有一个默认的截止时间。 2.2.6. RPC termination在 gRPC 里，客户端和服务端对调用成功的判断是独立的、本地的，他们的结论可能不一致。这意味着，比如你有一个 RPC 在服务端成功结束(“我已经返回了所有应答!”)，到那时在客户端可能是失败的(“应答在最后期限后才来到!”)。也可能在客户端把所有请求发送完前，服务端却判断调用已经完成了。 2.2.7. Cancelling RPCs无论客户端还是服务端均可以再任何时间取消一个 RPC 。一个取消会立即终止 RPC 这样可以避免更多操作被执行。它不是一个”撤销”， 在取消前已经完成的不会被回滚。当然，通过同步调用的 RPC 不能被取消，因为直到 RPC 结束前，程序控制权还没有交还给应用。 2.2.8. Metadata元数据是一个特殊 RPC 调用对应的信息(授权详情) ，这些信息以键值对的形式存在，一般键的类型是字符串，值的类型一般也是字符串(当然也可以是二进制数据)。元数据对 gRPC 本事来说是不透明的 - 它让客户端提供调用相关的信息给服务端，反之亦然。对于元数据的访问是语言相关的。 2.2.9 Channels在创建客户端stub时，一个 gRPC Channel提供一个特定主机和端口服务端的连接。客户端可以通过指定Channel参数来修改 gRPC 的默认行为，比如打开关闭消息压缩。一个Channel具有状态，包含已连接和空闲 。gRPC 如何处理关闭Channel是语言相关的。有些语言可允许询问Channel状态。 3. Authentication本文档概述了gRPC身份验证，包括我们内置的支持身份验证机制，如何插入您自己的身份验证系统，以及如何在我们支持的语言中使用gRPC身份验证的示例。 3.1. OverviewgRPC旨在与各种身份验证机制配合使用，可以轻松安全地使用gRPC与其他系统进行通信。您可以使用我们支持的机制 - 带或不带基于Google令牌的身份验证的SSL / TLS - 或者您可以通过扩展我们提供的代码来插入您自己的身份验证系统。 gRPC还提供了一个简单的身份验证API，允许您在创建channel或方法调用时提供所有必要的身份验证信息作为凭据。 3.2. Supported auth mechanismsgRPC内置了以下身份验证机制： SSL/TLS: gRP 集成 SSL/TLS 并对服务端授权所使用的 SSL/TLS 进行了改良，对客户端和服务端交换的所有数据进行了加密。对客户端来讲提供了可选的机制提供凭证来获得共同的授权。 Token-based authentication with Google:","categories":[{"name":"rpc","slug":"rpc","permalink":"http://blog.shagle.cn/categories/rpc/"}],"tags":[{"name":"grpc","slug":"grpc","permalink":"http://blog.shagle.cn/tags/grpc/"}]},{"title":"Redis之字符串","slug":"Redis之字符串","date":"2019-03-08T05:21:20.000Z","updated":"2019-03-08T05:23:54.000Z","comments":true,"path":"2019/03/08/Redis之字符串/","link":"","permalink":"http://blog.shagle.cn/2019/03/08/Redis之字符串/","excerpt":"","text":"1. 简单动态字符串当Redis需要的不仅仅是一个字符串字面量，而是一个可以被修改的字符串值时，Redis就会使用SDS来表示字符串值，比如在Redis的数据库里面，包含字符串值的键值对在底层都是由SDS实现的。举个例子，如果客户端执行命令：12redis&gt; SET msg &quot;hello world&quot;OK 那么Redis将在数据库中创建一个新的键值对，其中： 键值对的键是一个字符串对象，对象的底层实现是一个保存着字符串”msg”的SDS。 键值对的值也是一个字符串对象，对象的底层实现是一个保存着字符串”hello world”的SDS。又比如，如果客户端执行命令： 12redis&gt; RPUSH fruits &quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;(integer) 3 键值对的键是一个字符串对象，对象的底层实现是一个保存了字符串”fruits”的SDS。 键值对的值是一个列表对象，列表对象包含了三个字符串对象，这三个字符串对象分别由三个SDS实现：第一个SDS保存着字符串”apple”，第二个SDS保存着字符串”banana”，第三个SDS保存着字符串”cherry”。 1.1 SDS的定义每个sds.h/sdshdr结构表示一个SDS值： 1234567891011struct sdshdr &#123; // 记录buf数组中已使用字节的数量 // 等于SDS所保存字符串的长度 int len; // 记录buf数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[];&#125;; 图2-1展示了一个SDS示例： free属性的值为0，表示这个SDS没有分配任何未使用空间。 len属性的值为5，表示这个SDS保存了一个五字节长的字符串。 buf属性是一个char类型的数组，数组的前五个字节分别保存 SDS遵循C字符串以空字符结尾的惯例，保存空字符的1字节空间不计算在SDS的len属性里面，并且为空字符分配额外的1字节空间，以及添加空字符到字符串末尾等操作，都是由SDS函数自动完成的，所以这个空字符对于SDS的使用者来说是完全透明的。遵循空字符结尾这一惯例的好处是，SDS可以直接重用一部分C字符串函数库里面的函数。 2。2 对c和sds之间区别进行总结 C字符串 SDS 获取字符串长度的复杂度为O(N) 获取字符串长度复杂度为O(1) API是不安全的，可能会造成缓冲区溢出 API思安全的，不会造成缓冲区溢出 修改字符串长度N次必然需要执行N次内存重新分配 修改字符串长度N次最多需要执行N次内存分配 只能保持文本数据 可以保存文本或二进制数据 可以使用所有&lt;string.h&gt;库中的函数 可以使用一部分&lt;string.h&gt;库中的函数 SDS 主要API 函数 作用 时间复杂度 sdsnew| 创建一个包含给定 C 字符串的 SDS 。 |O(N) ， N 为给定 C 字符串的长度。sdsempty| 创建一个不包含任何内容的空 SDS 。 |O(1)sdsfree| 释放给定的 SDS 。 |O(1)sdslen| 返回 SDS 的已使用空间字节数。 |这个值可以通过读取 SDS 的 len 属性来直接获得， 复杂度为 O(1) 。sdsavail| 返回 SDS 的未使用空间字节数。 |这个值可以通过读取 SDS 的 free 属性来直接获得， 复杂度为 O(1) 。sdsdup| 创建一个给定 SDS 的副本（copy）。 |O(N) ， N 为给定 SDS 的长度。sdsclear| 清空 SDS 保存的字符串内容。| 因为惰性空间释放策略，复杂度为 O(1) 。sdscat| 将给定 C 字符串拼接到 SDS 字符串的末尾。 |O(N) ， N 为被拼接 C 字符串的长度。sdscatsds| 将给定 SDS 字符串拼接到另一个 SDS 字符串的末尾。 |O(N) ， N 为被拼接 SDS 字符串的长度。sdscpy| 将给定的 C 字符串复制到 SDS 里面， 覆盖 SDS 原有的字符串。 |O(N) ， N 为被复制 C 字符串的长度。sdsgrowzero| 用空字符将 SDS 扩展至给定长度。| O(N) ， N 为扩展新增的字节数。sdsrange| 保留 SDS 给定区间内的数据， 不在区间内的数据会被覆盖或清除。 |O(N) ， N 为被保留数据的字节数。sdstrim| 接受一个 SDS 和一个 C 字符串作为参数， 从 SDS 左右两端分别移除所有在 C 字符串中出现过的字符。 |O(M*N) ， M 为 SDS 的长度， N 为给定 C 字符串的长度。sdscmp| 对比两个 SDS 字符串是否相同。 |O(N) ， N 为两个 SDS 中较短的那个 SDS 的长度。","categories":[{"name":"NoSql","slug":"NoSql","permalink":"http://blog.shagle.cn/categories/NoSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://blog.shagle.cn/tags/redis/"}]},{"title":"Redis之链表","slug":"Redis之链表","date":"2019-03-08T05:17:42.000Z","updated":"2019-03-08T05:21:05.000Z","comments":true,"path":"2019/03/08/Redis之链表/","link":"","permalink":"http://blog.shagle.cn/2019/03/08/Redis之链表/","excerpt":"","text":"1. 链表1.1 链表和链表节点的实现每个链表节点使用一个adlist.h/listNode结构来表示： 123456789101112typedef struct listNode &#123; // 前置节点 struct listNode * prev; // 后置节点 struct listNode * next; // 节点的值 void * value;&#125;listNode; 多个listNode可以通过prev和next指针组成双端链表，如图3-1所示。 虽然仅仅使用多个listNode结构就可以组成链表，但使用adlist.h/list来持有链表的话，操作起来会更方便： 123456789101112131415161718192021typedef struct list &#123; // 表头节点 listNode * head; // 表尾节点 listNode * tail; // 链表所包含的节点数量 unsigned long len; // 节点值复制函数 void *(*dup)(void *ptr); // 节点值释放函数 void (*free)(void *ptr); // 节点值对比函数 int (*match)(void *ptr,void *key);&#125; list; list结构为链表提供了表头指针head、表尾指针tail，以及链表长度计数器len，而dup、free和match成员则是用于实现多态链表所需的类型特定函数： dup 函数用于复制链表节点所保存的值； free 函数用于释放链表节点所保存的值； match函数则用于对比链表节点所保存的值和另一个输入值是否相等。图3-2是由一个list结构和三个listNode结构组成的链表。 Redis的链表实现的特性可以总结如下： 双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的复杂度都是O(1)。 无环：表头节点的prev指针和表尾节点的next指针都指向NULL，对链表的访问以NULL为终点。 带表头指针和表尾指针：通过list结构的head指针和tail指针，程序获取链表的表头节点和表尾节点的复杂度为O(1)。 带链表长度计数器：程序使用list结构的len属性来对list持有的链表节点进行计数，程序获取链表中节点数量的复杂度为O(1)。 多态：链表节点使用void*指针来保存节点值，并且可以通过list结构的dup、free […] 1.2 链表和链表节点的API表3-1列出了所有用于操作链表和链表节点的API。 表 3-1 链表和链表节点 API 函数 作用 时间复杂度 listSetDupMethod 将给定的函数设置为链表的节点值复制函数。 O(1) 。 listGetDupMethod 返回链表当前正在使用的节点值复制函数。 复制函数可以通过链表的 dup 属性直接获得， O(1) listSetFreeMethod 将给定的函数设置为链表的节点值释放函数。 O(1) 。 listGetFree 返回链表当前正在使用的节点值释放函数。 释放函数可以通过链表的 free 属性直接获得， O(1) listSetMatchMethod 将给定的函数设置为链表的节点值对比函数。 O(1) listGetMatchMethod 返回链表当前正在使用的节点值对比函数。 对比函数可以通过链表的 match 属性直接获得， O(1) listLength 返回链表的长度（包含了多少个节点）。 链表长度可以通过链表的 len 属性直接获得， O(1) 。 listFirst 返回链表的表头节点。 表头节点可以通过链表的 head 属性直接获得， O(1) 。 listLast 返回链表的表尾节点。 表尾节点可以通过链表的 tail 属性直接获得， O(1) 。 listPrevNode 返回给定节点的前置节点。 前置节点可以通过节点的 prev 属性直接获得， O(1) 。 listNextNode 返回给定节点的后置节点。 后置节点可以通过节点的 next 属性直接获得， O(1) 。 listNodeValue 返回给定节点目前正在保存的值。 节点值可以通过节点的 value 属性直接获得， O(1) 。 listCreate 创建一个不包含任何节点的新链表。 O(1) listAddNodeHead 将一个包含给定值的新节点添加到给定链表的表头。 O(1) listAddNodeTail 将一个包含给定值的新节点添加到给定链表的表尾。 O(1) listInsertNode 将一个包含给定值的新节点添加到给定节点的之前或者之后。 O(1) listSearchKey 查找并返回链表中包含给定值的节点。 O(N) ， N 为链表长度。 listIndex 返回链表在给定索引上的节点。 O(N) ， N 为链表长度。 listDelNode 从链表中删除给定节点。 O(1) 。 listRotate 将链表的表尾节点弹出，然后将被弹出的节点插入到链表的表头， 成为新的表头节点。 O(1) listDup 复制一个给定链表的副本。 O(N) ， N 为链表长度。 listRelease 释放给定链表，以及链表中的所有节点。 O(N) ， N 为链表长度。 1.3 重点回顾 链表被广泛用于实现Redis的各种功能，比如列表键、发布与订阅、慢查询、监视器等。 每个链表节点由一个listNode结构来表示，每个节点都有一个指向前置节点和后置节点的指针，所以Redis的链表实现是双端链表。 每个链表使用一个list结构来表示，这个结构带有表头节点指针、表尾节点指针，以及链表长度等信息。 因为链表表头节点的前置节点和表尾节点的后置节点都指向NULL，所以Redis的链表实现是无环链表。 通过为链表设置不同的类型特定函数，Redis的链表可以用于保存各种不同类型的值。","categories":[{"name":"NoSql","slug":"NoSql","permalink":"http://blog.shagle.cn/categories/NoSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://blog.shagle.cn/tags/redis/"}]},{"title":"Redis之对象","slug":"Redis之对象","date":"2019-03-07T09:32:18.000Z","updated":"2019-03-07T09:45:08.000Z","comments":true,"path":"2019/03/07/Redis之对象/","link":"","permalink":"http://blog.shagle.cn/2019/03/07/Redis之对象/","excerpt":"","text":"在前面的数个章节里，我们陆续介绍了Redis用到的所有主要数据结构，比如简单动态字符串（SDS）、双端链表、字典、压缩列表、整数集合等等。 Redis并没有直接使用这些数据结构来实现键值对数据库，而是基于这些数据结构创建了一个对象系统，这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象，每种对象都用到了至少一种我们前面所介绍的数据结构。 通过这五种不同类型的对象，Redis可以在执行命令之前，根据对象的类型来判断一个对象是否可以执行给定的命令。使用对象的另一个好处是，我们可以针对不同的使用场景，为对象设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率。 除此之外，Redis的对象系统还实现了基于引用计数技术的内存回收机制，当程序不再使用某个对象的时候，这个对象所占用的内存就会被自动释放；另外，Redis还通过引用计数技术实现了对象共享机制，这一机制可以在适当的条件下，通过让多个数据库键共享同一个对象来节约内存。 最后，Redis的对象带有访问时间记录信息，该信息可以用于计算数据库键的空转时长，在服务器启用了maxmemory功能的情况下，空转时长较大的那些键可能会优先被服务器删除。 本章接下来将逐一介绍以上提到的Redis对象系统的各个特性。 1. 对象的类型与编码Redis使用对象来表示数据库中的键和值，每次当我们在Redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键（键对象），另一个对象用作键值对的值（值对象）。举个例子，以下SET命令在数据库中创建了一个新的键值对，其中键值对的键是一个包含了字符串值”msg”的对象，而键值对的值则是一个包含了字符串值”hello world”的对象： 12redis&gt; SET msg &quot;hello world&quot;OK Redis中的每个对象都由一个redisObject结构表示，该结构中和保存数据有关的三个属性分别是type属性、encoding属性和ptr属性： 1234567891011121314typedef struct redisObject &#123; // 类型 unsigned type:4; // 编码 unsigned encoding:4; // 指向底层实现数据结构的指针 void *ptr; // ...&#125; robj; 1.1 类型对象的type属性记录了对象的类型，这个属性的值可以是表8-1列出的常量的其中一个。 对于Redis数据库保存的键值对来说，键总是一个字符串对象，而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种，因此： 当我们称呼一个数据库键为“字符串键”时，我们指的是“这个数据库键所对应的值为字符串对象”； 当我们称呼一个键为“列表键”时，我们指的是“这个数据库键所对应的值为列表对象”。 TYPE命令的实现方式也与此类似，当我们对一个数据库键执行TYPE命令时，命令返回的结果为数据库键对应的值对象的类型，而不是键对象的类型： 123456789101112131415161718192021222324252627282930313233343536373839# 键为字符串对象，值为字符串对象redis&gt; SET msg &quot;hello world&quot;OKredis&gt; TYPE msgstring# 键为字符串对象，值为列表对象redis&gt; RPUSH numbers 1 3 5(integer) 6redis&gt; TYPE numberslist# 键为字符串对象，值为哈希对象redis&gt; HMSET profile name Tom age 25 career ProgrammerOKredis&gt; TYPE profilehash# 键为字符串对象，值为集合对象redis&gt; SADD fruits apple banana cherry(integer) 3redis&gt; TYPE fruitsset# 键为字符串对象，值为有序集合对象redi\u0007s&gt; ZADD price 8.5 apple 5.0 banana 6.0 cherry(integer) 3redis&gt; TYPE pricezset 1.2 编码和底层实现对象的ptr指针指向对象的底层实现数据结构，而这些数据结构由对象的encoding属性决定。 encoding属性记录了对象所使用的编码，也即是说这个对象使用了什么数据结构作为对象的底层实现，这个属性的值可以是表8-3列出的常量的其中一个。 每种类型的对象都至少使用了两种不同的编码，表8-4列出了每种类型的对象可以使用的编码。 使用OBJECT ENCODING命令可以查看一个数据库键的值对象的编码： 1234567891011121314151617181920212223redis&gt; SET msg &quot;hello wrold&quot;OKredis&gt; OBJECT ENCODING msg&quot;embstr&quot;redis&gt; SET story &quot;long long long long long long ago ...&quot;OKredis&gt; OBJECT ENCODING story&quot;raw&quot;redis&gt; SADD numbers 1 3 5(integer) 3redis&gt; OBJECT ENCODING numbers&quot;intset&quot;redis&gt; SADD numbers &quot;seven&quot;(integer) 1redis&gt; OBJECT ENCODING numbers&quot;hashtable&quot; 表8-5列出了不同编码的对象所对应的OBJECT ENCODING命令输出。 通过encoding属性来设定对象所使用的编码，而不是为特定类型的对象关联一种固定的编码，极大地提升了Redis的灵活性和效率，因为Redis可以根据不同的使用场景来为一个对象设置不同的编码，从而优化对象在某一场景下的效率。 举个例子，在列表对象包含的元素比较少时，Redis使用压缩列表作为列表对象的底层实现： 因为压缩列表比双端链表更节约内存，并且在元素数量较少时，在内存中以连续块方式保存的压缩列表比起双端链表可以更快被载入到缓存中； 随着列表对象包含的元素越来越多，使用压缩列表来保存元素的优势逐渐消失时，对象就会将底层实现从压缩列表转向功能更强、也更适合保存大量元素的双端链表上面； 其他类型的对象也会通过使用多种不同的编码来进行类似的优化。 在接下来的内容中，我们将分别介绍Redis中的五种不同类型的对象，说明这些对象底层所使用的编码方式，列出对象从一种编码转换成另一种编码所需的条件，以及同一个命令在多种不同编码上的实现方法。","categories":[{"name":"NoSql","slug":"NoSql","permalink":"http://blog.shagle.cn/categories/NoSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://blog.shagle.cn/tags/redis/"}]},{"title":"压缩列表zipList","slug":"压缩列表zipList","date":"2019-03-07T02:11:07.000Z","updated":"2019-03-07T05:30:57.000Z","comments":true,"path":"2019/03/07/压缩列表zipList/","link":"","permalink":"http://blog.shagle.cn/2019/03/07/压缩列表zipList/","excerpt":"","text":"压缩列表(ziplist)是列表键和哈希键的底层实现之一。 1. 压缩列表的构成压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序性数据结构。一个压缩列表可以包含任意多个节点,每个节点可以保存一个字节数组或者一个整数值。 当一个哈希键只包含少量key-value对，且每个key-value对的key和value要么是小整数，要么是较短字符串，那么redis就会使用ziplist作为哈希键的底层实现。 2. ziplist的实现：ziplist的内存布局如下所示： zlbytes：4字节，记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配，或者计算zlend的位置时使用 zltail：4字节，记录压缩列表尾部节点距离起始地址的偏移量：通过这个偏移量，程序无需遍历整个压缩列表就可以确定表尾节点的地址 zllen：2字节，记录压缩列表包含的节点数量 entry：不定，列表中的每个节点,节点的长度由节点保存的内存决定 zlend：1字节，特殊值0xFF，标记压缩列表的结束 因此通过下面的宏定义可以非常方便的求出各个字段的值 1234567#define ZIPLIST_BYTES(zl) (*((uint32_t*)(zl)))#define ZIPLIST_TAIL_OFFSET(zl) (*((uint32_t*)((zl)+sizeof(uint32_t))))#define ZIPLIST_LENGTH(zl) (*((uint16_t*)((zl)+sizeof(uint32_t)*2)))#define ZIPLIST_HEADER_SIZE (sizeof(uint32_t)*2+sizeof(uint16_t))#define ZIPLIST_ENTRY_HEAD(zl) ((zl)+ZIPLIST_HEADER_SIZE)#define ZIPLIST_ENTRY_TAIL(zl) ((zl)+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl)))#define ZIPLIST_ENTRY_END(zl) ((zl)+intrev32ifbe(ZIPLIST_BYTES(zl))-1) 一个简单的ziplist示意图如下： 列表zlbytes属性的值为0x50（十进制80），表示压缩列表的总长为80字节。 列表zltail属性的值为0x3c（十进制60），这表示如果我们有一个指向压缩列表起始地址的指针p，那么只要用指针p加上偏移量60，就可以计算出表尾节点entry3的地址。 列表zllen属性的值为0x3（十进制3），表示压缩列表包含三个节点。 3. 压缩列表节点的构成每个压缩列表节点可以保存一个字节数组或者一个整数值。 3.1 previous_entry_length节点的previous_entry_length属性以字节为单位，记录了压缩列表中前一个节点的长度。previous_entry_length属性的长度可以是1字节或者5字节： 如果前一节点的长度小于254字节，那么previous_entry_length属性的长度为1字节：前一节点的长度就保存在这一个字节里面。 如果前一节点的长度大于等于254字节，那么previous_entry_length属性的长度为5字节：其中属性的第一字节会被设置为0xFE（十进制值254），而之后的四个字节则用于保存前一节点的长度。 图7-5展示了一个包含一字节长previous_entry_length属性的压缩列表节点，属性的值为0x05，表示前一节点的长度为5字节。 图7-6展示了一个包含五字节长previous_entry_length属性的压缩节点，属性的值为0xFE00002766，其中值的最高位字节0xFE表示这是一个五字节长的previous_entry_length属性，而之后的四字节0x00002766（十进制值10086）才是前一节点的实际长度。 因为节点的previous_entry_length属性记录了前一个节点的长度，所以程序可以通过指针运算，根据当前节点的起始地址来计算出前一个节点的起始地址。举个例子，如果我们有一个指向当前节点起始地址的指针c，那么我们只要用指针c减去当前节点previous_entry_length属性的值，就可以得出一个指向前一个节点起始地址的指针p，如图7-7所示。 压缩列表的从表尾向表头遍历操作就是使用这一原理实现的，只要我们拥有了一个指向某个节点起始地址的指针，那么通过这个指针以及这个节点的previous_entry_length属性，程序就可以一直向前一个节点回溯，最终到达压缩列表的表头节点。 图7-8展示了一个从表尾节点向表头节点进行遍历的完整过程： 首先，我们拥有指向压缩列表表尾节点entry4起始地址的指针p1（指向表尾节点的指针可以通过指向压缩列表起始地址的指针加上zltail属性的值得出）； 通过用p1减去entry4节点previous_entry_length属性的值，我们得到一个指向entry4前一节点entry3起始地址的指针p2； 通过用p2减去entry3节点previous_entry_length属性的值，我们得到一个指向entry3前一节点entry2起始地址的指针p3； 通过用p3减去entry2节点previous_entry_length属性的值，我们得到一个指向entry2前一节点entry1起始地址的指针p4，entry1为压缩列表的表头节点； 最终，我们从表尾节点向表头节点遍历了整个列表。 3.2 encoding节点的encoding属性记录了节点的content属性所保存数据的类型以及长度 一字节、两字节或者五字节长，值的最高位为00、01或者10的是字节数组编码：这种编码表示节点的content属性保存着字节数组，数组的长度由编码除去最高两位之后的其他位记录； 一字节长，值的最高位以11开头的是整数编码：这种编码表示节点的content属性保存着整数值，整数值的类型和长度由编码除去最高两位之后的其他位记录；表7-2记录了所有可用的字节数组编码，而表7-3则记录了所有可用的整数编码。表格中的下划线“_”表示留空，而b、x等变量则代表实际的二进制数据，为了方便阅读，多个字节之间用空格隔开。 3.3 content节点的content属性负责保存节点的值，节点值可以是一个字节数组或者整数，值的类型和长度由节点的encoding属性决定。 图7-9展示了一个保存字节数组的节点示例： 编码的最高两位00表示节点保存的是一个字节数组； 编码的后六位001011记录了字节数组的长度11； content属性保存着节点的值”hello world”。 图7-10展示了一个保存整数值的节点示例： 编码11000000表示节点保存的是一个int16_t类型的整数值； content属性保存着节点的值10086。 3.4. 连锁更新前面说过，每个节点的previous_entry_length属性都记录了前一个节点的长度： 如果前一节点的长度小于254字节，那么previous_entry_length属性需要用1字节长的空间来保存这个长度值。 如果前一节点的长度大于等于254字节，那么previous_entry_length属性需要用5字节长的空间来保存这个长度值。 现在，考虑这样一种情况：在一个压缩列表中，有多个连续的、长度介于250字节到253字节之间的节点e1至eN，如图7-11所示。 因为e1至eN的所有节点的长度都小于254字节，所以记录这些节点的长度只需要1字节长的previous_entry_length属性，换句话说，e1至eN的所有节点的previous_entry_length属性都是1字节长的。这时，如果我们将一个长度大于等于254字节的新节点new设置为压缩列表的表头节点，那么new将成为e1的前置节点，如图7-12所示。 因为e1的previous_entry_length属性仅长1字节，它没办法保存新节点new的长度，所以程序将对压缩列表执行空间重分配操作，并将e1节点的previous_entry_length属性从原来的1字节长扩展为5字节长。 现在，麻烦的事情来了，e1原本的长度介于250字节至253字节之间，在为previous_entry_length属性新增四个字节的空间之后，e1的长度就变成了介于254字节至257字节之间，而这种长度使用1字节长的previous_entry_length属性是没办法保存的。 因此，为了让e2的previous_entry_length属性可以记录下e1的长度，程序需要再次对压缩列表执行空间重分配操作，并将e2节点的previous_entry_length属性从原来的1字节长扩展为5字节长。 正如扩展e1引发了对e2的扩展一样，扩展e2也会引发对e3的扩展，而扩展e3又会引发对e4的扩展……为了让每个节点的previous_entry_length属性都符合压缩列表对节点的要求，程序需要不断地对压缩列表执行空间重分配操作，直到eN为止。 Redis将这种在特殊情况下产生的连续多次空间扩展操作称之为“连锁更新”（cascade update），图7-13展示了这一过程。 除了添加新节点可能会引发连锁更新之外，删除节点也可能会引发连锁更新。 考虑图7-14所示的压缩列表，如果e1至eN都是大小介于250字节至253字节的节点，big节点的长度大于等于254字节（需要5字节的previous_entry_length来保存），而small节点的长度小于254字节（只需要1字节的previous_entry_length来保存），那么当我们将small节点从压缩列表中删除之后，为了让e1的previous_entry_length属性可以记录big节点的长度，程序将扩展e1的空间，并由此引发之后的连锁更新。 因为连锁更新在最坏情况下需要对压缩列表执行N次空间重分配操作，而每次空间重分配的最坏复杂度为O(N)，所以连锁更新的最坏复杂度为O(N2)。 要注意的是，尽管连锁更新的复杂度较高，但它真正造成性能问题的几率是很低的： 首先，压缩列表里要恰好有多个连续的、长度介于250字节至253字节之间的节点，连锁更新才有可能被引发，在实际中，这种情况并不多见； 其次，即使出现连锁更新，但只要被更新的节点数量不多，就不会对性能造成任何影响：比如说，对三五个节点进行连锁更新是绝对不会影响性能的； 因为以上原因，ziplistPush等命令的平均复杂度仅为O(N)，在实际中，我们可以放心地使用这些函数，而不必担心连锁更新会影响压缩列表的性能。","categories":[{"name":"NoSql","slug":"NoSql","permalink":"http://blog.shagle.cn/categories/NoSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://blog.shagle.cn/tags/redis/"}]},{"title":"算法之SkipList跳表","slug":"算法之SkipList跳表","date":"2019-03-06T07:10:11.000Z","updated":"2019-03-06T07:23:04.000Z","comments":true,"path":"2019/03/06/算法之SkipList跳表/","link":"","permalink":"http://blog.shagle.cn/2019/03/06/算法之SkipList跳表/","excerpt":"","text":"1. 为什么选择跳表目前经常使用的平衡数据结构有：B树，红黑树，AVL树，Splay Tree, Treep等。 想象一下，给你一张草稿纸，一只笔，一个编辑器，你能立即实现一颗红黑树，或者AVL树 出来吗？ 很难吧，这需要时间，要考虑很多细节，要参考一堆算法与数据结构之类的树， 还要参考网上的代码，相当麻烦。 用跳表吧，跳表是一种随机化的数据结构，目前开源软件 Redis 和 LevelDB 都有用到它， 它的效率和红黑树以及 AVL 树不相上下，但跳表的原理相当简单，只要你能熟练操作链表， 就能轻松实现一个 SkipList。 2. 有序表的搜索考虑一个有序表： 从该有序表中搜索元素 &lt; 23, 43, 59 &gt; ，需要比较的次数分别为 &lt; 2, 4, 6 &gt;，总共比较的次数为 2 + 4 + 6 = 12 次。有没有优化的算法吗? 链表是有序的，但不能使用二分查找。类似二叉搜索树，我们把一些节点提取出来，作为索引。得到如下结构： 这里我们把 &lt; 14, 34, 50, 72 &gt; 提取出来作为一级索引，这样搜索的时候就可以减少比较次数了。 我们还可以再从一级索引提取一些元素出来，作为二级索引，变成如下结构： 这里元素不多，体现不出优势，如果元素足够多，这种索引结构就能体现出优势来了。 3. 跳表下面的结构是就是跳表： 其中 -1 表示 INT_MIN， 链表的最小值，1 表示 INT_MAX，链表的最大值。 跳表具有如下性质： (1) 由很多层结构组成 (2) 每一层都是一个有序的链表 (3) 最底层(Level 1)的链表包含所有元素 (4) 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。 (5) 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。 4. 跳表的搜索 例子：查找元素 117 (1) 比较 21， 比 21 大，往后面找 (2) 比较 37, 比 37大，比链表最大值小，从 37 的下面一层开始找 (3) 比较 71, 比 71 大，比链表最大值小，从 71 的下面一层开始找 (4) 比较 85， 比 85 大，从后面找 (5) 比较 117， 等于 117， 找到了节点。 具体的搜索算法如下： C代码 12345678910111213/* 如果存在 x, 返回 x 所在的节点， * 否则返回 x 的后继节点 */ find(x) &#123; p = top; while (1) &#123; while (p-&gt;next-&gt;key &lt; x) p = p-&gt;next; if (p-&gt;down == NULL) return p-&gt;next; p = p-&gt;down; &#125; &#125; 5. 跳表的插入先确定该元素要占据的层数 K（采用丢硬币的方式，这完全是随机的） 然后在 Level 1 … Level K 各个层的链表都插入元素。 例子：插入 119， K = 2 如果 K 大于链表的层数，则要添加新的层。 例子：插入 119， K = 4 6. 丢硬币决定 K插入元素的时候，元素所占有的层数完全是随机的，通过一下随机算法产生： 123456789int random_level() &#123; K = 1; while (random(0,1)) K++; return K; &#125; 相当与做一次丢硬币的实验，如果遇到正面，继续丢，遇到反面，则停止，用实验中丢硬币的次数 K 作为元素占有的层数。显然随机变量 K 满足参数为 p = 1/2 的几何分布，K 的期望值 E[K] = 1/p = 2. 就是说，各个元素的层数，期望值是 2 层。 7. 跳表的高度。n 个元素的跳表，每个元素插入的时候都要做一次实验，用来决定元素占据的层数 K，跳表的高度等于这 n 次实验中产生的最大 K，待续。。。 8. 跳表的空间复杂度分析根据上面的分析，每个元素的期望高度为 2， 一个大小为 n 的跳表，其节点数目的期望值是 2n。 9. 跳表的删除在各个层中找到包含 x 的节点，使用标准的 delete from list 方法删除该节点。 例子：删除 71 本文出自","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.shagle.cn/categories/算法/"}],"tags":[{"name":"SkipList跳表","slug":"SkipList跳表","permalink":"http://blog.shagle.cn/tags/SkipList跳表/"}]},{"title":"redis设计与实现","slug":"redis设计与实现","date":"2019-03-04T06:45:49.000Z","updated":"2019-03-08T05:23:54.000Z","comments":true,"path":"2019/03/04/redis设计与实现/","link":"","permalink":"http://blog.shagle.cn/2019/03/04/redis设计与实现/","excerpt":"","text":"1. 简介Redis数据库里面的每个键值对（key-value pair）都是由对象（object）组成的，其中： 数据库键总是一个字符串对象（string object）； 而数据库键的值则可以是字符串对象、列表对象（list object）、哈希对象（hash object）、集合对象（set object）、有序集合对象（sorted set object）这五种对象中的其中一种。 2. 字符串3. 链表4. 字典5. 跳跃表6. 整数集合7. 压缩列表压缩列表参考：https://blog.csdn.net/u012658346/article/details/51321337 8. 对象","categories":[{"name":"NoSql","slug":"NoSql","permalink":"http://blog.shagle.cn/categories/NoSql/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://blog.shagle.cn/tags/redis/"}]},{"title":"Java技术之ReentrantReadWriteLock源码解析","slug":"Java技术之ReentrantReadWriteLock源码解析","date":"2019-02-28T07:14:17.000Z","updated":"2019-02-28T07:24:27.000Z","comments":true,"path":"2019/02/28/Java技术之ReentrantReadWriteLock源码解析/","link":"","permalink":"http://blog.shagle.cn/2019/02/28/Java技术之ReentrantReadWriteLock源码解析/","excerpt":"","text":"1. 阅读须知 JDK版本：1.8 文章中使用/**/注释的方法会做深入分析 2. 正文ReentrantReadWriteLock，从字面上理解为可重入读写锁，基于AQS（AbstractQueuedSynchronizer，不了解AQS的读者可以去看笔者关于AQS源码解析的文章进行学习）实现，根据读写锁的特性，我们可以猜测，读锁应该是基于AQS的共享锁实现，而写锁应该是基于AQS的独占锁实现，我们来验证这个猜想，首先看一下ReentrantReadWriteLock的构造方法： ReentrantReadWriteLock： 123456public ReentrantReadWriteLock(boolean fair) &#123; //根据传入的boolean变量fair来确定使用公平锁或非公平锁 sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this);&#125; ReentrantReadWriteLock默认的无参构造方法使用的是非公平锁。我们来介绍一下ReentrantReadWriteLock中的同步器Sync中的一些变量： ReentrantReadWriteLock.Sync： 123456789101112131415161718//读锁占用高16位表示持有读锁的线程的数量static final int SHARED_SHIFT = 16;//根据SHARED_SHIFT变量的含义，每增加一个持有读锁的线程，state变量就需要累加这个值，也就是1左移16位static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);//持有读锁的线程的最大数量（65535）static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;//用于计算写锁的重入计数static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;//当前线程持有的读锁的重入数量。只在构造函数和readObject方法中初始化。线程的锁重入计数降至0时删除private transient ThreadLocalHoldCounter readHolds;//最后一个成功获取readLock的线程的持有锁计数private transient HoldCounter cachedHoldCounter;//firstReader是获取读锁的第一个线程。//更确切地说，firstReader是最后一次将共享计数从0更改为1的唯一线程，//并且自那以后未释放读锁; 如果没有这样的线程，则返回null。private transient Thread firstReader = null;//firstReaderHoldCount是firstReader的锁重入计数private transient int firstReaderHoldCount; ReentrantReadWriteLock使用AQS的state的高16位表示持有读锁的线程的数量，低16位表示写锁被同一个线程申请的次数，也就是锁重入的次数。接下来我们来看加锁实现，我们首先来看读锁部分： ReentrantReadWriteLock.ReadLock： 123public void lock() &#123; sync.acquireShared(1);&#125; acquireShared方法我们在AQS（AbstractQueuedSynchronizer）源码解析（共享锁部分）这篇文章中进行过详细分析，方法的开始会调用有子类实现的tryAcquireShared方法尝试以共享模式获得锁，我们来看ReentrantReadWriteLock对tryAcquireShared方法的实现： ReentrantReadWriteLock.Sync： 12345678910111213141516171819202122232425262728293031323334353637protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); //如果独占锁的重入计数不为0（说明有线程持有独占锁）并且持有独占锁的线程不是当前线程返回-1代表获取共享锁失败 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); //共享锁的持有线程数量 /*判断当前获取读锁的线程是否需要阻塞*/ //共享锁的持有线程的数量是否超过了最大值 //CAS增加共享锁的持有线程的数量是否成功 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; //满足条件说明当前没有任何任何线程持有共享锁，则将当前线程设置为获取共享锁的第一个线程 firstReader = current; //锁重入数量初始化为1 firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; //如果当前获取共享锁的线程是获取共享锁的第一个线程，则递增锁重入数量 firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) //如果最后一个成功获取readLock的线程的锁重入计数对象还未初始化或者对象内部维护的线程id不是当前线程id //则将cachedHoldCounter赋值为当前线程的锁重入计数对象 cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; //递增当前线程的锁重入计数 &#125; return 1; &#125; /*tryAcquireShared方法的完整版*/ return fullTryAcquireShared(current);&#125; 这里说明一下方法的执行过程： 如果另一个线程持有写锁，则获取共享锁失败。 否则，此线程符合锁定状态，判断是否应该因为队列策略而阻塞。如果没有，尝试通过CAS增加共享锁的持有线程的数量。请注意，这步不会检查重入获取，它会被推迟到fullTryAcquireShared方法执行，以避免在更典型的非重入情况下检查锁重入计数。 如果步骤2因线程需要阻塞或CAS失败或计数饱和而失败，则调用fullTryAcquireShared方法。 关于readerShouldBlock（判断当前获取读锁的线程是否需要阻塞）方法，有公平和非公平两种实现，我们首先来看非公平的实现： ReentrantReadWriteLock.NonfairSync： 123final boolean readerShouldBlock() &#123; return apparentlyFirstQueuedIsExclusive();&#125; apparentlyFirstQueuedIsExclusive方法来自AQS，主要用于判断等待队列的头结点的下一个节点也就是第一个排队的线程是否以独占模式等待。这里我们要结合调用readerShouldBlock方法之前的if判断进行分析，如果这个if判断不满足，说明有两种情况可能发生： 当前没有线程占用写锁，这种情况readerShouldBlock方法会返回false。 当前有线程占用写锁，并且占用写锁的线程就是当前线程（当前线程是head节点），这时就发生了锁降级的情况，也就是当前线程持有写锁，并在申请读锁，这时就要判断head节点的下一个节点是否要申请写锁，如果是则readerShouldBlock方法返回true，说明本次申请读锁的操作需要阻塞。 接下来我们来看readerShouldBlock方法公平锁的实现： ReentrantReadWriteLock.FairSync： 123final boolean readerShouldBlock() &#123; return hasQueuedPredecessors();&#125; hasQueuedPredecessors方法我们在ReentrantLock源码解析这篇文章中分析过，它的主要作用是确认当前线程是否是下一个能够优先获得锁的线程，公平性也就是通过这个判断来保证的。公平锁我们很好理解，就是根据等待队列中节点的顺序来保证获取锁的顺序。 ReentrantReadWriteLock.Sync： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051final int fullTryAcquireShared(Thread current) &#123; HoldCounter rh = null; for (;;) &#123; int c = getState(); //同样的判断是否有非当前线程持有独占锁 if (exclusiveCount(c) != 0) &#123; if (getExclusiveOwnerThread() != current) return -1; //同样的判断当前获取读锁操作是否需要阻塞 &#125; else if (readerShouldBlock()) &#123; //确保没有重复获取读锁 if (firstReader == current) &#123; &#125; else &#123; if (rh == null) &#123; rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) &#123; rh = readHolds.get(); //这里如果当前线程持有的共享锁重入计数为0，则移除锁重入计数对象 if (rh.count == 0) readHolds.remove(); &#125; &#125; if (rh.count == 0) return -1; //锁重入计数为0时，返回-1代表获取共享锁失败，要进行排队 &#125; &#125; if (sharedCount(c) == MAX_COUNT) //超过最大持有读锁线程数量抛出Error throw new Error(\"Maximum lock count exceeded\"); //再次尝试获取共享锁，判断CAS增加共享锁的持有线程的数量是否成功 //整体共享锁获取成功的处理逻辑与tryAcquireShared方法基本一致 if (compareAndSetState(c, c + SHARED_UNIT)) &#123; if (sharedCount(c) == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; &#125; return 1; &#125; &#125;&#125; 接下来我们来看读锁释放的实现： ReentrantReadWriteLock.ReadLock： 123public void unlock() &#123; sync.releaseShared(1);&#125; 这里的releaseShared释放共享锁方法同样来自于AQS，方法中首先会调用由子类覆盖的tryReleaseShared方法，通过尝试设置state变量来释放共享锁，我们来看ReentrantReadWriteLock对于tryReleaseShared方法的实现： ReentrantReadWriteLock.Sync： 123456789101112131415161718192021222324252627282930313233protected final boolean tryReleaseShared(int unused) &#123; Thread current = Thread.currentThread(); //判断当前线程是否是获取读锁的第一个线程 if (firstReader == current) &#123; //如果锁重入计数为1，直接将获取读锁的第一个线程置为null，释放资源 if (firstReaderHoldCount == 1) firstReader = null; else //如果锁重入计数不为1（大于1），则在释放时递减锁重入计数 firstReaderHoldCount--; &#125; else &#123; HoldCounter rh = cachedHoldCounter; //这里的判断上文分析过 if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; //当前线程的锁重入计数 if (count &lt;= 1) &#123; //小于等于1时说明这是最后一个重入锁，则移除锁重入计数对象 readHolds.remove(); if (count &lt;= 0) //锁重入计数小于等于0说明本次解锁操作没有对应的加锁操作，抛出异常 throw unmatchedUnlockException(); &#125; --rh.count; //递减锁重入计数 &#125; //下面的自旋操作为递减共享锁持有的线程数量，与加锁时的递增操作正好相反 for (;;) &#123; int c = getState(); int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; 到这里，读锁的加锁和解锁操作就分析完了，下面我们来分析写锁的加锁和解锁操作，首先来看加锁： ReentrantReadWriteLock.WriteLock： 123public void lock() &#123; sync.acquire(1);&#125; 果然，写锁是基于AQS的独占锁实现，这里的acquire方法我们在AQS（AbstractQueuedSynchronizer）源码解析（独占锁部分）这篇文章中已经详细分析过，方法的第一步就是调用由子类实现的tryAcquire方法通过操作state变量尝试以独占模式获取锁，我们来看ReentrantReadWriteLock对tryAcquire方法的实现： ReentrantReadWriteLock.Sync： 123456789101112131415161718192021222324252627protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); //如果AQS的state变量不为0，说明当前读锁或写锁有被占用 if (c != 0) &#123; //这里的判断如果成立说明读锁被占用写锁未被占用 //或者写锁被占用但占用的线程不是当前线程，这是返回false代表获取写锁失败 if (w == 0 || current != getExclusiveOwnerThread()) return false; //写锁最大重入数量的判断 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); //走到这里说明是写锁重入，则递增写锁重入计数 setState(c + acquires); return true; &#125; //到这里说明当前读锁和写锁都未被任何线程占用 /*判断获取写锁的线程是否需要阻塞*/ //判断CAS递增写锁重入计数是否失败 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; //设置写锁的拥有者线程为当前线程 setExclusiveOwnerThread(current); return true;&#125; 这里的writerShouldBlock方法同样区分公平和非公平两个版本的实现，我们先来看非公平版本的实现： ReentrantReadWriteLock.NonfairSync： 123final boolean writerShouldBlock() &#123; return false;&#125; 我们发现方法直接返回false，也就是说每个想要获取非公平写锁的线程都可以直接参与竞争。而writerShouldBlock方法公平锁的版本与读锁的readerShouldBlock方法的公平版本是一样的，都是需要确认当前线程是否是下一个能够优先获得锁的线程，以此来保证公平性。最后我们来看写锁的解锁操作： ReentrantReadWriteLock.WriteLock： 123public void unlock() &#123; sync.release(1);&#125; 这里的release方法我们在AQS独占锁源码解析的文章中同样进行过详细的分析，AQS的release方法首先会尝试调用由子类实现的tryRelease方法来尝试设置state变量来释放独占锁，锁完全释放后，会对后继节点进行唤醒操作，这个流程我们已经分析过，不再赘述。我们来看ReentrantReadWriteLock的对tryRelease方法的实现： ReentrantReadWriteLock.WriteLock： 12345678910111213protected final boolean tryRelease(int releases) &#123; //加锁和解锁的线程必须是同一个，不然抛出异常 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //递减写锁的重入计数 int nextc = getState() - releases; boolean free = exclusiveCount(nextc) == 0; //如果递减后的锁重入计数为0，说明锁已经被完全释放，这时将锁的拥有者线程置为null if (free) setExclusiveOwnerThread(null); setState(nextc); //设置最新的锁重入计数 return free;&#125; 这样解锁的流程就分析完成了。 ReentrantReadWriteLock的写锁还支持Condition，与ReentrantLock一样完全基于AQS的ConditionObject实现，我们已经分析过ConditionObject源码，不明白的同学可以前往进行查阅学习。到这里，ReentrantReadWriteLock的源码分析就完成了。 本文出自","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"ReentrantReadWriteLock","slug":"ReentrantReadWriteLock","permalink":"http://blog.shagle.cn/tags/ReentrantReadWriteLock/"}]},{"title":"Java技术之CPU使用率为什么飚升？","slug":"Java技术之CPU使用率为什么飚升？","date":"2019-02-27T09:07:00.000Z","updated":"2019-02-27T09:12:09.000Z","comments":true,"path":"2019/02/27/Java技术之CPU使用率为什么飚升？/","link":"","permalink":"http://blog.shagle.cn/2019/02/27/Java技术之CPU使用率为什么飚升？/","excerpt":"","text":"我的疑惑一个 while 死循环，会不会引起 CPU 使用率飚升？ 频繁 Young GC 会不会引起 CPU 使用率飚升？ 线程数很高的应用，CPU 使用率一定高么？ CPU 使用率高的应用，线程数一定高么？ BLOCKED 状态的线程会不会引起 CPU 使用率飚升？ 分时操作系统 CPU 是耗费 us ？ 还是耗费 sy ？ 我的思考CPU 使用率怎么算？ CPU% = 1 - idleTime / sysTime * 100 idleTime：CPU处于空闲状态的时间 sysTime：CPU处于用户态和内核台的时间总和 CPU 使用率跟啥有关系？ 我们常听说计算密集型的程序是比较耗 CPU 使用率的。 那 JAVA 应用中哪些操作是比较耗 CPU 使用的？ 列举下日常程序中常见的耗CPU的操作： 频繁GC，访问量高时，有可能造成频繁的GC、甚至FGC。当调用量大时，内存分配过快，就会造成GC线程不停的执行，导致CPU飙高。 序列化与反序列化，后文中举了一个真实的案例，程序执行xml解析的时，调用量增大的情况下，导致了CPU被打满。 加密、解密。 正则表达式校验，曾经线上发生一次血案，正则校验将CPU打满。大概原因是：Java 正则表达式使用的引擎实现是 NFA 自动机，这种引擎在进行字符匹配会发生回溯（backtracking）。 线程上下文切换、当启动了很多线程，而这些线程都处于不断的阻塞状态（锁等待、IO等待等）和执行状态的变化过程中。当锁竞争激烈时，很容易出现这种情况。 某些线程在做无阻塞的运算，简单的例子while(true)中不停的做运算，没有任何阻塞。写程序时，如果需要做很久的计算，可以适当将程序sleep下。 CPU 与进程、线程有关系么？ 现在分时操作系统是通过循轮方式分配时间片进行进程调度的，如果进程在等待或阻塞，不会造成 CPU 资源使用。线程称为轻进程，共享进程资源，关于线程的调度，CPU 对于线程也是分时调度。而在 Java 中，线程的调用由 JVM 负责，线程的调度一般有两种模式，分时调度和抢占式调度。 我的解惑一个 while 死循环，会不会引起 CPU 使用率飚升？ 会的。先不说别的，死循环会调用 CPU 寄存器进行计数，这个操作就会占用 CPU。其次，如果线程一直处于死循环状态，CPU 调用会进行线程切换么？ 死循环不会让出 CPU，除非操作系统时间片到期，但死循环会不断向系统申请时间片，直到系统没有空闲时间做别的事情。 这个问题在 stackoverflow 也有人提问：why does an infinite loop of the unintended kind increase the CPU use? 地址：https://stackoverflow.com/questions/2846165/why-does-an-infinite-loop-of-the-unintended-kind-increase-the-cpu-use 频繁 Young GC 会不会引起 CPU 使用率飚升？ 会的。Young GC 本身是 JVM 进行垃圾回收的操作，会计算内存和调用寄存器，频繁 Young GC 一定是会占用 CPU。 之前有个一个案例，for 循环从数据库查询数据集合，二次封装新的数据集合，这时如果量比较大时，内存没有足够的空间存储，那么 JVM 就会 GC 回收那些不再使用的数据，因此量大的时候，就会收到 CPU 使用率报警。 线程数很高的应用，CPU 使用率一定高么？ 不会。通过 jstack 查看系统线程状态，查看整个线程数很多，但 Runable 和 Running 状态的线程不多，这时 CPU 使用率不一定会高。 之前有过一个案例，查看系统线程数 1000+，jstack 分析 900多个线程是 BLOCKED 和 WAITING 状态的，这种线程是不会占用 CPU 的。 如果线程数很高，其实大多数原因是死锁，大量线程处于 BLOCKED 和 WAITING 状态。 CPU 使用率高的应用，线程数一定高么？ 不会。同上，CPU 使用率高的关键因素还是计算密集型操作，一个线程如果有大量计算，也会造成 CPU 使用率高，也是现在为什么一个大数据脚本任务，要大规模集群共同运算才能运行的原因。 BLOCKED 状态的线程会不会引起 CPU 使用率飚升？ 不一定，CPU使用率的飙升，更多是因为上下文的切换或者runnable状态线程过多导致。Blocked状态，未必会引起CPU上升。 分时操作系统 CPU us高或者sy高是什么意思？ 通过top命令，我们可以观察到cpu的us，sy值，示例如下： Us 用户空间占用CPU百分比，简单来说，us高是因为我们的程序导致的，通过分析线程堆栈，可以很容易的定位到问题线程。 Sy 内核空间占用CPU百分比，sy高的时候，如果是程序问题导致，基本是因为线程上下文切换造成的。 我的经验平时怎么定位 CPU 使用率高的原因的？ 其实网上有个教程和方法，我简述我的分析过程。 首先发现某台应用 CPU 使用率高，一要看先线程数、JVM、系统 load 等参数，共同作证。二要打印 jstack，通过工具分析线程情况，推荐 fastThread 这个在线的 Thread 分析工具。 以下是线上发生的真实案例，简要介绍下： 某日晚，突然收到短信报警，CPU利用率100%。立刻dump该机器jstack，通过 http://fastthread.io/ 查看日志如下： 进一步查看具体日志： 通过这段日志，已经定位到了具体CPU被打满的方法，接收MQ之后，MQ消息体为xml，反序列化的时候，造成了CPU飙高。 希望本文对大家有所帮助。 本文出自","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"cpu","slug":"cpu","permalink":"http://blog.shagle.cn/tags/cpu/"}]},{"title":"Java技术之引用类型","slug":"Java技术之引用类型","date":"2019-02-26T05:40:42.000Z","updated":"2019-02-26T05:58:24.000Z","comments":true,"path":"2019/02/26/Java技术之引用类型/","link":"","permalink":"http://blog.shagle.cn/2019/02/26/Java技术之引用类型/","excerpt":"","text":"一.了解 强引用、软引用、弱引用、虚引用的概念在Java中，虽然不需要程序员手动去管理对象的生命周期，但是如果希望某些对象具备一定的生命周期的话（比如内存不足时JVM就会自动回收某些对象从而避免OutOfMemory的错误）就需要用到软引用和弱引用了。 从Java SE2开始，就提供了四种类型的引用：强引用、软引用、弱引用和虚引用。Java中提供这四种引用类型主要有两个目的：第一是可以让程序员通过代码的方式决定某些对象的生命周期；第二是有利于JVM进行垃圾回收。下面来阐述一下这四种类型引用的概念： 1.1.强引用（StrongReference）强引用就是指在程序代码之中普遍存在的，比如下面这段代码中的object和str都是强引用： 12Object object = new Object();String str = \"hello\"; 只要某个对象有强引用与之关联，JVM必定不会回收这个对象，即使在内存不足的情况下，JVM宁愿抛出OutOfMemory错误也不会回收这种对象。比如下面这段代码： 12345678910public class Main &#123; public static void main(String[] args) &#123; new Main().fun1(); &#125; public void fun1() &#123; Object object = new Object(); Object[] objArr = new Object[1000]; &#125;&#125; 当运行至Object[] objArr = new Object[1000];这句时，如果内存不足，JVM会抛出OOM错误也不会回收object指向的对象。不过要注意的是，当fun1运行完之后，object和objArr都已经不存在了，所以它们指向的对象都会被JVM回收。 如果想中断强引用和某个对象之间的关联，可以显示地将引用赋值为null，这样一来的话，JVM在合适的时间就会回收该对象。 比如Vector类的clear方法中就是通过将引用赋值为null来实现清理工作的： 12345678910111213141516171819202122232425/** * Removes the element at the specified position in this Vector. * Shifts any subsequent elements to the left (subtracts one from their * indices). Returns the element that was removed from the Vector. * * @throws ArrayIndexOutOfBoundsException if the index is out of range * (&#123;@code index &lt; 0 || index &gt;= size()&#125;) * @param index the index of the element to be removed * @return element that was removed * @since 1.2 */public synchronized E remove(int index) &#123; modCount++; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); Object oldValue = elementData[index]; int numMoved = elementCount - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--elementCount] = null; // Let gc do its work return (E)oldValue;&#125; 1.2.软引用（SoftReference）软引用是用来描述一些有用但并不是必需的对象，在Java中用java.lang.ref.SoftReference类来表示。对于软引用关联着的对象，只有在内存不足的时候JVM才会回收该对象。因此，这一点可以很好地用来解决OOM的问题，并且这个特性很适合用来实现缓存：比如网页缓存、图片缓存等。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被JVM回收，这个软引用就会被加入到与之关联的引用队列中。下面是一个使用示例： 123456789import java.lang.ref.SoftReference; public class Main &#123; public static void main(String[] args) &#123; SoftReference&lt;String&gt; sr = new SoftReference&lt;String&gt;(new String(\"hello\")); System.out.println(sr.get()); &#125;&#125; 1.3.弱引用（WeakReference）弱引用也是用来描述非必需对象的，当JVM进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。在java中，用java.lang.ref.WeakReference类来表示。下面是使用示例： 123456789101112import java.lang.ref.WeakReference; public class Main &#123; public static void main(String[] args) &#123; WeakReference&lt;String&gt; sr = new WeakReference&lt;String&gt;(new String(\"hello\")); System.out.println(sr.get()); System.gc(); //通知JVM的gc进行垃圾回收 System.out.println(sr.get()); &#125;&#125; 输出结果为： 12hellonull 第二个输出结果是null，这说明只要JVM进行垃圾回收，被弱引用关联的对象必定会被回收掉。不过要注意的是，这里所说的被弱引用关联的对象是指只有弱引用与之关联，如果存在强引用同时与之关联，则进行垃圾回收时也不会回收该对象（软引用也是如此）。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被JVM回收，这个软引用就会被加入到与之关联的引用队列中。 1.4.虚引用（PhantomReference）虚引用和前面的软引用、弱引用不同，它并不影响对象的生命周期。在java中用java.lang.ref.PhantomReference类表示。如果一个对象与虚引用关联，则跟没有引用与之关联一样，在任何时候都可能被垃圾回收器回收。 要注意的是，虚引用必须和引用队列关联使用，当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会把这个虚引用加入到与之 关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 虚引用主要用于检测对象是否已经从内存中删除。 1234567891011import java.lang.ref.PhantomReference;import java.lang.ref.ReferenceQueue; public class Main &#123; public static void main(String[] args) &#123; ReferenceQueue&lt;String&gt; queue = new ReferenceQueue&lt;String&gt;(); PhantomReference&lt;String&gt; pr = new PhantomReference&lt;String&gt;(new String(\"hello\"), queue); System.out.println(pr.get()); &#125;&#125; 二.进一步理解软引用和弱引用对于强引用，我们平时在编写代码时经常会用到。而对于其他三种类型的引用，使用得最多的就是软引用和弱引用，这2种既有相似之处又有区别。它们都是用来描述非必需对象的，但是被软引用关联的对象只有在内存不足时才会被回收，而被弱引用关联的对象在JVM进行垃圾回收时总会被回收。 在SoftReference类中，有三个方法，两个构造方法和一个get方法（WekReference类似）： 两个构造方法： 123456789public SoftReference(T referent) &#123; super(referent); this.timestamp = clock;&#125; public SoftReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); this.timestamp = clock;&#125; get方法用来获取与软引用关联的对象的引用，如果该对象被回收了，则返回null。 在使用软引用和弱引用的时候，我们可以显示地通过System.gc()来通知JVM进行垃圾回收，但是要注意的是，虽然发出了通知，JVM不一定会立刻执行，也就是说这句是无法确保此时JVM一定会进行垃圾回收的。 三.如何利用软引用和弱引用解决OOM问题前面讲了关于软引用和弱引用相关的基础知识，那么到底如何利用它们来优化程序性能，从而避免OOM的问题呢？ 下面举个例子，假如有一个应用需要读取大量的本地图片，如果每次读取图片都从硬盘读取，则会严重影响性能，但是如果全部加载到内存当中，又有可能造成内存溢出，此时使用软引用可以解决这个问题。 设计思路是：用一个HashMap来保存图片的路径 和 相应图片对象关联的软引用之间的映射关系，在内存不足时，JVM会自动回收这些缓存图片对象所占用的空间，从而有效地避免了OOM的问题。在Android开发中对于大量图片下载会经常用到。 下面这段代码是摘自博客： http://blog.csdn.net/arui319/article/details/8489451 1234567891011121314151617181920212223242526272829303132333435363738394041.....private Map&lt;String, SoftReference&lt;Bitmap&gt;&gt; imageCache = new HashMap&lt;String, SoftReference&lt;Bitmap&gt;&gt;();....public void addBitmapToCache(String path) &#123; // 强引用的Bitmap对象 Bitmap bitmap = BitmapFactory.decodeFile(path); // 软引用的Bitmap对象 SoftReference&lt;Bitmap&gt; softBitmap = new SoftReference&lt;Bitmap&gt;(bitmap); // 添加该对象到Map中使其缓存 imageCache.put(path, softBitmap);&#125; public Bitmap getBitmapByPath(String path) &#123; // 从缓存中取软引用的Bitmap对象 SoftReference&lt;Bitmap&gt; softBitmap = imageCache.get(path); // 判断是否存在软引用 if (softBitmap == null) &#123; return null; &#125; // 取出Bitmap对象，如果由于内存不足Bitmap被回收，将取得空 Bitmap bitmap = softBitmap.get(); return bitmap;&#125; 当然这里我们把缓存替换策略交给了JVM去执行，这是一种比较简单的处理方法。复杂一点的缓存，我们可以自己单独设计一个类，这里面就涉及到缓存策略的问题了，具体可以参考之前的一篇博文：《缓存算法（页面置换算法）-FIFO、LFU、LRU》 参考资料： 《深入理解JVM虚拟机》 http://blog.csdn.net/arui319/article/details/8489451 http://blog.csdn.net/zsuguangh/article/details/6429592 http://mobile.51cto.com/abased-406998.htm","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"强引用、软引用、弱引用、虚引用","slug":"强引用、软引用、弱引用、虚引用","permalink":"http://blog.shagle.cn/tags/强引用、软引用、弱引用、虚引用/"}]},{"title":"Java技术之深入分析ThreadLocal","slug":"Java技术之深入分析ThreadLocal","date":"2019-02-26T01:36:46.000Z","updated":"2019-02-26T06:18:44.000Z","comments":true,"path":"2019/02/26/Java技术之深入分析ThreadLocal/","link":"","permalink":"http://blog.shagle.cn/2019/02/26/Java技术之深入分析ThreadLocal/","excerpt":"","text":"ThreadLoacal是什么？ThreadLocal是啥？以前面试别人时就喜欢问这个，有些伙伴喜欢把它和线程同步机制混为一谈，事实上ThreadLocal与线程同步无关。ThreadLocal虽然提供了一种解决多线程环境下成员变量的问题，但是它并不是解决多线程共享变量的问题。那么ThreadLocal到底是什么呢？ API是这样介绍它的： This class provides thread-local variables. These variables differ from their normal counterparts in that each thread that accesses one (via its {@code get} or {@code set} method) has its own, independently initialized copy of the variable. {@code ThreadLocal} instances are typically private static fields in classes that wish to associate state with a thread (e.g.,a user ID or Transaction ID). 该类提供了线程局部 (thread-local) 变量。这些变量不同于它们的普通对应物，因为访问某个变量（通过其get或set方法）的每个线程都有自己的局部变量，它独立于变量的初始化副本。 ThreadLocal实例通常是类中的private static字段，它们希望将状态与某一个线程（例如，用户 ID 或事务 ID）相关联。 所以ThreadLocal与线程同步机制不同，线程同步机制是多个线程共享同一个变量，而ThreadLocal是为每一个线程创建一个单独的变量副本，故而每个线程都可以独立地改变自己所拥有的变量副本，而不会影响其他线程所对应的副本。可以说ThreadLocal为多线程环境下变量问题提供了另外一种解决思路。 ThreadLocal定义了四个方法： get()：返回此线程局部变量的当前线程副本中的值。 initialValue()：返回此线程局部变量的当前线程的“初始值”。 remove()：移除此线程局部变量当前线程的值。 set(T value)：将此线程局部变量的当前线程副本中的值设置为指定值。 除了这四个方法，ThreadLocal内部还有一个静态内部类ThreadLocalMap，该内部类才是实现线程隔离机制的关键，get()、set()、remove()都是基于该内部类操作。ThreadLocalMap提供了一种用键值对方式存储每一个线程的变量副本的方法，key为当前ThreadLocal对象，value则是对应线程的变量副本。 对于ThreadLocal需要注意的有两点： ThreadLocal实例本身是不存储值，它只是提供了一个在当前线程中找到副本值得key。 是ThreadLocal包含在Thread中，而不是Thread包含在ThreadLocal中，有些小伙伴会弄错他们的关系。 下图是Thread、ThreadLocal、ThreadLocalMap的关系（http://blog.xiaohansong.com/2016/08/06/ThreadLocal-memory-leak/） ThreadLocal使用示例示例如下： 12345678910111213141516171819202122232425262728293031323334353637383940public class SeqCount &#123; private static ThreadLocal&lt;Integer&gt; seqCount = new ThreadLocal&lt;Integer&gt;() &#123; // 实现initialValue() public Integer initialValue() &#123; return 0; &#125; &#125;; public int nextSeq() &#123; seqCount.set(seqCount.get() + 1); return seqCount.get(); &#125; public static void main(String[] args) &#123; SeqCount seqCount = new SeqCount(); SeqThread thread1 = new SeqThread(seqCount); SeqThread thread2 = new SeqThread(seqCount); SeqThread thread3 = new SeqThread(seqCount); SeqThread thread4 = new SeqThread(seqCount); thread1.start(); thread2.start(); thread3.start(); thread4.start(); &#125; private static class SeqThread extends Thread &#123; private SeqCount seqCount; SeqThread(SeqCount seqCount) &#123; this.seqCount = seqCount; &#125; public void run() &#123; for (int i = 0; i &lt; 3; i++) &#123; System.out.println(Thread.currentThread().getName() + \" seqCount :\" + seqCount.nextSeq()); &#125; &#125; &#125;&#125; 运行结果： 从运行结果可以看出，ThreadLocal确实是可以达到线程隔离机制，确保变量的安全性。这里我们想一个问题，在上面的代码中ThreadLocal的initialValue()方法返回的是0，加入该方法返回得是一个对象呢，会产生什么后果呢？例如： 12345678910111213A a = new A(); private static ThreadLocal&lt;A&gt; seqCount = new ThreadLocal&lt;A&gt;()&#123; // 实现initialValue() public A initialValue() &#123; return a; &#125;&#125;; class A &#123; // .... &#125; 具体过程请参考：对ThreadLocal实现原理的一点思考 ThreadLocal源码解析ThreadLocal虽然解决了这个多线程变量的复杂问题，但是它的源码实现却是比较简单的。ThreadLocalMap是实现ThreadLocal的关键，我们先从它入手。 ThreadLocalMapThreadLocalMap其内部利用Entry来实现key-value的存储，如下： 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 从上面代码中可以看出Entry的key就是ThreadLocal，而value就是值。同时，Entry也继承WeakReference，所以说Entry所对应key（ThreadLocal实例）的引用为一个弱引用（关于弱引用这里就不多说了，感兴趣的可以关注这篇博客：Java技术之引用类型） ThreadLocalMap的源码稍微多了点，我们就看两个最核心的方法getEntry()、set(ThreadLocal key, Object value)方法。 set(ThreadLocal key, Object value) 1234567891011121314151617181920212223242526272829303132private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; // 根据 ThreadLocal 的散列值，查找对应元素在数组中的位置 int i = key.threadLocalHashCode &amp; (len - 1); // 采用“线性探测法”，寻找合适位置 for (ThreadLocal.ThreadLocalMap.Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); // key 存在，直接覆盖 if (k == key) &#123; e.value = value; return; &#125; // key == null，但是存在值（因为此处的e != null），说明之前的ThreadLocal对象已经被回收了 if (k == null) &#123; // 用新元素替换陈旧的元素 replaceStaleEntry(key, value, i); return; &#125; &#125; // ThreadLocal对应的key实例不存在也没有陈旧元素，new 一个 tab[i] = new ThreadLocal.ThreadLocalMap.Entry(key, value); int sz = ++size; // cleanSomeSlots 清楚陈旧的Entry（key == null） // 如果没有清理陈旧的 Entry 并且数组中的元素大于了阈值，则进行 rehash if (!cleanSomeSlots(i, sz) &amp;&amp; (sz &gt;= threshold)) &#123; rehash(); &#125;&#125; 这个set()操作和我们在集合了解的put()方式有点儿不一样，虽然他们都是key-value结构，不同在于他们解决散列冲突的方式不同。集合Map的put()采用的是拉链法，而ThreadLocalMap的set()则是采用开放定址法（具体请参考散列冲突处理系列博客）。掌握了开放地址法该方法就一目了然了。 set()操作除了存储元素外，还有一个很重要的作用，就是replaceStaleEntry()和cleanSomeSlots()，这两个方法可以清除掉key == null 的实例，防止内存泄漏。在set()方法中还有一个变量很重要：threadLocalHashCode，定义如下： 1private final int threadLocalHashCode = nextHashCode(); 从名字上面我们可以看出threadLocalHashCode应该是ThreadLocal的散列值，定义为final，表示ThreadLocal一旦创建其散列值就已经确定了，生成过程则是调用nextHashCode()： 123456private static AtomicInteger nextHashCode = new AtomicInteger();private static final int HASH_INCREMENT = 0x61c88647;private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125; nextHashCode表示分配下一个ThreadLocal实例的threadLocalHashCode的值，HASH_INCREMENT则表示分配两个ThradLocal实例的threadLocalHashCode的增量，从nextHashCode就可以看出他们的定义。 getEntry() 12345678910private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if ((e != null) &amp;&amp; (e.get() == key)) &#123; return e; &#125; else &#123; return getEntryAfterMiss(key, i, e); &#125;&#125; 由于采用了开放定址法，所以当前key的散列值和元素在数组的索引并不是完全对应的，首先取一个探测数（key的散列值），如果所对应的key就是我们所要找的元素，则返回，否则调用getEntryAfterMiss()，如下： 123456789101112131415161718private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; return e; &#125; if (k == null) &#123; expungeStaleEntry(i); &#125; else &#123; i = nextIndex(i, len); &#125; e = tab[i]; &#125; return null;&#125; 这里有一个重要的地方，当key == null时，调用了expungeStaleEntry()方法，该方法用于处理key == null，有利于GC回收，能够有效地避免内存泄漏。 get() 返回当前线程所对应的线程变量 1234567891011121314151617 public T get() &#123; // 获取当前线程 Thread t = Thread.currentThread(); // 获取当前线程的成员变量 threadLocal ThreadLocalMap map = getMap(t); if (map != null) &#123; // 从当前线程的ThreadLocalMap获取相对应的Entry ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; // 获取目标值 @SuppressWarnings(\"unchecked\") T result = (T) e.value; return result; &#125; &#125; return setInitialValue();&#125; 首先通过当前线程获取所对应的成员变量ThreadLocalMap，然后通过ThreadLocalMap获取当前ThreadLocal的Entry，最后通过所获取的Entry获取目标值result。 getMap()方法可以获取当前线程所对应的ThreadLocalMap，如下： 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; set(T value) 设置当前线程的线程局部变量的值。 12345678910public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; map.set(this, value); &#125; else &#123; createMap(t, value); &#125;&#125; 获取当前线程所对应的ThreadLocalMap，如果不为空，则调用ThreadLocalMap的set()方法，key就是当前ThreadLocal，如果不存在，则调用createMap()方法新建一个，如下： 123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; initialValue() 返回该线程局部变量的初始值。 123 protected T initialValue() &#123; return null;&#125; 该方法定义为protected级别且返回为null，很明显是要子类实现它的，所以我们在使用ThreadLocal的时候一般都应该覆盖该方法。该方法不能显示调用，只有在第一次调用get()或者set()方法时才会被执行，并且仅执行1次。 remove() 将当前线程局部变量的值删除。 123456public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) &#123; m.remove(this); &#125;&#125; 该方法的目的是减少内存的占用。当然，我们不需要显示调用该方法，因为一个线程结束后，它所对应的局部变量就会被垃圾回收。 ThreadLocal为什么会内存泄漏前面提到每个Thread都有一个ThreadLocal.ThreadLocalMap的map，该map的key为ThreadLocal实例，它为一个弱引用，我们知道弱引用有利于GC回收。当ThreadLocal的key == null时，GC就会回收这部分空间，但是value却不一定能够被回收，因为他还与Current Thread存在一个强引用关系，如下（图片来自http://www.jianshu.com/p/ee8c9dccc953）： 由于存在这个强引用关系，会导致value无法回收。如果这个线程对象不会销毁那么这个强引用关系则会一直存在，就会出现内存泄漏情况。所以说只要这个线程对象能够及时被GC回收，就不会出现内存泄漏。如果碰到线程池，那就更坑了。 那么要怎么避免这个问题呢？ 在前面提过，在ThreadLocalMap中的setEntry()、getEntry()，如果遇到key == null的情况，会对value设置为null。当然我们也可以显示调用ThreadLocal的remove()方法进行处理。 下面再对ThreadLocal进行简单的总结： ThreadLocal 不是用于解决共享变量的问题的，也不是为了协调线程同步而存在，而是为了方便每个线程处理自己的状态而引入的一个机制。这点至关重要。 每个Thread内部都有一个ThreadLocal.ThreadLocalMap类型的成员变量，该成员变量用来存储实际的ThreadLocal变量副本。 ThreadLocal并不是为线程保存对象的副本，它仅仅只起到一个索引的作用。它的主要木得视为每一个线程隔离一个类的实例，这个实例的作用范围仅限于线程内部。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://blog.shagle.cn/tags/ThreadLocal/"}]},{"title":"Java技术之ReentrantReadWriteLock的实现原理","slug":"Java技术之ReentrantReadWriteLock的实现原理","date":"2019-02-25T02:42:29.000Z","updated":"2019-02-25T10:15:36.000Z","comments":true,"path":"2019/02/25/Java技术之ReentrantReadWriteLock的实现原理/","link":"","permalink":"http://blog.shagle.cn/2019/02/25/Java技术之ReentrantReadWriteLock的实现原理/","excerpt":"","text":"1. 概述ReentrantReadWriteLock是Lock的另一种实现方式，我们已经知道了ReentrantLock是一个排他锁，同一时间只允许一个线程访问，而ReentrantReadWriteLock允许多个读线程同时访问，但不允许写线程和读线程、写线程和写线程同时访问。相对于排他锁，提高了并发性。在实际应用中，大部分情况下对共享数据（如缓存）的访问都是读操作远多于写操作，这时ReentrantReadWriteLock能够提供比排他锁更好的并发性和吞吐量。 读写锁内部维护了两个锁，一个用于读操作，一个用于写操作。所有 ReadWriteLock实现都必须保证 writeLock操作的内存同步效果也要保持与相关 readLock的联系。也就是说，成功获取读锁的线程会看到写入锁之前版本所做的所有更新。 ReentrantReadWriteLock支持以下功能： 1）支持公平和非公平的获取锁的方式； 2）支持可重入。读线程在获取了读锁后还可以获取读锁；写线程在获取了写锁之后既可以再次获取写锁又可以获取读锁； 3）还允许从写入锁降级为读取锁，其实现方式是：先获取写入锁，然后获取读取锁，最后释放写入锁。但是，从读取锁升级到写入锁是不允许的； 4）读取锁和写入锁都支持锁获取期间的中断； 5）Condition支持。仅写入锁提供了一个 Conditon 实现；读取锁不支持 Conditon ，readLock().newCondition() 会抛出 UnsupportedOperationException。 2. ReadWriteLock接口简单说明ReadWriteLock接口只定义了两个方法： 123456789101112131415public interface ReadWriteLock &#123; /** * Returns the lock used for reading. * * @return the lock used for reading */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing */ Lock writeLock();&#125; 通过调用相应方法获取读锁或写锁，获取的读锁及写锁都是Lock接口的实现，可以如同使用Lock接口一样使用（其实也有一些特性是不支持的）。 3. ReentrantReadWriteLock使用示例读写锁的使用并不复杂，可以参考以下使用示例： 123456789101112131415161718192021222324252627class RWDictionary &#123; private final Map&lt;String, Data&gt; m = new TreeMap&lt;String, Data&gt;(); private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); private final Lock r = rwl.readLock(); private final Lock w = rwl.writeLock(); public Data get(String key) &#123; r.lock(); try &#123; return m.get(key); &#125; finally &#123; r.unlock(); &#125; &#125; public String[] allKeys() &#123; r.lock(); try &#123; return m.keySet().toArray(); &#125; finally &#123; r.unlock(); &#125; &#125; public Data put(String key, Data value) &#123; w.lock(); try &#123; return m.put(key, value); &#125; finally &#123; w.unlock(); &#125; &#125; public void clear() &#123; w.lock(); try &#123; m.clear(); &#125; finally &#123; w.unlock(); &#125; &#125;&#125; 与普通重入锁使用的主要区别在于需要使用不同的锁对象引用读写锁，并且在读写时分别调用对应的锁。 4. ReentrantReadWriteLock锁实现分析本节通过学习源码分析可重入读写锁的实现。 4.1 图解重要函数及对象关系根据示例代码可以发现，读写锁需要关注的重点函数为获取读锁及写锁的函数，对于读锁及写锁对象则主要关注加锁和解锁函数，这几个函数及对象关系如下图： 从图中可见读写锁的加锁解锁操作最终都是调用ReentrantReadWriteLock类的内部类Sync提供的方法。与Java技术之ReentrantLock的实现原理一文中描述相似，Sync对象通过继承AbstractQueuedSynchronizer进行实现，故后续分析主要基于Sync类进行。 4.2. 读写锁Sync结构分析Sync继承于AbstractQueuedSynchronizer，其中主要功能均在AbstractQueuedSynchronizer中完成，其中最重要功能为控制线程获取锁失败后转换为等待状态及在满足一定条件后唤醒等待状态的线程。先对AbstractQueuedSynchronizer进行观察。 4.2.1. AbstractQueuedSynchronizer图解为了更好理解AbstractQueuedSynchronizer的运行机制，可以首先研究其内部数据结构，如下图： 图中展示AQS类较为重要的数据结构，包括int类型变量state用于记录锁的状态，继承自AbstractOwnableSynchronizer类的Thread类型变量exclusiveOwnerThread用于指向当前排他的获取锁的线程，AbstractQueuedSynchronizer.Node类型的变量head及tail。其中Node对象表示当前等待锁的节点，Node中thread变量指向等待的线程，waitStatus表示当前等待节点状态，mode为节点类型。多个节点之间使用prev及next组成双向链表，参考CLH锁队列的方式进行锁的获取，但其中与CLH队列的重要区别在于CLH队列中后续节点需要自旋轮询前节点状态以确定前置节点是否已经释放锁，期间不释放CPU资源，而AQS中Node节点指向的线程在获取锁失败后调用LockSupport.park函数使其进入阻塞状态，让出CPU资源，故在前置节点释放锁时需要调用unparkSuccessor函数唤醒后继节点。根据以上说明可得知此上图图主要表现当前thread0线程获取了锁，thread1线程正在等待。 4.2.2. 读写锁Sync对于AQS使用读写锁中Sync类是继承于AQS，并且主要使用上文介绍的数据结构中的state及waitStatus变量进行实现。实现读写锁与实现普通互斥锁的主要区别在于需要分别记录读锁状态及写锁状态，并且等待队列中需要区别处理两种加锁操作。Sync使用state变量同时记录读锁与写锁状态，将int类型的state变量分为高16位与第16位，高16位记录读锁状态，低16位记录写锁状态，如下图所示： Sync使用不同的mode描述等待队列中的节点以区分读锁等待节点和写锁等待节点。mode取值包括SHARED及EXCLUSIVE两种，分别代表当前等待节点为读锁和写锁。 4.3. 读写锁Sync代码过程分析4.3.1. 写锁加锁通过对于重要函数关系的分析，写锁加锁最终调用Sync类的acquire函数（继承自AQS） 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 现在分情况图解分析 4.3.1.1. 无锁状态无锁状态AQS内部数据结构如下图所示： 其中state变量为0，表示高位地位地位均为0，没有任何锁，且等待节点的首尾均指向空（此处特指head节点没有初始化时），锁的所有者线程也为空。在无锁状态进行加锁操作，线程调用acquire函数，首先使用tryAcquire函数判断锁是否可获取成功，由于当前是无锁状态必然成功获取锁（如果多个线程同时进入此函数，则有且只有一个线程可调用compareAndSetState成功，其他线程转入获取锁失败的流程）。获取锁成功后AQS状态为： 4.3.1.2. 有锁状态在加写锁时如果当前AQS已经是有锁状态，则需要进一步处理。有锁状态主要分为已有写锁和已有读锁状态，并且根据最终当前线程是否可直接获取锁分为两种情况： 非重入：如果满足一下两个条件之一，当前线程必须加入等待队列（暂不考虑非公平锁抢占情况） a. 已有读锁； b. 有写锁且获取写锁的线程不为当前请求锁的线程。 重入：有写锁且当前获取写锁的线程与当前请求锁的线程为同一线程，则直接获取锁并将写锁状态值加1。 写锁重入状态如图： 写锁非重入等待状态如图： 在非重入状态，当前线程创建等待节点追加到等待队列队尾，如果当前头结点为空，则需要创建一个默认的头结点。之后再当前获取锁的线程释放锁后，会唤醒等待中的节点，即为thread1。如果当前等待队列存在多个等待节点，由于thread1等待节点为EXCLUSIVE模式，则只会唤醒当前一个节点，不会传播唤醒信号。 4.3.2. 读锁加锁通过对于重要函数关系的分析，写锁加锁最终调用Sync类的acquireShared函数（继承自AQS）： 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 同上文，现在分情况图解分析 4.3.2.1. 无锁状态无所状态AQS内部数据状态图与写加锁是无锁状态一致： 在无锁状态进行加锁操作，线程调用acquireShared函数，首先使用tryAcquireShared函数判断共享锁是否可获取成功，由于当前为无锁状态则获取锁一定成功（如果同时多个线程在读锁进行竞争，则只有一个线程能够直接获取读锁，其他线程需要进入fullTryAcquireShared函数继续进行锁的获取，该函数在后文说明）。当前线程获取读锁成功后，AQS内部结构如图所示： 其中有两个新的变量：firstReader及firstReaderHoldCount。firstReader指向在无锁状态下第一个获取读锁的线程，firstReaderHoldCount记录第一个获取读锁的线程持有当前锁的计数（主要用于重入）。 4.3.2.2. 有锁状态无锁状态获取读锁比较简单，在有锁状态则需要分情况讨论。其中需要分当前被持有的锁是读锁还是写锁，并且每种情况需要区分等待队列中是否有等待节点。 已有读锁且等待队列为空此状态比较简单，图示如： 此时线程申请读锁，首先调用readerShouldBlock函数进行判断，该函数根据当前锁是否为公平锁判断规则稍有不同。如果为非公平锁，则只需要当前第一个等待节点不是写锁就可以尝试获取锁（考虑第一点为写锁主要为了方式写锁“饿死”）；如果是公平锁则只要有等待节点且当前锁不为重入就需要等待。由于本节的前提是等待队列为空的情况，故readerShouldBlock函数一定返回false，则当前线程使用CAS对读锁计数进行增加（同上文，如果同时多个线程在读锁进行竞争，则只有一个线程能够直接获取读锁，其他线程需要进入fullTryAcquireShared函数继续进行锁的获取）。在成功对读锁计数器进行增加后，当前线程需要继续对当前线程持有读锁的计数进行增加。此时分为两种情况： 当前线程是第一个获取读锁的线程，此时由于第一个获取读锁的线程已经通过firstReader及firstReaderHoldCount两个变量进行存储，则仅仅需要将firstReaderHoldCount加1即可; 当前线程不是第一个获取读锁的线程，则需要使用readHolds进行存储，readHolds是ThreadLocal的子类，通过readHolds可获取当前线程对应的HoldCounter类的对象，该对象保存了当前线程获取读锁的计数。考虑程序的局部性原理，又使用cachedHoldCounter缓存最近使用的HoldCounter类的对象，如在一段时间内只有一个线程请求读锁则可加速对读锁获取的计数。 第一个读锁线程重入如图： 非首节点获取读锁 根据上图所示，thread0为首节点，thread1线程继续申请读锁，获取成功后使用ThreadLocal链接的方式进行存储计数对象，并且由于其为最近获取读锁的线程，则cachedHoldCounter对象设置指向thread1对应的计数对象。 已有读锁且等待队列不为空 在当前锁已经被读锁获取，且等待队列不为空的情况下 ，可知等待队列的头结点一定为写锁获取等待，这是由于在读写锁实现过程中，如果某线程获取了读锁，则会唤醒当前等到节点之后的所有等待模式为SHARED的节点，直到队尾或遇到EXCLUSIVE模式的等待节点（具体实现函数为setHeadAndPropagate后续还会遇到）。所以可以确定当前为读锁状态其有等待节点情况下，首节点一定是写锁等待。如图所示： 上图展示当前thread0与thread1线程获取读锁，thread0为首个获取读锁的节点，并且thread2线程在等待获取写锁。在上图显示的状态下，无论公平锁还是非公平锁的实现，新的读锁加锁一定会进行排队，添加等待节点在写锁等待节点之后，这样可以防止写操作的饿死。申请读锁后的状态如图所示： 如图所示，在当前锁被为读锁且有等待队列情况下，thread3及thread4线程申请读锁，则被封装为等待节点追加到当前等待队列后，节点模式为SHARED，线程使用LockSupport.park函数进入阻塞状态，让出CPU资源，直到前驱的等待节点完成锁的获取和释放后进行唤醒。 已有写锁被获取 当前线程申请读锁时发现写锁已经被获取，则无论等待队列是否为空，线程一定会需要加入等待队列（注意在非公平锁实现且前序没有写锁申请的等待，线程有机会抢占获取锁而不进入等待队列）。写锁被获取的情况下，AQS状态为如下状态 在两种情况下，读锁获取都会进入等待队列等待前序节点唤醒，这里不再赘述。 4.3.2.3. 读锁加锁读等待节点被唤醒读写锁与单纯的排他锁主要区别在于读锁的共享性，在读写锁实现中保证读锁能够共享的其中一个机制就在于，如果一个读锁等待节点被唤醒后其会继续唤醒拍在当前唤醒节点之后的SHARED模式等待节点。查看源码： 12345678910111213141516171819202122232425262728 private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; //注意看这里 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 在for循环中，线程如果获取读锁成功后，需要调用setHeadAndPropagate方法。查看其源码： 12345678910private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 在满足传播条件情况下，获取读锁后继续唤醒后续节点，所以如果当前锁是读锁状态则等待节点第一个节点一定是写锁等待节点。 4.3.2.4. 锁降级锁降级算是获取读锁的特例，如在t0线程已经获取写锁的情况下，再调取读锁加锁函数则可以直接获取读锁，但此时其他线程仍然无法获取读锁或写锁，在t0线程释放写锁后，如果有节点等待则会唤醒后续节点，后续节点可见的状态为目前有t0线程获取了读锁。所降级有什么应用场景呢？引用读写锁中使用示例代码 1234567891011121314151617181920212223242526272829303132 class CachedData &#123; Object data; volatile boolean cacheValid; final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() &#123; rwl.readLock().lock(); if (!cacheValid) &#123; // Must release read lock before acquiring write lock rwl.readLock().unlock(); rwl.writeLock().lock(); try &#123; // Recheck state because another thread might have // acquired write lock and changed state before we did. if (!cacheValid) &#123; data = ... cacheValid = true; &#125; // Downgrade by acquiring read lock before releasing write lock rwl.readLock().lock(); &#125; finally &#123; rwl.writeLock().unlock(); // Unlock write, still hold read &#125; &#125; try &#123; use(data); &#125; finally &#123; rwl.readLock().unlock(); &#125; &#125;&#125; 其中针对变量cacheValid的使用主要过程为加读锁、读取、释放读锁、加写锁、修改值、加读锁、释放写锁、使用数据、释放读锁。其中后续几步（加写锁、修改值、加读锁、释放写锁、使用数据、释放读锁）为典型的锁降级。如果不使用锁降级，则过程可能有三种情况： 第一种：加写锁、修改值、释放写锁、使用数据，即使用写锁修改数据后直接使用刚修改的数据，这样可能有数据的不一致，如当前线程释放写锁的同时其他线程（如t0）获取写锁准备修改（还没有改）cacheValid变量，而当前线程却继续运行，则当前线程读到的cacheValid变量的值为t0修改前的老数据； 第二种：加写锁、修改值、使用数据、释放写锁，即将修改数据与再次使用数据合二为一，这样不会有数据的不一致，但是由于混用了读写两个过程，以排它锁的方式使用读写锁，减弱了读写锁读共享的优势，增加了写锁（独占锁）的占用时间； 第三种：加写锁、修改值、释放写锁、加读锁、使用数据、释放读锁，即使用写锁修改数据后再请求读锁来使用数据，这是时数据的一致性是可以得到保证的，但是由于释放写锁和获取读锁之间存在时间差，则当前想成可能会需要进入等待队列进行等待，可能造成线程的阻塞降低吞吐量。 因此针对以上情况提供了锁的降级功能，可以在完成数据修改后尽快读取最新的值，且能够减少写锁占用时间。 最后注意，读写锁不支持锁升级，即获取读锁、读数据、获取写锁、释放读锁、释放写锁这个过程，因为读锁为共享锁，如同时有多个线程获取了读锁后有一个线程进行锁升级获取了写锁，这会造成同时有读锁（其他线程）和写锁的情况，造成其他线程可能无法感知新修改的数据（此为逻辑性错误），并且在JAVA读写锁实现上由于当前线程获取了读锁，再次请求写锁时必然会阻塞而导致后续释放读锁的方法无法执行，这回造成死锁（此为功能性错误）。 4.3.3. 写锁释放锁过程了解了加锁过程后解锁过程就非常简单，每次调用解锁方法都会减少重入计数次数，直到减为0则唤醒后续第一个等待节点，如唤醒的后续节点为读等待节点，则后续节点会继续传播唤醒状态。 4.3.4. 读锁释放过程读锁释放过比写锁稍微复杂，因为是共享锁，所以可能会有多个线程同时获取读锁，故在解锁时需要做两件事： 获取当前线程对应的重入计数，并进行减1，此处天生为线程安全的，不需要特殊处理； 当前读锁获取次数减1，此处由于可能存在多线程竞争，故使用自旋CAS进行设置。完成以上两步后，如读状态为0，则唤醒后续等待节点。 5. 总结根据以上分析，本文主要展示了读写锁的场景及方式，并分析读写锁核心功能（加解锁）的代码实现。Java读写锁同时附带了更多其他方法，包括锁状态监控和带超时机制的加锁方法等，本文不在赘述。并且读写锁中写锁可使用Conditon机制也不在详细说明。 本文出自","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"ReentrantReadWriteLock","slug":"ReentrantReadWriteLock","permalink":"http://blog.shagle.cn/tags/ReentrantReadWriteLock/"}]},{"title":"Java技术之ThreadLocal的使用","slug":"Java技术之ThreadLocal的使用","date":"2019-02-21T09:21:01.000Z","updated":"2019-02-21T09:31:27.000Z","comments":true,"path":"2019/02/21/Java技术之ThreadLocal的使用/","link":"","permalink":"http://blog.shagle.cn/2019/02/21/Java技术之ThreadLocal的使用/","excerpt":"","text":"1. 类ThreadLocal的使用变量值的共享可以使用public static变量的形式，所有的线程都使用同一个public static变量。如果想实现每一个线程都有自己的共享变量该如何解决呢？JDK中提供的类ThreadLocal正是为了解决这样的问题。类ThreadLocal主要解决的就是每个线程绑定自己的值，可以将ThreadLocal类比喻成全局存放数据的盒子，盒子中可以存储每个线程的私有数据。 2. 解决get（）返回null问题1234567package ext;public class ThreadLocalExt extends ThreadLocal &#123; @Override protected Object initialValue() &#123; return \"我是默认值 第一次get不再为null\"; &#125;&#125; 覆盖initialValue（）方法具有初始值。 3. 类InheritableThreadLocal的使用使用类InheritableThreadLocal可以在子线程中取得父线程继承下来的值。 3.1 值继承使用InheritableThreadLocal类可以让子线程从父线程中取得值。 12345678package ext;import java.util.Date;public class InheritableThreadLocalExt extends InheritableThreadLocal &#123; @Override protected Object initialValue() &#123; return new Date().getTime(); &#125;&#125; 类Tools.java代码如下： 12345package tools;import ext.InheritableThreadLocalExt;public class Tools &#123; public static InheritableThreadLocalExt tl = new InheritableThreadLocalExt();&#125; 类ThreadA.java代码如下 12345678910111213141516package extthread;import tools.Tools;public class ThreadA extends Thread &#123; @Override public void run() &#123; try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(\"在ThreadA线程中取值=\" + Tools.tl.get()); Thread.sleep(100); &#125; &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 类Run.java代码如下： 123456789101112131415161718package test;import tools.Tools;import extthread.ThreadA;public class Run &#123; public static void main(String[] args) &#123; try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(\" 在Main线程中取值=\" + Tools.tl.get()); Thread.sleep(100); &#125; Thread.sleep(5000); ThreadA a = new ThreadA(); a.start(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 程序运行结果如图3-64所示。 3.2 值继承再修改如果在继承的同时还可以对值进行进一步的处理那就更好了。 123456789101112package ext;import java.util.Date;public class InheritableThreadLocalExt extends InheritableThreadLocal &#123; @Override protected Object initialValue() &#123; return new Date().getTime(); &#125; @Override protected Object childValue(Object parentValue) &#123; return parentValue + \" 我在子线程加的~!\"; &#125;&#125; 程序运行后的效果如图3-65所示。 但在使用InheritableThreadLocal类需要注意一点的是，如果子线程在取得值的同时，主线程将InheritableThreadLocal中的值进行更改，那么子线程取到的值还是旧值。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"threadLocal","slug":"threadLocal","permalink":"http://blog.shagle.cn/tags/threadLocal/"}]},{"title":"Java技术之join的使用","slug":"Java技术之join的使用","date":"2019-02-21T06:28:50.000Z","updated":"2019-02-21T08:17:32.000Z","comments":true,"path":"2019/02/21/Java技术之join的使用/","link":"","permalink":"http://blog.shagle.cn/2019/02/21/Java技术之join的使用/","excerpt":"","text":"在很多情况下，主线程创建并启动子线程，如果子线程中要进行大量的耗时运算，主线程往往将早于子线程结束之前结束。这时，如果主线程想等待子线程执行完成之后再结束，比如子线程处理一个数据，主线程要取得这个数据中的值，就要用到join（）方法了。方法join（）的作用是等待线程对象销毁。 1. 学习方法join前的铺垫在介绍join方法之前，先来看一个实验。创建测试用的java项目，名称为joinTest1，类MyThread.java代码如下： 1234567891011121314package extthread;public class MyThread extends Thread &#123; @Override public void run() &#123; try &#123; int secondValue = (int) (Math.random() * 10000); System.out.println(secondValue); Thread.sleep(secondValue); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 类Test.java代码如下： 123456789101112package test;import extthread.MyThread;public class Test &#123; public static void main(String[] args) &#123; MyThread threadTest = new MyThread(); threadTest.start(); // Thread.sleep(?) System.out.println(\"我想当threadTest对象执行完毕后我再执行\"); System.out.println(\"但上面代码中的sleep()中的值应该写多少呢？\"); System.out.println(\"答案是：根据不能确定:)\"); &#125;&#125; 程序运行结果如图3-44所示。 2. 20190221150830.png方法join可以解决这个问题。新建java项目joinTest2，类MyThread.java代码如下： 1234567891011121314package extthread;public class MyThread extends Thread &#123; @Override public void run() &#123; try &#123; int secondValue = (int) (Math.random() * 10000); System.out.println(secondValue); Thread.sleep(secondValue); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;&#125; 类Test.java代码如下： 1234567891011121314package test;import extthread.MyThread;public class Test &#123; public static void main(String[] args) &#123; try &#123; MyThread threadTest = new MyThread(); threadTest.start(); threadTest.join(); System.out.println(\"我想当threadTest对象执行完毕后我再执行，我做到了\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 程序运行后的结果如图3-45所示。 方法join的作用是使所属的线程对象x正常执行run（）方法中的任务，而使当前线程z进行无限期的阻塞，等待线程x销毁后再继续执行线程z后面的代码。 方法join具有使线程排队运行的作用，有些类似同步的运行效果。join与synchronized的区别是：join在内部使用wait（）方法进行等待，而sychronized关键字使用的是“对象监视器”原理做为同步 3. 方法join与异常在join过程中，如果当前线程对象被中断，则当前线程出现异常。创建测试用的项目joinException，类ThreadA.java代码如下： 12345678910package extthread;public class ThreadA extends Thread &#123; @Override public void run() &#123; for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; String newString = new String(); Math.random(); &#125; &#125;&#125; 类ThreadB.java代码如下： 123456789101112131415package extthread;public class ThreadB extends Thread &#123; @Override public void run() &#123; try &#123; ThreadA a = new ThreadA(); a.start(); a.join(); System.out.println(\"线程B在run end处打印了\"); &#125; catch (InterruptedException e) &#123; System.out.println(\"线程B在catch处打印了\"); e.printStackTrace(); &#125; &#125;&#125; 类ThreadC.java代码如下： 123456789101112package extthread;public class ThreadC extends Thread &#123; private ThreadB threadB; public ThreadC(ThreadB threadB) &#123; super(); this.threadB = threadB; &#125; @Override public void run() &#123; threadB.interrupt(); &#125;&#125; 类Run.java代码如下： 12345678910111213141516package test.run;import extthread.ThreadB;import extthread.ThreadC;public class Run &#123; public static void main(String[] args) &#123; try &#123; ThreadB b = new ThreadB(); b.start(); Thread.sleep(500); ThreadC c = new ThreadC(b); c.start(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 程序运行后的效果如图3-46所示。 说明方法join（）与interrupt（）方法如果彼此遇到，则会出现异常。但进程按钮还呈“红色”，原因是线程ThreadA还在继续运行，线程ThreadA并未出现异常，是正常执行的状态。 方法join（long）中的参数是设定等待的时间。 4. 方法join（long）与sleep（long）的区别方法join（long）的功能在内部是使用wait（long）方法来实现的，所以join（long）方法具有释放锁的特点。方法join（long）源代码如下： 12345678910111213141516171819202122public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(\"timeout value is negative\"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 从源代码中可以了解到，当执行wait（long）方法后，当前线程的锁被释放，那么其他线程就可以调用此线程中的同步方法了。Thread.sleep（long）方法不释放锁。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"join","slug":"join","permalink":"http://blog.shagle.cn/tags/join/"}]},{"title":"Java技术之线程通信","slug":"Java技术之线程通信","date":"2019-02-21T06:04:00.000Z","updated":"2019-02-21T06:14:54.000Z","comments":true,"path":"2019/02/21/Java技术之线程通信/","link":"","permalink":"http://blog.shagle.cn/2019/02/21/Java技术之线程通信/","excerpt":"","text":"1. 通过管道进行线程间通信：字节流在Java语言中提供了各种各样的输入/输出流Stream，使我们能够很方便地对数据进行操作，其中管道流（pipeStream）是一种特殊的流，用于在不同线程间直接传送数据。一个线程发送数据到输出管道，另一个线程从输入管道中读数据。通过使用管道，实现不同线程间的通信，而无须借助于类似临时文件之类的东西。在Java的JDK中提供了4个类来使线程间可以进行通信： 1）PipedInputStream和PipedOutputStream 2）PipedReader和PipedWriter创建测试用的项目pipeInputOutput。类WriteData.java代码如下： 12345678910111213141516171819package service;import java.io.IOException;import java.io.PipedOutputStream;public class WriteData &#123; public void writeMethod(PipedOutputStream out) &#123; try &#123; System.out.println(\"write :\"); for (int i = 0; i &lt; 300; i++) &#123; String outData = \"\" + (i + 1); out.write(outData.getBytes()); System.out.print(outData); &#125; System.out.println(); out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 类ReadData.java代码如下： 123456789101112131415161718192021package service;import java.io.IOException;import java.io.PipedInputStream;public class ReadData &#123; public void readMethod(PipedInputStream input) &#123; try &#123; System.out.println(\"read :\"); byte[] byteArray = new byte[20]; int readLength = input.read(byteArray); while (readLength != -1) &#123; String newData = new String(byteArray, 0, readLength); System.out.print(newData); readLength = input.read(byteArray); &#125; System.out.println(); input.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 两个自定义线程代码如图3-37所示： 类Run.java代码如下： 1234567891011121314151617181920212223242526272829package test;import java.io.IOException;import java.io.PipedInputStream;import java.io.PipedOutputStream;import service.ReadData;import service.WriteData;import extthread.ThreadRead;import extthread.ThreadWrite;public class Run &#123; public static void main(String[] args) &#123; try &#123; WriteData writeData = new WriteData(); ReadData readData = new ReadData(); PipedInputStream inputStream = new PipedInputStream(); PipedOutputStream outputStream = new PipedOutputStream(); // inputStream.connect(outputStream); outputStream.connect(inputStream); ThreadRead threadRead = new ThreadRead(readData, inputStream); threadRead.start(); Thread.sleep(2000); ThreadWrite threadWrite = new ThreadWrite(writeData, outputStream); threadWrite.start(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 使用代码inputStream.connect（outputStream）或outputStream.connect（inputStream）的作用使两个Stream之间产生通信链接，这样才可以将数据进行输出与输入。程序运行结果如图3-38所示： 2. 通过管道进行线程间通信：字符流当然，在管道中还可以传递字符流。创建测试用的项目pipeReaderWriter。 类WriteData.java代码如下： 12345678910111213141516171819package service;import java.io.IOException;import java.io.PipedWriter;public class WriteData &#123; public void writeMethod(PipedWriter out) &#123; try &#123; System.out.println(\"write :\"); for (int i = 0; i &lt; 300; i++) &#123; String outData = \"\" + (i + 1); out.write(outData); System.out.print(outData); &#125; System.out.println(); out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 类ReadData.java代码如下： 123456789101112131415161718192021package service;import java.io.IOException;import java.io.PipedReader;public class ReadData &#123; public void readMethod(PipedReader input) &#123; try &#123; System.out.println(\"read :\"); char[] byteArray = new char[20]; int readLength = input.read(byteArray); while (readLength != -1) &#123; String newData = new String(byteArray, 0, readLength); System.out.print(newData); readLength = input.read(byteArray); &#125; System.out.println(); input.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 两个自定义线程代码如图3-39所示： 类Run.java代码如下： 1234567891011121314151617181920212223242526272829package test;import java.io.IOException;import java.io.PipedReader;import java.io.PipedWriter;import service.ReadData;import service.WriteData;import extthread.ThreadRead;import extthread.ThreadWrite;public class Run &#123; public static void main(String[] args) &#123; try &#123; WriteData writeData = new WriteData(); ReadData readData = new ReadData(); PipedReader inputStream = new PipedReader(); PipedWriter outputStream = new PipedWriter(); // inputStream.connect(outputStream); outputStream.connect(inputStream); ThreadRead threadRead = new ThreadRead(readData, inputStream); threadRead.start(); Thread.sleep(2000); ThreadWrite threadWrite = new ThreadWrite(writeData, outputStream); threadWrite.start(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 程序运行结果如图3-40所示： 打印的结果和前一个示例基本一样，此实验是在两个线程中通过管道流进行字符数据的传输。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"线程通信","slug":"线程通信","permalink":"http://blog.shagle.cn/tags/线程通信/"}]},{"title":"jvm","slug":"jvm","date":"2019-01-31T05:45:53.000Z","updated":"2019-02-01T03:21:22.000Z","comments":true,"path":"2019/01/31/jvm/","link":"","permalink":"http://blog.shagle.cn/2019/01/31/jvm/","excerpt":"","text":"类加载 在java代码中，类型(类型指Class，Interface等信息)的加载，连接与初始化过程都是在程序运行期间完成的 提供了更大的灵活性，增加了更多的可能性 Java虚拟机与程序的生命周期 在如下几种情况下，java虚拟机将结束生命周期 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致java虚拟机进程终止 类的加载，连接与初始化 加载：查找并加载类的二进制数据 连接 -验证：确保被加载的类的正确性 -准备：为类的静态变量分配内存，并将其初始化为默认值 -解析：把类中的符号引用转换为直接引用 初始化：为类的静态变量赋予正确的初始值 使用 卸载 Java程序对类的使用方式可以分为两种 -主动使用(七种) 创建类的实例 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射(如Class.forName(“com.tet.Test””)) 初始化一个类的子类 java虚拟机启动时被标明为类的类(java test) JDK 1.7 开始提供的动态语言支持：java.lang.invoke.MethodHandle实例的解析结果REF_getStatic,REF_putStatic,REF_invokeStatic句柄对应的类没有初始化则初始化 -被动使用 所有的Java虚拟机实现必须在每个类或接口被Java程序首次主动使用时才初始化他们","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://blog.shagle.cn/tags/jvm/"}]},{"title":"理解Callable 和 Spring DeferredResult（翻译）","slug":"SpringMVC异步","date":"2019-01-28T02:37:00.000Z","updated":"2019-01-28T07:19:29.000Z","comments":true,"path":"2019/01/28/SpringMVC异步/","link":"","permalink":"http://blog.shagle.cn/2019/01/28/SpringMVC异步/","excerpt":"","text":"1-介绍Servlet 3中的异步支持为在另一个线程中处理HTTP请求提供了可能性。当有一个长时间运行的任务时，这是特别有趣的，因为当另一个线程处理这个请求时，容器线程被释放，并且可以继续为其他请求服务。这个主题已经解释了很多次，Spring框架提供的关于这个功能的类似乎有一点混乱——在一个Controller中返回Callable 和 DeferredResult。在这篇文章中，我将实施这两个例子，以显示其差异。这里所显示的所有示例都包括执行一个控制器，该控制器将执行一个长期运行的任务，然后将结果返回给客户机。长时间运行的任务由taskservice处理： 123456789101112131415@Servicepublic class TaskServiceImpl implements TaskService &#123; private final Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public String execute() &#123; try &#123; Thread.sleep(5000); logger.info(\"Slow task executed\"); return \"Task finished\"; &#125; catch (InterruptedException e) &#123; throw new RuntimeException(); &#125; &#125;&#125; 这个web应用是用Spring Boot创建的，我们将执行下面的类来运行我们的例子： 1234567@SpringBootApplicationpublic class MainApp &#123; public static void main(String[] args) &#123; SpringApplication.run(MainApp.class, args); &#125;&#125; 2-阻塞的Controller在这个例子中，一个请求到达控制器。servlet线程不会被释放，直到长时间运行的方法被执行，我们退出@requestmapping注释的方法。 12345678910111213141516171819@RestControllerpublic class BlockingController &#123; private final Logger logger = LoggerFactory.getLogger(this.getClass()); private final TaskService taskService; @Autowired public BlockingController(TaskService taskService) &#123; this.taskService = taskService; &#125; @RequestMapping(value = \"/block\", method = RequestMethod.GET, produces = \"text/html\") public String executeSlowTask() &#123; logger.info(\"Request received\"); String result = taskService.execute(); logger.info(\"Servlet thread released\"); return result; &#125;&#125; 如果我们运行这个例子http://localhost:8080/block，在日志里我们会发现servlet request不会被释放，直到长时间的任务执行完（5秒后）。 1232015-07-12 12:41:11.849 [nio-8080-exec-6] x.s.web.controller.BlockingController : Request received2015-07-12 12:41:16.851 [nio-8080-exec-6] x.spring.web.service.TaskServiceImpl : Slow task executed2015-07-12 12:41:16.851 [nio-8080-exec-6] x.s.web.controller.BlockingController : Servlet thread released 3-返回Callable在这个例子中，不是直接返回的结果，我们将返回一个Callable： 12345678910111213141516171819@RestControllerpublic class AsyncCallableController &#123; private final Logger logger = LoggerFactory.getLogger(this.getClass()); private final TaskService taskService; @Autowired public AsyncCallableController(TaskService taskService) &#123; this.taskService = taskService; &#125; @RequestMapping(value = \"/callable\", method = RequestMethod.GET, produces = \"text/html\") public Callable&lt;String&gt; executeSlowTask() &#123; logger.info(\"Request received\"); Callable&lt;String&gt; callable = taskService::execute; logger.info(\"Servlet thread released\"); return callable; &#125;&#125; 返回Callable意味着Spring MVC将调用在不同的线程中执行定义的任务。Spring将使用TaskExecutor来管理线程。在等待完成的长期任务之前，servlet线程将被释放。 1232015-07-12 13:07:07.012 [nio-8080-exec-5] x.s.w.c.AsyncCallableController : Request received2015-07-12 13:07:07.013 [nio-8080-exec-5] x.s.w.c.AsyncCallableController : Servlet thread released2015-07-12 13:07:12.014 [ MvcAsync2] x.spring.web.service.TaskServiceImpl : Slow task executed 你可以看到我们在长时间运行的任务执行完毕之前就已经从servlet返回了。这并不意味着客户端收到了一个响应。与客户端的通信仍然是开放的等待结果，但接收到的请求的线程已被释放，并可以服务于另一个客户的请求。 4-返回DeferredResult首先，我们需要创建一个deferredresult对象。此对象将由控制器返回。我们将完成和Callable相同的事，当我们在另一个线程处理长时间运行的任务的时候释放servlet线程。 123456789101112131415161718192021@RestControllerpublic class AsyncDeferredController &#123; private final Logger logger = LoggerFactory.getLogger(this.getClass()); private final TaskService taskService; @Autowired public AsyncDeferredController(TaskService taskService) &#123; this.taskService = taskService; &#125; @RequestMapping(value = \"/deferred\", method = RequestMethod.GET, produces = \"text/html\") public DeferredResult&lt;String&gt; executeSlowTask() &#123; logger.info(\"Request received\"); DeferredResult&lt;String&gt; deferredResult = new DeferredResult&lt;&gt;(); CompletableFuture.supplyAsync(taskService::execute) .whenCompleteAsync((result, throwable) -&gt; deferredResult.setResult(result)); logger.info(\"Servlet thread released\"); return deferredResult; &#125;&#125; 所以，返回DeferredResult和返回Callable有什么区别？不同的是这一次线程是由我们管理。创建一个线程并将结果set到DeferredResult是由我们自己来做的。用completablefuture创建一个异步任务。这将创建一个新的线程，在那里我们的长时间运行的任务将被执行。也就是在这个线程中，我们将set结果到DeferredResult并返回。是在哪个线程池中我们取回这个新的线程？默认情况下，在completablefuture的supplyasync方法将在forkjoin池运行任务。如果你想使用一个不同的线程池，你可以通过传一个executor到supplyasync方法： 1public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor) 如果我们运行这个例子，我们将得到如下结果： 1232015-07-12 13:28:08.433 [io-8080-exec-10] x.s.w.c.AsyncDeferredController : Request received2015-07-12 13:28:08.475 [io-8080-exec-10] x.s.w.c.AsyncDeferredController : Servlet thread released2015-07-12 13:28:13.469 [onPool-worker-1] x.spring.web.service.TaskServiceImpl : Slow task executed 5-结论以下是Servlet异步请求处理的简要概述： A ServletRequest可以通过调用置于异步模式request.startAsync()。这样做的主要作用是Servlet（以及任何过滤器）可以退出，但响应保持打开状态以便稍后处理完成。 对request.startAsync()返回的调用AsyncContext，可用于进一步控制异步处理。例如，它提供的dispatch方法类似于Servlet API的转发，但它允许应用程序在Servlet容器线程上恢复请求处理。 在ServletRequest提供对电流DispatcherType，它可以使用处理该初始请求，异步调度，正向，以及其他的调度类型之间进行区分。 DeferredResult 处理工作如下： 控制器返回a DeferredResult并将其保存在可以访问它的某个内存中队列或列表中。 Spring MVC调用request.startAsync()。 同时，DispatcherServlet所有已配置的过滤器都会退出请求处理线程，但响应仍保持打开状态。 应用程序DeferredResult从某个线程设置，Spring MVC将请求调度回Servlet容器。 将DispatcherServlet被再次调用，并且处理与异步生产返回值恢复。 Callable 处理工作如下： 控制器返回一个Callable。 Spring MVC调用request.startAsync()并将其提交Callable到a TaskExecutor以在单独的线程中进行处理。 同时，DispatcherServlet所有过滤器都退出Servlet容器线程，但响应仍保持打开状态。 最终Callable产生一个结果，Spring MVC将请求发送回Servlet容器以完成处理。 将DispatcherServlet被再次调用，并且处理从所述异步生产返回值恢复Callable。 官方文档 站在一定高度来看这问题，Callable和Deferredresult做的是同样的事情——释放容器线程，在另一个线程上异步运行长时间的任务。不同的是谁管理执行任务的线程。 文中涉及的代码spring-rest 翻译自Xavier Padró’s Blog","categories":[{"name":"Spring MVC","slug":"Spring-MVC","permalink":"http://blog.shagle.cn/categories/Spring-MVC/"}],"tags":[{"name":"异步controller","slug":"异步controller","permalink":"http://blog.shagle.cn/tags/异步controller/"}]},{"title":"springMVC与servlet3整合分析","slug":"springMVC-servlet3","date":"2019-01-27T08:13:31.000Z","updated":"2019-01-28T05:32:22.000Z","comments":true,"path":"2019/01/27/springMVC-servlet3/","link":"","permalink":"http://blog.shagle.cn/2019/01/27/springMVC-servlet3/","excerpt":"","text":"Tomcat对Servlet规范的支持说明Servlet 3.0标准的官方说明文件 一、Servlet3.0我们可以知道，Servlet 3.0提供了两个非常重要的功能：Shared libraries（共享库） / runtimes pluggability（运行时插件能力） 我们总结为以下两点： 第一点：Servlet容器启动会扫描当前应用里面每一个jar包的ServletContainerInitializer的实现 第二点：ServletContainerInitializer的实现类，必须要绑定到META-INF/services/javax.servlet.ServletContainerInitializer文件中。并且该文件中的内容就是ServletContainerInitializer实现类的全类名。 总结：容器在启动应用的时候，会扫描当前应用每一个jar包里面META-INF/services/javax.servlet.ServletContainerInitializer，指定的实现类，启动并运行这个实现类的方法；利用@HandlesTypes传入感兴趣的类型； Demo示例： 创建web项目后（要选择3.0），在src目录下创建META-INF/services/并新建文件：javax.servlet.ServletContainerInitializer 新建HelloService接口，HelloService接口的实现类HelloServiceImpl、实现了HelloService的抽象类AbstractHelloService、实现了HelloService的接口HelloServiceExt。 123public class HelloServiceImpl implements HelloService &#123;&#125; 123public abstract class AbstractHelloService implements HelloService &#123;&#125; 123public interface HelloServiceExt extends HelloService &#123;&#125; 新建ServletContainerInitializer实现类： 123456789101112131415161718192021222324252627282930313233343536373839404142//容器启动的时候会将@HandlesTypes指定的这个类型下面的子类（实现类，子接口等）传递过来；//传入感兴趣的类型；@HandlesTypes(value=&#123;HelloService.class&#125;)public class MyServletContainerInitializer implements ServletContainerInitializer &#123; /** * 应用启动的时候，会运行onStartup方法； * * Set&lt;Class&lt;?&gt;&gt; arg0：感兴趣的类型的所有子类型； * ServletContext arg1:代表当前Web应用的ServletContext；一个Web应用一个ServletContext； * * 1）、使用ServletContext注册Web组件（Servlet、Filter、Listener）（可以导入第三方组件） * 2）、使用编码的方式，在项目启动的时候给ServletContext里面添加组件； * 必须在项目启动的时候来添加； * 1）、ServletContainerInitializer得到的ServletContext； * 2）、ServletContextListener得到的ServletContext； */ @Override public void onStartup(Set&lt;Class&lt;?&gt;&gt; arg0, ServletContext sc) throws ServletException &#123; // TODO Auto-generated method stub System.out.println(\"感兴趣的类型：\"); for (Class&lt;?&gt; claz : arg0) &#123; System.out.println(claz); &#125; //注册组件 ServletRegistration ServletRegistration.Dynamic servlet = sc.addServlet(\"userServlet\", new UserServlet()); //配置servlet的映射信息 servlet.addMapping(\"/user\"); //注册Listener sc.addListener(UserListener.class); //注册Filter FilterRegistration FilterRegistration.Dynamic filter = sc.addFilter(\"userFilter\", UserFilter.class); //配置Filter的映射信息 filter.addMappingForUrlPatterns(EnumSet.of(DispatcherType.REQUEST), true, \"/*\"); &#125;&#125; 控制台输出： 12345678感兴趣的类型：class com.my.spring.annotation.service.AbstractHelloServiceinterface com.my.spring.annotation.service.HelloServiceExtclass com.my.spring.annotation.service.HelloServiceImplUserListener...contextInitialized.........UserFilter...doFilter...UserFilter...doFilter... Stop服务器后可以监听到，控制台： 12信息: Stopping service CatalinaUserListener...contextDestroyed... 二、Servelet3.0与SpringMVC整合分析利用注解进行整合时，主要解决的问题是：原来在web.xml中初始化的组件如何在注解版本加载。 这是下面讲解的主线，一定要抓住这个问题往下看，否则，看着看着很容易找不着北，甚至不知道在干什么。 1. 创建Maven项目，并导入依赖12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.my.springmvc.annotation&lt;/groupId&gt; &lt;artifactId&gt;02-SpringmvcAnnotation&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;webVersion&gt;3.0&lt;/webVersion&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.11.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0-alpha-1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;configuration&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2. 应用启动说明可以打开依赖包spring-web-xxx.RELEASE.jar下的META-INF/services/javax.servlet.ServletContainerInitializer看一下 web容器在启动的时候，会扫描每个jar包下的META-INF/services/javax.servlet.ServletContainerInitializer 加载这个文件指定的类SpringServletContainerInitializer 12345678910111213141516171819202122232425262728293031323334353637383940@HandlesTypes(WebApplicationInitializer.class)public class SpringServletContainerInitializer implements ServletContainerInitializer &#123; /** * */ @Override public void onStartup(Set&lt;Class&lt;?&gt;&gt; webAppInitializerClasses, ServletContext servletContext) throws ServletException &#123; List&lt;WebApplicationInitializer&gt; initializers = new LinkedList&lt;WebApplicationInitializer&gt;(); if (webAppInitializerClasses != null) &#123; for (Class&lt;?&gt; waiClass : webAppInitializerClasses) &#123; // Be defensive: Some servlet containers provide us with invalid classes, // no matter what @HandlesTypes says... if (!waiClass.isInterface() &amp;&amp; !Modifier.isAbstract(waiClass.getModifiers()) &amp;&amp; WebApplicationInitializer.class.isAssignableFrom(waiClass)) &#123; try &#123; initializers.add((WebApplicationInitializer) waiClass.newInstance()); &#125; catch (Throwable ex) &#123; throw new ServletException(\"Failed to instantiate WebApplicationInitializer class\", ex); &#125; &#125; &#125; &#125; if (initializers.isEmpty()) &#123; servletContext.log(\"No Spring WebApplicationInitializer types detected on classpath\"); return; &#125; servletContext.log(initializers.size() + \" Spring WebApplicationInitializers detected on classpath\"); AnnotationAwareOrderComparator.sort(initializers); for (WebApplicationInitializer initializer : initializers) &#123; initializer.onStartup(servletContext); &#125; &#125;&#125; spring的应用一启动会加载感兴趣的WebApplicationInitializer接口的下的所有组件； 并且为WebApplicationInitializer组件创建对象（组件不是接口，不是抽象类）WebApplicationInitializer有三层抽象类：(1) AbstractContextLoaderInitializer：创建根容器；createRootApplicationContext()；(2) AbstractDispatcherServletInitializer：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建一个web的ioc容器；createServletApplicationContext();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建了DispatcherServlet；createDispatcherServlet()；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将创建的DispatcherServlet添加到ServletContext中；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;getServletMappings();(3) AbstractAnnotationConfigDispatcherServletInitializer：注解方式配置的DispatcherServlet初始化器&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;两个抽象方法：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建根容器：createRootApplicationContext()，&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;getRootConfigClasses();传入一个配置类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建web的ioc容器： createServletApplicationContext();，&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;获取配置类；getServletConfigClasses();// 留给用户自定义实现 Servlet 3.0与SpringMVC整合原理总结： 以注解方式来启动SpringMVC；只需要继承AbstractAnnotationConfigDispatcherServletInitializer；，并且要实现抽象方法指定DispatcherServlet的配置信息。（会自动将创建的DispatcherServlet添加到ServletContext中；） 三、Servelet3.0与SpringMVC整合Spring官方推荐，两个父子容器的形式： Servlet WebApplicationContextWEB容器，只来扫描Controller、resolvers等与Web组件相关的组件。 Root WebApplicationContext根容器，只来扫描业务逻辑组件。 Coding： 新建AbstractAnnotationConfigDispatcherServletInitializer 的子类 MyWebAppInitializer 12345678910111213141516171819202122232425262728293031323334package com.my.springmvc.annotation;import org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer;import com.my.springmvc.annotation.config.AppConfig;import com.my.springmvc.annotation.config.RootConfig;//web容器启动的时候创建对象；调用方法来初始化容器以及前端控制器public class MyWebAppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; //获取根容器的配置类（就类似于Spring的配置文件，以前是利用监听器方式读取配置文件）创建父容器； @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; // TODO Auto-generated method stub return new Class&lt;?&gt;[]&#123;RootConfig.class&#125;; &#125; //获取web容器的配置类（相当于以前的SpringMVC配置文件）创建 子容器； @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; // TODO Auto-generated method stub return new Class&lt;?&gt;[]&#123;AppConfig.class&#125;; &#125; //获取DispatcherServlet的映射信息 // /：拦截所有请求（包括静态资源（xx.js,xx.png）），但是不包括*.jsp； // /*：拦截所有请求；连*.jsp页面都拦截；jsp页面是tomcat的jsp引擎解析的；所以，不要写成/* @Override protected String[] getServletMappings() &#123; // TODO Auto-generated method stub return new String[]&#123;\"/\"&#125;; &#125; &#125; 创建根容器(父容器)和子容器的配置类：RootConfig和AppConfig 1234567891011121314package com.my.springmvc.annotation.config;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.ComponentScan.Filter;import org.springframework.context.annotation.FilterType;import org.springframework.stereotype.Controller;//Spring的容器不扫描controller;父容器(根容器)@ComponentScan(value=\"com.my.spring.annotation\",excludeFilters=&#123; @Filter(type=FilterType.ANNOTATION,classes=&#123;Controller.class&#125;)&#125;)public class RootConfig &#123;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.my.springmvc.annotation.config;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.ComponentScan.Filter;import org.springframework.context.annotation.FilterType;import org.springframework.stereotype.Controller;import org.springframework.web.servlet.config.annotation.DefaultServletHandlerConfigurer;import org.springframework.web.servlet.config.annotation.EnableWebMvc;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.ViewResolverRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;import com.my.springmvc.annotation.controller.MyFirstInterceptor;//SpringMVC只扫描Controller；子容器//只扫描就必须加useDefaultFilters=false 禁用默认的过滤规则；(排除扫描是不用加的)@ComponentScan(value=\"com.my.spring.annotation\",includeFilters=&#123; @Filter(type=FilterType.ANNOTATION,classes=&#123;Controller.class&#125;)&#125;,useDefaultFilters=false)@EnableWebMvcpublic class AppConfig extends WebMvcConfigurerAdapter &#123; //定制 //视图解析器 @Override public void configureViewResolvers(ViewResolverRegistry registry) &#123; // TODO Auto-generated method stub //默认所有的页面都从 /WEB-INF/ xxx .jsp //registry.jsp(); registry.jsp(\"/WEB-INF/views/\", \".jsp\"); &#125; //静态资源访问 @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) &#123; // TODO Auto-generated method stub configurer.enable(); &#125; //拦截器 @Override public void addInterceptors(InterceptorRegistry registry) &#123; // TODO Auto-generated method stub //super.addInterceptors(registry); registry.addInterceptor(new MyFirstInterceptor()).addPathPatterns(\"/**\"); &#125;&#125; 测试用到的Controller：HelloController 1234567891011121314151617181920212223242526272829package com.my.springmvc.annotation.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import com.my.springmvc.annotation.service.HelloService;@Controllerpublic class HelloController &#123; @Autowired HelloService helloService; @ResponseBody @RequestMapping(\"/hello\") public String hello()&#123; String hello = helloService.sayHello(\"tomcat..\"); return hello; &#125; // /WEB-INF/views/success.jsp @RequestMapping(\"/suc\") public String success()&#123; return \"success\"; &#125;&#125; 测试用的Service：HelloService 12345678910111213package com.my.springmvc.annotation.service;import org.springframework.stereotype.Service;@Servicepublic class HelloService &#123; public String sayHello(String name)&#123; return \"Hello \"+name; &#125;&#125; 运行测试 四、定制与接管SpringMVC原来会将所有的配置定义在web.xml文件中，如果用注解定制与接管SpringMVC则分两步： @EnableWebMvc:开启SpringMVC定制配置功能；可以加到配置类上。@EnableWebMvc相当于在web.xml中“&lt; mvc:annotation-driven /&gt;”官网上的原版解释如下： 123456789101112131415161718192021222324251.11.1. Enable MVC ConfigSame in Spring WebFluxIn Java config use the @EnableWebMvc annotation:@Configuration@EnableWebMvcpublic class WebConfig &#123;&#125;In XML use the &lt;mvc:annotation-driven&gt; element:&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;mvc:annotation-driven/&gt;&lt;/beans&gt;The above registers a number of Spring MVC infrastructure beans also adapting to dependencies available on the classpath: e.g. payload converters for JSON, XML, etc. 在官网上每一个注解都会有相应的解释和例子。 配置组件（视图解析器、视图映射、静态资源映射、拦截器……）官网上表示In Java config implement WebMvcConfigurer interface: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111public class RootConfig implements WebMvcConfigurer &#123; @Override public void configurePathMatch(PathMatchConfigurer configurer) &#123; // TODO Auto-generated method stub &#125; @Override public void configureContentNegotiation(ContentNegotiationConfigurer configurer) &#123; // TODO Auto-generated method stub &#125; @Override public void configureAsyncSupport(AsyncSupportConfigurer configurer) &#123; // TODO Auto-generated method stub &#125; @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) &#123; // TODO Auto-generated method stub &#125; @Override public void addFormatters(FormatterRegistry registry) &#123; // TODO Auto-generated method stub &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; // TODO Auto-generated method stub &#125; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; // TODO Auto-generated method stub &#125; @Override public void addCorsMappings(CorsRegistry registry) &#123; // TODO Auto-generated method stub &#125; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // TODO Auto-generated method stub &#125; @Override public void configureViewResolvers(ViewResolverRegistry registry) &#123; // TODO Auto-generated method stub &#125; @Override public void addArgumentResolvers(List&lt;HandlerMethodArgumentResolver&gt; argumentResolvers) &#123; // TODO Auto-generated method stub &#125; @Override public void addReturnValueHandlers(List&lt;HandlerMethodReturnValueHandler&gt; returnValueHandlers) &#123; // TODO Auto-generated method stub &#125; @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; // TODO Auto-generated method stub &#125; @Override public void extendMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; // TODO Auto-generated method stub &#125; @Override public void configureHandlerExceptionResolvers(List&lt;HandlerExceptionResolver&gt; exceptionResolvers) &#123; // TODO Auto-generated method stub &#125; @Override public void extendHandlerExceptionResolvers(List&lt;HandlerExceptionResolver&gt; exceptionResolvers) &#123; // TODO Auto-generated method stub &#125; @Override public Validator getValidator() &#123; // TODO Auto-generated method stub return null; &#125; @Override public MessageCodesResolver getMessageCodesResolver() &#123; // TODO Auto-generated method stub return null; &#125;&#125; 可以看到如果是实现WebMvcConfigurer接口，则需要实现的方法太多，但是我们一般用不了这些方法，所以，可以继承WebMvcConfigurer的一个抽象类WebMvcConfigurerAdapter，这个抽象类已经实现了这些所有的方法（空的而已），所以，我们就可以有目的的进行定制。比如：定制视图解析器、静态资源访问、拦截器 1234567891011121314151617181920212223242526272829303132333435//SpringMVC只扫描Controller；子容器//useDefaultFilters=false 禁用默认的过滤规则；@ComponentScan(value=\"com.my.spring.annotation\",includeFilters=&#123; @Filter(type=FilterType.ANNOTATION,classes=&#123;Controller.class&#125;)&#125;,useDefaultFilters=false)@EnableWebMvcpublic class AppConfig extends WebMvcConfigurerAdapter &#123; //定制 //视图解析器 @Override public void configureViewResolvers(ViewResolverRegistry registry) &#123; // TODO Auto-generated method stub //默认所有的页面都从 /WEB-INF/ xxx .jsp //registry.jsp(); registry.jsp(\"/WEB-INF/views/\", \".jsp\"); &#125; //静态资源访问 @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) &#123; // TODO Auto-generated method stub configurer.enable(); &#125; //拦截器 @Override public void addInterceptors(InterceptorRegistry registry) &#123; // TODO Auto-generated method stub //super.addInterceptors(registry); registry.addInterceptor(new MyFirstInterceptor()).addPathPatterns(\"/**\"); &#125;&#125; 上面定制化中用到的拦截器定义如下MyFirstInterceptor： 1234567891011121314151617181920212223242526272829public class MyFirstInterceptor implements HandlerInterceptor &#123; //目标方法运行之前执行 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // TODO Auto-generated method stub System.out.println(\"preHandle...\"+request.getRequestURI()); return true; &#125; //目标方法执行正确以后执行 @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; // TODO Auto-generated method stub System.out.println(\"postHandle...\"); &#125; //页面响应以后执行 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; // TODO Auto-generated method stub System.out.println(\"afterCompletion...\"); &#125;&#125; 更多的定制方法可以参考官网：https://docs.spring.io/spring/docs/5.0.12.RELEASE/spring-framework-reference/web.html#mvc-config 其中1.11 MVC Config章节有对每个组件的详细说明。（调用什么方法，相当于之前的什么写法） 五、Servelet3.0与SpringMVC整合——异步请求1. servlet 3.0另外一个重大的更新功能是异步请求在Servlet 3.0之前，Servlet采用Thread-Per-Request的方式处理请求。即每一次Http请求都由某一个线程从头到尾负责处理。 如果一个请求需要进行IO操作，比如访问数据库、调用第三方服务接口等，那么其所对应的线程将同步地等待IO操作完成， 而IO操作是非常慢的，所以此时的线程并不能及时地释放回线程池以供后续使用，在并发量越来越大的情况下，这将带来严重的性能问题。即便是像Spring、Struts这样的高层框架也脱离不了这样的桎梏，因为他们都是建立在Servlet之上的。为了解决这样的问题，Servlet 3.0引入了异步处理，然后在Servlet 3.1中又引入了非阻塞IO来进一步增强异步处理的性能。 配置步骤： 支持异步处理asyncSupported=true 1@WebServlet(value=\"/async\",asyncSupported=true) 开启异步模式 1AsyncContext startAsync = req.startAsync(); startAsync 可以设置异步请求的监听器、异步处理的超时时间等等。 业务逻辑进行异步处理;开始异步处理 在start方法中的run方法中获取相应3和4的代码如下： 1234567891011121314151617startAsync.start(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(\"副线程开始。。。\"+Thread.currentThread()+\"==&gt;\"+System.currentTimeMillis()); sayHello(); startAsync.complete(); //获取到异步上下文 AsyncContext asyncContext = req.getAsyncContext(); // 4、获取响应 ServletResponse response = asyncContext.getResponse(); response.getWriter().write(\"hello async...\"); System.out.println(\"副线程结束。。。\"+Thread.currentThread()+\"==&gt;\"+System.currentTimeMillis()); &#125; catch (Exception e) &#123; &#125; &#125;&#125;); 完整的异步Servlet代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.io.IOException;import javax.servlet.AsyncContext;import javax.servlet.ServletException;import javax.servlet.ServletResponse;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet(value=\"/async\",asyncSupported=true)public class HelloAsyncServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; //1、支持异步处理asyncSupported=true //2、开启异步模式 System.out.println(\"主线程开始。。。\"+Thread.currentThread()+\"==&gt;\"+System.currentTimeMillis()); AsyncContext startAsync = req.startAsync(); //3、业务逻辑进行异步处理;开始异步处理 startAsync.start(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(\"副线程开始。。。\"+Thread.currentThread()+\"==&gt;\"+System.currentTimeMillis()); sayHello(); startAsync.complete(); //获取到异步上下文 AsyncContext asyncContext = req.getAsyncContext(); //4、获取响应 ServletResponse response = asyncContext.getResponse(); response.getWriter().write(\"hello async...\"); System.out.println(\"副线程结束。。。\"+Thread.currentThread()+\"==&gt;\"+System.currentTimeMillis()); &#125; catch (Exception e) &#123; &#125; &#125; &#125;); System.out.println(\"主线程结束。。。\"+Thread.currentThread()+\"==&gt;\"+System.currentTimeMillis()); &#125; public void sayHello() throws Exception&#123; System.out.println(Thread.currentThread()+\" processing...\"); Thread.sleep(3000); &#125;&#125; 控制台输出： 123456789主线程开始。。。Thread[http-nio-8080-exec-2,5,main]==&gt;1548248108792主线程结束。。。Thread[http-nio-8080-exec-2,5,main]==&gt;1548248108796副线程开始。。。Thread[http-nio-8080-exec-3,5,main]==&gt;1548248108796Thread[http-nio-8080-exec-3,5,main] processing...UserFilter...doFilter...主线程开始。。。Thread[http-nio-8080-exec-5,5,main]==&gt;1548248112056主线程结束。。。Thread[http-nio-8080-exec-5,5,main]==&gt;1548248112056副线程开始。。。Thread[http-nio-8080-exec-6,5,main]==&gt;1548248112056Thread[http-nio-8080-exec-6,5,main] processing... 2. Springmvc整合servlet 3.0异步请求功能Springmvc官网的Async Request说明1.6章节Async Requests，该章节有详细的例子和说明 12345678910111213141516171819202122232425262728293031Here is a very concise overview of Servlet asynchronous request processing:A ServletRequest can be put in asynchronous mode by calling request.startAsync(). The main effect of doing so is that the Servlet, as well as any Filters, can exit but the response will remain open to allow processing to complete later.The call to request.startAsync() returns AsyncContext which can be used for further control over async processing. For example it provides the method dispatch, that is similar to a forward from the Servlet API except it allows an application to resume request processing on a Servlet container thread.The ServletRequest provides access to the current DispatcherType that can be used to distinguish between processing the initial request, an async dispatch, a forward, and other dispatcher types.DeferredResult processing:Controller returns a DeferredResult and saves it in some in-memory queue or list where it can be accessed.Spring MVC calls request.startAsync().Meanwhile the DispatcherServlet and all configured Filter’s exit the request processing thread but the response remains open.The application sets the DeferredResult from some thread and Spring MVC dispatches the request back to the Servlet container.The DispatcherServlet is invoked again and processing resumes with the asynchronously produced return value.Callable processing:Controller returns a Callable.Spring MVC calls request.startAsync() and submits the Callable to a TaskExecutor for processing in a separate thread.Meanwhile the DispatcherServlet and all Filter’s exit the Servlet container thread but the response remains open.Eventually the Callable produces a result and Spring MVC dispatches the request back to the Servlet container to complete processing.The DispatcherServlet is invoked again and processing resumes with the asynchronously produced return value from the Callable. 上面英文的意思如下程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Controllerpublic class AsyncController &#123; @ResponseBody @RequestMapping(\"/createOrder\") public DeferredResult&lt;Object&gt; createOrder()&#123; DeferredResult&lt;Object&gt; deferredResult = new DeferredResult&lt;&gt;((long)3000, \"create fail...\"); DeferredResultQueue.save(deferredResult); return deferredResult; &#125; @ResponseBody @RequestMapping(\"/create\") public String create()&#123; //创建订单 String order = UUID.randomUUID().toString(); DeferredResult&lt;Object&gt; deferredResult = DeferredResultQueue.get(); deferredResult.setResult(order); return \"success===&gt;\"+order; &#125; /** * 1、控制器返回Callable * 2、Spring异步处理，将Callable 提交到 TaskExecutor 使用一个隔离的线程进行执行 * 3、DispatcherServlet和所有的Filter退出web容器的线程，但是response 保持打开状态； * 4、Callable返回结果，SpringMVC将请求重新派发给容器，恢复之前的处理； * 5、根据Callable返回的结果。SpringMVC继续进行视图渲染流程等（从收请求-视图渲染）。 * * preHandle.../springmvc-annotation/async01 主线程开始...Thread[http-bio-8081-exec-3,5,main]==&gt;1513932494700 主线程结束...Thread[http-bio-8081-exec-3,5,main]==&gt;1513932494700 =========DispatcherServlet及所有的Filter退出线程============================ ================等待Callable执行========== 副线程开始...Thread[MvcAsync1,5,main]==&gt;1513932494707 副线程开始...Thread[MvcAsync1,5,main]==&gt;1513932496708 ================Callable执行完成========== ================再次收到之前重发过来的请求======== preHandle.../springmvc-annotation/async01 postHandle...（Callable的之前的返回值就是目标方法的返回值） afterCompletion... 异步的拦截器: 1）、原生API的AsyncListener 2）、SpringMVC：实现AsyncHandlerInterceptor； * @return */ @ResponseBody @RequestMapping(\"/async01\") public Callable&lt;String&gt; async01()&#123; System.out.println(\"主线程开始...\"+Thread.currentThread()+\"==&gt;\"+System.currentTimeMillis()); Callable&lt;String&gt; callable = new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; System.out.println(\"副线程开始...\"+Thread.currentThread()+\"==&gt;\"+System.currentTimeMillis()); Thread.sleep(2000); System.out.println(\"副线程开始...\"+Thread.currentThread()+\"==&gt;\"+System.currentTimeMillis()); return \"Callable&lt;String&gt; async01()\"; &#125; &#125;; System.out.println(\"主线程结束...\"+Thread.currentThread()+\"==&gt;\"+System.currentTimeMillis()); return callable; &#125;&#125; 总结：Springmvc对异步请求主要分为两种：返回Callable和返回DeferredResult。 返回Callable： 1234567891011121314A controller may also wrap any supported return value with java.util.concurrent.Callable:@PostMappingpublic Callable&lt;String&gt; processUpload(final MultipartFile file) &#123; return new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; // ... return \"someView\"; &#125; &#125;;&#125;The return value will then be obtained by executing the the given task through the configured TaskExecutor. 在实际的开发中，一般不会像返回Callable这么简单，一般都会用到返回DeferredResult。 返回DeferredResult 12345678910111213Once the asynchronous request processing feature is enabled in the Servlet container, controller methods can wrap any supported controller method return value with DeferredResult:@GetMapping(\"/quotes\")@ResponseBodypublic DeferredResult&lt;String&gt; quotes() &#123; DeferredResult&lt;String&gt; deferredResult = new DeferredResult&lt;String&gt;(); // Save the deferredResult somewhere.. return deferredResult;&#125;// From some other thread...deferredResult.setResult(data);The controller can produce the return value asynchronously, from a different thread, for example in response to an external event (JMS message), a scheduled task, or other. 上面官网的意思是：当请求不能得到及时响应时，先new DeferredResult();并立刻返回，并把这个对象保存到其他的地方。另外一个线程拿到这个对象后，进行真正的处理，处理完成后，通过调用setResult(data)方法，将结果响应出去。","categories":[{"name":"servlet3.0","slug":"servlet3-0","permalink":"http://blog.shagle.cn/categories/servlet3-0/"},{"name":"spring mvc","slug":"servlet3-0/spring-mvc","permalink":"http://blog.shagle.cn/categories/servlet3-0/spring-mvc/"}],"tags":[{"name":"servlet3.0","slug":"servlet3-0","permalink":"http://blog.shagle.cn/tags/servlet3-0/"},{"name":"spring mvc","slug":"spring-mvc","permalink":"http://blog.shagle.cn/tags/spring-mvc/"}]},{"title":"Servlet 3.0 新特性概述","slug":"servlet3","date":"2019-01-25T14:41:21.000Z","updated":"2019-01-25T15:16:17.000Z","comments":true,"path":"2019/01/25/servlet3/","link":"","permalink":"http://blog.shagle.cn/2019/01/25/servlet3/","excerpt":"","text":"Servlet 3.0 作为 Java EE 6 规范体系中一员，随着 Java EE 6 规范一起发布。该版本在前一版本（Servlet 2.5）的基础上提供了若干新特性用于简化 Web 应用的开发和部署。其中有几项特性的引入让开发者感到非常兴奋，同时也获得了 Java 社区的一片赞誉之声： 异步处理支持：有了该特性，Servlet 线程不再需要一直阻塞，直到业务处理完毕才能再输出响应，最后才结束该 Servlet 线程。在接收到请求之后，Servlet 线程可以将耗时的操作委派给另一个线程来完成，自己在不生成响应的情况下返回至容器。针对业务处理较耗时的情况，这将大大减少服务器资源的占用，并且提高并发处理速度。 新增的注解支持：该版本新增了若干注解，用于简化 Servlet、过滤器（Filter）和监听器（Listener）的声明，这使得 web.xml 部署描述文件从该版本开始不再是必选的了。 可插性支持：熟悉 Struts2 的开发者一定会对其通过插件的方式与包括 Spring 在内的各种常用框架的整合特性记忆犹新。将相应的插件封装成 JAR 包并放在类路径下，Struts2 运行时便能自动加载这些插件。现在 Servlet 3.0 提供了类似的特性，开发者可以通过插件的方式很方便的扩充已有 Web 应用的功能，而不需要修改原有的应用。下面我们将逐一讲解这些新特性，通过下面的学习，读者将能够明晰了解 Servlet 3.0 的变化，并能够顺利使用它进行日常的开发工作。 异步处理支持Servlet 3.0 之前，一个普通 Servlet 的主要工作流程大致如下：首先，Servlet 接收到请求之后，可能需要对请求携带的数据进行一些预处理；接着，调用业务接口的某些方法，以完成业务处理；最后，根据处理的结果提交响应，Servlet 线程结束。其中第二步的业务处理通常是最耗时的，这主要体现在数据库操作，以及其它的跨网络调用等，在此过程中，Servlet 线程一直处于阻塞状态，直到业务方法执行完毕。在处理业务的过程中，Servlet 资源一直被占用而得不到释放，对于并发较大的应用，这有可能造成性能的瓶颈。对此，在以前通常是采用私有解决方案来提前结束 Servlet 线程，并及时释放资源。 Servlet 3.0 针对这个问题做了开创性的工作，现在通过使用 Servlet 3.0 的异步处理支持，之前的 Servlet 处理流程可以调整为如下的过程：首先，Servlet 接收到请求之后，可能首先需要对请求携带的数据进行一些预处理；接着，Servlet 线程将请求转交给一个异步线程来执行业务处理，线程本身返回至容器，此时 Servlet 还没有生成响应数据，异步线程处理完业务以后，可以直接生成响应数据（异步线程拥有 ServletRequest 和 ServletResponse 对象的引用），或者将请求继续转发给其它 Servlet。如此一来， Servlet 线程不再是一直处于阻塞状态以等待业务逻辑的处理，而是启动异步线程之后可以立即返回。 异步处理特性可以应用于 Servlet 和过滤器两种组件，由于异步处理的工作模式和普通工作模式在实现上有着本质的区别，因此默认情况下，Servlet 和过滤器并没有开启异步处理特性，如果希望使用该特性，则必须按照如下的方式启用： 对于使用传统的部署描述文件 (web.xml) 配置 Servlet 和过滤器的情况，Servlet 3.0 为 和 标签增加了 子标签，该标签的默认取值为 false，要启用异步处理支持，则将其设为 true 即可。以 Servlet 为例，其配置方式如下所示： 12345&lt;servlet&gt; &lt;servlet-name&gt;DemoServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;footmark.servlet.Demo Servlet&lt;/servlet-class&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;/servlet&gt; 对于使用 Servlet 3.0 提供的 @WebServlet 和 @WebFilter 进行 Servlet 或过滤器配置的情况，这两个注解都提供了 asyncSupported 属性，默认该属性的取值为 false，要启用异步处理支持，只需将该属性设置为 true 即可。以 @WebFilter 为例，其配置方式如下所示： 12@WebFilter(urlPatterns = \"/demo\",asyncSupported = true) public class DemoFilter implements Filter&#123;...&#125; 一个简单的模拟异步处理的 Servlet 示例如下： 1234567891011121314151617181920212223242526272829303132333435363738@WebServlet(urlPatterns = \"/demo\", asyncSupported = true)public class AsyncDemoServlet extends HttpServlet &#123; @Override public void doGet(HttpServletRequest req, HttpServletResponse resp) throws IOException, ServletException &#123; resp.setContentType(\"text/html;charset=UTF-8\"); PrintWriter out = resp.getWriter(); out.println(\"进入Servlet的时间：\" + new Date() + \".\"); out.flush(); //在子线程中执行业务调用，并由其负责输出响应，主线程退出 AsyncContext ctx = req.startAsync(); new Thread(new Executor(ctx)).start(); out.println(\"结束Servlet的时间：\" + new Date() + \".\"); out.flush(); &#125;&#125; public class Executor implements Runnable &#123; private AsyncContext ctx = null; public Executor(AsyncContext ctx)&#123; this.ctx = ctx; &#125; public void run()&#123; try &#123; //等待十秒钟，以模拟业务方法的执行 Thread.sleep(10000); PrintWriter out = ctx.getResponse().getWriter(); out.println(\"业务处理完毕的时间：\" + new Date() + \".\"); out.flush(); ctx.complete(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 除此之外，Servlet 3.0 还为异步处理提供了一个监听器，使用 AsyncListener 接口表示。它可以监控如下四种事件： 异步线程开始时，调用 AsyncListener 的 onStartAsync(AsyncEvent event) 方法； 异步线程出错时，调用 AsyncListener 的 onError(AsyncEvent event) 方法； 异步线程执行超时，则调用 AsyncListener 的 onTimeout(AsyncEvent event) 方法； 异步执行完毕时，调用 AsyncListener 的 onComplete(AsyncEvent event) 方法； 要注册一个 AsyncListener，只需将准备好的 AsyncListener 对象传递给 AsyncContext 对象的 addListener() 方法即可，如下所示： 1234567AsyncContext ctx = req.startAsync(); ctx.addListener(new AsyncListener() &#123; public void onComplete(AsyncEvent asyncEvent) throws IOException &#123; // 做一些清理工作或者其他 &#125; ... &#125;); 新增的注解支持Servlet 3.0 的部署描述文件 web.xml 的顶层标签 有一个 metadata-complete 属性，该属性指定当前的部署描述文件是否是完全的。如果设置为 true，则容器在部署时将只依赖部署描述文件，忽略所有的注解（同时也会跳过 web-fragment.xml 的扫描，亦即禁用可插性支持，具体请看后文关于 可插性支持的讲解）；如果不配置该属性，或者将其设置为 false，则表示启用注解支持（和可插性支持）。 @WebServlet@WebServlet 用于将一个类声明为 Servlet，该注解将会在部署时被容器处理，容器将根据具体的属性配置将相应的类部署为 Servlet。该注解具有下表给出的一些常用属性（以下所有属性均为可选属性，但是 vlaue 或者 urlPatterns 通常是必需的，且二者不能共存，如果同时指定，通常是忽略 value 的取值）：表 1. @WebServlet 主要属性列表 属性名 类型 描述 name String 指定 Servlet 的 name 属性，等价于 。如果没有显式指定，则该 Servlet 的取值即为类的全限定名。 value String[] 该属性等价于 urlPatterns 属性。两个属性不能同时使用。 urlPatterns String[] 指定一组 Servlet 的 URL 匹配模式。等价于 标签。 loadOnStartup int 指定 Servlet 的加载顺序，等价于 标签。 initParams WebInitParam[] 指定一组 Servlet 初始化参数，等价于 标签。 asyncSupported boolean 声明 Servlet 是否支持异步操作模式，等价于 标签。 description String 该 Servlet 的描述信息，等价于 标签。 displayName String 该 Servlet 的显示名，通常配合工具使用，等价于 标签。 下面是一个简单的示例： 12345@WebServlet(urlPatterns = &#123;\"/simple\"&#125;, asyncSupported = true, loadOnStartup = -1, name = \"SimpleServlet\", displayName = \"ss\", initParams = &#123;@WebInitParam(name = \"username\", value = \"tom\")&#125; ) public class SimpleServlet extends HttpServlet&#123; … &#125; 如此配置之后，就可以不必在 web.xml 中配置相应的 和 元素了，容器会在部署时根据指定的属性将该类发布为 Servlet。它的等价的 web.xml 配置形式如下： 123456789101112131415&lt;servlet&gt; &lt;display-name&gt;ss&lt;/display-name&gt; &lt;servlet-name&gt;SimpleServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;footmark.servlet.SimpleServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;-1&lt;/load-on-startup&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;init-param&gt; &lt;param-name&gt;username&lt;/param-name&gt; &lt;param-value&gt;tom&lt;/param-value&gt; &lt;/init-param&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;SimpleServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/simple&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; @WebInitParam该注解通常不单独使用，而是配合 @WebServlet 或者 @WebFilter 使用。它的作用是为 Servlet 或者过滤器指定初始化参数，这等价于 web.xml 中 和 的 子标签。@WebInitParam 具有下表给出的一些常用属性：表 2. @WebInitParam 的常用属性 |属性名| 类型| 是否可选| 描述||name| String| 否| 指定参数的名字，等价于 。||value| String| 否| 指定参数的值，等价于 。||description| String| 是| 关于参数的描述，等价于 。| @WebFilter@WebFilter 用于将一个类声明为过滤器，该注解将会在部署时被容器处理，容器将根据具体的属性配置将相应的类部署为过滤器。该注解具有下表给出的一些常用属性 ( 以下所有属性均为可选属性，但是 value、urlPatterns、servletNames 三者必需至少包含一个，且 value 和 urlPatterns 不能共存，如果同时指定，通常忽略 value 的取值 )：表 3. @WebFilter 的常用属性 属性名 类型 描述 filterName String 指定过滤器的 name 属性，等价于 value String[] 该属性等价于 urlPatterns 属性。但是两者不应该同时使用。 urlPatterns String[] 指定一组过滤器的 URL 匹配模式。等价于 标签。 servletNames String[] 指定过滤器将应用于哪些 Servlet。取值是 @WebServlet 中的 name 属性的取值，或者是 web.xml 中 的取值。 dispatcherTypes DispatcherType 指定过滤器的转发模式。具体取值包括：ASYNC、ERROR、FORWARD、INCLUDE、REQUEST。 initParams WebInitParam[] 指定一组过滤器初始化参数，等价于 标签。 asyncSupported boolean 声明过滤器是否支持异步操作模式，等价于 标签。 description String 该过滤器的描述信息，等价于 标签。 displayName String 该过滤器的显示名，通常配合工具使用，等价于 标签。 下面是一个简单的示例： 12@WebFilter(servletNames = &#123;\"SimpleServlet\"&#125;,filterName=\"SimpleFilter\") public class LessThanSixFilter implements Filter&#123;...&#125; 如此配置之后，就可以不必在 web.xml 中配置相应的 和 元素了，容器会在部署时根据指定的属性将该类发布为过滤器。它等价的 web.xml 中的配置形式为： 12345678&lt;filter&gt; &lt;filter-name&gt;SimpleFilter&lt;/filter-name&gt; &lt;filter-class&gt;xxx&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;SimpleFilter&lt;/filter-name&gt; &lt;servlet-name&gt;SimpleServlet&lt;/servlet-name&gt; &lt;/filter-mapping&gt; @WebListener该注解用于将类声明为监听器，被 @WebListener 标注的类必须实现以下至少一个接口： ServletContextListener ServletContextAttributeListener ServletRequestListener ServletRequestAttributeListener HttpSessionListener HttpSessionAttributeListener该注解使用非常简单，其属性如下：表 4. @WebListener 的常用属性 属性名 类型 是否可选 描述 value String 是 该监听器的描述信息。 一个简单示例如下： 12@WebListener(\"This is only a demo listener\") public class SimpleListener implements ServletContextListener&#123;...&#125; 如此，则不需要在 web.xml 中配置 标签了。它等价的 web.xml 中的配置形式如下： 123&lt;listener&gt; &lt;listener-class&gt;footmark.servlet.SimpleListener&lt;/listener-class&gt; &lt;/listener&gt; @MultipartConfig该注解主要是为了辅助 Servlet 3.0 中 HttpServletRequest 提供的对上传文件的支持。该注解标注在 Servlet 上面，以表示该 Servlet 希望处理的请求的 MIME 类型是 multipart/form-data。另外，它还提供了若干属性用于简化对上传文件的处理。具体如下：表 5. @MultipartConfig 的常用属性 属性名 类型 是否可选 描述 fileSizeThreshold int 是 当数据量大于该值时，内容将被写入文件。 location String 是 存放生成的文件地址。 maxFileSize long 是 允许上传的文件最大值。默认值为 -1，表示没有限制。 maxRequestSize long 是 针对该 multipart/form-data 请求的最大数量，默认值为 -1，表示没有限制。 可插性支持如果说 3.0 版本新增的注解支持是为了简化 Servlet/ 过滤器 / 监听器的声明，从而使得 web.xml 变为可选配置， 那么新增的可插性 (pluggability) 支持则将 Servlet 配置的灵活性提升到了新的高度。熟悉 Struts2 的开发者都知道，Struts2 通过插件的形式提供了对包括 Spring 在内的各种开发框架的支持，开发者甚至可以自己为 Struts2 开发插件，而 Servlet 的可插性支持正是基于这样的理念而产生的。使用该特性，现在我们可以在不修改已有 Web 应用的前提下，只需将按照一定格式打成的 JAR 包放到 WEB-INF/lib 目录下，即可实现新功能的扩充，不需要额外的配置。 Servlet 3.0 引入了称之为“Web 模块部署描述符片段”的 web-fragment.xml 部署描述文件，该文件必须存放在 JAR 文件的 META-INF 目录下，该部署描述文件可以包含一切可以在 web.xml 中定义的内容。JAR 包通常放在 WEB-INF/lib 目录下，除此之外，所有该模块使用的资源，包括 class 文件、配置文件等，只需要能够被容器的类加载器链加载的路径上，比如 classes 目录等。 现在，为一个 Web 应用增加一个 Servlet 配置有如下三种方式 ( 过滤器、监听器与 Servlet 三者的配置都是等价的，故在此以 Servlet 配置为例进行讲述，过滤器和监听器具有与之非常类似的特性 )： 编写一个类继承自 HttpServlet，将该类放在 classes 目录下的对应包结构中，修改 web.xml，在其中增加一个 Servlet 声明。这是最原始的方式； 编写一个类继承自 HttpServlet，并且在该类上使用 @WebServlet 注解将该类声明为 Servlet，将该类放在 classes 目录下的对应包结构中，无需修改 web.xml 文件。 编写一个类继承自 HttpServlet，将该类打成 JAR 包，并且在 JAR 包的 META-INF 目录下放置一个 web-fragment.xml 文件，该文件中声明了相应的 Servlet 配置。web-fragment.xml 文件示例如下： 12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-fragment xmlns=http://java.sun.com/xml/ns/javaee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" version=\"3.0\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-fragment_3_0.xsd\" metadata-complete=\"true\"&gt; &lt;servlet&gt; &lt;servlet-name&gt;fragment&lt;/servlet-name&gt; &lt;servlet-class&gt;footmark.servlet.FragmentServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;fragment&lt;/servlet-name&gt; &lt;url-pattern&gt;/fragment&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-fragment&gt; 从上面的示例可以看出，web-fragment.xml 与 web.xml 除了在头部声明的 XSD 引用不同之外，其主体配置与 web.xml 是完全一致的。 由于一个 Web 应用中可以出现多个 web-fragment.xml 声明文件，加上一个 web.xml 文件，加载顺序问题便成了不得不面对的问题。Servlet 规范的专家组在设计的时候已经考虑到了这个问题，并定义了加载顺序的规则。 web-fragment.xml 包含了两个可选的顶层标签， 和 ，如果希望为当前的文件指定明确的加载顺序，通常需要使用这两个标签， 主要用于标识当前的文件，而 则用于指定先后顺序。一个简单的示例如下： 12345678910111213&lt;web-fragment...&gt; &lt;name&gt;FragmentA&lt;/name&gt; &lt;ordering&gt; &lt;after&gt; &lt;name&gt;FragmentB&lt;/name&gt; &lt;name&gt;FragmentC&lt;/name&gt; &lt;/after&gt; &lt;before&gt; &lt;others/&gt; &lt;/before&gt; &lt;/ordering&gt; ...&lt;/web-fragment&gt; 如上所示， 标签的取值通常是被其它 web-fragment.xml 文件在定义先后顺序时引用的，在当前文件中一般用不着，它起着标识当前文件的作用。 在 标签内部，我们可以定义当前 web-fragment.xml 文件与其他文件的相对位置关系，这主要通过 的 和 子标签来实现的。在这两个子标签内部可以通过 标签来指定相对应的文件。比如： 1234&lt;after&gt; &lt;name&gt;FragmentB&lt;/name&gt; &lt;name&gt;FragmentC&lt;/name&gt; &lt;/after&gt; 以上片段则表示当前文件必须在 FragmentB 和 FragmentC 之后解析。 的使用于此相同，它所表示的是当前文件必须早于 标签里所列出的 web-fragment.xml 文件。 除了将所比较的文件通过 在 和 中列出之外，Servlet 还提供了一个简化的标签 。它表示除了当前文件之外的其他所有的 web-fragment.xml 文件。该标签的优先级要低于使用 明确指定的相对位置关系。 除了以上的新特性之外，ServletContext 对象的功能在新版本中也得到了增强。现在，该对象支持在运行时动态部署 Servlet、过滤器、监听器，以及为 Servlet 和过滤器增加 URL 映射等。以 Servlet 为例，过滤器与监听器与之类似。ServletContext 为动态配置 Servlet 增加了如下方法： ServletRegistration.Dynamic addServlet(String servletName,Class&lt;? extends Servlet&gt; servletClass) ServletRegistration.Dynamic addServlet(String servletName, Servlet servlet) ServletRegistration.Dynamic addServlet(String servletName, String className) T createServlet(Class clazz) ServletRegistration getServletRegistration(String servletName) Map&lt;String,? extends ServletRegistration&gt; getServletRegistrations() 其中前三个方法的作用是相同的，只是参数类型不同而已；通过 createServlet() 方法创建的 Servlet，通常需要做一些自定义的配置，然后使用 addServlet() 方法来将其动态注册为一个可以用于服务的 Servlet。两个 getServletRegistration() 方法主要用于动态为 Servlet 增加映射信息，这等价于在 web.xml( 抑或 web-fragment.xml) 中使用 标签为存在的 Servlet 增加映射信息。 以上 ServletContext 新增的方法要么是在 ServletContextListener 的 contexInitialized 方法中调用，要么是在 ServletContainerInitializer 的 onStartup() 方法中调用。 ServletContainerInitializer 也是 Servlet 3.0 新增的一个接口，容器在启动时使用 JAR 服务 API(JAR Service API) 来发现 ServletContainerInitializer 的实现类，并且容器将 WEB-INF/lib 目录下 JAR 包中的类都交给该类的 onStartup() 方法处理，我们通常需要在该实现类上使用 @HandlesTypes 注解来指定希望被处理的类，过滤掉不希望给 onStartup() 处理的类。 HttpServletRequest 对文件上传的支持此前，对于处理上传文件的操作一直是让开发者头疼的问题，因为 Servlet 本身没有对此提供直接的支持，需要使用第三方框架来实现，而且使用起来也不够简单。如今这都成为了历史，Servlet 3.0 已经提供了这个功能，而且使用也非常简单。为此，HttpServletRequest 提供了两个方法用于从请求中解析出上传的文件： Part getPart(String name) Collection getParts() 前者用于获取请求中给定 name 的文件，后者用于获取所有的文件。每一个文件用一个 javax.servlet.http.Part 对象来表示。该接口提供了处理文件的简易方法，比如 write()、delete() 等。至此，结合 HttpServletRequest 和 Part 来保存上传的文件变得非常简单，如下所示： 123Part photo = request.getPart(\"photo\"); photo.write(\"/tmp/photo.jpg\"); // 可以将两行代码简化为 request.getPart(\"photo\").write(\"/tmp/photo.jpg\") 一行。 另外，开发者可以配合前面提到的 @MultipartConfig 注解来对上传操作进行一些自定义的配置，比如限制上传文件的大小，以及保存文件的路径等。其用法非常简单，故不在此赘述了。 需要注意的是，如果请求的 MIME 类型不是 multipart/form-data，则不能使用上面的两个方法，否则将抛异常。 总结Servlet 3.0 的众多新特性使得 Servlet 开发变得更加简单，尤其是异步处理特性和可插性支持的出现，必将对现有的 MVC 框架产生深远影响。虽然我们通常不会自己去用 Servlet 编写控制层代码，但是也许在下一个版本的 Struts 中，您就能切实感受到这些新特性带来的实质性改变。","categories":[{"name":"servlet","slug":"servlet","permalink":"http://blog.shagle.cn/categories/servlet/"}],"tags":[{"name":"servlet3.0","slug":"servlet3-0","permalink":"http://blog.shagle.cn/tags/servlet3-0/"}]},{"title":"Sharding-JDBC介绍","slug":"Sharding-JDBC介绍","date":"2019-01-21T09:37:31.000Z","updated":"2019-01-21T10:02:40.000Z","comments":true,"path":"2019/01/21/Sharding-JDBC介绍/","link":"","permalink":"http://blog.shagle.cn/2019/01/21/Sharding-JDBC介绍/","excerpt":"背景关系型数据库在大于一定数据量的情况下性能会急剧下降。在面对互联网海量数据的情况时,所有数据都存于一张表,显然很容易会达到数据表可承受的数据量阈值。单纯分表虽然可以解决数据量过大导致检索变慢的问题,但无法解决高并发情况下访问同一个库,导致数据库响应变慢的问题。所以通常水平拆分都至少要采用分库的方式,以一并解决大数据量&amp;;高并发的问题。但分表也有不可替代的…","text":"背景关系型数据库在大于一定数据量的情况下性能会急剧下降。在面对互联网海量数据的情况时,所有数据都存于一张表,显然很容易会达到数据表可承受的数据量阈值。单纯分表虽然可以解决数据量过大导致检索变慢的问题,但无法解决高并发情况下访问同一个库,导致数据库响应变慢的问题。所以通常水平拆分都至少要采用分库的方式,以一并解决大数据量&amp;;高并发的问题。但分表也有不可替代的… 1. 背景关系型数据库在大于一定数据量的情况下性能会急剧下降。在面对互联网海量数据的情况时,所有数据都存于一张表,显然很容易会达到数据表可承受的数据量阈值。单纯分表虽然可以解决数据量过大导致检索变慢的问题,但无法解决高并发情况下访问同一个库,导致数据库响应变慢的问题。所以通常水平拆分都至少要采用分库的方式,以一并解决大数据量&amp;;高并发的问题。但分表也有不可替代的场景。最常见的分表需求是事务问题。同一个库则不需要考虑分布式事务问题,善于使用同库不同表可有效的避免分布式事务带来的麻烦。目前,强一致性的分布式事务由于性能问题,导致使用起来性能并不一定会比不分库分表快,因此采用最终一致性的分布式事务居多。 2. 分库分表分库分表用于应对当前互联网常见的两个场景:大数据量 &amp;; 高并发。通常分为:垂直拆分 &amp;; 水平拆分。 垂直拆分是根据业务将一个库(表)拆分为多个库(表)。如:将经常和不经常访问的字段拆分至不同的库(表)中,与业务关系密切。 水平拆分是根据分片算法将一个库(表)拆分为多个库(表)。 3. Sharding-JDBCSharding-JDBC是当当应用框架ddframe中,从关系型数据库模块dd-rdb中分离出来的数据库水平分片框架,是继dubbox、elastic-job之后ddframe开源的第三个项目。 Sharding-JDBC直接分装jdbc协议,可理解为增强版的JDBC驱动,旧代码迁移成本几乎为零,定位为轻量级java框架,使用客户端直连数据库,以jar包形式提供服务,无proxy层。 主要包括以下特点: 可适用于任何基于java的ORM框架,如:JPA、Hibernate、Mybatis、Spring JDBC Template,或直接使用JDBC 可基于任何第三方的数据库连接池,如:DBCP、C3P0、Durid等 理论上可支持任意实现JDBC规范的数据库。目前仅支持mysql 分片策略灵活,可支持等号、between、in等多维度分片,也可支持多分片键。 SQL解析功能完善,支持聚合、分组、排序、limit、or等查询,并支持Binding Table以及笛卡尔积表查询。 性能高,单库查询QPS为原生JDBC的99.8%,双库查询QPS比单库增加94%。 架构 核心概念 LogicTable:数据分片的逻辑表,对于水平拆分的数据库(表)来说,是同一类表的总称。如:订单数据根据主键尾数拆分为10张表,分表是t order 0到t order 9,他们的逻辑表名为t_order。 ActualTable:分片数据中真实存在的物理表。 DataNode:数据分片的最小单元,由数据源名称和数据表组成。如:ds 1.t order_0。 DynamicTable:逻辑表和物理表不一定需要在配置规则中静态配置。如,按照日期分片的场景,物理表的名称随着时间的推移会产生变化。 BindingTable:指在任何场景下分片规则均一致的主表和子表。例:订单表和订单项表,均按照订单ID分片,则此两张表互为BindingTable关系。BindingTable关系的多表关联查询不会出现笛卡尔积关联,查询效率将大大提升。 ShardingColumn:分片字段用于将数据库(表)水平拆分的字段。 ShardingAlgorithm:分片算法。 SQL Hint:对于分片字段非SQL决定,而由其他外置条件决定的场景,可使用SQL Hint灵活的注入分片字段。 数据源分布规则配置 12345678910111213private Map&lt;String, DataSource&gt; createDataSourceMap(List&lt;Database&gt; dbs) &#123; if (CollectionUtils.isEmpty(dbs)) &#123; logger.error(\"db configuration is null!\"); return null; &#125; Map&lt;String, DataSource&gt; dataSourceMap = new HashMap&lt;&gt;(); for (Database db : dbs) &#123; dataSourceMap.put(db.getDbname(), createDataSource(db)); &#125; return dataSourceMap; &#125; DataSourceRule dataSourceRule = new DataSourceRule(createDataSourceMap(dataSourceProperties.getDbs())); 逻辑表&amp;;物理表映射 1TableRule orderTableRule =TableRule.builder(\"order\").actualTables(Arrays.asList(\"t_order_0\", \"t_order_1\")).dataSourceRule(dataSourceRule).build(); 分片策略配置 Sharding-jdbc认为对于分片策略有两种维度: 数据源分片策略(DatabaseShardingStrategy) 数据被分配的目标数据源。 表分片策略(TableShardingStrategy) 数据被分配的目标表,该目标表在该数据对应的目标数据源内。 123456789101112DatabaseShardingStrategy databaseShardingStrategy = new DatabaseShardingStrategy(\"user_id\", new ModuloDatabaseShardingAlgorithm()); TableShardingStrategy tableShardingStrategy = new TableShardingStrategy(\"order_id\", new ModuloTableShardingAlgorithm()); ShardingRule shardingRule = ShardingRule.builder() .dataSourceRule(dataSourceRule) .tableRules(Arrays.asList(orderTableRule, orderItemTableRule)) .databaseShardingStrategy(databaseShardingStrategy) .tableShardingStrategy(tableShardingStrategy) .build(); // ShardingDataSource DataSource shardingDataSource = ShardingDataSourceFactory.createDataSource(shardingRule); JDBC规范重写针对DataSource、Connection、Statement、PreparedStatement和ResultSet五个核心接口封装。 DataSource:ShardingDataSource Connetion:ShardingConnection ShardingConnection是一种逻辑上的分布式数据库链接,成员变量ShardingContext,即数据源运行的上下文信息。 ShardingContext包括:ShardingRule:分片规则;ExecutorEngine:执行引擎,通过多线程的方式并行执行SQL。 Statement:ShardingStatement PreparedStatement:ShardingPreparedStatement ResultSet:ShardingResultSet SQL解析 常见的SQL解析主要有:fdb/jsqlparser、Druid;sharding-jdbc 1.5.0.M1将SQL解析引擎从Druid换成了自研的解析引擎。 Sharding-jdbc支持join、aggregation、order by、group by、limit、or;目前不支持union、部分子查询、函数内分片等不太应在分片场景中出现的SQL解析。 SQL解析引擎在sharding-jdbc-core模块下com.dangdang.ddframe.rdb.sharding.parsing包下,包含两个组件: Lexer:词法解析器 Parser:SQL解析器 Lexer词法解析器关键类:LexerEngine、Lexer、Token、Tokenizer Lexer原理:顺序解析SQL,将字符串拆成N个Token。 通过Lexer#nextToken方法不断解析出Token Token结构(以select为例): SQL解析(以Select为例)关键类:SQLParsingEngine、AbstractSelectParser(MySQLSelectParser)、SelectStatement、ExpressionClauseParser(parse(SQLStatement)) SQLParseEngine:SQL解析引擎,parse()方法为SQL解析的入口。 - AbstractSelectParser(MySQLSelectParser):SQL解析器,和词法解析器Lexer类似,不同数据库有不同的实现。 - ExpressionClauseParser:解析SQLStatement。 SQL路由&amp;;改写 入口:ShardingPreparedStatement.route - 关键类:ShardingPreparedStatement、PreparedStatementRoutingEngine、ParsingSQLRouter、SimpleRoutingEngine 、ComplexRoutingEngine 、SQLRewriteEngine、 SQL执行 &amp;; 归并 入口:ShardingPreparedStatement.executeQuery 关键类:ShardingPreparedStatement、PreparedStatementExecutor、ExecutorEngine 入口:ShardingPreparedStatement.executeQuery 关键类:ShardingPreparedStatement、ShardingResultSet、MergeEngine 读写分离12345678910111213141516171819202122&lt;rdb:master-slave-data-source id=\"db_cluster0\" master-data-source-ref=\"db0\" slave-data-sources-ref=\"db0_slave1, db0_slave0\" /&gt; &lt;rdb:master-slave-data-source id=\"db_cluster1\" master-data-source-ref=\"db1\" slave-data-sources-ref=\"db1_slave0, db1_slave1\" /&gt; &lt;rdb:strategy id=\"databaseStrategy\" sharding-columns=\"user_id\" algorithm-class=\"com.bing.shardingjdbc.spring.algorithm.ModuloDatabaseShardingAlgorithm\" /&gt; &lt;rdb:strategy id=\"orderTableStrategy\" sharding-columns=\"order_id\" algorithm-expression=\"t_order_$&#123;order_id.longValue() % 2&#125;\" /&gt; &lt;rdb:strategy id=\"orderItemTableStrategy\" sharding-columns=\"order_id\" algorithm-class=\"com.bing.shardingjdbc.spring.algorithm.ModuloTableShardingAlgorithm\" /&gt; &lt;rdb:data-source id=\"shardingDataSource\"&gt; &lt;rdb:sharding-rule data-sources=\"db_cluster0, db_cluster1\" key-generator-class=\"com.dangdang.ddframe.rdb.sharding.keygen.DefaultKeyGenerator\"&gt; &lt;rdb:table-rules&gt; &lt;rdb:table-rule logic-table=\"order\" actual-tables=\"t_order_$&#123;0..1&#125;\" database-strategy=\"databaseStrategy\" table-strategy=\"orderTableStrategy\"&gt; &lt;rdb:generate-key-column column-name=\"order_id\" /&gt; &lt;/rdb:table-rule&gt; &lt;rdb:table-rule logic-table=\"order_item\" actual-tables=\"t_order_item_$&#123;0..1&#125;\" database-strategy=\"databaseStrategy\" table-strategy=\"orderItemTableStrategy\"&gt; &lt;rdb:generate-key-column column-name=\"item_id\" /&gt; &lt;/rdb:table-rule&gt; &lt;/rdb:table-rules&gt; &lt;/rdb:sharding-rule&gt; &lt;rdb:props&gt; &lt;prop key=\"metrics.enable\"&gt;true&lt;/prop&gt; &lt;prop key=\"sql.show\"&gt;true&lt;/prop&gt; &lt;/rdb:props&gt; &lt;/rdb:data-source&gt; 关键类:MasterSlaveDataSourceFactory、MasterSlaveDataSource、 MasterSlaveLoadBalanceStrategy(负载均衡策略,包括Random &amp;; RoundRobin)、默认主从负载均衡策略:轮询RoundRobinMasterSlaveLoadBalanceStrategy 分布式主键 Twitter snowflake 1位符号位,始终为0; 41位时间戳,一般实现上不会存储当前的时间戳,而是时间戳的差值(当前时间-固定的开始时间),这样可以使产生的id从更小值开始;41位时间戳可以使用69年,1L&lt;&lt;41/(1000L 60 60 24 365) = 69年 10位节点位,前五位数据中心标识,后五位机器标识,可以部署1024个节点 12位序列号,支持同一个节点同一毫秒可以生成4069个ID Sharding-JDBC :1bit符号位(为0),41bit时间位,10bit工作进程位,12bit序列位。 spring 配置: Flicker利用MySQL的auto increment、replace into、MyISAM,生成一个64位的ID。 - 先创建一个单独的数据库:如global id - 创建表: 123456CREATE TABLE global_id_64 ( id bigint(20) unsigned NOT NULL auto_increment, stub char(1) NOT NULL default '', PRIMARY KEY (id), UNIQUE KEY stub (stub) ) ENGINE=MyISAM 应用端在一个事务里提交: 12REPLACE INTO Tickets64 (stub) VALUES ('a'); SELECT LAST_INSERT_ID(); 解决单点问题:启用两台数据库服务器,通过区分auto_increment的起始值和步长来生成奇偶数的ID: 1234567Server1: auto-increment-increment = 2 //自增长字段每次递增的量 auto-increment-offset = 1//自增长字段开始值 Server2: auto-increment-increment = 2 auto-increment-offset = 2 应用端轮询取id柔性事务——最大努力送达型Sharding-JDBC最大努力送达型事务认为对该数据库的操作最终一定可以成功,因此通过最大努力反复尝试送达操作。 事务日志存储器 基于内存: 1SoftTransactionConfiguration.setStorageType(TransactionLogDataSourceType.MEMORY); 基于RDB: 1SoftTransactionConfiguration.setTransactionLogDataSource(txLogDataSource); 默认的storageType 为 RDB。 异步作业内嵌异步作业:// 使用内嵌异步作业,仅用于开发环境// 内嵌了一个注册中心,默认zookeeperPort 418112NestedBestEffortsDeliveryJobConfiguration nestedJobConfig = new NestedBestEffortsDeliveryJobConfiguration(); txConfig.setBestEffortsDeliveryJobConfiguration(Optional.of(nestedJobConfig)); 独立部署作业事务日志库用于异步作业的zk下载sharding-jdbc-transaction-async-job,通过start.sh脚本启动异步作业: 官网：https://github.com/apache/incubator-shardingsphere","categories":[{"name":"分布式","slug":"分布式","permalink":"http://blog.shagle.cn/categories/分布式/"}],"tags":[{"name":"Sharding-jdbc","slug":"Sharding-jdbc","permalink":"http://blog.shagle.cn/tags/Sharding-jdbc/"},{"name":"ShardingSphere","slug":"ShardingSphere","permalink":"http://blog.shagle.cn/tags/ShardingSphere/"}]},{"title":"阿里GTS开源版本fescar分布式事务发布了","slug":"阿里GTS开源版本fescar分布式事务发布了","date":"2019-01-18T06:51:58.000Z","updated":"2019-01-18T07:00:03.000Z","comments":true,"path":"2019/01/18/阿里GTS开源版本fescar分布式事务发布了/","link":"","permalink":"http://blog.shagle.cn/2019/01/18/阿里GTS开源版本fescar分布式事务发布了/","excerpt":"","text":"前言碎语阿里重磅开源fescar分布式事务框架、其前身是拥有多项专利的云分布式事务产品GTS、很早前阿里在推广GTS分布式事务的时候就隐隐透露过可能会有开源项目的推出，终于在社区千呼万唤之下fescar发布了。目前是0.1的版本，因为脱胎于商业产品，社区版本要上生产环境可能需要在社区迭代孵化一段时间。代码可以先拉下来研究一下，后期持续关注fescar的发展。 项目地址：https://github.com/alibaba/fescar 什么是FESCAR？ 一种分布式事务解决方案，具有高性能和易用性的微服务架构。 让我们想象一下传统的单片应用程序。其业务由3个模块构成。他们使用单个本地数据源。 当然，本地交易可以保证数据的一致性。 微服务架构发生了变化。提到的3个模块设计为3个不同数据源之上的3个服务（模式：每个服务的数据库）。本地事务自然保证每个服务中的数据一致性。 但整个业务逻辑范围如何呢？ FESCAR怎么做？FESCAR只是上述问题的解决方案。 首先，如何定义分布式事务？ 我们说，分布式事务是一个全局事务，由一批Branch Transation组成，通常Branch Transation只是本地事务。 FESACR有3个基本组件： 事务协调器（TC）：维护全局和分支事务的状态，驱动全局提交或回滚。 Transaction Manager（TM）：定义全局事务的范围：开始全局事务，提交或回滚全局事务。 资源管理器（RM）：管理分支事务的资源，与TC通信以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 FESCAR管理分布式事务的典型生命周期： TM要求TC开始新的全球交易。TC生成表示全局事务的XID。 XID通过微服务的调用链传播。 RM将本地事务注册为XID到TC的相应全局事务的分支。 TM要求TC提交或回滚XID的相应全局事务。 TC在XID的相应全局事务下驱动所有分支事务以完成分支提交或rollbaking。 有关原理和设计的更多详细信息，请访问FESCAR维基页面。 历史 TXC：淘宝交易构造函数。阿里巴巴中间件团队自2014年起启动该项目，以满足应用程序架构从单一服务变为微服务所导致的直接交易问题。 GTS：全球交易服务。TXC作为Aliyun中间件产品，新名称GTS自2016年起发布。 FESCAR：我们从2019年开始基于TXC / GTS开源开源项目FESCAR，以便与社区密切合作。","categories":[{"name":"分布式","slug":"分布式","permalink":"http://blog.shagle.cn/categories/分布式/"}],"tags":[]},{"title":"Spring 循环引用的处理","slug":"Spring中循环引用的处理","date":"2019-01-15T05:14:49.000Z","updated":"2019-01-15T05:30:02.000Z","comments":true,"path":"2019/01/15/Spring中循环引用的处理/","link":"","permalink":"http://blog.shagle.cn/2019/01/15/Spring中循环引用的处理/","excerpt":"在使用spring的场景中，有时会碰到如下的一种情况，即bean之间的循环引用。即两个bean之间互相进行引用的情况。这时，在spring xml配置文件中，就会出现如下的配置：","text":"在使用spring的场景中，有时会碰到如下的一种情况，即bean之间的循环引用。即两个bean之间互相进行引用的情况。这时，在spring xml配置文件中，就会出现如下的配置： 12&lt;bean id=\"beanA\" class=\"BeanA\" p:beanB-ref=\"beaB\"/&gt;&lt;bean id=\"beanB\" class=\"BeanB\" p:beanA-ref=\"beaA\"/&gt; 并且，在一般情况下，这个配置在现有的spring3.0中是可以正常工作的，前提是没有对beanA和beanB进行增强。但是，如果任意一方进行了增强，比如通过spring的代理对beanA进行了增强，即实际返回的对象和原始对象不一致的情况，在这种情况下，就会报如下一个错误： 123456&quot;Bean with name &apos;&quot; + beanName + &quot;&apos; has been injected into other beans [&quot; +StringUtils.collectionToCommaDelimitedString(actualDependentBeans) +&quot;] in its raw version as part of a circular reference, but has eventually been &quot; +&quot;wrapped. This means that said other beans do not use the final version of the &quot; +&quot;bean. This is often the result of over-eager type matching - consider using &quot; +&quot;&apos;getBeanNamesOfType&apos; with the &apos;allowEagerInit&apos; flag turned off, for example.&quot; 这个错误即对于一个bean，其所引用的对象并不是由spring容器最终生成的对象，而只是一个原始对象，而spring不允许这种情况出现，即持有过程中间对象。那么，这个错误是如何产生的，以及在spring内部，是如何来检测这种情况的呢。这就得从spring如何创建一个对象，以及如何处理bean间引用，以及spring使用何种策略处理循环引用问题说起。 这里会涉及到在spring内部所使用的两个内部属性，singletonFactories和earlySingletonObjects，这两个属性在类DefaultSingletonBeanRegistry中被定义，定义如下: 12345/** Cache of singleton factories: bean name --&gt; ObjectFactory */private final Map&lt;String, ObjectFactory&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&gt;(); /** Cache of early singleton objects: bean name --&gt; bean instance */private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(); 官方对此的属性定义不是很明确，这里我们可以这样来理解。 singletonFactories，用于存储在spring内部所使用的beanName-&gt;对象工厂的引用，一旦最终对象被创建(通过objectFactory.getObject())，此引用信息将删除 earlySingletonObjects，用于存储在创建Bean早期对创建的原始bean的一个引用，注意这里是原始bean，即使用工厂方法或构造方法创建出来的对象，一旦对象最终创建好，此引用信息将删除 从上面的解释，可以看出，这两个对象都是一个临时工。在所有的对象创建完毕之后，此两个对象的size都为0。 那么再来看下这两个对象如何进行协作： 方法1： 123456789101112131415161718/** * Add the given singleton factory for building the specified singleton * if necessary. * &lt;p&gt;To be called for eager registration of singletons, e.g. to be able to * resolve circular references. * @param beanName the name of the bean * @param singletonFactory the factory for the singleton object */protected void addSingletonFactory(String beanName, ObjectFactory singletonFactory) &#123; Assert.notNull(singletonFactory, \"Singleton factory must not be null\"); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125;&#125; 方法2： 12345678910111213141516171819202122232425/** * Return the (raw) singleton object registered under the given name. * &lt;p&gt;Checks already instantiated singletons and also allows for an early * reference to a currently created singleton (resolving a circular reference). * @param beanName the name of the bean to look for * @param allowEarlyReference whether early references should be created or not * @return the registered singleton object, or &lt;code&gt;null&lt;/code&gt; if none found */protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null);&#125; 方法3： 1234567891011121314/** * Add the given singleton object to the singleton cache of this factory. * &lt;p&gt;To be called for eager registration of singletons. * @param beanName the name of the bean * @param singletonObject the singleton object */protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; this.singletonObjects.put(beanName, (singletonObject != null ? singletonObject : NULL_OBJECT)); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125;&#125; 方法1和方法2中的官方注释都很明显地显示了，针对于循环引用的处理，即能够处理循环引用问题。 在方法1中，对象信息对beanFactory的形式被放入singletonFactories中，这时earlySingletonObjects中肯定没有此对象(因为remove)。 在方法2中，在一定条件下（allowEarlyReference为true）的条件下，对象从singleFactories中的objectFactory中被取出来，同时remove掉，被放入earlySingletonObjects中。这时,earlySingletonObjects就持有对象信息了；当然，如果allowEarlyReference为false的情况下，且earlySingletonObjects本身就没有持有对象的情况下，肯定不会将对象从objectFactory中取出来的。这个很重要，因为后面将根据此信息进行循环引用处理。 在方法3中，对象被加入到singletonObjects中，同时singletonFactories和earlySingletonObjects中都remove掉持有的对象（不管持有与否），这就表示在之前的处理中，这只相当于一个临时容器，处理完毕之后都会remove掉。 那么，我们来看这3个方法是不是按照先后顺序被调用的呢。代码顺序如下所示： 类AbstracBeanFactory获取bean。M-1 12345678protected &lt;T&gt; T doGetBean(final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123;if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; ……&#125; 进入getSingleton方法M-2 123456789Object singletonObject = this.singletonObjects.get(beanName); try &#123;//首先执行getObject方法，再执行finnaly中的addSingleton方法，即上文中的方法3 singletonObject = singletonFactory.getObject(); &#125;finally &#123;addSingleton(beanName, singletonObject); &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null); &#125; 查看singletonFactory.getObject(),即createBean(beanName, mbd, args),最终转向doCreateBean方法M-312345678910protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; instanceWrapper = createBeanInstance(beanName, mbd, args); addSingletonFactory(beanName, new ObjectFactory() &#123; public Object getObject() throws BeansException &#123; return getEarlyBeanReference(beanName, mbd, bean); &#125; &#125;); &#125; 上面代码会调用方法addSingletonFactory，即上文所说的方法1。那么方法2会在什么地方调用呢。答案在两个地点。 第一个地方，称之为调用点A，即在最开始获取bean时，会调用。 1Object sharedInstance = getSingleton(beanName); 此方法最终会调用到 1getSingleton(beanName, true) 这里传递了参数true。即会尝试解析singletonFactories。然而，在最开始创建对象时，singletonFactories中肯定不会持有对象信息，所以会返回null。 第二个地方，称之为调用点B，即在完成bean创建时，会有一个验证过程。即在方法M-3中，即在调用方法2之前。代码如下： 12345678910111213141516171819if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;String&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw 文章开头的异常。 &#125; &#125; &#125; 调用点B的逻辑有点多，后面的逻辑主要是作循环引用验证。注意在调用点B传递参数为false，即不会解析singletonFactories。 在正常的情况下，调用顺序如下：以下有无，表示是否持有对指定Bean的引用 method name singletonFactories earlySingletonObjects singletonObjects getSingleton(beanName, true) 无 无 无 doCreateBean(beanName,mdb,args) 有 无 无 getSingleton(beanName, true); 有 无 无 addSingleton(beanName, singletonObject) 无 无 有 但是出现循环引用之后呢，就会出现这种情况： method name singletonFactories earlySingletonObjects singletonObjects getSingleton(A, true); A无B无 A无B无 A无B无 doCreateBean(A,mdb,args) A有B无 A无B无 A无B无 populateBean(A, mbd, instanceWrapper) 解析B…… getSingleton(B, true) A有B无 A无B无 A无B无 doCreateBean(B,mdb,args) A有B有 A无B无 A无B无 populateBean(B, mbd, instanceWrapper)由B准备解析A…… getSingleton(A, true) A无B有 A有B无 A无B无 完成populateBean(B, mbd, instanceWrapper)解析…… addSingleton(B, singletonObject) A无B无 A有B无 A无B有 完成populateBean(A, mbd, instanceWrapper) A- = initializeBean(beanName, exposedObject, mbd)在initializeBean之后A变为A- getSingleton(A, false);验证 addSingleton(A, singletonObject) …… 在上面这个过程中，在对A进行验证时，就会从earlySingletonObjects中取得一个A，但是这个A和后面的A-可能不是同一个对象，这是因为有了beanPostProcessor存在，它可以改变bean的最终值，比如对原始bean进行封装，代理等。在这个过程中，出现了3个对象A,A-,B，而B中所持有的A对象为原始的A。如果这里的A和A-不是同一个对象，即产生了beanA有了beanB的引用，但beanB并没有beanA的引用，而是另一个beanA的引用。这肯定不满足条件。 那么我们来看spring对这种情况的处理，即在上文中的方法3，再次将代码贴在下面： 12345678910111213141516Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123;//判断点1 if (exposedObject == bean) &#123;//判断点2 exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123;判断点3 String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;String&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; 判断点4抛出对象不致异常。&#125; 上面有4个判断点，依次如下 判断点1，首先确定这个对象能从earlySingletonObjects中取出对象来，经过上面的分析，我们知道，在正常情况下，此对象为null，即不存在循环检测。而在循环引用中，此对象能够被取出来。 判断点2，再判断这个对象和当前通过beanPostProcessor处理过的对象是否相同，如果相同，表示对象没有经过修改，即A=A-，那么循环引用成立。无需处理 判断点3，判断当前对象A是否被其他对象所依赖，在循环引用中，已经处理了A和B，那么在依赖表中，即在属性dependentBeanMap和dependenciesForBeanMap中。其中A-&gt;B表示A依赖于B，B-&gt;A表示B依赖于A。那么在dependentBeanMap中就会出现两个entry，分别为A-&gt;B和B-&gt;A。这里A依赖于A，那么表示A已经被依赖，则进入进一步检测中。在检测中，将取得一个A的被依赖列表中的bean已经被创建的对象列表值。 判断点4，如果被依赖对象列表不为空，则表示出现循环引用。因为按照创建规则，如果A-&gt;B，则必须先创建B，而B-&gt;A，则必须先创建A。在这里，A被B依赖，就要求A必须在B之前被创建，而B又被A依赖，又要求A必须在B之前被创建。这创建的两个对象必须满足一致才可以。即在A-&gt;B中的两个对象，必须和B-&gt;A的两个对象，互相一致才可以，否则就不是循环引用。 至此，整个流程梳理清楚。那么，如何处理这种循环引用呢？答案其实也很简单，在xml中将两方的循环切掉。然后使用一个beanPostProcessor即可以，此beanPostProcessor必须要在放到所有beanPostPrcessor的最后面。然后此beanPostProcessor，这样写即可： 1234判断当前bean为beanABeanB beanB=beanFactory.getBean(“beanB”);beanA.setBeanB(beanB);beanB.setBeanA(beanA);","categories":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shagle.cn/categories/Spring/"}],"tags":[]},{"title":"Spring 循环依赖","slug":"Spring-循环依赖分析","date":"2019-01-15T02:43:02.000Z","updated":"2019-01-15T05:14:24.000Z","comments":true,"path":"2019/01/15/Spring-循环依赖分析/","link":"","permalink":"http://blog.shagle.cn/2019/01/15/Spring-循环依赖分析/","excerpt":"引言：循环依赖就是N个类中循环嵌套引用，如果在日常开发中我们用new 对象的方式发生这种循环依赖的话程序会在运行时一直循环调用，直至内存溢出报错。下面说一下Spring是如果解决循环依赖的。","text":"引言：循环依赖就是N个类中循环嵌套引用，如果在日常开发中我们用new 对象的方式发生这种循环依赖的话程序会在运行时一直循环调用，直至内存溢出报错。下面说一下Spring是如果解决循环依赖的。 第一种：构造器参数循环依赖Spring容器会将每一个正在创建的Bean 标识符放在一个“当前创建Bean池”中，Bean标识符在创建过程中将一直保持在这个池中，因此如果在创建Bean过程中发现自己已经在“当前创建Bean池”里时将抛出BeanCurrentlyInCreationException异常表示循环依赖；而对于创建完毕的Bean将从“当前创建Bean池”中清除掉。 首先我们先初始化三个Bean。 123456789101112131415public class StudentA &#123; private StudentB studentB ; public void setStudentB(StudentB studentB) &#123; this.studentB = studentB; &#125; public StudentA() &#123; &#125; public StudentA(StudentB studentB) &#123; this.studentB = studentB; &#125;&#125; 123456789101112131415public class StudentB &#123; private StudentC studentC ; public void setStudentC(StudentC studentC) &#123; this.studentC = studentC; &#125; public StudentB() &#123; &#125; public StudentB(StudentC studentC) &#123; this.studentC = studentC; &#125;&#125; 123456789101112131415public class StudentC &#123; private StudentA studentA ; public void setStudentA(StudentA studentA) &#123; this.studentA = studentA; &#125; public StudentC() &#123; &#125; public StudentC(StudentA studentA) &#123; this.studentA = studentA; &#125;&#125; OK，上面是很基本的3个类，，StudentA有参构造是StudentB。StudentB的有参构造是StudentC，StudentC的有参构造是StudentA ，这样就产生了一个循环依赖的情况，我们都把这三个Bean交给Spring管理，并用有参构造实例化 123456789 &lt;bean id=\"a\" class=\"com.zfx.student.StudentA\"&gt; &lt;constructor-arg index=\"0\" ref=\"b\"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;bean id=\"b\" class=\"com.zfx.student.StudentB\"&gt; &lt;constructor-arg index=\"0\" ref=\"c\"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;bean id=\"c\" class=\"com.zfx.student.StudentC\"&gt; &lt;constructor-arg index=\"0\" ref=\"a\"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 下面是测试类： 123456public class Test &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(\"com/zfx/student/applicationContext.xml\"); //System.out.println(context.getBean(\"a\", StudentA.class)); &#125;&#125; 执行结果报错信息为： 12Caused by: org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &apos;a&apos;: Requested bean is currently in creation: Is there an unresolvable circular reference? 如果大家理解开头那句话的话，这个报错应该不惊讶，Spring容器先创建单例StudentA，StudentA依赖StudentB，然后将A放在“当前创建Bean池”中，此时创建StudentB,StudentB依赖StudentC ,然后将B放在“当前创建Bean池”中,此时创建StudentC，StudentC又依赖StudentA， 但是，此时Student已经在池中，所以会报错，，因为在池中的Bean都是未初始化完的，所以会依赖错误 ，（初始化完的Bean会从池中移除） 第二种：setter方式单例，默认方式如果要说setter方式注入的话，我们最好先看一张Spring中Bean实例化的图 如图中前两步骤得知：Spring是先将Bean对象实例化之后再设置对象属性的 修改配置文件为set方式注入 12345678910&lt;!--scope=\"singleton\"(默认就是单例方式) --&gt;&lt;bean id=\"a\" class=\"com.zfx.student.StudentA\" scope=\"singleton\"&gt; &lt;property name=\"studentB\" ref=\"b\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"b\" class=\"com.zfx.student.StudentB\" scope=\"singleton\"&gt; &lt;property name=\"studentC\" ref=\"c\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"c\" class=\"com.zfx.student.StudentC\" scope=\"singleton\"&gt; &lt;property name=\"studentA\" ref=\"a\"&gt;&lt;/property&gt;&lt;/bean&gt; 下面是测试类： 123456public class Test &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(\"com/zfx/student/applicationContext.xml\"); System.out.println(context.getBean(\"a\", StudentA.class)); &#125;&#125; 打印结果为： 1com.zfx.student.StudentA@1fbfd6 为什么用set方式就不报错了呢 ？ 我们结合上面那张图看，Spring先是用构造实例化Bean对象 ，此时Spring会将这个实例化结束的对象放到一个Map中，并且Spring提供了获取这个未设置属性的实例化对象引用的方法。 结合我们的实例来看，，当Spring实例化了StudentA、StudentB、StudentC后，紧接着会去设置对象的属性，此时StudentA依赖StudentB，就会去Map中取出存在里面的单例StudentB对象，以此类推，不会出来循环的问题喽、 下面是Spring源码中的实现方法，。以下的源码在Spring的Bean包中的DefaultSingletonBeanRegistry.java类中 12345678910111213141516171819202122232425262728293031/** Cache of singleton objects: bean name --&gt; bean instance（缓存单例实例化对象的Map集合） */ private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(64); /** Cache of singleton factories: bean name --&gt; ObjectFactory（单例的工厂Bean缓存集合） */ private final Map&lt;String, ObjectFactory&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&gt;(16); /** Cache of early singleton objects: bean name --&gt; bean instance（早期的单身对象缓存集合） */ private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(16); /** Set of registered singletons, containing the bean names in registration order（单例的实例化对象名称集合） */ private final Set&lt;String&gt; registeredSingletons = new LinkedHashSet&lt;String&gt;(64); /** * 添加单例实例 * 解决循环引用的问题 * Add the given singleton factory for building the specified singleton * if necessary. * &lt;p&gt;To be called for eager registration of singletons, e.g. to be able to * resolve circular references. * @param beanName the name of the bean * @param singletonFactory the factory for the singleton object */ protected void addSingletonFactory(String beanName, ObjectFactory singletonFactory) &#123; Assert.notNull(singletonFactory, \"Singleton factory must not be null\"); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125; &#125; 第三种：setter方式原型，prototype修改配置文件为： 123456789&lt;bean id=\"a\" class=\"com.zfx.student.StudentA\" scope=\"prototype\"&gt; &lt;property name=\"studentB\" ref=\"b\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"b\" class=\"com.zfx.student.StudentB\" scope=\"prototype\"&gt; &lt;property name=\"studentC\" ref=\"c\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"c\" class=\"com.zfx.student.StudentC\" scope=\"prototype\"&gt; &lt;property name=\"studentA\" ref=\"a\"&gt;&lt;/property&gt;&lt;/bean&gt; scope=&quot;prototype&quot; 意思是 每次请求都会创建一个实例对象。两者的区别是：有状态的bean都使用Prototype作用域，无状态的一般都使用singleton单例作用域。测试用例： 1234567public class Test &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext(\"com/zfx/student/applicationContext.xml\"); //此时必须要获取Spring管理的实例，因为现在scope=\"prototype\" 只有请求获取的时候才会实例化对象 System.out.println(context.getBean(\"a\", StudentA.class)); &#125;&#125; 打印结果： 12Caused by: org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &apos;a&apos;: Requested bean is currently in creation: Is there an unresolvable circular reference? 注意：对于“singleton”作用域bean，可以通过“setAllowCircularReferences(false）；”来禁用循环引用。 为什么原型模式就报错了呢 ？ 对于“prototype”作用域Bean，Spring容器无法完成依赖注入，因为“prototype”作用域的Bean，Spring容器不进行缓存，因此无法提前暴露一个创建中的Bean。 面试官：spring循环依赖是怎么解决的？ 回答：循环依赖就是循环引用，就是两个或多个Bean相互之间的持有对方，比如CircleA引用CircleB，CircleB引用CircleA，则它们最终反映为一个环。 Spring如何解决循环依赖？ 假设场景如下，A-&gt;B-&gt;A 1、实例化A，并将未注入属性的A暴露出去，即提前曝光给容器Wrap 2、开始为A注入属性，发现需要B，调用getBean（B） 3、实例化B，并注入属性，发现需要A的时候，从单例缓存中查找，没找到时继而从Wrap中查找，从而完成属性的注入 4、递归完毕之后回到A的实例化过程，A将B注入成功，并注入A的其他属性值，自此即完成了循环依赖的注入 spring中的循环依赖会有3种情况： 1.构造器循环依赖 构造器的循环依赖是不可以解决的，spring容器将每一个正在创建的bean标识符放在一个当前创建bean池中，在创建的过程一直在里面，如果在创建的过程中发现已经存在这个池里面了，这时就会抛出异常表示循环依赖了。 2.setter循环依赖 对于setter的循环依赖是通过spring容器提前暴露刚完成构造器注入，但并未完成其他步骤（如setter注入）的bean来完成的，而且只能决定单例作用域的bean循环依赖，通过提前暴露一个单例工厂方法，从而使其他的bean能引用到该bean.当你依赖到了该Bean而单例缓存里面有没有该Bean的时候就会调用该工厂方法生产Bean， Spring是先将Bean对象实例化之后再设置对象属性的 Spring先是用构造实例化Bean对象，此时Spring会将这个实例化结束的对象放到一个Map中，并且Spring提供了获取这个未设置属性的实例化对象引用的方法。 为什么不把Bean暴露出去，而是暴露个Factory呢？因为有些Bean是需要被代理的 3.prototype范围的依赖 对于“prototype”作用域bean，Spring容器无法完成依赖注入，因为“prototype”作用域的bean，Spring容器不进行缓存，因此无法提前暴露一个创建中的Bean。","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[]},{"title":"Spring 加载BeanDefinitionReader","slug":"spring-BeanDefinitionReader","date":"2019-01-11T02:55:58.000Z","updated":"2019-01-11T03:11:23.000Z","comments":true,"path":"2019/01/11/spring-BeanDefinitionReader/","link":"","permalink":"http://blog.shagle.cn/2019/01/11/spring-BeanDefinitionReader/","excerpt":"","text":"1. 基本概念BeanDefinitionReader ，该接口的作用就是加载 Bean。 在 Spring 中，Bean 一般来说都在配置文件中定义。而在配置的路径由在 web.xml 中定义。所以加载 Bean 的步骤大致就是： 加载资源，通过配置文件的路径（Location）加载配置文件（Resource） 解析资源，通过解析配置文件的内容得到 Bean。 下面来看它的接口定义： 1234567891011121314151617181920212223public interface BeanDefinitionReader &#123; BeanDefinitionRegistry getRegistry(); @Nullable ResourceLoader getResourceLoader(); @Nullable ClassLoader getBeanClassLoader(); BeanNameGenerator getBeanNameGenerator(); // 通过 Resource 加载 Bean int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException; // 通过 Resource 加载 Bean int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException; // 通过 location 加载 Bean int loadBeanDefinitions(String location) throws BeanDefinitionStoreException; int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException;&#125; 具体的继承关系如下： 2. 流程分析首先来看 Spring Ioc 容器从启动开始到调用 BeanDefinitionReader 加载 Bean 的过程如下： 注意：由于这里采用 XML 文件作为 Spring 的配置文件，所以默认调用 XmlBeanDefinitionReader 来处理 2.1.通过 BeanFactory 加载 Bean在 Spring 容器（ApplicationContext）内部存在一个内部容器（BeanFactory）负责 Bean 的创建与管理。 在创建完 BeanFactory ，下一步就是要去加载 Bean。它由loadBeanDefinitions方法负责。 1234567891011121314151617181920212223//实现父类抽象的载入bean定义方法@Overrideprotected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; //创建XmlBeanDefinitionReader，即创建Bean读取器，并通过回调设置到容器中去，容器使用读取器读取Bean定义资源 // Create a new XmlBeanDefinitionReader for the given BeanFactory. XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // 为Bean读取器设置Spring资源加载器，AbstractXmlApplicationContext的祖先父类AbstractApplicationContext继承DefaultResourceLoader，因此，容器本身也是一个资源加载器 // Configure the bean definition reader with this context's // resource loading environment. beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); //为Bean读取设置SAX xml解析器 beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); //当Bean读取器读取Bean定义的xml资源文件时，启用xml的校验机制 // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. initBeanDefinitionReader(beanDefinitionReader); //Bean读取器真正实现加载的方法 loadBeanDefinitions(beanDefinitionReader);&#125; 观察代码，该方法的主要目的是创建了 BeanDefinitionReader ，并由它去加载 Bean。具体过程如下： 创建 BeanDefinitionReader 设置 BeanDefinitionReader 的相关属性 初始化 BeanDefinitionReader 通过 BeanDefinitionReader 加载 Bean 2.2.通过 BeanDefinitionReader 加载 Bean在创建完 BeanDefinitionReader 后，则就需要通过它来 加载 Bean，过程如下： 1234567891011121314151617//xml Bean读取器加载Bean定义资源protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; //获取Bean定义资源的定位 Resource[] configResources = getConfigResources(); if (configResources != null) &#123; //Xml bean 读取器调用其父类AbstractBeanDefinitionReader读取定位的Bean定义资源 reader.loadBeanDefinitions(configResources); &#125; //如果子类中获取的Bean定义资源位为空，则获取FileSystemXmlApplicationContext //构造方法中setConfigLocations方法设置的资源 String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; //xml Bean读取器调用其父类AbstractBeanDefinitionReader读取定位的Bean定义资源 reader.loadBeanDefinitions(configLocations); &#125;&#125; 2.3.通过 Location 加载 Bean加载的 Bean 的责任被交给了 BeanDefinitionReader ，下面来看看该类的 loadBeanDefinitions 方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public int loadBeanDefinitions(String location, @Nullable Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; //获取在IOC容器初始化过程中设置的资源加载器 ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) &#123; throw new BeanDefinitionStoreException( \"Cannot import bean definitions from location [\" + location + \"]: no ResourceLoader available\"); &#125; if (resourceLoader instanceof ResourcePatternResolver) &#123; // Resource pattern matching available. try &#123; //将指定位置的Bean定义资源文件解析为Spring IOC容器封装的资源 //加载多个指定位置的Bean定义资源文件 Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); //委派调用其子类XmlBeanDefinitionReader的方法，实现加载功能 int loadCount = loadBeanDefinitions(resources); if (actualResources != null) &#123; for (Resource resource : resources) &#123; actualResources.add(resource); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded \" + loadCount + \" bean definitions from location pattern [\" + location + \"]\"); &#125; return loadCount; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( \"Could not resolve bean definition resource pattern [\" + location + \"]\", ex); &#125; &#125; else &#123; //将指定位置的bean定义资源文件解析为Spring IOC容器封装的资源， //加载单个指定位置的Bean定义资源文件 // Can only load single resources by absolute URL. Resource resource = resourceLoader.getResource(location); //委派调用其子类XmlBeanDefinitionReader的方法，实现加载功能 int loadCount = loadBeanDefinitions(resource); if (actualResources != null) &#123; actualResources.add(resource); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded \" + loadCount + \" bean definitions from location [\" + location + \"]\"); &#125; return loadCount; &#125;&#125;@Overridepublic int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException &#123; Assert.notNull(locations, \"Location array must not be null\"); int counter = 0; for (String location : locations) &#123; //此处loadBeanDefinitions并没有实现，具体实现在各个子类中 //比如XmlBeanDefinitionReader中 counter += loadBeanDefinitions(location); &#125; return counter;&#125; 观察代码，该方法的工作流程可分为四个步骤： 取得资源加载器 加载资源，通过 location 利用 ResourceLoader 加载 通过 Resource 加载 Bean 2.4.通过 Resource 加载 Bean在得到资源（Resource）后，该方法对它进行了封装，使其变成一个 EncodedResource 对象。 1234567891011//XmlBeanDefinitionReader加载资源的入口方法@Overridepublic int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &#123; //将读入的XML资源进行特殊编码处理 return loadBeanDefinitions(new EncodedResource(resource));&#125;public EncodedResource(Resource resource) &#123; this(resource, null, null);&#125; 2.5.通过 EncodedResource 加载 Bean1234567891011121314151617181920212223242526272829303132333435363738394041424344//这里是载入XML形式Bean定义资源文件方法public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Assert.notNull(encodedResource, \"EncodedResource must not be null\"); if (logger.isInfoEnabled()) &#123; logger.info(\"Loading XML bean definitions from \" + encodedResource); &#125; Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException( \"Detected cyclic loading of \" + encodedResource + \" - check your import definitions!\"); &#125; try &#123; //将资源文件转为InputStream的IO流 InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; //从InputStream中得到XML的解析源 InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; //这里是具体的读取过程 return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; //关闭充Resource中得到的IO流 inputStream.close(); &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( \"IOException parsing XML document from \" + encodedResource.getResource(), ex); &#125; finally &#123; currentResources.remove(encodedResource); if (currentResources.isEmpty()) &#123; this.resourcesCurrentlyBeingLoaded.remove(); &#125; &#125;&#125; 取得已加载的资源集合 将当前资源添加到集合 将资源转换成流 通过流创建 InputSource ，并设置编码 通过 InputSource 加载 Bean 2.6.通过 InputSource 加载 Bean之所以把 Resource 转换成 InputSource ，就是为了 SAX 解析作准备。 123456789101112131415161718192021222324252627282930313233343536373839//从特定XML文件中实际载入Bean定义资源的方法protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; //将xml文件转为DOM对象，解析过程由documentLoader实现 Document doc = doLoadDocument(inputSource, resource); //这里是启动对Bean定义解析的详细过程，该解析过程会用到Spring的Bean配置规则 return registerBeanDefinitions(doc, resource); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (SAXParseException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"Line \" + ex.getLineNumber() + \" in XML document from \" + resource + \" is invalid\", ex); &#125; catch (SAXException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"XML document from \" + resource + \" is invalid\", ex); &#125; catch (ParserConfigurationException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Parser configuration exception parsing XML from \" + resource, ex); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"IOException parsing XML document from \" + resource, ex); &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Unexpected exception parsing XML document from \" + resource, ex); &#125;&#125;// 解析 XML 文件，并返回 Document 对象。protected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception &#123; return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware());&#125; 3.Bean 注册上一步中 XmlBeanDefinitionReader 已经取得了 XML 的 Document 对象，完成了资源的解析过程。 下一步就是 Bean 的注册过程。 123456789101112131415//注册bean//按照Spring的bean语义要求将bean定义资源解析并转换为容器内部数据接口public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; //得到BeanDefinitionDocumentReader来对xml格式的BeanDefinition解析 //先实例化一个BeanDefinitionDocumentReader，这个对象是通过BeanUtils.instantiateClass方法实例化出来的 //实际上BeanUtils.instantiateClass中是封装了Java的反射的一些方法，通过基本的Java反射来构造实例。 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); //获取容器中注册的Bean数量 int countBefore = getRegistry().getBeanDefinitionCount(); //解析过程入口，这里使用了委派模式，BeanDefinitionDocumentReader只是个接口， //具体的解析实现过程有实现类DefaultBeanDefinitionDocumentReader完成 documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); //统计解析的Bean数量 return getRegistry().getBeanDefinitionCount() - countBefore;&#125; 4. 总结分析完 BeanDefinitionReader 具体工作流程，最后通过一个图简单阐述：","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"BeanDefinitionReader","slug":"BeanDefinitionReader","permalink":"http://blog.shagle.cn/tags/BeanDefinitionReader/"}]},{"title":"Spring IOC容器的初始化过程","slug":"Spring-IOC容器的初始化过程","date":"2019-01-10T15:59:13.000Z","updated":"2019-01-10T07:59:41.000Z","comments":true,"path":"2019/01/10/Spring-IOC容器的初始化过程/","link":"","permalink":"http://blog.shagle.cn/2019/01/10/Spring-IOC容器的初始化过程/","excerpt":"Spring IOC容器初始化过程分为Resource定位，载入解析，注册。IOC容器初始化过程中不包含Bean的依赖注入。Bean的依赖注入一般会发生在第一次通过getBean向容器索取Bean的时候。","text":"Spring IOC容器初始化过程分为Resource定位，载入解析，注册。IOC容器初始化过程中不包含Bean的依赖注入。Bean的依赖注入一般会发生在第一次通过getBean向容器索取Bean的时候。 ClassPathXmlApplicationContext初始化过程实际的构造方法： 12345678910111213public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; //super方法为容器设置好Bean资源加载器 //该方法最终会调用到AbstractApplicationContext的无参构造方法 //这里会默认设置解析路径的模式为Ant-style super(parent); //设置Bean定义资源文件的路径 setConfigLocations(configLocations); if (refresh) &#123; //调用容器的refresh，载入BeanDefinition的入口 refresh(); &#125;&#125; refresh()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // 调用容器准备刷新的方法，此方法中会获取容器的当前时间，给容器设置同步标识 //初始化前的准备工作，例如对系统属性或环境变量进行准备以及验证。 prepareRefresh(); //通知子类启动refreshBeanFactory的调用 //初始化BeanFactory，并进行XML文件读取 //ClassPathXmlApplicationContext包含着BeanFactory所提供的一切特征 //这一步会复用BeanFactory中的配置文件读取解析以及其他功能 //这一步之后ClassPathXmlApplicationContext已经包含了BeanFactory所提供的功能，可以进行Bean的提取等基础操作了。 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); //准备当前上下文用的BeanFactory，为BeanFactory配置容器特性，例如类加载器，事件处理器等各种功能填充。 //对BeanFactory各种功能的填充，比如@Qualifier和@Autowired注解就是在这一步增加的支持 prepareBeanFactory(beanFactory); try &#123; //为子类设置BeanFactory的后置处理器 //子类覆盖方法做额外的处理。 postProcessBeanFactory(beanFactory); //调用BeanFactoryPostProcessor，激活各种BeanFactory处理器 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. //注册拦截Bean创建的Bean处理器，这里只是注册，真正调用实在getBean的时候。 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. //为上下文初始化Message源，国际化处理 initMessageSource(); // Initialize event multicaster for this context. //初始化应用消息广播器，并放入applicationEventMulticaster bean中 initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. 留给子类来初始化其他的Bean onRefresh(); // Check for listener beans and register them. 在所有注册的bean中查找Listener bean，注册到消息广播器中 registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. //初始化剩下的单实例，非惰性的 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. 完成刷新过程，通知生命周期处理器lifecycleProcessor刷新过程，同时发出ContextRefreshEvent通知别人 finishRefresh(); &#125; catch (BeansException ex) &#123; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &apos;active&apos; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; &#125;&#125; 重点看下ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();这句，告诉子类启动refreshBeanFactory方法以及通过getBeanFactory获得BeanFactory： 12345678protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory); &#125; return beanFactory;&#125; refreshBeanFactory方法在AbstractRefreshableApplicationContext实现： 123456789101112131415161718192021protected final void refreshBeanFactory() throws BeansException &#123; //如果已经存在BeanFactory，销毁并关闭 if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; //创建IOC容器，创建了DefaultListableBeanFactory容器，给ApplicationContext使用 DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); //启动对BeanDefinitions的载入 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex); &#125;&#125; 对BeanDefinition的载入，loadBeanDefinitions方法： 1234567891011121314protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; //创建bean读取器，容器使用该读取器去读取Bean定义资源 XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); //配置bean读取器 beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); //当Bean读取器读取Bean定义的xml资源文件时，启用xml的校验机制 initBeanDefinitionReader(beanDefinitionReader); //通过beanDefinitionReader加载BeanDefinitions loadBeanDefinitions(beanDefinitionReader);&#125; loadBeanDefinitions(beanDefinitionReader)方法： 123456789101112protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; //获得Bean配置文件的资源位置 Resource[] configResources = getConfigResources(); if (configResources != null) &#123; reader.loadBeanDefinitions(configResources); &#125; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; //最终还是转换成Resource的形式去加载资源 reader.loadBeanDefinitions(configLocations); &#125;&#125; 在AbstractBeanDefinitionReader中的loadBeanDefinitions(configResources)方法： 12345678910public int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException &#123; Assert.notNull(resources, &quot;Resource array must not be null&quot;); int counter = 0; for (Resource resource : resources) &#123; //此处loadBeanDefinitions并没有实现，具体实现在各个子类中 //比如XmlBeanDefinitionReader中 counter += loadBeanDefinitions(resource); &#125; return counter;&#125; XmlBeanDefinitionReader中的loadBeanDefinitions方法： 12345678910111213141516171819202122232425public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; try &#123; //得到xml文件的InputStream InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; //得到InputSource InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; //doLoadBeanDefinitions是从xml文件中加载BeanDefinitions return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; &#125; catch (IOException ex) &#123;......&#125; finally &#123;......&#125;&#125; xml配置文件的读取以及转化为Bean对象的过程当Spring定位到xml之后，将xml转换为文件流的形式，作为InputSource和Resource对象传递给文档解析器进行解析，文档解析的开始是XmlDefinitionReader的doLoadBeanDefinitions方法。 1234567891011121314//inputSource是SAX的InputSource//resource对象是对xml文件描述的一个对象protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; //xml的解析模式 int validationMode = getValidationModeForResource(resource); //将inputResource解析为Document对象 Document doc = this.documentLoader.loadDocument( inputSource, getEntityResolver(), this.errorHandler, validationMode, isNamespaceAware()); //Document传递给registerBeanDefinitions方法 //此方法才是真正把Document对象解析为BeanDefinition对象的具体实现 return registerBeanDefinitions(doc, resource); &#125;&#125; registerBeanDefinitions方法： 1234567891011121314151617public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; // Support old XmlBeanDefinitionParser SPI for backwards-compatibility. if (this.parserClass != null) &#123; XmlBeanDefinitionParser parser = (XmlBeanDefinitionParser) BeanUtils.instantiateClass(this.parserClass); return parser.registerBeanDefinitions(this, doc, resource); &#125; //先实例化一个BeanDefinitionDocumentReader，这个对象是通过BeanUtils.instantiateClass方法实例化出来的 //实际上BeanUtils.instantiateClass中是封装了Java的反射的一些方法，通过基本的Java反射来构造实例。 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); //记录下注册之前BeanDefinition中对象的个数。 int countBefore = getRegistry().getBeanDefinitionCount(); //开始解析Document documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;&#125; DefaultBeanDefinitionDocumentReader类中的registerBeanDefinitions方法： 1234567//在这里解析Documentpublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; logger.debug(&quot;Loading bean definitions&quot;); Element root = doc.getDocumentElement(); doRegisterBeanDefinitions(root);&#125; doRegisterBeanDefinitions方法： 1234567891011121314151617181920212223protected void doRegisterBeanDefinitions(Element root) &#123; String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; Assert.state(this.environment != null, &quot;environment property must not be null&quot;); String[] specifiedProfiles = StringUtils.tokenizeToStringArray(profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!this.environment.acceptsProfiles(specifiedProfiles)) &#123; return; &#125; &#125; //BeanDefinitionParserDelegate对象描述了Spring中bean节点中定义的所有属性和子节点 BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createHelper(readerContext, root, parent); //xml解析的预处理，可以自己定义一些节点属性等，此方法Spring默认实现为空 preProcessXml(root); //把Document对象解析为BeanDefinition对象 parseBeanDefinitions(root, this.delegate); //xml解析的后处理，可以在解析完xml之后，实现自己的逻辑。Spring默认实现为空。 postProcessXml(root); this.delegate = parent;&#125; parseBeanDefinitions方法： 12345678910111213141516171819202122232425262728//解析在root级别的元素，比如import，alias，beanprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; //校验是不是Spring的默认命名空间。 //默认命名空间是http://www.springframework.org/schema/beans //如果是Spring的默认命名空间，就按照默认命名空间来解析，否则就按照自定义标签来解析 if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; //查看子节点是不是默认命名空间，是就按照默认解析，不是就按照自定义标签进行解析 if (delegate.isDefaultNamespace(ele)) &#123; //解析Spring默认的标签 parseDefaultElement(ele, delegate); &#125; else &#123; //解析自定义标签 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; //解析自定义标签 delegate.parseCustomElement(root); &#125;&#125; 解析默认的标签，parseDefaultElement方法： 12345678910111213141516//此方法会依次解析文档中的import，alias，bean，beans标签private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; processAliasRegistration(ele); &#125; else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // recurse doRegisterBeanDefinitions(ele); &#125;&#125; import标签的解析，importBeanDefinitionResource方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950protected void importBeanDefinitionResource(Element ele) &#123; //获取import标签中的resource属性，此属性表示资源地址 //resource属性不可为空 String location = ele.getAttribute(RESOURCE_ATTRIBUTE); if (!StringUtils.hasText(location)) &#123; getReaderContext().error(&quot;Resource location must not be empty&quot;, ele); return; &#125; // 解析resource中的占位符为真正的路径，比如&quot;$&#123;user.dir&#125;&quot; location = environment.resolveRequiredPlaceholders(location); Set&lt;Resource&gt; actualResources = new LinkedHashSet&lt;Resource&gt;(4); // 解析路径，判断是相对路径还是绝对路径 boolean absoluteLocation = false; try &#123; absoluteLocation = ResourcePatternUtils.isUrl(location) || ResourceUtils.toURI(location).isAbsolute(); &#125; catch (URISyntaxException ex) &#123;...&#125; //绝对路径 if (absoluteLocation) &#123; try &#123; //递归调用Bean的解析过程 int importCount = getReaderContext().getReader().loadBeanDefinitions(location, actualResources); &#125; &#125; else &#123;//相对路径，计算出绝对路径，进行递归调用解析过程 try &#123; int importCount; Resource relativeResource = getReaderContext().getResource().createRelative(location); if (relativeResource.exists()) &#123; importCount = getReaderContext().getReader().loadBeanDefinitions(relativeResource); actualResources.add(relativeResource); &#125; else &#123; String baseLocation = getReaderContext().getResource().getURL().toString(); importCount = getReaderContext().getReader().loadBeanDefinitions( StringUtils.applyRelativePath(baseLocation, location), actualResources); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Imported &quot; + importCount + &quot; bean definitions from relative location [&quot; + location + &quot;]&quot;); &#125; &#125; catch (IOException ex) &#123;......&#125; &#125; //解析完成后进行监听器激活处理 Resource[] actResArray = actualResources.toArray(new Resource[actualResources.size()]); getReaderContext().fireImportProcessed(location, actResArray, extractSource(ele));&#125; 总结 IOC容器初始化入口是在构造方法中调用refresh开始的。 通过ResourceLoader来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身就给除了ResourceLoader的实现。 创建的IOC容器是DefaultListableBeanFactory。 IOC对Bean的管理和依赖注入功能的实现是通过对其持有的BeanDefinition进行相关操作来完成的。 通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册。 XmlBeanDefinitionReader是BeanDefinitionReader的实现了，通过它来解析xml配置中的bean定义。 实际的处理过程是委托给BeanDefinitionParserDelegate来完成的。得到Bean的定义信息，这些信息在Spring中使用BeanDefinition对象来表示。 BeanDefinition的注册是由BeanDefinitionRegistry实现的registerBeanDefiition方法进行的。内部使用ConcurrentHashMap来保存BeanDefiition。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shagle.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shagle.cn/tags/Spring/"},{"name":"IOC","slug":"IOC","permalink":"http://blog.shagle.cn/tags/IOC/"}]},{"title":"Spring源码深度解析(1)","slug":"Spring源码深度解析1","date":"2019-01-10T14:07:37.000Z","updated":"2019-01-10T15:21:31.000Z","comments":true,"path":"2019/01/10/Spring源码深度解析1/","link":"","permalink":"http://blog.shagle.cn/2019/01/10/Spring源码深度解析1/","excerpt":"","text":"第1章无 第2章 容器的基本实现源码分析是一件非常煎熬非常有挑战性的任务，你准备好开始战斗了吗？在正式开始分析 Spring 源码之前，我们有必要先来回顾一下 Spring 中最简单的用法，尽管我相信您已经对这个例子非常熟悉了。 2.1 容器基本用法bean是Spring中最核心的东西，因为Spring就像是个大水桶，而bean就像是容器中的水，水桶脱离了水便也没什么用处了，那么我们先看看bean的定义。 123456789public class MyTestBean &#123; private String testStr = \"testStr\"; public String getTestStr() &#123; return testStr; &#125; public void setTestStr(String testStr) &#123; this.testStr = testStr; &#125;&#125; 很普通，bean没有任何特别之处，的确，Spring的目的就是让我们的bean能成为一个纯粹的POJO，这也是Spring所追求的。接下来看看配置文件：1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.Springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.Springframework.org/schema/beans http://www. Springframework. org/schema/beans/Spring-beans.xsd\"&gt; &lt;bean id=\"myTestBean\" class=\"bean.MyTestBean\"/&gt;&lt;/beans&gt; 在上面的配置中我们看到了bean的声明方式，尽管Spring中bean的元素定义着N种属性来支撑我们业务的各种应用，但是我们只要声明成这样，基本上就已经可以满足我们的大多数应用了。好了，你可能觉得还有什么，但是，真没了，Spring的入门示例到这里已经结束，我们可以写测试代码测试了。 123456789@SuppressWarnings(\"deprecation\")public class BeanFactoryTest &#123;@Testpublic void testSimpleLoad()&#123; BeanFactory bf = new XmlBeanFactory(new ClassPathResource ( \"beanFactoryTest.xml\")); MyTestBean bean=(MyTestBean) bf.getBean(\"myTestBean\"); assertEquals(\"testStr\",bean.getTestStr()); &#125;&#125; 相信聪明的读者会很快看到我们期望的结果：在Eclipse中显示了Green Bar。 直接使用BeanFactory作为容器对于Spring的使用来说并不多见，甚至是甚少使用，因为在企业级的应用中大多数都会使用的是ApplicationContext（后续章节我们会介绍它们之间的区别），这里只是用于测试，让读者更快更好地分析Spring的内部原理。 OK，我们又复习了一遍Spring，你是不是会很不屑呢？这样的小例子没任何挑战性。嗯，确实，这样的使用是过于简单了，但是本书的目的并不是介绍如何使用Spring，而是帮助您更好地了解 Spring 的内部原理。读者可以自己先想想，上面的一句简单代码都执行了什么样的逻辑呢？这样一句简单代码其实在Spring中执行了太多太多的逻辑，即使笔者用半本书的文字也只能介绍它的大致原理。那么就让我们快速的进入分析状态吧。 2.2 功能分析现在我们可以来好好分析一下上面测试代码的功能，来探索上面的测试代码中Spring究竟帮助我们完成了什么工作？不管之前你是否使用过Spring，当然，你应该使用过的，毕竟本书面用的是对Spring有一定使用经验的读者，你都应该能猜出来，这段测试代码完成的功能无非就是以下几点。 （1）读取配置文件beanFactoryTest.xml。（2）根据 beanFactoryTest.xml 中的配置找到对应的类的配置，并实例化。（3）调用实例化后的实例。为了更清楚地描述，笔者临时画了设计类图，如图2-1所示，如果想完成我们预想的功能，至少需要3个类。 ConfigReader：用于读取及验证配置文件。我们要用配置文件里面的东西，当然首先要做的就是读取，然后放置在内存中。 ReflectionUtil：用于根据配置文件中的配置进行反射实例化。比如在上例中beanFactoryTest.xml出现的，我们就可以根据bean.MyTestBean进行实例化。 App：用于完成整个逻辑的串联。按照最原始的思维方式，整个过程无非如此，但是作为一个风靡世界的优秀源码真的就这么简单吗？ 2.3 工程搭建不如我们首先大致看看 Spring 的源码。在 Spring 源码中，用于实现上面功能的是org.Springframework.beans.jar，我们看源码的时候要打开这个工程，如果我们只使用上面的功能，那就没有必要引入Spring的其他更多的包，当然Core是必须的，还有些依赖的包如图2-2所示。 引入依赖的 JAR 消除掉所有编译错误后，终于可以看源码了。或许你已经知道了答案， Spring 居然用了 N 多代码实现了这个看似很简单的功能，那么这些代码都是做什么用的呢？Spring在架构或者编码的时候又是如何考虑的呢？带着疑问，让我们踏上了研读Spring源码的征程。 2.4 Spring的结构组成我们首先尝试梳理一下Spring的框架结构，从全局的角度了解一下Spring的结构组成。 2.4.1 beans包的层级结构笔者认为阅读源码的最好方法是通过示例跟着操作一遍，虽然有时候或者说大多数时候会被复杂的代码绕来绕去，绕到最后已经不知道自己身在何处了，但是，如果配以UML还是可以搞定的。笔者就是按照自己的思路进行分析，并配合必要的UML，希望读者同样可以跟得上思路。我们先看看整个beans工程的源码结构，如图2-3所示。 beans包中的各个源码包的功能如下。src/main/java用于展现Spring的主要逻辑。src/main/resources用于存放系统的配置文件。src/test/java用于对主要逻辑进行单元测试。src/test/resources用于存放测试用的配置文件。 2.4.2 核心类介绍通过beans工程的结构介绍，我们现在对beans的工程结构有了初步的认识，但是在正式开始源码分析之前，有必要了解一下Spring中最核心的两个类。 1．DefaultListableBeanFactoryXmlBeanFactory继承自DefaultListableBeanFactory，而DefaultListableBeanFactory是整个bean加载的核心部分，是 Spring 注册及加载 bean 的默认实现，而对于 XmlBeanFactory 与DefaultListableBeanFactory 不同的地方其实是在 XmlBeanFactory 中使用了自定义的 XML 读取器XmlBeanDefinitionReader，实现了个性化的BeanDefinitionReader读取，DefaultListableBeanFactory继承了 AbstractAutowireCapableBeanFactory 并实现了ConfigurableListableBeanFactory 以及BeanDefinitionRegistry接口。以下是ConfigurableListableBeanFactory的层次结构图（见图2-4）以及相关类图（见图2-5）。 从上面的类图以及层次结构图中，我们可以很清晰地从全局角度了解 DefaultListableBean Factory的脉络。如果读者没有了解过Spring源码可能对上面的类图不是很理解，不过没关系，通过后续的学习，你会逐渐了解每个类的作用。那么，让我们先简单地了解一下上面类图中的各个类的作用。 AliasRegistry：定义对alias的简单增删改等操作。SimpleAliasRegistry：主要使用map作为alias的缓存，并对接口AliasRegistry进行实现。SingletonBeanRegistry：定义对单例的注册及获取。BeanFactory：定义获取bean及bean的各种属性。DefaultSingletonBeanRegistry：对接口SingletonBeanRegistry各函数的实现。HierarchicalBeanFactory：继承BeanFactory，也就是在BeanFactory定义的功能的基础上增加了对parentFactory的支持。BeanDefinitionRegistry：定义对BeanDefinition的各种增删改操作。FactoryBeanRegistrySupport：在DefaultSingletonBeanRegistry基础上增加了对FactoryBean的特殊处理功能。 ConfigurableBeanFactory：提供配置Factory的各种方法。ListableBeanFactory：根据各种条件获取bean的配置清单。 AbstractBeanFactory：综合 FactoryBeanRegistrySupport和 ConfigurableBeanFactory的功能。AutowireCapableBeanFactory：提供创建bean、自动注入、初始化以及应用bean的后处理器。AbstractAutowireCapableBeanFactory：综合AbstractBeanFactory并对接口Autowire Capable BeanFactory进行实现。ConfigurableListableBeanFactory：BeanFactory配置清单，指定忽略类型及接口等。DefaultListableBeanFactory：综合上面所有功能，主要是对Bean注册后的处理。XmlBeanFactory对DefaultListableBeanFactory类进行了扩展，主要用于从XML文档中读取BeanDefinition，对于注册及获取Bean都是使用从父类DefaultListableBeanFactory继承的方法去实现，而唯独与父类不同的个性化实现就是增加了XmlBeanDefinitionReader类型的reader属性。在XmlBeanFactory中主要使用reader属性对资源文件进行读取和注册。 2．XmlBeanDefinitionReader XML配置文件的读取是Spring中重要的功能，因为Spring的大部分功能都是以配置作为切入点的，那么我们可以从XmlBeanDefinitionReader中梳理一下资源文件读取、解析及注册的大致脉络，首先我们看看各个类的功能。 ResourceLoader：定义资源加载器，主要应用于根据给定的资源文件地址返回对应的Resource。 BeanDefinitionReader：主要定义资源文件读取并转换为BeanDefinition的各个功能。 EnvironmentCapable：定义获取Environment方法。DocumentLoader：定义从资源文件加载到转换为Document的功能。AbstractBeanDefinitionReader：对EnvironmentCapable、BeanDefinitionReader类定义的功能进行实现。BeanDefinitionDocumentReader：定义读取Docuemnt并注册BeanDefinition功能。BeanDefinitionParserDelegate：定义解析Element的各种方法。经过以上分析，我们可以梳理出整个XML配置文件读取的大致流程，如图2-6所示，在XmlBeanDifinitionReader中主要包含以下几步的处理。 （1）通过继承自AbstractBeanDefinitionReader中的方法，来使用ResourLoader将资源文件路径转换为对应的Resource文件。（2）通过DocumentLoader对Resource文件进行转换，将Resource文件转换为Document文件。（3）通过实现接口BeanDefinitionDocumentReader的DefaultBeanDefinitionDocumentReader类对Document进行解析，并使用BeanDefinitionParserDelegate对Element进行解析。 2.5 容器的基础XmlBeanFactory好了，到这里我们已经对Spring的容器功能有了一个大致的了解，尽管你可能还很迷糊，但是不要紧，接下来我们会详细探索每个步骤的实现。再次重申一下代码，我们接下来要深入分析以下功能的代码实现： BeanFactory bf = new XmlBeanFactory(new ClassPathResource(“beanFactoryTest.xml”));通过XmlBeanFactory初始化时序图（如图2-7所示）我们来看一看上面代码的执行逻辑。 时序图从BeanFactoryTest测试类开始，通过时序图我们可以一目了然地看到整个逻辑处理顺序。在测试的BeanFactoryTest中首先调用ClassPathResource的构造函数来构造Resource资源文件的实例对象，这样后续的资源处理就可以用Resource提供的各种服务来操作了，当我们有了Resource后就可以进行XmlBeanFactory的初始化了。那么Resource资源是如何封装的呢？ 2.5.1 配置文件封装Spring的配置文件读取是通过 ClassPathResource进行封装的，如 new ClassPathResource (“beanFactoryTest.xml”)，那么ClassPathResource完成了什么功能呢？在Java中，将不同来源的资源抽象成URL，通过注册不同的handler（URLStreamHandler）来处理不同来源的资源的读取逻辑，一般handler的类型使用不同前缀（协议，Protocol）来识别，如“file:”、“http:”、“jar:”等，然而 URL 没有默认定义相对 Classpath 或ServletContext等资源的handler，虽然可以注册自己的URLStreamHandler来解析特定的URL前缀（协议），比如“classpath:”，然而这需要了解URL的实现机制，而且URL也没有提供一些基本的方法，如检查当前资源是否存在、检查当前资源是否可读等方法。因而 Spring 对其内部使用到的资源实现了自己的抽象结构：Resource接口来封装底层资源。 12345678910111213141516171819202122232425262728293031323334353637383940414243public interface InputStreamSource &#123; InputStream getInputStream() throws IOException;&#125;public interface Resource extends InputStreamSource &#123; boolean exists(); boolean isReadable(); boolean isOpen(); URL getURL() throws IOException; URI getURI() throws IOException; File getFile() throws IOException; long lastModified() throws IOException; Resource createRelative(String relativePath) throws IOException; String getFilename(); String getDescription();&#125;``` InputStreamSource封装任何能返回InputStream的类，比如File、Classpath下的资源和Byte Array等。它只有一个方法定义：getInputStream()，该方法返回一个新的 InputStream对象。Resource接口抽象了所有Spring内部使用到的底层资源：File、URL、Classpath等。首先，它定义了3个判断当前资源状态的方法：存在性（exists）、可读性（isReadable）、是否处于打开状态（isOpen）。另外，Resource接口还提供了不同资源到URL、URI、File类型的转换，以及获取lastModified属性、文件名（不带路径信息的文件名，getFilename()）的方法。为了便于操作，Resource 还提供了基于当前资源创建一个相对资源的方法：createRelative()。在错误处理中需要详细地打印出错的资源文件，因而Resource还提供了getDescription()方法用于在错误处理中的打印信息。 对不同来源的资源文件都有相应的Resource实现：文件（FileSystemResource）、Classpath资源（ClassPathResource）、URL资源（UrlResource）、InputStream资源（InputStreamResource）、Byte数组（ByteArrayResource）等。相关类图如2-8所示。![](20190110223733.png)在日常的开发工作中，资源文件的加载也是经常用到的，可以直接使用Spring提供的类，比如在希望加载文件时可以使用以下代码：Resource resource=new ClassPathResource(“beanFactoryTest.xml”);InputStream inputStream=resource.getInputStream();得到 inputStream 后，我们就可以按照以前的开发方式进行实现了，并且我们已经可以利用Resource及其子类为我们提供好的诸多特性。有了Resource接口便可以对所有资源文件进行统一处理。至于实现，其实是非常简单的，以getInputStream为例，ClassPathResource中的实现方式便是通过class或者classLoader提供的底层方法进行调用，而对于 FileSystemResource 的实现其实更简单，直接使用 FileInputStream对文件进行实例化。```javaClassPathResource.javaif (this.clazz != null) &#123; is = this.clazz.getResourceAsStream(this.path);&#125;else &#123; is = this.classLoader.getResourceAsStream(this.path);&#125;FileSystemResource.javapublic InputStream getInputStream() throws IOException &#123; return new FileInputStream(this.file);&#125; 当通过Resource相关类完成了对配置文件进行封装后配置文件的读取工作就全权交给XmlBeanDefinitionReader 来处理了。 了解了 Spring 中将配置文件封装为 Resource 类型的实例方法后，我们就可以继续探寻XmlBeanFactory的初始化过程了，XmlBeanFactory的初始化有若干办法，Spring中提供了很多的构造函数，在这里分析的是使用Resource实例作为构造函数参数的办法，代码如下： XmlBeanFactory.java1234public XmlBeanFactory(Resource resource) throws BeansException &#123; //调用XmlBeanFactory（Resource,BeanFactory）构造方法， this(resource, null);&#125; 构造函数内部再次调用内部构造函数： 12345//parentBeanFactory为父类BeanFactory用于factory合并，可以为空public XmlBeanFactory(Resource resource, BeanFactory parentBeanFactory) throws BeansException &#123; super(parentBeanFactory); this.reader.loadBeanDefinitions(resource);&#125; 上面函数中的代码this.reader.loadBeanDefinitions(resource) 才是资源加载的真正实现，也是我们分析的重点之一。我们可以看到时序图中提到的XmlBeanDefinitionReader加载数据就是在这里完成的，但是在XmlBeanDefinitionReader加载数据前还有一个调用父类构造函数初始化的过程：super(parentBeanFactory)，跟踪代码到父类AbstractAutowireCapableBeanFactory的构造函数中： 123456public AbstractAutowireCapableBeanFactory() &#123; super(); ignoreDependencyInterface(BeanNameAware.class); ignoreDependencyInterface(BeanFactoryAware.class); ignoreDependencyInterface(BeanClassLoaderAware.class);&#125; 这里有必要提及一下ignoreDependencyInterface方法。ignoreDependencyInterface的主要功能是忽略给定接口的自动装配功能，那么，这样做的目的是什么呢？会产生什么样的效果呢？ 举例来说，当A中有属性B，那么当Spring在获取A的Bean的时候如果其属性B还没有初始化，那么Spring会自动初始化B，这也是Spring中提供的一个重要特性。但是，某些情况下，B不会被初始化，其中的一种情况就是B实现了BeanNameAware接口。Spring中是这样介绍的：自动装配时忽略给定的依赖接口，典型应用是通过其他方式解析Application上下文注册依赖，类似于 BeanFactory 通过 BeanFactoryAware 进行注入或者 ApplicationContext 通过ApplicationContextAware进行注入。 2.5.2 加载Bean之前提到的在XmlBeanFactory构造函数中调用了XmlBeanDefinitionReader类型的reader属性提供的方法this.reader.loadBeanDefinitions(resource)，而这句代码则是整个资源加载的切入点，我们先来看看这个方法的时序图，如图2-9所示。 看到图2-9我们才知道什么叫山路十八弯，绕了这么半天还没有真正地切入正题，比如加载XML文档和解析注册Bean，一直还在做准备工作。我们根据上面的时序图来分析一下这里究竟在准备什么？从上面的时序图中我们尝试梳理整个的处理过程如下。 （1）封装资源文件。当进入 XmlBeanDefinitionReader 后首先对参数 Resource 使用EncodedResource类进行封装。（2）获取输入流。从Resource中获取对应的InputStream并构造InputSource。（3）通过构造的InputSource实例和Resource实例继续调用函数doLoadBeanDefinitions。 我们来看一下loadBeanDefinitions函数具体的实现过程： 123public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &#123; return loadBeanDefinitions(new EncodedResource(resource));&#125; 那么EncodedResource的作用是什么呢？通过名称，我们可以大致推断这个类主要是用于对资源文件的编码进行处理的。其中的主要逻辑体现在getReader()方法中，当设置了编码属性的时候Spring会使用相应的编码作为输入流的编码。 12345678public Reader getReader() throws IOException &#123; if (this.encoding != null) &#123; return new InputStreamReader(this.resource.getInputStream(), this.encoding); &#125; else &#123; return new InputStreamReader(this.resource.getInputStream()); &#125;&#125; 上面代码构造了一个有编码（encoding）的InputStreamReader。当构造好encodedResource对象后，再次转入了可复用方法 loadBeanDefinitions(new EncodedResource(resource))。 这个方法内部才是真正的数据准备阶段，也就是时序图所描述的逻辑： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//这里是载入XML形式Bean定义资源文件方法public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Assert.notNull(encodedResource, \"EncodedResource must not be null\"); if (logger.isInfoEnabled()) &#123; logger.info(\"Loading XML bean definitions from \" + encodedResource); &#125; //通过属性来记录已经加载的资源 Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException( \"Detected cyclic loading of \" + encodedResource + \" - check your import definitions!\"); &#125; try &#123; //将资源文件转为InputStream的IO流 //从encodedResource中获取已经封装的Resource对象并再次从Resource中获取其中的inputStream InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; //从InputStream中得到XML的解析源 //InputSource这个类并不来自于Spring，它的全路径是org.xml.sax.InputSource InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; //这里是具体的读取过程 return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; //关闭充Resource中得到的IO流 inputStream.close(); &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( \"IOException parsing XML document from \" + encodedResource.getResource(), ex); &#125; finally &#123; currentResources.remove(encodedResource); if (currentResources.isEmpty()) &#123; this.resourcesCurrentlyBeingLoaded.remove(); &#125; &#125;&#125; 我们再次整理一下数据准备阶段的逻辑，首先对传入的resource参数做封装，目的是考虑到Resource可能存在编码要求的情况，其次，通过SAX读取XML文件的方式来准备InputSource对象，最后将准备的数据通过参数传入真正的核心处理部分doLoadBeanDefinitions(inputSource, encodedResource.getResource())。 123456789101112131415161718192021222324252627282930313233//从特定XML文件中实际载入Bean定义资源的方法protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; //将xml文件转为DOM对象，解析过程由documentLoader实现 Document doc = doLoadDocument(inputSource, resource); //这里是启动对Bean定义解析的详细过程，该解析过程会用到Spring的Bean配置规则 return registerBeanDefinitions(doc, resource); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (SAXParseException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"Line \" + ex.getLineNumber() + \" in XML document from \" + resource + \" is invalid\", ex); &#125; catch (SAXException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"XML document from \" + resource + \" is invalid\", ex); &#125; catch (ParserConfigurationException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Parser configuration exception parsing XML from \" + resource, ex); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"IOException parsing XML document from \" + resource, ex); &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Unexpected exception parsing XML document from \" + resource, ex); &#125;&#125; 在上面冗长的代码中假如不考虑异常类的代码，其实只做了三件事，这三件事的每一件都必不可少。（1）获取对XML文件的验证模式。（2）加载XML文件，并得到对应的Document。（3）根据返回的Document注册Bean信息。 这3个步骤支撑着整个Spring容器部分的实现基础，尤其是第3步对配置文件的解析，逻辑非常的复杂，那么我们先从获取XML文件的验证模式开始讲起。 2.6 获取XML的验证模式了解XML文件的读者都应该知道XML文件的验证模式保证了XML文件的正确性，而比较常用的验证模式有两种：DTD和XSD。它们之间什么区别呢？ 2.6.1 DTD与XSD区别无 2.6.2 验证模式的读取无 2.7 获取Document经过了验证模式准备的步骤就可以进行Document加载了，同样XmlBeanFactoryReader类对于文档读取并没有亲力亲为，而是委托给了DocumentLoader去执行，这里的DocumentLoader是个接口，而真正调用的是DefaultDocumentLoader，解析代码如下： 1234567891011121314@Overridepublic Document loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception &#123; //创建解析器工厂 DocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware); if (logger.isDebugEnabled()) &#123; logger.debug(\"Using JAXP provider [\" + factory.getClass().getName() + \"]\"); &#125; //创建文档解析器 DocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler); //解析Spring中的Bean定义资源 return builder.parse(inputSource);&#125; 对于这部分代码其实并没有太多可以描述的，因为通过SAX解析XML文档的套路大致都差不多，Spring 在这里并没有什么特殊的地方，同样首先创建 DocumentBuilderFactory，再通过DocumentBuilderFactory创建DocumentBuilder，进而解析inputSource来返回Document对象。对此感兴趣的读者可以在网上获取更多的资料。这里有必要提及一下 EntityResolver，对于参数entityResolver，传入的是通过getEntityResolver()函数获取的返回值，如下代码： 12345678910111213protected EntityResolver getEntityResolver() &#123; if (this.entityResolver == null) &#123; // Determine default EntityResolver to use. ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader != null) &#123; this.entityResolver = new ResourceEntityResolver(resourceLoader); &#125; else &#123; this.entityResolver = new DelegatingEntityResolver(getBeanClassLoader()); &#125; &#125; return this.entityResolver;&#125; 2.7.1 EntityResolver用法无 2.8 解析及注册BeanDefinitions当把文件转换为Document后，接下来的提取及注册bean就是我们的重头戏。继续上面的分析，当程序已经拥有XML文档文件的Document实例对象时，就会被引入下面这个方法。 1234567891011121314//按照Spring的bean语义要求将bean定义资源解析并转换为容器内部数据接口public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; //得到BeanDefinitionDocumentReader来对xml格式的BeanDefinition解析 //先实例化一个BeanDefinitionDocumentReader，这个对象是通过BeanUtils.instantiateClass方法实例化出来的 //实际上BeanUtils.instantiateClass中是封装了Java的反射的一些方法，通过基本的Java反射来构造实例。 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); //获取容器中注册的Bean数量 int countBefore = getRegistry().getBeanDefinitionCount(); //解析过程入口，这里使用了委派模式，BeanDefinitionDocumentReader只是个接口， //具体的解析实现过程有实现类DefaultBeanDefinitionDocumentReader完成 documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); //统计解析的Bean数量 return getRegistry().getBeanDefinitionCount() - countBefore;&#125; 其中的参数 doc 是通过上一节 loadDocument 加载转换出来的。在这个方法中很好地应用了面向对象中单一职责的原则，将逻辑处理委托给单一的类进行处理，而这个逻辑处理类就是BeanDefinitionDocumentReader。 BeanDefinitionDocumentReader是一个接口，而实例化的工作是在createBeanDefinitionDocumentReader()中完成的，而通过此方法，BeanDefinitionDocumentReader真正的类型其实已经是DefaultBeanDefinitionDocumentReader了，进入DefaultBeanDefinition Document Reader 后，发现这个方法的重要目的之一就是提取 root，以便于再次将 root 作为参数继续BeanDefinition的注册。 12345678910//根据Spring DTD对bean的定义规则解析Bean定义Document对象@Overridepublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; //获得XML描述符 this.readerContext = readerContext; logger.debug(\"Loading bean definitions\"); //获得Document的根元素 Element root = doc.getDocumentElement(); doRegisterBeanDefinitions(root);&#125; 经过艰难险阻，磕磕绊绊，我们终于到了核心逻辑的底部doRegisterBeanDefinitions(root)，至少我们在这个方法中看到了希望。如果说以前一直是XML加载解析的准备阶段，那么doRegisterBeanDefinitions算是真正地开始进行解析了，我们期待的核心部分真正开始了。 12345678910111213141516171819202122232425262728293031323334353637protected void doRegisterBeanDefinitions(Element root) &#123; // Any nested &lt;beans&gt; elements will cause recursion in this method. In // order to propagate and preserve &lt;beans&gt; default-* attributes correctly, // keep track of the current (parent) delegate, which may be null. Create // the new (child) delegate with a reference to the parent for fallback purposes, // then ultimately reset this.delegate back to its original (parent) reference. // this behavior emulates a stack of delegates without actually necessitating one. //具体的解析过程由BeanDefinitionParserDelegate实现 //BeanDefinitionParserDelegate中定义了Spring Bean定义XML文件的各种格式 BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) &#123; //处理profile属性 String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Skipped XML bean definition file due to specified profiles [\" + profileSpec + \"] not matching: \" + getReaderContext().getResource()); &#125; return; &#125; &#125; &#125; //在解析Bean定义之前，进行自定义的解析，增强解析过程的可扩展性 preProcessXml(root); //从Document的根元素开始进行Bena定义的Document对象 parseBeanDefinitions(root, this.delegate); //在解析Bean定义之后，进行自定义的解析，增加解析过程的可扩展性 postProcessXml(root); this.delegate = parent;&#125; 通过上面的代码我们看到了处理流程，首先是对profile的处理，然后开始进行解析，可是当我们跟进preProcessXml(root)或者postProcessXml(root)发现代码是空的，既然是空的写着还有什么用呢？就像面向对象设计方法学中常说的一句话，一个类要么是面向继承的设计的，要么就用final修饰。在DefaultBeanDefinitionDocumentReader中并没有用final修饰，所以它是面向继承而设计的。这两个方法正是为子类而设计的，如果读者有了解过设计模式，可以很快速地反映出这是模版方法模式，如果继承自DefaultBeanDefinitionDocumentReader的子类需要在Bean解析前后做一些处理的话，那么只需要重写这两个方法就可以了。 2.8.1 profile属性的使用我们注意到在注册Bean的最开始是对PROFILE_ATTRIBUTE属性的解析，可能对于我们来说，profile属性并不是很常用。让我们先了解一下这个属性。分析profile前我们先了解下profile的用法，官方示例代码片段如下： 12345678910111213&lt;beans xmlns=\"http://www.Springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:jdbc=\"http://www. Springframework.org/schema/jdbc\" xmlns:jee=\"http://www.Springframework.org/schema/jee\" xsi:schemaLocation=\"...\"&gt; ... ...&lt;beans profile=\"dev\"&gt; ... ...&lt;/beans&gt; &lt;beans profile=\"production\"&gt; ... ... &lt;/beans&gt;&lt;/beans&gt; 集成到Web环境中时，在web.xml中加入以下代码： 1234&lt;context-param&gt; &lt;param-name&gt;Spring.profiles.active&lt;/param-name&gt; &lt;param-value&gt;dev&lt;/param-value&gt;&lt;/context-param&gt; 有了这个特性我们就可以同时在配置文件中部署两套配置来适用于生产环境和开发环境，这样可以方便的进行切换开发、部署环境，最常用的就是更换不同的数据库。 了解了 profile 的使用再来分析代码会清晰得多，首先程序会获取 beans 节点是否定义了profile 属性，如果定义了则会需要到环境变量中去寻找，所以这里首先断言 environment 不可能为空，因为 profile 是可以同时指定多个的，需要程序对其拆分，并解析每个 profile 是都符合环境变量中所定义的，不定义则不会浪费性能去解析。 2.8.2 解析并注册BeanDefinition处理了 profile 后就可以进行 XML 的读取了，跟踪代码进入 parseBeanDefinitions(root, this.delegate)。 123456789101112131415161718192021222324252627//使用Spring的bean规则从Document的根元素开始进行Bean定义的Document对象protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; //Bean定义的Document对象使用了Spring默认的Xml命名空间 if (delegate.isDefaultNamespace(root)) &#123; //获取Bean定义的Document对象根元素的所有子节点 NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; //Bean定义的Document元素节点使用的是Spring默认的XML命名空间 if (delegate.isDefaultNamespace(ele)) &#123; //使用Spring的Bena规则解析元素节点 parseDefaultElement(ele, delegate); &#125; else &#123; //没用使用Spring默认的XML命名空间，则使用用户自定义的解析器解析元素节点 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; //Document的根节点没有使用Spring默认的命名空间，则使用用户自定义的解析规则解析Document根节点 delegate.parseCustomElement(root); &#125;&#125; 上面的代码看起来逻辑还是蛮清晰的，因为在Spring的XML配置里面有两大类Bean声明，一个是默认的，如：1234&lt;bean id=\"test\" class=\"test.TestBean\"/&gt;//另一类就是自定义的，如：&lt;tx:annotation-driven/&gt; 而两种方式的读取及解析差别是非常大的，如果采用Spring默认的配置，Spring当然知道该怎么做，但是如果是自定义的，那么就需要用户实现一些接口及配置了。对于根节点或者子节点如果是默认命名空间的话则采用 parseDefaultElement 方法进行解析，否则使用delegate.parseCustomElement方法对自定义命名空间进行解析。而判断是否默认命名空间还是自定义命名空间的办法其实是使用node.getNamespaceURI()获取命名空间，并与Spring中固定的命名空间 http://www.Springframework.org/schema/beans 进行比对。如果一致则认为是默认，否则就认为是自定义。而对于默认标签解析与自定义标签解析我们将会在下一章中进行讨论。","categories":[{"name":"Spring源码深度解析","slug":"Spring源码深度解析","permalink":"http://blog.shagle.cn/categories/Spring源码深度解析/"},{"name":"Spring","slug":"Spring源码深度解析/Spring","permalink":"http://blog.shagle.cn/categories/Spring源码深度解析/Spring/"}],"tags":[]},{"title":"Spring中Bean的生命周期","slug":"Spring中Bean的生命周期","date":"2019-01-10T14:02:37.000Z","updated":"2019-01-10T08:38:40.000Z","comments":true,"path":"2019/01/10/Spring中Bean的生命周期/","link":"","permalink":"http://blog.shagle.cn/2019/01/10/Spring中Bean的生命周期/","excerpt":"BeanFactory和ApplicationContext是Spring中两种很重要的容器，前者提供了最基本的依赖注入的支持，后者在继承前者的基础上进行了功能的拓展，增加了事件传播，资源访问，国际化的支持等功能。同时两者的生命周期也稍微有些不同。","text":"BeanFactory和ApplicationContext是Spring中两种很重要的容器，前者提供了最基本的依赖注入的支持，后者在继承前者的基础上进行了功能的拓展，增加了事件传播，资源访问，国际化的支持等功能。同时两者的生命周期也稍微有些不同。 BeanFactory中Bean的生命周期 容器寻找Bean的定义信息，并将其实例化。 使用依赖注入，Spring按照Bean定义信息配置Bean的所有属性。 如果Bean实现了BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的id。 如果实现了BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身。 如果BeanPostProcessor和Bean关联，那么它们的postProcessBeforeInitialization()方法将被调用。（需要手动进行注册！） 如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法。 如果Bean指定了init-method方法，就会调用init-method方法。 如果BeanPostProcessor和Bean关联，那么它的postProcessAfterInitialization()方法将被调用。（需要手动注册！） 现在Bean已经可以使用了。 scope为singleton的Bean缓存在Spring IOC容器中。 scope为prototype的Bean生命周期交给客户端。 销毁。 如果Bean实现了DisposableBean接口，destory()方法将会被调用。 如果配置了destory-method方法，就调用这个方法。 ApplicationContext中Bean的生命周期 容器寻找Bean的定义信息，并将其实例化。会对scope为singleton且非懒加载的bean进行实例化 使用依赖注入，Spring按照Bean定义信息配置Bean的所有属性。 如果Bean实现了BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的id。 如果实现了BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身。 如果实现了ApplicationContextAware接口，会调用该接口的setApplicationContext()方法，传入该Bean的ApplicationContext，这样该Bean就获得了自己所在的ApplicationContext。 如果Bean实现了BeanPostProcessor接口，则调用postProcessBeforeInitialization()方法。 如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法。 如果Bean制定了init-method方法，就会调用init-method方法。 如果Bean实现了BeanPostProcessor接口，则调用postProcessAfterInitialization()方法。 现在Bean已经可以使用了。 scope为singleton的Bean缓存在Spring IOC容器中。 scope为prototype的Bean生命周期交给客户端。 销毁。 如果Bean实现了DisposableBean接口，destory()方法将会被调用。 如果配置了destory-method方法，就调用这个方法。 两种容器中的不同之处 BeanFactory容器中不会调用ApplicationContext接口的setApplicationContext()方法。 BeanFactory中BeanPostProcessor接口的postProcessBeforeInitialzation()方法和postProcessAfterInitialization()方法不会自动调用，必须自己通过代码手动注册。 BeanFactory容器启动的时候，不会去实例化所有Bean,包括所有scope为singleton且非懒加载的Bean也是一样，而是在调用的时候去实例化。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shagle.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shagle.cn/tags/Spring/"},{"name":"Bean","slug":"Bean","permalink":"http://blog.shagle.cn/tags/Bean/"}]},{"title":"Spring ApplicationContext事件机制","slug":"Spring-ApplicationContext事件机制","date":"2019-01-10T11:04:30.000Z","updated":"2019-01-10T08:43:41.000Z","comments":true,"path":"2019/01/10/Spring-ApplicationContext事件机制/","link":"","permalink":"http://blog.shagle.cn/2019/01/10/Spring-ApplicationContext事件机制/","excerpt":"ApplicationContext中事件处理是由ApplicationEvent类和ApplicationListener接口来提供的。如果一个Bean实现了ApplicationListener接口，并且已经发布到容器中去，每次ApplicationContext发布一个ApplicationEvent事件，这个Bean就会接到通知。Spring事件机制是观察者模式的实现。","text":"ApplicationContext中事件处理是由ApplicationEvent类和ApplicationListener接口来提供的。如果一个Bean实现了ApplicationListener接口，并且已经发布到容器中去，每次ApplicationContext发布一个ApplicationEvent事件，这个Bean就会接到通知。Spring事件机制是观察者模式的实现。 Spring中提供的标准事件： ContextRefreshEvent，当ApplicationContext容器初始化完成或者被刷新的时候，就会发布该事件。比如调用ConfigurableApplicationContext接口中的refresh()方法。此处的容器初始化指的是所有的Bean都被成功装载，后处理（post-processor）Bean被检测到并且激活，所有单例Bean都被预实例化，ApplicationContext容器已经可以使用。只要上下文没有被关闭，刷新可以被多次触发。XMLWebApplicationContext支持热刷新，GenericApplicationContext不支持热刷新。 ContextStartedEvent，当ApplicationContext启动的时候发布事件，即调用ConfigurableApplicationContext接口的start方法的时候。这里的启动是指，所有的被容器管理生命周期的Bean接受到一个明确的启动信号。在经常需要停止后重新启动的场合比较适用。 ContextStoppedEvent，当ApplicationContext容器停止的时候发布事件，即调用ConfigurableApplicationContext的close方法的时候。这里的停止是指，所有被容器管理生命周期的Bean接到一个明确的停止信号。 ContextClosedEvent，当ApplicationContext关闭的时候发布事件，即调用ConfigurableApplicationContext的close方法的时候，关闭指的是所有的单例Bean都被销毁。关闭上下后，不能重新刷新或者重新启动。 RequestHandledEvent，只能用于DispatcherServlet的web应用，Spring处理用户请求结束后，系统会触发该事件。 实现ApplicationEvent，容器事件，必须被ApplicationContext发布。 ApplicationListener，监听器，可由容器中任何监听器Bean担任。 实现了ApplicationListener接口之后，需要实现方法onApplicationEvent()，在容器将所有的Bean都初始化完成之后，就会执行该方法。 观察者模式观察者模式，Observer Pattern也叫作发布订阅模式Publish/Subscribe。定义对象间一对多的依赖关系，使得每当一个对象改变状态，则所有依赖与它的对象都会得到通知，并被自动更新。 观察者模式的几角色名称： Subject被观察者，定义被观察者必须实现的职责，它能动态的增加取消观察者，它一般是抽象类或者是实现类，仅仅完成作为被观察者必须实现的职责：管理观察者并通知观察者。 Observer观察者，观察者接受到消息后，即进行更新操作，对接收到的信息进行处理。 ConcreteSubject具体的被观察者，定义被观察者自己的业务逻辑，同时定义对哪些事件进行通知。 ConcreteObserver具体的观察者，每个观察者接收到消息后的处理反应是不同的，每个观察者都有自己的处理逻辑。 观察者模式的优点 观察者和被观察者之间是抽象耦合，不管是增加观察者还是被观察者都非常容易扩展。 建立一套触发机制。 观察者模式的缺点观察者模式需要考虑开发效率和运行效率问题，一个被观察者，多个观察者，开发和调试比较复杂，Java消息的通知默认是顺序执行的，一个观察者卡壳，会影响整体的执行效率。这种情况一般考虑异步的方式。 使用场景 关联行为场景，关联是可拆分的。 事件多级触发场景。 跨系统的消息交换场景，如消息队列的处理机制。 Java中的观察者模式java.util.Observable类和java.util.Observer接口。 订阅发布模型观察者模式也叫作发布/订阅模式。 Spring中的观察者模式Spring在事件处理机制中使用了观察者模式： 事件，ApplicationEvent，该抽象类继承了EventObject，EventObject是JDK中的类，并建议所有的事件都应该继承自EventObject。 事件监听器，ApplicationListener，是一个接口，该接口继承了EventListener接口。EventListener接口是JDK中的，建议所有的事件监听器都应该继承EventListener。 事件发布，ApplicationEventPublisher，ApplicationContext继承了该接口，在ApplicationContext的抽象实现类AbstractApplicationContext中做了实现 AbstractApplicationContext类中publishEvent方法实现： 1234567891011public void publishEvent(ApplicationEvent event) &#123; Assert.notNull(event, &quot;Event must not be null&quot;); if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Publishing event in &quot; + getDisplayName() + &quot;: &quot; + event); &#125; //事件发布委托给ApplicationEventMulticaster来执行 getApplicationEventMulticaster().multicastEvent(event); if (this.parent != null) &#123; this.parent.publishEvent(event); &#125;&#125; ApplicationEventMulticaster的multicastEvent方法的实现在SimpleApplicationEventMulticaster类中： 12345678910111213141516public void multicastEvent(final ApplicationEvent event) &#123; //获得监听器集合，遍历监听器，可支持同步和异步的广播事件 for (final ApplicationListener listener : getApplicationListeners(event)) &#123; Executor executor = getTaskExecutor(); if (executor != null) &#123; executor.execute(new Runnable() &#123; public void run() &#123; listener.onApplicationEvent(event); &#125; &#125;); &#125; else &#123; listener.onApplicationEvent(event); &#125; &#125;&#125; 这就执行了了onApplicationEvent方法，这里是事件发生的地方。 Spring如何根据事件找到事件对应的监听器在Spring容器初始化的时候，也就是在refresh方法中： 1234567891011121314151617public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; ...... try &#123; ...... // Initialize event multicaster for this context. //初始化一个事件注册表 initApplicationEventMulticaster(); ...... // Check for listener beans and register them. //注册事件监听器 registerListeners(); ...... &#125; &#125;&#125; initApplicationEventMulticaster方法初始化事件注册表： 12345678910111213protected void initApplicationEventMulticaster() &#123; //获得beanFactory ConfigurableListableBeanFactory beanFactory = getBeanFactory(); //先查找BeanFactory中是否有ApplicationEventMulticaster if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); &#125; else &#123;//如果BeanFactory中不存在，就创建一个SimpleApplicationEventMulticaster this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); &#125;&#125; 在AbstractApplicationEventMulticaster类中有如下属性： 123456//注册表private final ListenerRetriever defaultRetriever = new ListenerRetriever(false);//注册表的缓存private final Map&lt;ListenerCacheKey, ListenerRetriever&gt; retrieverCache = new ConcurrentHashMap&lt;ListenerCacheKey, ListenerRetriever&gt;(64);private BeanFactory beanFactory; ListenerRetriever的结构如下： 123456//用来存放监听事件public final Set&lt;ApplicationListener&gt; applicationListeners;//存放监听事件的类名称public final Set&lt;String&gt; applicationListenerBeans;private final boolean preFiltered; 初始化注册表之后，就会把事件注册到注册表中，registerListeners()： 12345678910111213protected void registerListeners() &#123; //获取所有的Listener，把事件的bean放到ApplicationEventMulticaster中 for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); //把事件的名称放到ApplicationListenerBean里去。 for (String lisName : listenerBeanNames) &#123; getApplicationEventMulticaster().addApplicationListenerBean(lisName); &#125;&#125; Spring使用反射机制，通过方法getBeansOfType获取所有继承了ApplicationListener接口的监听器，然后把监听器放到注册表中，所以我们可以在Spring配置文件中配置自定义监听器，在Spring初始化的时候，会把监听器自动注册到注册表中去。 ApplicationContext发布事件可以参考上面的内容。发布事件的时候的一个方法，getApplicationListeners： 12345678910111213141516171819202122232425262728293031323334353637383940414243protected Collection&lt;ApplicationListener&gt; getApplicationListeners(ApplicationEvent event) &#123; //获取事件类型 Class&lt;? extends ApplicationEvent&gt; eventType = event.getClass(); //或去事件源类型 Class sourceType = event.getSource().getClass(); ListenerCacheKey cacheKey = new ListenerCacheKey(eventType, sourceType); //从缓存中查找ListenerRetriever ListenerRetriever retriever = this.retrieverCache.get(cacheKey); //缓存中存在，直接返回对应的Listener if (retriever != null) &#123; return retriever.getApplicationListeners(); &#125; else &#123;//缓存中不存在，就获取相应的Listener retriever = new ListenerRetriever(true); LinkedList&lt;ApplicationListener&gt; allListeners = new LinkedList&lt;ApplicationListener&gt;(); Set&lt;ApplicationListener&gt; listeners; Set&lt;String&gt; listenerBeans; synchronized (this.defaultRetriever) &#123; listeners = new LinkedHashSet&lt;ApplicationListener&gt;(this.defaultRetriever.applicationListeners); listenerBeans = new LinkedHashSet&lt;String&gt;(this.defaultRetriever.applicationListenerBeans); &#125; //根据事件类型，事件源类型，获取所需要的监听事件 for (ApplicationListener listener : listeners) &#123; if (supportsEvent(listener, eventType, sourceType)) &#123; retriever.applicationListeners.add(listener); allListeners.add(listener); &#125; &#125; if (!listenerBeans.isEmpty()) &#123; BeanFactory beanFactory = getBeanFactory(); for (String listenerBeanName : listenerBeans) &#123; ApplicationListener listener = beanFactory.getBean(listenerBeanName, ApplicationListener.class); if (!allListeners.contains(listener) &amp;&amp; supportsEvent(listener, eventType, sourceType)) &#123; retriever.applicationListenerBeans.add(listenerBeanName); allListeners.add(listener); &#125; &#125; &#125; OrderComparator.sort(allListeners); this.retrieverCache.put(cacheKey, retriever); return allListeners; &#125;&#125; 根据事件类型，事件源类型获取所需要的监听器supportsEvent(listener, eventType, sourceType)： 1234567protected boolean supportsEvent( ApplicationListener listener, Class&lt;? extends ApplicationEvent&gt; eventType, Class sourceType) &#123; SmartApplicationListener smartListener = (listener instanceof SmartApplicationListener ? (SmartApplicationListener) listener : new GenericApplicationListenerAdapter(listener)); return (smartListener.supportsEventType(eventType) &amp;&amp; smartListener.supportsSourceType(sourceType));&#125; 这里没有进行实际的处理，实际处理在smartListener.supportsEventType(eventType)和smartListener.supportsSourceType(sourceType)方法中。 smartListener.supportsEventType(eventType)： 12345678910public boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; eventType) &#123; Class typeArg = GenericTypeResolver.resolveTypeArgument(this.delegate.getClass(), ApplicationListener.class); if (typeArg == null || typeArg.equals(ApplicationEvent.class)) &#123; Class targetClass = AopUtils.getTargetClass(this.delegate); if (targetClass != this.delegate.getClass()) &#123; typeArg = GenericTypeResolver.resolveTypeArgument(targetClass, ApplicationListener.class); &#125; &#125; return (typeArg == null || typeArg.isAssignableFrom(eventType));&#125; 该方法主要的逻辑就是根据事件类型判断是否和监听器参数泛型的类型是否一致。 smartListener.supportsSourceType(sourceType)方法的实现为： 123public boolean supportsSourceType(Class&lt;?&gt; sourceType) &#123; return true;&#125; 定义自己的监听器要明确指定参数泛型，表明该监听器支持的事件，如果不指明具体的泛型，则没有监听器监听事件。 还可以定义自己的事件暂先不做解析。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shagle.cn/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shagle.cn/tags/Spring/"},{"name":"Spring 事件机制","slug":"Spring-事件机制","permalink":"http://blog.shagle.cn/tags/Spring-事件机制/"}]},{"title":"spring-使用ignoreDependencyInterface方法的正确姿势","slug":"spring-ignoreDependencyInterface","date":"2019-01-10T09:23:26.000Z","updated":"2019-01-10T09:40:07.000Z","comments":true,"path":"2019/01/10/spring-ignoreDependencyInterface/","link":"","permalink":"http://blog.shagle.cn/2019/01/10/spring-ignoreDependencyInterface/","excerpt":"在阅读Spring容器扩展部分源码的过程中，我了解到BeanFactory接口中有个方法叫ignoreDependencyInterface。从官方文档的“字面”来看，其作用指定自动装配(autowiring)的时候忽略的接口。还有一个很相似的方法叫ignoreDependencyType，同样其官方字面意思是指自动装配(autowiring)的时候忽略的类。","text":"在阅读Spring容器扩展部分源码的过程中，我了解到BeanFactory接口中有个方法叫ignoreDependencyInterface。从官方文档的“字面”来看，其作用指定自动装配(autowiring)的时候忽略的接口。还有一个很相似的方法叫ignoreDependencyType，同样其官方字面意思是指自动装配(autowiring)的时候忽略的类。 究竟这两个方法是不是我们的理解相同呢？真的可以让指定的接口和类在自动装配的时候被忽略？有没有注意不到的坑？ 12void ignoreDependencyInterface(Class&lt;?&gt; ifc);void ignoreDependencyType(Class&lt;?&gt; type); 先上结论： 自动装配时忽略指定接口或类的依赖注入，使用ignoreDependencyType已经足够 ignoreDependencyInterface的真正意思是在自动装配时忽略指定接口的实现类中，对外的依赖。具体详述见下文的逐步踩坑。 1. “自动装配(autowiring)”的坑首先我们来试试水。我们试试能不能忽略一些我们常用的类。假设有一个类，叫ListHolder，就只有一个用@Autowired注解的ArrayList对象。 123456789101112public class ListHolder &#123; @Autowired private ArrayList&lt;String&gt; list; public ArrayList&lt;String&gt; getList() &#123; return list; &#125; public void setList(ArrayList&lt;String&gt; list) &#123; this.list = list; &#125;&#125; xml配置文件配置了ArrayList bean和ListHolder bean： 12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;bean id=\"list\" class=\"java.util.ArrayList\"&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;value&gt;foo&lt;/value&gt; &lt;value&gt;bar&lt;/value&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=\"listHolder\" class=\"com.huxuecong.ignoreDependency.ListHolder\"/&gt; &lt;bean class=\"com.huxuecong.autowire.IgnoreAutowiringProcessor\"/&gt; &lt;context:annotation-config&gt;&lt;/context:annotation-config&gt;&lt;/beans&gt; 我们定义一个BeanFactoryPostProcessor接口实现类，在接口实现类中调用ignoreDependencyType方法：123456public class IgnoreAutowiringProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; beanFactory.ignoreDependencyType(ArrayList.class); &#125;&#125; 运行结果：1[foo, bar] 没有起作用。即使调用了ignoreDependencyType方法，ArrayList还是被注入了。说明ignoreDependencyType方法完全不起到该有的作用。 由于我对Spring的了解尚浅，我很怀疑自动装配是不是真的和我了解的相同，使用@Autowired注解就可以了呢？ 经过一番中英文搜索之后，我终于发现有博客专门讲ignoreDependencyType和ignoreDependencyInterface方法。在博客中提到了我之前没用过的自动装配方式：在beans标签中使用default-autowire属性来注入依赖。于是我这次按照网友的说法，对我的例子进行改造： (1)ListHolder中的list对象不使用@Autowired注解 1234567891011public class ListHolder &#123; private ArrayList&lt;String&gt; list; public ArrayList&lt;String&gt; getList() &#123; return list; &#125; public void setList(ArrayList&lt;String&gt; list) &#123; this.list = list; &#125;&#125; (2)xml配置文件中去掉&lt;context:annotation-config/&gt;标签，并且在beans标签添加default-autowire的属性，其值为“byType”，意思是按照对象的类型进行装配。12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\" default-autowire=\"byType\"&gt; &lt;bean id=\"list\" class=\"java.util.ArrayList\"&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;value&gt;foo&lt;/value&gt; &lt;value&gt;bar&lt;/value&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=\"listHolder\" class=\"com.huxuecong.ignoreDependency.ListHolder\"/&gt; &lt;bean class=\"com.huxuecong.autowire.IgnoreAutowiringProcessor\"/&gt;&lt;/beans&gt; 这次运行之后，结果就符合期待了：1null 经过这次踩坑，发现英语中的autowiring特定指的是通过beans标签default-autowire属性来依赖注入的方式，而不是指使用@Autowired注解进行的依赖注入。区别在于，使用default-autowire会自动给所有的类都会从容器中查找匹配的依赖并注入，而使用@Autowired注解只会给这些注解的对象从容器查找依赖并注入。自动装配和@Autowired注解的装配不是同一回事。但从这次例子来看，ignoreDependencyType方法和我们期待的完全一致，可以在自动装配的时候忽略ArrayList类的对象。 2. ignoreDependencyInterface的坑在愉快地使用ignoreDependencyType方法后，立即如法炮制ignoreDependencyInterface方法，如无意外，应该效果一样，使得某个接口的实现类被忽略。于是在上面的例子上进行改造： (1)ListHolder类中的ArrayList类型改为List类型： 1234567891011public class ListHolder &#123; private List&lt;String&gt; list; public List&lt;String&gt; getList() &#123; return list; &#125; public void setList(List&lt;String&gt; list) &#123; this.list = list; &#125;&#125; (2)ignoreDependencyType改为使用ignoreDependencyInterface方法： 123456public class IgnoreAutowiringProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; beanFactory.ignoreDependencyInterface(List.class); &#125;&#125; 运行结果：1[foo, bar] 完全不起作用，ignoreDependencyInterface不按照我们的想法工作。曾经一度怀疑Spring是否有bug，但是从Spring的流行性和网上搜索结果来看，这种可能微乎其微，更多是对该方法的理解不对。我突发奇想，能不能也把接口List.class传给ignoreDependencyType，而不是使用ArrayList.class呢？于是又在上面的代码基础上，改为： 123456public class IgnoreAutowiringProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; beanFactory.ignoreDependencyType(List.class); &#125;&#125; 这次的运行结果：null从这次的结果来看，如果真的要忽略某个接口的实现类，大不必使用ignoreDependencyInterface方法，ignoreDependencyType方法已经居家必用了。迷之一样的ignoreDependencyInterface方法到底是用来干嘛的呢？ 3. ignoreDependencyInterface的真正奥义谷歌苦寻无果，无论中英文都没有发现比较详细的阐述，也说明该方法甚少被使用。只能自行在源码中寻找答案。经过若干个小时在咖啡厅的不断调试，终于发现最终的奥义，我们只看最终关键的代码。调用ignoreDependencyInterface方法后，被忽略的接口会存储在BeanFactory的名为ignoredDependencyInterfaces的Set集合中，而调用ignoreDependencyType则存储在ignoredDependencyTypes的Set集合中： 123456789101112131415public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; private final Set&lt;Class&lt;?&gt;&gt; ignoredDependencyInterfaces = new HashSet&lt;&gt;(); private final Set&lt;Class&lt;?&gt;&gt; ignoredDependencyTypes = new HashSet&lt;&gt;(); public void ignoreDependencyType(Class&lt;?&gt; type) &#123; this.ignoredDependencyTypes.add(type); &#125; public void ignoreDependencyInterface(Class&lt;?&gt; ifc) &#123; this.ignoredDependencyInterfaces.add(ifc); &#125;...&#125; ignoredDependencyInterfaces集合在同类中被使用仅在一处——isExcludedFromDependencyCheck方法中： 123protected boolean isExcludedFromDependencyCheck(PropertyDescriptor pd) &#123; return (AutowireUtils.isExcludedFromDependencyCheck(pd) || this.ignoredDependencyTypes.contains(pd.getPropertyType()) || AutowireUtils.isSetterDefinedInInterface(pd, this.ignoredDependencyInterfaces));&#125; isExcludedFromDependencyCheck方法的意思是判断给定的bean属性在依赖检测中要被排除，假如该方法返回true，也就是在依赖检测中这个bean的属性要被排除，在自动装配时就会被忽略。通过这个方法的源码也就明白，实际上我们说的在自动装配时忽略某个类或者接口的实现，使用ignoreDependencyType方法已经足够了，因为在isExcludedFromDependencyCheck方法中使用ignoredDependencyTypes集合是否包含属性的类型来判断。因此在我们例子中，ListHolder对象中的list属性是List接口的实现，而我们又把List.class参数传给ignoreDependencyType方法，自然就会在自动装配时被忽略。而ignoredDependencyInterface的真正作用还得看AutowireUtils类的isSetterDefinedInInterface方法。 123456789101112131415public static boolean isSetterDefinedInInterface(PropertyDescriptor pd, Set&lt;Class&lt;?&gt;&gt; interfaces) &#123; //获取bean中某个属性对象在bean类中的setter方法 Method setter = pd.getWriteMethod(); if (setter != null) &#123; // 获取bean的类型 Class&lt;?&gt; targetClass = setter.getDeclaringClass(); for (Class&lt;?&gt; ifc : interfaces) &#123; if (ifc.isAssignableFrom(targetClass) &amp;&amp; // bean类型是否接口的实现类 ClassUtils.hasMethod(ifc, setter.getName(), setter.getParameterTypes())) &#123; // 接口是否有入参和bean类型完全相同的setter方法 return true; &#125; &#125; &#125; return false;&#125; 这个方法的意思就是判断这一堆接口中有没有某个接口是拥有该bean属性的setter方法的。在我的例子中就是判断List接口有没有list属性类型的setter方法，也就是有无自己本身类型的setter方法。List接口的方法当中当然没有setList(List list)的方法啊，因此也不会生效。所以ignoredDependencyInterface方法并不是让我们在自动装配时直接忽略实现了该接口的依赖。这个方法的真正意思是忽略该接口的实现类中和接口setter方法入参类型相同的依赖。举个例子。首先定义一个要被忽略的接口。 123456public interface IgnoreInterface &#123; void setList(List&lt;String&gt; list); void setSet(Set&lt;String&gt; set);&#125; 然后需要实现该接口，在实现类中注意要有setter方法入参相同类型的域对象，在例子中就是List和Set。1234567891011121314151617181920212223public class IgnoreInterfaceImpl implements IgnoreInterface &#123; private List&lt;String&gt; list; private Set&lt;String&gt; set; @Override public void setList(List&lt;String&gt; list) &#123; this.list = list; &#125; @Override public void setSet(Set&lt;String&gt; set) &#123; this.set = set; &#125; public List&lt;String&gt; getList() &#123; return list; &#125; public Set&lt;String&gt; getSet() &#123; return set; &#125;&#125; 定义xml配置文件： 1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"default-autowire=\"byType\"&gt; &lt;bean id=\"list\" class=\"java.util.ArrayList\"&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;value&gt;foo&lt;/value&gt; &lt;value&gt;bar&lt;/value&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=\"set\" class=\"java.util.HashSet\"&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;value&gt;foo&lt;/value&gt; &lt;value&gt;bar&lt;/value&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=\"ii\" class=\"com.huxuecong.ignoreDependency.IgnoreInterfaceImpl\"/&gt; &lt;bean class=\"com.huxuecong.autowire.IgnoreAutowiringProcessor\"/&gt;&lt;/beans&gt; 最后调用ignoreDependencyInterface: 1beanFactory.ignoreDependencyInterface(IgnoreInterface.class); 运行结果：12nullnull 而如果不调用ignoreDependencyInterface，则是：12[foo, bar][bar, foo] 忽略接口生效。但其意思和我们最初理解的存在一定的差距。我们最初理解是在自动装配时忽略该接口的实现，实际上是在自动装配时忽略该接口实现类中和setter方法入参相同的类型，也就是忽略该接口实现类中存在依赖外部的bean属性注入。典型应用就是BeanFactoryAware和ApplicationContextAware接口。首先看该两个接口的源码：1234567public interface BeanFactoryAware extends Aware &#123; void setBeanFactory(BeanFactory beanFactory) throws BeansException;&#125;public interface ApplicationContextAware extends Aware &#123; void setApplicationContext(ApplicationContext applicationContext) throws BeansException;&#125; 在Spring源码中在不同的地方忽略了该两个接口：12beanFactory.ignoreDependencyInterface(ApplicationContextAware.class);ignoreDependencyInterface(BeanFactoryAware.class); 使得我们的BeanFactoryAware接口实现类在自动装配时不能被注入BeanFactory对象的依赖：123456789101112public class MyBeanFactoryAware implements BeanFactoryAware &#123; private BeanFactory beanFactory; // 自动装配时忽略注入 @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = beanFactory; &#125; public BeanFactory getBeanFactory() &#123; return beanFactory; &#125;&#125; ApplicationContextAware接口实现类中的ApplicationContext对象的依赖同理：123456789101112public class MyApplicationContextAware implements ApplicationContextAware &#123; private ApplicationContext applicationContext; // 自动装配时被忽略注入 @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; public ApplicationContext getApplicationContext() &#123; return applicationContext; &#125;&#125; 这样的做法使得ApplicationContextAware和BeanFactoryAware中的ApplicationContext或BeanFactory依赖在自动装配时被忽略，而统一由框架设置依赖，如ApplicationContextAware接口的设置会在ApplicationContextAwareProcessor类中完成：12345678910111213141516171819202122private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof EmbeddedValueResolverAware) &#123; ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); &#125; if (bean instanceof ResourceLoaderAware) &#123; ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); &#125; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; if (bean instanceof MessageSourceAware) &#123; ((MessageSourceAware) bean).setMessageSource(this.applicationContext); &#125; if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125; &#125;&#125; 通过这种方式保证了ApplicationContextAware和BeanFactoryAware中的容器保证是生成该bean的容器。但在实践中我们什么时候会使用ignoreDependencyInterface接口？笔者使用Spring经验有限，只能给出目前的应用场景很少，但起码想到一个：假如我们想自定义一个类似的xxAware接口，比如ApplicationEventMulticasterAware。那么调用ignoreDependencyInterface方法可以保证获取到的ApplicationEventMulticaster对象就是生成该bean容器中的ApplicationEventMulticaster对象。","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"ignoreDependencyInterface","slug":"ignoreDependencyInterface","permalink":"http://blog.shagle.cn/tags/ignoreDependencyInterface/"}]},{"title":"Spring 国际化MessageSource","slug":"Spring-国际化MessageSource","date":"2019-01-10T07:07:39.000Z","updated":"2019-01-10T07:19:03.000Z","comments":true,"path":"2019/01/10/Spring-国际化MessageSource/","link":"","permalink":"http://blog.shagle.cn/2019/01/10/Spring-国际化MessageSource/","excerpt":"","text":"1. spring 国际化Spring中定义了一个MessageSource接口，以用于支持信息的国际化和包含参数的信息的替换。MessageSource接口的定义如下，对应的方法说明已经在方法上注释了。 1234567891011121314151617181920212223242526272829303132public interface MessageSource &#123; /** * 解析code对应的信息进行返回，如果对应的code不能被解析则返回默认信息defaultMessage。 * @param 需要进行解析的code，对应资源文件中的一个属性名 * @param 需要用来替换code对应的信息中包含参数的内容，如：&#123;0&#125;,&#123;1,date&#125;,&#123;2,time&#125; * @param defaultMessage 当对应code对应的信息不存在时需要返回的默认值 * @param locale 对应的Locale * @return */ String getMessage(String code, Object[] args, String defaultMessage, Locale locale); /** * 解析code对应的信息进行返回，如果对应的code不能被解析则抛出异常NoSuchMessageException * @param code 需要进行解析的code，对应资源文件中的一个属性名 * @param args 需要用来替换code对应的信息中包含参数的内容，如：&#123;0&#125;,&#123;1,date&#125;,&#123;2,time&#125; * @param locale 对应的Locale * @return * @throws NoSuchMessageException 如果对应的code不能被解析则抛出该异常 */ String getMessage(String code, Object[] args, Locale locale) throws NoSuchMessageException; /** * 通过传递的MessageSourceResolvable对应来解析对应的信息 * @param resolvable * @param locale 对应的Locale * @return * @throws NoSuchMessageException 如不能解析则抛出该异常 */ String getMessage(MessageSourceResolvable resolvable, Locale locale) throws NoSuchMessageException;&#125; 我们熟悉的ApplicationContext接口继承了MessageSource接口，所以我们所有的ApplicationContext实现类都实现了MessageSource接口，也就是我们我们可以通过ApplicationContext来调用MessageSource接口方法以实现信息的国际化和替换信息中包含的参数。所有ApplicationContext实现类对MessageSource接口的实现都是在AbstractApplicationContext中实现的，其对MessageSource接口实现的源码如下： 123456789101112131415161718192021222324252627@Overridepublic String getMessage(String code, Object args[], String defaultMessage, Locale locale) &#123; return getMessageSource().getMessage(code, args, defaultMessage, locale);&#125;@Overridepublic String getMessage(String code, Object args[], Locale locale) throws NoSuchMessageException &#123; return getMessageSource().getMessage(code, args, locale);&#125;@Overridepublic String getMessage(MessageSourceResolvable resolvable, Locale locale) throws NoSuchMessageException &#123; return getMessageSource().getMessage(resolvable, locale);&#125;/** * Return the internal MessageSource used by the context. * @return the internal MessageSource (never &#123;@code null&#125;) * @throws IllegalStateException if the context has not been initialized yet */private MessageSource getMessageSource() throws IllegalStateException &#123; if (this.messageSource == null) &#123; throw new IllegalStateException(\"MessageSource not initialized - \" + \"call 'refresh' before accessing messages via the context: \" + this); &#125; return this.messageSource;&#125; 从中我们可以看到AbstractApplicationContext对MessageSource的实现都是自身所持有的MessageSource类型的messageSource对象来实现的。那么对应的messageSource又是如何初始化的呢？在其中定义了一个initMessageSource()来做对应的初始化工作，其源码如下。 1234567891011121314151617181920212223242526272829protected void initMessageSource() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) &#123; this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class); // Make MessageSource aware of parent MessageSource. if (this.parent != null &amp;&amp; this.messageSource instanceof HierarchicalMessageSource) &#123; HierarchicalMessageSource hms = (HierarchicalMessageSource) this.messageSource; if (hms.getParentMessageSource() == null) &#123; // Only set parent context as parent MessageSource if no parent MessageSource // registered already. hms.setParentMessageSource(getInternalParentMessageSource()); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Using MessageSource [\" + this.messageSource + \"]\"); &#125; &#125; else &#123; // Use empty MessageSource to be able to accept getMessage calls. DelegatingMessageSource dms = new DelegatingMessageSource(); dms.setParentMessageSource(getInternalParentMessageSource()); this.messageSource = dms; beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource); if (logger.isDebugEnabled()) &#123; logger.debug(\"Unable to locate MessageSource with name '\" + MESSAGE_SOURCE_BEAN_NAME + \"': using default [\" + this.messageSource + \"]\"); &#125; &#125;&#125; 从上述源码中我们可以看到如果bean容器中存在一个名为messageSource（MESSAGE_SOURCE_BEAN_NAME常量对应的值为messageSource）的bean，则取该bean作为messageSource，如果对应的messageSource是一个HierarchicalMessageSource，则会在父容器存在的情况下取父容器对应的messageSource作为当前messageSource的parentMessageSource。如果当前bean容器中不存在beanName为messageSource的bean，则会生成一个DelegatingMessageSource来作为当前的MessageSource。DelegatingMessageSource基本算是对MessageSource的一个空的实现，在对应父容器的messageSource存在时就使用父容器的messageSource处理，否则就不处理，具体可以参考Spring的API文档或查看DelegatingMessageSource的源码。 鉴于ApplicationContext实现类对MessageSource接口实现的这种机制，如果我们需要通过ApplicationContext来获取国际化信息，那么我们只需要在对应的ApplicationContext中定义一个MessageSource类型的bean，并且指定对应的beanName为messageSource即可。Spring中对MessageSource提供了三个实现类，分别是ReloadableResourceBundleMessageSource、StaticMessageSource和ResourceBundleMessageSource。 2. ResourceBundleMessageSourceResourceBundleMessageSource是基于JDK ResourceBundle的MessageSource接口实现类。它会将访问过的ResourceBundle缓存起来，以便于下次直接从缓存中获取进行使用。 2.1 示例如下我们在bean容器中定义了一个messageSource和一个名为hello的bean，并指定了messageSource的basename为message，即根资源文件应为类路径下的message.properties，其它的都是需要带Locale后缀的，如中国大陆是message_zh_CN.properties。 12345&lt;bean id=\"messageSource\" class=\"org.springframework.context.support.ResourceBundleMessageSource\"&gt; &lt;property name=\"basename\" value=\"message\"/&gt;&lt;/bean&gt;&lt;bean id=\"hello\" class=\"com.app.Hello\"/&gt; 其中类Hello的代码如下所示，我们可以看到其通过实现ApplicationContextAware接口注入了当前的ApplicationContext对象，然后在其doSomething()方法中我们通过注入的ApplicationContext对象以code为“appName”获取从对应的国际化信息，这里在中文环境下默认就会从message_zh_CN.properties文件中获取。 123456789101112131415public class Hello implements ApplicationContextAware &#123; private ApplicationContext context; public void doSomething() &#123; String appName = context.getMessage(\"appName\", null, null); System.out.println(appName); &#125; public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.context = applicationContext; &#125;&#125; 接下来我们在类路径下分别建立message_zh_CN.properties文件和message.properties文件。其内容分别对应如下。 1、message.properties文件内容 1appName=test 2、message_zh_CN.properties文件内容 1appName=测试 接下来我们运行如下测试代码，将看到控制台将输出“测试”，因为在获取对应信息时我们没有指定Locale，所以默认会取当前的Locale，即zh_CN，所以对应的信息将从message_zh_CN.properties文件中获取。1234567891011121314@ContextConfiguration(&#123;\"classpath:/applicationContext.xml\"&#125;)@RunWith(SpringJUnit4ClassRunner.class)public class ApplicationContextTest &#123; @Autowired private ApplicationContext context; @Test public void test() &#123; Hello hello = context.getBean(\"hello\", Hello.class); hello.doSomething(); &#125; &#125; 2.2 指定多个basename在上述示例中我们通过setBasename()指定了ResourceBundleMessageSource的一个对应资源文件的基名称。但有时候我们可能会存在多种分类的资源文件，它们对应不同的基名称，如view.properties、remind.properties等，对于这种情况我们就可以通过ResourceBundleMessageSource的setBasenames()方法来指定多个basename。12345678&lt;bean id=\"messageSource\" class=\"org.springframework.context.support.ResourceBundleMessageSource\"&gt;&lt;property name=\"basenames\"&gt; &lt;array&gt; &lt;value&gt;remind&lt;/value&gt; &lt;value&gt;view&lt;/value&gt; &lt;/array&gt;&lt;/property&gt;&lt;/bean&gt; 2.3 defaultEncoding可以通过setDefaultEncoding()来指定将用来加载对应资源文件时使用的编码，默认为空，表示将使用默认的编码进行获取。 2.4 fallbackToSystemLocale默认情况下，当指定Locale不存在某code对应的属性时，默认将尝试从系统对应的Locale中解析对应的code，只有都不能解析时才会使用基文件进行解析，如果还不能解析则将抛出异常。打个比方针对基名称“message”我们有两个属性文件， message.properties和message_zh_CN.properties，其中前者定义了appName=test，且定义了hello=hello，而后者只定义了appName=测试，那么当我们通过如下代码获取对应code对应的信息时，输出将如代码中注释所示，即输出两个“测试”，一个“hello”。 123System.out.println(this.messageSource.getMessage(\"appName\", null, null));//测试System.out.println(this.messageSource.getMessage(\"appName\", null, Locale.ENGLISH));//测试System.out.println(this.messageSource.getMessage(\"hello\", null, Locale.CHINA));//hello 第一个输出因为我们没有指定Locale，则默认会使用当前系统的Locale，即中文环境，此时将从message_zh_CN.properties中获取对应code对应的信息，所以输出为“测试”。第二个是因为我们没有定义Locale.ENGLISH对应的本地资源文件，默认将使用当前系统的Locale，即Locale.CHINA，所以输出为“测试”。第三个是因为Locale.CHINA对应的资源文件message_zh_CN.properties文件中不存在对应code的属性，所以将从基文件message.properties中获取，即输出为“hello”。前面已经提到了当指定Locale不能解析指定的code时，默认将使用系统当前的Locale来解析对应的code，这是通过ResourceBundleMessageSource的fallbackToSystemLocale属性来定义的，默认为true，我们可以通过对应的set方法来设置其值为false，以使在指定的Locale不能解析指定的code时将使用基文件来解析对应的code。 1234&lt;bean id=\"messageSource\" class=\"org.springframework.context.support.ResourceBundleMessageSource\"&gt; &lt;property name=\"basename\" value=\"message\"/&gt; &lt;property name=\"fallbackToSystemLocale\" value=\"false\"/&gt;&lt;/bean&gt; 当我们指定了fallbackToSystemLocale为false后，再运行上述测试代码时对应结果将如下。其中第一个跟第三个的输出结果将不变，第二个将变为“test”，因为此时使用Locale.ENGLISH不能解析appName时将使用基文件message.properties来解析。 123System.out.println(this.messageSource.getMessage(\"appName\", null, null));//测试System.out.println(this.messageSource.getMessage(\"appName\", null, Locale.ENGLISH));//testSystem.out.println(this.messageSource.getMessage(\"hello\", null, Locale.CHINA));//hello 关于ResourceBundleMessageSource的更多信息请参考Spring API文档，或查看对应的源码。 3. ReloadableResourceBundleMessageSourceReloadableResourceBundleMessageSource是以ResourceBundleMessageSource结尾的，但实际上它跟ResourceBundleMessageSource没有什么直接的关系。ReloadableResourceBundleMessageSource也是对MessageSource的一种实现，其用法配置等和ResourceBundleMessageSource基本一致。所不同的是ReloadableResourceBundleMessageSource内部是使用PropertiesPersister来加载对应的文件，这包括properties文件和xml文件，然后使用java.util.Properties来保存对应的数据。另外，ReloadableResourceBundleMessageSource允许我们指定非类路径下的文件作为对应的资源文件，而ResourceBundleMessageSource是限制了我们只能将对应的资源文件放置在类路径下的。在指定basename时，我们还可以使用Spring支持的资源文件的前缀，如classpath等。 12345&lt;bean id=\"messageSource\" class=\"org.springframework.context.support.ReloadableResourceBundleMessageSource\"&gt; &lt;property name=\"basename\" value=\"classpath:message\"/&gt; &lt;property name=\"fallbackToSystemLocale\" value=\"false\"/&gt; &lt;property name=\"defaultEncoding\" value=\"UTF-8\"/&gt;&lt;/bean&gt; 3.1 cacheSecondsReloadableResourceBundleMessageSource也是支持缓存对应的资源文件的，默认的缓存时间为永久，即获取了一次资源文件后就将其缓存起来，以后再也不重新去获取该文件。这个可以通过setCacheSeconds()方法来指定对应的缓存时间，单位为秒。前面我们已经说过ResourceBundleMessageSource也是会缓存对应的资源文件的，而且其也可以通过setCacheSeconds()方法指定对应的缓存时间，但是即使指定了也不会生效，其不会对缓存过的文件重新加载。1234&lt;bean id=\"messageSource\" class=\"org.springframework.context.support.ReloadableResourceBundleMessageSource\"&gt; &lt;property name=\"basename\" value=\"classpath:message\"/&gt; &lt;property name=\"cacheSeconds\" value=\"1200\"/&gt;&lt;/bean&gt; 3.2 concurrentRefreshReloadableResourceBundleMessageSource使用concurrentRefresh属性来控制是否允许并发刷新，默认为true。其表示当线程A正在刷新缓存的资源文件F时，线程B也准备刷新缓存的资源文件F，那么线程A将继续执行刷新缓存的资源文件F的动作，而线程B将直接获取到原来缓存的资源文件F，当然这里也可以是取的线程A刚刚刷新的那个资源文件F。如果我们设定concurrentRefresh为false，那么先获取到对应锁的线程A将先刷新缓存中的资源文件F，然后在其释放对应的锁后，线程B将获取到对应的锁并再一次刷新缓存中的资源文件F。 3.3 注入MessageSource除了直接使用ApplicationContext对象来获取对应code的国际化信息外，我们还可以给对应的bean直接注入一个MessageSource对象以直接通过对应的MessageSource对象来获取对应code的国际化信息。给bean注入MessageSource主要有两种方式，一种是直接注入，一种是间接的通过实现MessageSourceAware接口进行注入。 3.3.1 直接注入直接注入就可以跟普通bean注入一样进行注入，可以使用注解标注进行注入，也可以使用XML配置进行注入。以下是一个使用XML方式通过set方法进行注入的示例。 1234567&lt;bean id=\"messageSource\" class=\"org.springframework.context.support.ResourceBundleMessageSource\"&gt; &lt;property name=\"basename\" value=\"message\"/&gt;&lt;/bean&gt;&lt;bean id=\"hello\" class=\"com.app.Hello\"&gt; &lt;property name=\"messageSource\" ref=\"messageSource\"/&gt;&lt;/bean&gt; 对应Hello的定义如下。 1234567891011121314public class Hello &#123; private MessageSource messageSource; public void doSomething() &#123; String appName = this.messageSource.getMessage(\"appName\", null, null); System.out.println(appName); &#125; public void setMessageSource(MessageSource messageSource) &#123; this.messageSource = messageSource; &#125;&#125; 3.3.2 实现MessageSourceAware接口当一个bean实现了MessageSourceAware接口时，ApplicationContext在实例化对应的bean后会将自己作为MessageSource回调MessageSourceAware实现类的setMessageSource()方法以实现MessageSource的注入。如下代码中Hello类就实现了MessageSourceAware接口。 1234567891011121314public class Hello implements MessageSourceAware &#123; private MessageSource messageSource; public void doSomething() &#123; String appName = this.messageSource.getMessage(\"appName\", null, null); System.out.println(appName); &#125; public void setMessageSource(MessageSource messageSource) &#123; this.messageSource = messageSource; &#125;&#125;","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"国际化","slug":"国际化","permalink":"http://blog.shagle.cn/tags/国际化/"}]},{"title":"Java技术之ResourceBundle使用详解","slug":"Java技术之ResourceBundle使用详解","date":"2019-01-10T06:51:50.000Z","updated":"2019-01-10T06:58:29.000Z","comments":true,"path":"2019/01/10/Java技术之ResourceBundle使用详解/","link":"","permalink":"http://blog.shagle.cn/2019/01/10/Java技术之ResourceBundle使用详解/","excerpt":"","text":"1. JAVA中ResourceBundle使用详解 这个类主要用来解决国际化和本地化问题。国际化和本地化可不是两个概念，两者都是一起出现的。可以说，国际化的目的就是为了实现本地化。比如对于“取消”，中文中我们使用“取消”来表示，而英文中我们使用“cancel”。若我们的程序是面向国际的（这也是软件发展的一个趋势），那么使用的人群必然是多语言环境的，实现国际化就非常有必要。而ResourceBundle可以帮助我们轻松完成这个任务：当程序需要一个特定于语言环境的资源时（如 String），程序可以从适合当前用户语言环境的资源包（大多数情况下也就是.properties文件）中加载它。这样可以编写很大程度上独立于用户语言环境的程序代码，它将资源包中大部分（即便不是全部）特定于语言环境的信息隔离开来。 这使编写的程序可以： 轻松地本地化或翻译成不同的语言 一次处理多个语言环境 以后可以轻松进行修改，以便支持更多的语言环境说的简单点，这个类的作用就是读取资源属性文件（properties），然后根据.properties文件的名称信息（本地化信息），匹配当前系统的国别语言信息（也可以程序指定），然后获取相应的properties文件的内容。 使用这个类，properties需要遵循一定的命名规范，一般的命名规范是： 自定义名语言代码国别代码.properties，如果是默认的，直接写为：自定义名.properties。 比如：1234myres_en_US.properties myres_zh_CN.propertiesmyres.properties 当在中文操作系统下，如果myres_zh_CN.properties、myres.properties两个文件都存在，则优先会使用myres_zh_CN.properties，当myres_zh_CN.properties不存在时候，会使用默认的myres.properties。 没有提供语言和地区的资源文件是系统默认的资源文件。 资源文件都必须是ISO-8859-1编码，因此，对于所有非西方语系的处理，都必须先将之转换为Java Unicode Escape格式。转换方法是通过JDK自带的工具native2ascii. 1.1. ResourceBundle的类层次结构 PropertyResourceBundle将本地化的文本存储于Java property文件中。 1.2. 从ResourceBundle中获取值 获取ResourceBundle实例后可以通过下面的方法获得本地化值。 getObject(String key); getString(String key); getStringArray(String key); 还可以通过keySet()方法获取所有的key。Set keys = bundle.keySet(); 其它ResourceBundle 方法可以通过查看文档获得。 1.3. 测试及验证 1.3.1. 新建4个属性文件 1234my_en_US.properties：cancelKey=cancelmy_zh_CN.properties：cancelKey=\\u53D6\\u6D88（取消）my_zh.properties：cancelKey=\\u53D6\\u6D88zh（取消zh）my.properties：cancelKey=\\u53D6\\u6D88default（取消default） 1.3.2. 获取bundle 其中new Locale(“zh”, “CN”)提供本地化信息，上面这行代码，程序会首先在classpath下寻找my_zh_CN.properties文件，若my_zh_CN.properties文件不存在，则取找my_zh.properties，如还是不存在，继续寻找my.properties,若都找不到就抛出异常。 代码 123456789101112131415161718192021public static void main(String args[]) &#123; ResourceBundle bundle = ResourceBundle.getBundle(\"my\", new Locale(\"zh\", \"CN\")); String cancel = bundle.getString(\"cancelKey\"); System.out.println(cancel); bundle = ResourceBundle.getBundle(\"my\", Locale.US); cancel = bundle.getString(\"cancelKey\"); System.out.println(cancel); bundle = ResourceBundle.getBundle(\"my\", Locale.getDefault()); cancel = bundle.getString(\"cancelKey\"); System.out.println(cancel); bundle = ResourceBundle.getBundle(\"my\", Locale.GERMAN); cancel = bundle.getString(\"cancelKey\"); System.out.println(cancel); bundle = ResourceBundle.getBundle(\"my\"); for (String key : bundle.keySet()) &#123; System.out.println(bundle.getString(key)); &#125;&#125; 输出结果 12345取消 cancel 取消 取消 取消 说明：前面三个分别按照zh_CN,US,默认的结果输出，第四个由于我们未定义GERMAN属性文件，这时ResourceBundle为我们提供了一个fallback（也就是一个备用方案），这个备用方案就是根据当前系统的语言环境来得到的本地化信息。所以若是找不到GERMAN的，之后就会去找CHINA了，所以找到了res_zh_CH.properties这个资源包。最后一个是若有多个属性文件，可以按照Map的形式遍历，获得属性文件内的各个值。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"ResourceBundle","slug":"ResourceBundle","permalink":"http://blog.shagle.cn/tags/ResourceBundle/"},{"name":"国际化","slug":"国际化","permalink":"http://blog.shagle.cn/tags/国际化/"}]},{"title":"Spring 事件机制","slug":"Spring-事件机制","date":"2019-01-10T06:17:35.000Z","updated":"2019-01-10T06:30:10.000Z","comments":true,"path":"2019/01/10/Spring-事件机制/","link":"","permalink":"http://blog.shagle.cn/2019/01/10/Spring-事件机制/","excerpt":"","text":"1. 使用Spring 事件首先spring事件分为事件发布者(EventPublisher)、事件监听者(EventListener),还包括一个事件广播者(这个是spring实现相关，这一节不讨论)。使用spring事件机制，需要自定义事件发布者和监听者。以一个简单的例子开始，事件发布者发送一个string类型的消息，接受者将接收到的消息打印出来。 1.1 事件发布者1234567891011121314@Componentpublic class SaySomethingPublisher implements ApplicationEventPublisherAware&#123; private ApplicationEventPublisher applicationEventPublisher; public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) &#123; this.applicationEventPublisher = applicationEventPublisher; &#125; public void saySomething(String msg)&#123; applicationEventPublisher.publishEvent(msg); &#125;&#125;// 需要实现ApplicationEventPublisherAware这个Aware接口，广播事件需要利用applicationEventPublisher 关于ApplicationEventPublisherAware如下： 1234public interface ApplicationEventPublisher &#123; void publishEvent(ApplicationEvent event); void publishEvent(Object event);&#125; 用户发布的事件类型可以是： 用户可以继承ApplicationEvent从而自定义Event类型 也可以使用任意Object类型，但是如果event真实类型不是ApplicationEvent的话，那么event会被封装成PayloadApplicationEvent 1.2 事件监听者12345678910//事件监听者需要实现ApplicationListener接口@Componentpublic class ListenerA implements ApplicationListener&lt;PayloadApplicationEvent&lt;String&gt;&gt; &#123; // 由于监听的是String类型的事件会被封装成PayloadApplicationEvent，所以此处类型是PayloadApplicationEvent public void onApplicationEvent(PayloadApplicationEvent event) &#123; // getSource返回真实的事件 Object msg = event.getSource(); System.out.println(\"ListenerA receive:\" + msg); &#125;&#125; 关于发布出去的事件，那些监听者会监听到？ 发布的事件类型是ApplicationEvent的实现类A那么所有监听者的onApplicationEvent的参数类型是A或者A的子类都会收到事件。 发布的事件类型是不是ApplicationEvent类型，类型是B这种情况下，最终事件会被包装成PayloadApplicationEvent&lt;B&gt;, 那么所有监听者方法onApplicationEvent的参数是PayloadApplicationEvent&lt;B&gt;的监听者会收到， 假设有C是B的父类，且有一个监听者X监听PayloadApplicationEvent&lt;C&gt;,那X是收不到PayloadApplicationEvent&lt;B&gt;类型的事件的 2. Spring事件原理Spring事件机制是观察者模式的一种实现，但是除了发布者和监听者者两个角色之外，还有一个EventMultiCaster的角色负责把事件转发给监听者，工作流程如下： 也就是说上面代码中发布者调用applicationEventPublisher.publishEvent(msg); 是会将事件发送给了EventMultiCaster， 而后由EventMultiCaster注册着所有的Listener，然后根据事件类型决定转发给那个Listener。 2.1 EventMultiCasterApplicationContext完成bean的装配和初始化后(非lazy-init的singleton bean会加载后就初始化)，会尝试创建一个eventMultiCaster，创建代码如下： 123456789101112131415161718192021protected void initApplicationEventMulticaster() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); //判断有没有一个name是“applicationEventMulticaster”且实现了“ ApplicationEventMulticaster”的bean，有的话那它就是eventMultiCaster if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); if (logger.isDebugEnabled()) &#123; logger.debug(\"Using ApplicationEventMulticaster [\" + this.applicationEventMulticaster + \"]\"); &#125; &#125; else &#123; // 没有这样一个bean，那就会创建一个默认的 this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); if (logger.isDebugEnabled()) &#123; logger.debug(\"Unable to locate ApplicationEventMulticaster with name '\" + APPLICATION_EVENT_MULTICASTER_BEAN_NAME + \"': using default [\" + this.applicationEventMulticaster + \"]\"); &#125; &#125;&#125; 默认SimpleApplicationEventMulticaster直接看一下SimpleApplicationEventMulticaster用来广播event的代码：123456789101112131415161718192021public void multicastEvent(final ApplicationEvent event, ResolvableType eventType) &#123; // 这个是用来根据event的类型找到合适的listener的 ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; Executor executor = getTaskExecutor(); // executor不是空的时候会在executor中激活listener if (executor != null) &#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; invokeListener(listener, event); &#125; &#125;); &#125; // 否则就直接在当前调用线程中激活listener else &#123; invokeListener(listener, event); &#125; &#125;&#125; 在创建SimpleApplicationEventMulticaster时，executor是null，所以默认情况下所有的listener 的onApplicationEvent是直接在当前线程(事件发布者所在线程)中调用，所以如果onApplicationEvent有阻塞操作也会导致事件发布者被阻塞，后续的其他listener也会被阻塞无法调用。 自定义multicaster「2.1」中介绍spring会加载一个叫applicationEventMulticaster且实现了ApplicationEventMulticaster接口的multicaster，自定义multicaster需要实现了该接口然后将bean的名字设为applicationEventMulticaster即可。下面的例子为默认的SimpleApplicationEventMulticaster添加了executor，以使事件发布者和监听者不用在同一个线程中调用： 12345678//使用线程池运行listener&lt;bean id=\"executorService\" class=\"java.util.concurrent.Executors\" factory-method=\"newCachedThreadPool\"&gt; &lt;/bean&gt;&lt;bean id=\"applicationEventMulticaster\" class=\"org.springframework.context.event.SimpleApplicationEventMulticaster\"&gt; &lt;property name=\"taskExecutor\" ref=\"executorService\"&gt; &lt;/property&gt;&lt;/bean&gt; 3. 附Spring启动完成之后(已经完成bean解析，non-lazy-init的singleton实例化和初始化，完成listener的注册)，默认会发布一个ContextRefreshedEvent事件，该事件包装的消息是一个ApplicationContext对象。","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"ApplicationEvent","slug":"ApplicationEvent","permalink":"http://blog.shagle.cn/tags/ApplicationEvent/"}]},{"title":"Spring 错误的使用BeanFactoryPostProcessor","slug":"Spring-错误的使用BeanFactoryPostProcessor","date":"2019-01-10T03:05:30.000Z","updated":"2019-01-10T06:26:55.000Z","comments":true,"path":"2019/01/10/Spring-错误的使用BeanFactoryPostProcessor/","link":"","permalink":"http://blog.shagle.cn/2019/01/10/Spring-错误的使用BeanFactoryPostProcessor/","excerpt":"在公司内，Spring基本都是首选的IOC框架，Spring也提供了很多扩展点让我们介入到容器的生命周期中，例如BeanFactoryPostProcessor、BeanPostProcessor等。今天就记录下BeanFactoryPostProcessor的一种不正确用法。","text":"在公司内，Spring基本都是首选的IOC框架，Spring也提供了很多扩展点让我们介入到容器的生命周期中，例如BeanFactoryPostProcessor、BeanPostProcessor等。今天就记录下BeanFactoryPostProcessor的一种不正确用法。 1. 约定实例化：instantiation初始化：initialization 2. BeanFactoryPostProcessor的作用首先贴下BeanFactoryPostProcessor的源码吧 1234public interface BeanFactoryPostProcessor &#123; void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125; 首先请一字一句通读一下doc，其中两句话非常重要： BeanFactoryPostProcessor允许使用者修改容器中的bean definitions BeanFactoryPostProcessor可以与bean definitions打交道，但是千万不要进行bean实例化（感觉这里应该说的是不要在BeanFactoryPostProcessor进行可能触发bean实例化的操作）。这么做可能会导致bean被提前实例化，会破坏容器造成预估不到的副作用。如果你需要hack到bean实例化过程，请考虑使用BeanPostProcessor。 从doc中可以读到，BeanFactoryPostProcessor的主要作用是让你能接触到bean definitions，对bean definitions进行一定hack，但是也仅此而已了。绝对不允许在BeanFactoryPostProcessor中触发到bean的实例化！！！ 为啥呢，doc说得很清楚but never bean instances. Doing so may cause premature bean instantiation, violating the container and causing unintended side-effects. 下面就列举错误使用造成的两种典型“副作用”。 3. 副作用1——使用注解进行依赖注入失败贴一下示例代码片段吧。 1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class PrematureBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; Map&lt;String, BBean&gt; map = beanFactory.getBeansOfType(BBean.class); for (BBean bBean : map.values()) &#123; assert bBean.getABean() == null; &#125; &#125;&#125;@Component(\"bBean\")public class BBean &#123; @Autowired private ABean aBean; public ABean getABean() &#123; return aBean; &#125;&#125;@Componentpublic class ABean &#123; private String name = \"a\"; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 如上demo所示，在运行后，BBean中被期待注入的ABean最终为null。这是为啥呢？ 贴一段ApplicationContext的启动代码吧 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778@Override public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. //调用容器准备刷新的方法，获取容器的当前时间，同时给容器设置同步表示 prepareRefresh(); //告诉子类启动refreshBeanFactory()方法，bean定义资源文件的载入从子类的refreshBeanFactory()方法启动 // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); //为BeanFactory配置容器特性，例如类加载器，事件处理器等 //准备在上下文中使用的bean工厂 // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; //为容器的某些子类指定特殊的BeanPost事件处理器 // Allows post-processing of the bean factory in context subclasses. 允许在上下文子类中对bean工厂进行后处理。 postProcessBeanFactory(beanFactory); // 调用所有注册的BeanFactoryPostProcessor的bean // Invoke factory processors registered as beans in the context. 在上下文中调用注册为bean的工厂处理器。 invokeBeanFactoryPostProcessors(beanFactory); //为BeanFactory注册BeanPost事件处理器。 //BeanPostProcessor是bean后置处理器，用于监听容器触发的事件 // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); //初始化资源信息，和国际化相关 // Initialize message source for this context. initMessageSource(); //初始化容器事件传播器 // Initialize event multicaster for this context. initApplicationEventMulticaster(); //调用子类的某些特殊Bean初始化方法 // Initialize other special beans in specific context subclasses. onRefresh(); //为事件传播器注册事件监听器 // Check for listener beans and register them. registerListeners(); //初始化所有剩余的单列bean // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); //初始化容器的生命周期事件处理器，并发布容器的生命周期事件 // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; //销毁已创建的bean // Destroy already created singletons to avoid dangling resources. destroyBeans(); // 取消refresh操作，重置容器的同步标识 // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125; &#125; 可以看到的是postProcessBeanFactory(beanFactory); 首先invoke了容器中的BeanFactoryPostProcessor实现类，其中当然就包括PrematureBeanFactoryPostProcessor，此时通过beanFactory.getBeansOfType触发了bean提前实例化。按理说，bean提前实例化也应该没问题的，aBean也应该是能够被注入的呀！那为啥最终不是这个结果呢。让我们研究下@Resource @AutoWired这种注解是如何注入依赖的，如何起作用的就明白了。@AutoWired起作用依赖AutowiredAnnotationBeanPostProcessor,@Resource依赖CommonAnnotationBeanPostProcessor，这俩都是BeanPostProcessor的实现。那BeanPostProcessors在何处被spring invoke呢，参见registerBeanPostProcessors(beanFactory);在postProcessBeanFactory(beanFactory); 后面被调用，也就是说BBean被触发提前初始化的时候，AutowiredAnnotationBeanPostProcessor还没有被注册自然也不会被执行到，自然ABean=null 4. 副作用2——可能会将ApplicationContext容器启动过程暴露在多线程之下“将ApplicationContext容器启动过程暴露在多线程之下”倒不完全是因为错误使用BeanFactoryPostProcessor，而是错上加错。假设我们发现在副作用1的场景下aBean无法注入，而将BBean通过如下方式修改 123456789101112131415161718192021222324@Component(\"bBean\")public class BBean implements ApplicationContextAware &#123; private ApplicationContext context; @Autowired private ABean aBean; public ABean getABean() &#123; return (ABean)context.getBean(\"aBean\"); &#125; @Override public String toString() &#123; return \"BBean&#123;\" + \"aBean=\" + aBean + '&#125;'; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.context = applicationContext; &#125;&#125; 这样问题就更大了，虽然在大多数的场景下不会有问题。但是如果BBean是类似于像DTS processer bean或者像是MetaQ的 listener bean情况就非常糟糕了。这种bean一旦被实例化+初始化之后就可以接受请求，如果在请求处理代码中触发了Spring bean的实例化过程，则此时的容器会被破坏，结果是无法预知的。而且问题和可能不太容易复现，因为只有在spring启动过程中请求进来触发ABean首次实例化才有可能会发生错误。强烈要求MetaQ listener DTSprocesser等bean依赖容器自身的依赖注入，不要认为干扰；如果实在要用listener or processor 中使用context.getBean(“aBean”)的方式，那也请做好listener or processor 的生命周期管理，保证在容器彻底起来之后才开始处理请求 5. 总结本文列举了BeanFactoryPostProcessor错误使用可能造成的问题。认真读doc，共勉！ 原文出自：https://www.jianshu.com/p/3d099ea43b0e参考：https://www.cnblogs.com/quanyongan/p/4133725.html","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"BeanFactoryPostProcessor","slug":"BeanFactoryPostProcessor","permalink":"http://blog.shagle.cn/tags/BeanFactoryPostProcessor/"}]},{"title":"Spring Properties Loader","slug":"Spring-Properties-Loader","date":"2019-01-09T06:20:11.000Z","updated":"2019-01-10T01:38:19.000Z","comments":true,"path":"2019/01/09/Spring-Properties-Loader/","link":"","permalink":"http://blog.shagle.cn/2019/01/09/Spring-Properties-Loader/","excerpt":"最近在做Spring项目时，使用到了@Value注解，可以动态注入到注解了@Value的属性上；一般我们会把用到的属性(key/value值)统一放到一个或者多个properties文件中，Spring启动时加载properties把属性读到Spring Property组件中，后续的注入交由组件完成。","text":"最近在做Spring项目时，使用到了@Value注解，可以动态注入到注解了@Value的属性上；一般我们会把用到的属性(key/value值)统一放到一个或者多个properties文件中，Spring启动时加载properties把属性读到Spring Property组件中，后续的注入交由组件完成。 我们一贯的做法是在application.xml 中，加载PropertiesLoaderSupport组件； 123456789101112131415&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:content=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/p http://www.springframework.org/schema/p/spring-p.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;bean class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"&gt; &lt;property name=\"location\" value=\"classpath*:config.properties\" /&gt; &lt;/bean&gt;&lt;/beans&gt; 1. 结构由于PropertyPlaceholderConfigurer实现了BeanFactoryPostProcessor接口；BeanFactory在加载的时候会调用该接口； 那我们看看加载过程； 首先来看看类结构： 12345678ackage org.springframework.beans.factory.config;import org.springframework.beans.BeansException;public interface BeanFactoryPostProcessor &#123; void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125; 看看postProcessBeanFactory在BeanFactory初始化时在哪里调用的，我会先从哪个地方调用了这个方法，一步一步找到，最初加载调用的地方； 除了第二行，其它显示的都是注释；鼠标点击第二行进入；最终会跳到： 这个是一个静态的私用方法，在找(由于代码太长我就不粘出来了；大家可以去找找看)PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors方法调用了本类中的静态方法PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors；那我们就找哪里调用了PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors方法； 发现跳到AbstractApplicationContext类中；而AbstractApplicationContext是所有实现ApplicationContext子类的抽象父类；我们在看看那个地方调用了AbstractApplicationContext.invokeBeanFactoryPostProcessors; 最终找到了加载properties的源头，refresh()方法我就过多介绍了； 2. 如何加载Properties上面我们知道类的加载过程，接下来看看properties如何加载的。 回到PlaceholderConfigurerSupport.postProcessBeanFactory() 123456789101112131415@Overridepublic void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; try &#123; Properties mergedProps = mergeProperties(); // Convert the merged properties, if necessary. convertProperties(mergedProps); // Let the subclass process the properties. processProperties(beanFactory, mergedProps); &#125; catch (IOException ex) &#123; throw new BeanInitializationException(\"Could not load properties\", ex); &#125;&#125; mergeProperties (): 改方法主要做了两件事 加载properties文件 loadProperties() 合并指定的Property (参考原码) convertProperties(): 该方法没有做什么处理，但是有兴趣的同学可以看看源码，去了解一下； processProperties():这是个抽象方法，交由子类实现； 子类就是文件开头介绍的PropertyPlaceholderConfigurer，看看该类实现了什么功能。12345678@Overrideprotected void processProperties(ConfigurableListableBeanFactory beanFactoryToProcess, Properties props) throws BeansException &#123; StringValueResolver valueResolver = new PlaceholderResolvingStringValueResolver(props); this.doProcessProperties(beanFactoryToProcess, valueResolver);&#125; Spring 最终把处理${} 或者 @Value的方式交由StringValueResolver来完成； 源码介绍的不够全面，需要你进入源码中，一步一步去理解。 3. 如何解析Properties通过看源码发现最终属性解析是在PropertyPlaceholderConfigurer.resolvePlaceholder方法中。 12345678910111213protected String resolvePlaceholder(String placeholder, Properties props, int systemPropertiesMode) &#123; String propVal = null; if (systemPropertiesMode == SYSTEM_PROPERTIES_MODE_OVERRIDE) &#123; propVal = resolveSystemProperty(placeholder); &#125; if (propVal == null) &#123; propVal = resolvePlaceholder(placeholder, props); &#125; if (propVal == null &amp;&amp; systemPropertiesMode == SYSTEM_PROPERTIES_MODE_FALLBACK) &#123; propVal = resolveSystemProperty(placeholder); &#125; return propVal;&#125; 参数介绍 placeholder:要解析的属性key props: PlaceholderConfigurerSupport.postProcessBeanFactory()方法中解析的properties systemPropertiesMode:有三个值 SYSTEM_PROPERTIES_MODE_NEVER:不从System.getProperty()中获取placeholder对应的值。 SYSTEM_PROPERTIES_MODE_FALLBACK: 如果props中找不到placeholder对应的值，就从System.getProperty()或者System.getenv()中找。 SYSTEM_PROPERTIES_MODE_OVERRIDE: 优先从System.getProperty()或者System.getenv()中找placeholder对应的值，如果找不到，才会从props中找 System.getProperty(): 如果systemPropertiesMode的值为SYSTEM_PROPERTIES_MODE_FALLBACK和SYSTEM_PROPERTIES_MODE_OVERRIDE时，默认是从System.getProperty()中查找的； System.getenv(): 如果System.getProperty()中没有有效的值，才会到System.getenv()中查找；但是要从System.getenv()中查找是受PropertyPlaceholderConfigurer.searchSystemEnvironment限制。 写到最后我们总结一下PropertyPlaceholderConfigurer 加载 properties文件 localProperties这个要指定合并的Properties 解析 props System.getProperty() System.getenv() Spring 版本 4+具体实现参考源码。 PropertyPlaceholderConfigurer BeanFactoryPostProcessor AbstractApplicationContext PostProcessorRegistrationDelegate PlaceholderResolvingStringValueResolver PropertyPlaceholderConfigurerResolver SpringProperties spring.properties 最后可以看看PropertySourcesPlaceholderConfigurer和PropertyPlaceholderConfigurer的实现方式有什么不一样？ 原文出自：https://www.jianshu.com/p/ba84993d2f06","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"PropertyPlaceholderConfigurer","slug":"PropertyPlaceholderConfigurer","permalink":"http://blog.shagle.cn/tags/PropertyPlaceholderConfigurer/"}]},{"title":"Spring 属性管理API","slug":"Spring-属性管理API","date":"2019-01-09T02:16:31.000Z","updated":"2019-01-09T06:52:39.000Z","comments":true,"path":"2019/01/09/Spring-属性管理API/","link":"","permalink":"http://blog.shagle.cn/2019/01/09/Spring-属性管理API/","excerpt":"Spring3.1提供了新的属性管理API，而且功能非常强大且很完善，对于一些属性配置信息都应该使用新的API来管理。","text":"Spring3.1提供了新的属性管理API，而且功能非常强大且很完善，对于一些属性配置信息都应该使用新的API来管理。 1. 新的属性管理API PropertySource：属性源，key-value属性对抽象，比如用于配置数据 PropertyResolver：属性解析器，用于解析相应key的value Environment：环境，本身是一个PropertyResolver，但是提供了Profile特性，即可以根据环境得到相应数据（即激活不同的Profile，可以得到不同的属性数据，比如用于多环境场景的配置（正式机、测试机、开发机DataSource配置）） Profile：剖面，只有激活的剖面的组件/配置才会注册到Spring容器，类似于maven中profile 也就是说，新的API主要从配置属性、解析属性、不同环境解析不同的属性、激活哪些组件/配置进行注册这几个方面进行了重新设计，使得API的目的更加清晰，而且功能更加强大。 2. PropertySource key-value对，API如下所示： 1234public String getName() //属性源的名字 public T getSource() //属性源（比如来自Map，那就是一个Map对象） public boolean containsProperty(String name) //是否包含某个属性 public abstract Object getProperty(String name) //得到属性名对应的属性值 非常类似于Map；用例如下： 12345678910@Test public void test() throws IOException &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"encoding\", \"gbk\"); PropertySource propertySource1 = new MapPropertySource(\"map\", map); System.out.println(propertySource1.getProperty(\"encoding\")); ResourcePropertySource propertySource2 = new ResourcePropertySource(\"resource\", \"classpath:resources.properties\"); //name, location System.out.println(propertySource2.getProperty(\"encoding\")); &#125; MapPropertySource的属性来自于一个Map，而ResourcePropertySource的属性来自于一个properties文件，另外还有如PropertiesPropertySource，其属性来自Properties，ServletContextPropertySource的属性来自ServletContext上下文初始化参数等等，大家可以查找PropertySource的继承层次查找相应实现。 12345678@Test public void test2() throws IOException &#123; //省略propertySource1/propertySource2 CompositePropertySource compositePropertySource = new CompositePropertySource(\"composite\"); compositePropertySource.addPropertySource(propertySource1); compositePropertySource.addPropertySource(propertySource2); System.out.println(compositePropertySource.getProperty(\"encoding\")); &#125; CompositePropertySource提供了组合PropertySource的功能，查找顺序就是注册顺序。 另外还有一个PropertySources，从名字可以看出其包含多个PropertySource： 1234public interface PropertySources extends Iterable&lt;PropertySource&lt;?&gt;&gt; &#123; boolean contains(String name); //是否包含某个name的PropertySource PropertySource&lt;?&gt; get(String name); //根据name找到PropertySource &#125; 示例如下： 123456789101112@Test public void test3() throws IOException &#123; //省略propertySource1/propertySource2 MutablePropertySources propertySources = new MutablePropertySources(); propertySources.addFirst(propertySource1); propertySources.addLast(propertySource2); System.out.println(propertySources.get(\"resource\").getProperty(\"encoding\")); for(PropertySource propertySource : propertySources) &#123; System.out.println(propertySource.getProperty(\"encoding\")); &#125; &#125; 默认提供了一个MutablePropertySources实现，我们可以调用addFirst添加到列表的开头，addLast添加到末尾，另外可以通过addBefore(propertySourceName, propertySource)或addAfter(propertySourceName, propertySource)添加到某个propertySource前面/后面；最后大家可以通过iterator迭代它，然后按照顺序获取属性。 到目前我们已经有属性了，接下来需要更好的API来解析属性了。 3. PropertyResolver 属性解析器，用来根据名字解析其值等。API如下所示： 123456789101112131415161718192021222324252627282930313233public interface PropertyResolver &#123; //是否包含某个属性 boolean containsProperty(String key); //获取属性值 如果找不到返回null String getProperty(String key); //获取属性值，如果找不到返回默认值 String getProperty(String key, String defaultValue); //获取指定类型的属性值，找不到返回null &lt;T&gt; T getProperty(String key, Class&lt;T&gt; targetType); //获取指定类型的属性值，找不到返回默认值 &lt;T&gt; T getProperty(String key, Class&lt;T&gt; targetType, T defaultValue); //获取属性值为某个Class类型，找不到返回null，如果类型不兼容将抛出ConversionException &lt;T&gt; Class&lt;T&gt; getPropertyAsClass(String key, Class&lt;T&gt; targetType); //获取属性值，找不到抛出异常IllegalStateException String getRequiredProperty(String key) throws IllegalStateException; //获取指定类型的属性值，找不到抛出异常IllegalStateException &lt;T&gt; T getRequiredProperty(String key, Class&lt;T&gt; targetType) throws IllegalStateException; //替换文本中的占位符（$&#123;key&#125;）到属性值，找不到不解析 String resolvePlaceholders(String text); //替换文本中的占位符（$&#123;key&#125;）到属性值，找不到抛出异常IllegalArgumentException String resolveRequiredPlaceholders(String text) throws IllegalArgumentException; &#125; 从API上我们已经看出解析器的作用了，具体功能就不要罗嗦了。示例如下： 12345678910@Test public void test() throws Exception &#123; //省略propertySources PropertyResolver propertyResolver = new PropertySourcesPropertyResolver(propertySources); System.out.println(propertyResolver.getProperty(\"encoding\")); System.out.println(propertyResolver.getProperty(\"no\", \"default\")); System.out.println(propertyResolver.resolvePlaceholders(\"must be encoding $&#123;encoding&#125;\")); //输出must be encoding gbk &#125; 从如上示例可以看出其非常简单。另外Environment也继承了PropertyResolver。 4. Environment 环境，比如JDK环境，Servlet环境，Spring环境等等；每个环境都有自己的配置数据，如System.getProperties()、System.getenv()等可以拿到JDK环境数据；ServletContext.getInitParameter()可以拿到Servlet环境配置数据等等；也就是说Spring抽象了一个Environment来表示环境配置。 123456789101112public interface Environment extends PropertyResolver &#123;//继承PropertyResolver //得到当前明确激活的剖面 String[] getActiveProfiles(); //得到默认激活的剖面，而不是明确设置激活的 String[] getDefaultProfiles(); //是否接受某些剖面 boolean acceptsProfiles(String... profiles); &#125; 从API上可以看出，除了可以解析相应的属性信息外，还提供了剖面相关的API，目的是： 可以根据剖面有选择的进行注册组件/配置。比如对于不同的环境注册不同的组件/配置（正式机、测试机、开发机等的数据源配置）。它的主要几个实现如下所示： MockEnvironment：模拟的环境，用于测试时使用； StandardEnvironment：标准环境，普通Java应用时使用，会自动注册System.getProperties() 和 System.getenv()到环境； StandardServletEnvironment：标准Servlet环境，其继承了StandardEnvironment，Web应用时使用，除了StandardEnvironment外，会自动注册ServletConfig（DispatcherServlet）、ServletContext及JNDI实例到环境； 除了这些，我们也可以根据需求定义自己的Environment。示例如下： 123456@Test public void test() &#123; //会自动注册 System.getProperties() 和 System.getenv() Environment environment = new StandardEnvironment(); System.out.println(environment.getProperty(\"file.encoding\")); &#125; 其默认有两个属性：systemProperties（System.getProperties()）和systemEnvironment（System.getenv()）。 在web环境中首先在web.xml中配置： 12345678910111213&lt;context-param&gt; &lt;param-name&gt;myConfig&lt;/param-name&gt; &lt;param-value&gt;hello&lt;/param-value&gt; &lt;/context-param&gt; &lt;servlet&gt; &lt;servlet-name&gt;spring&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; 使用StandardServletEnvironment加载时，默认除了StandardEnvironment的两个属性外，还有另外三个属性：servletContextInitParams（ServletContext）、servletConfigInitParams（ServletConfig）、jndiProperties（JNDI）。 然后在程序中通过如下代码注入Environment： 12@Autowired Environment env; 另外也可以直接使用ApplicationContext.getEnvironment()获取；接着就可以用如下代码获取配置： 12System.out.println(env.getProperty(\"myConfig\")); System.out.println(env.getProperty(\"contextConfigLocation\")); 另外我们在运行应用时可以通过-D传入系统参数（System.getProperty()），如java -Ddata=123 com.sishuok.spring3.EnvironmentTest，那么我们可以通过environment.getProperty(“data”) 获取到。 如果我们拿到的上下文是ConfigurableApplicationContext类型，那么可以：ctx.getEnvironment().getPropertySources() ；然后通过PropertySources再添加自定义的PropertySource。 5. Profileprofile，剖面，大体意思是：我们程序可能从某几个剖面来执行应用，比如正式机环境、测试机环境、开发机环境等，每个剖面的配置可能不一样（比如开发机可能使用本地的数据库测试，正式机使用正式机的数据库测试）等；因此呢，就需要根据不同的环境选择不同的配置；如果用过maven，maven中就有profile的概念。 profile有两种： 默认的：通过spring.profiles.default属性获取，如果没有配置默认值是default 明确激活的：通过spring.profiles.active获取查找顺序是：先进性明确激活的匹配，如果没有指定明确激活的（即集合为空）就找默认的；配置属性值从Environment读取。 API请参考Environment部分。设置profile属性，常见的有三种方式： 5.1. 启动Java应用时，通过-D传入系统参数1-Dspring.profiles.active=dev 5.2. 如果是web环境，可以通过上下文初始化参数设置1234&lt;context-param&gt; &lt;param-name&gt;spring.profiles.active&lt;/param-name&gt; &lt;param-value&gt;dev&lt;/param-value&gt; &lt;/context-param&gt; 5.3. 通过自定义添加PropertySource1234Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); map.put(\"spring.profiles.active\", \"dev\"); MapPropertySource propertySource = new MapPropertySource(\"map\", map); env.getPropertySources().addFirst(propertySource); 5.4 直接设置Profile1env.setActiveProfiles(\"dev\", \"test\"); 以上方式都可以设置多个profile，多个之间通过如逗号/分号等分隔。 接着我们就可以通过如下API判断是否激活相应的Profile了： 123if(env.acceptsProfiles(\"dev\", \"test\"))) &#123; //do something &#125; 它们之间是或的关系；即找到一个即可；如果有人想不匹配某个profile执行某些事情，可以通过如”!dev” 即没有dev激活时返回true。 当然这种方式还不是太友好，还需要我们手工编程使用，稍候会介绍如何更好的使用它们。 6. &lt;context:property-placeholder/&gt;${key}占位符属性替换器，配置如下： 12345678910&lt;context:property-placeholder location=\"属性文件，多个之间逗号分隔\" file-encoding=\"文件编码\" ignore-resource-not-found=\"是否忽略找不到的属性文件\" ignore-unresolvable=\"是否忽略解析不到的属性，如果不忽略，找不到将抛出异常\" properties-ref=\"本地Properties配置\" local-override=\"是否本地覆盖模式，即如果true，那么properties-ref的属性将覆盖location加载的属性，否则相反\" system-properties-mode=\"系统属性模式，默认ENVIRONMENT（表示先找ENVIRONMENT，再找properties-ref/location的），NEVER：表示永远不用ENVIRONMENT的，OVERRIDE类似于ENVIRONMENT\" order=\"顺序\" /&gt; ocation：表示属性文件位置，多个之间通过如逗号/分号等分隔； file-encoding：文件编码； ignore-resource-not-found：如果属性文件找不到，是否忽略，默认false，即不忽略，找不到将抛出异常 ignore-unresolvable：是否忽略解析不到的属性，如果不忽略，找不到将抛出异常 properties-ref：本地java.util.Properties配置 local-override：是否本地覆盖模式，即如果true，那么properties-ref的属性将覆盖location加载的属性 system-properties-mode：系统属性模式，ENVIRONMENT（默认），NEVER，OVERRIDE ENVIRONMENT：将使用Spring 3.1提供的PropertySourcesPlaceholderConfigurer，其他情况使用Spring 3.1之前的PropertyPlaceholderConfigurer如果是本地覆盖模式：那么查找顺序是：properties-ref、location、environment，否则正好反过来； OVERRIDE： PropertyPlaceholderConfigurer使用，因为在spring 3.1之前版本是没有Enviroment的，所以OVERRIDE是spring 3.1之前版本的Environment如果是本地覆盖模式：那么查找顺序是：properties-ref、location、System.getProperty(),System.getenv()，否则正好反过来； NEVER：只查找properties-ref、location； order：当配置多个&lt;context:property-placeholder/&gt;时的查找顺序，关于顺序问题请参考：http://www.iteye.com/topic/1131688 具体使用请参考如下文件中的如dataSource：https://github.com/zhangkaitao/es/blob/master/web/src/main/resources/spring-config.xml 7. @PropertySource()Spring 3.1提供的Java Config方式的注解，其属性会自动注册到相应的Environment；如： 1234@Configuration @PropertySource(value = \"classpath:resources.properties\", ignoreResourceNotFound = false) public class AppConfig &#123; &#125; 接着就可以使用env.getProperty(“encoding”)得到相应的属性值。 另外如果想进行Bean属性的占位符替换，需要注册PropertySourcesPlaceholderConfigurer： 1234@Bean public PropertySourcesPlaceholderConfigurer propertySourcesPlaceholderConfigurer() &#123; return new PropertySourcesPlaceholderConfigurer(); &#125; 如上配置等价于XML中的&lt;context:property-placeholder/&gt;配置。 如果想导入多个，在Java8之前需要使用@PropertySources注册多个@PropertySource()。 此处要注意：使用&lt;context:property-placeholder/&gt;不会自动把属性注册到Environment中，而@PropertySource()会；且在XML配置中并没有@PropertySource()等价的XML命名空间配置，如果需要，可以自己写一个。 8. 占位符替换使用Environment属性替换，如：123&lt;context:property-placeholder location=\"classpath:$&#123;env&#125;/resources.properties\"/&gt; &lt;context:component-scan base-package=\"com.sishuok.$&#123;package&#125;\"/&gt; &lt;import resource=\"classpath:$&#123;env&#125;/ctx.xml\"/&gt; 1234567@PropertySource(value = \"classpath:$&#123;env&#125;/resources.properties\")@ComponentScan(basePackages = \"com.sishuok.$&#123;package&#125;\")@ImportResource(value = &#123;\"classpath:$&#123;env&#125;/cfg.xml\"&#125;) @Value(\"$&#123;env&#125;\") new ClassPathXmlApplicationContext(\"classpath:$&#123;env&#125;/cfg.xml\") 使用PropertySourcesPlaceholderConfigurer / PropertyPlaceholderConfigurer进性Bean属性替换，如： 123456&lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name=\"url\" value=\"$&#123;connection.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;connection.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;connection.password&#125;\"/&gt; &lt;/bean&gt; 9. SpEL表达式：请参考Spring-表达式语言之在Bean定义中使用EL 通过如上方式可以实现不同的环境有不同的属性配置，但是如果我们想不同的环境加载不同的Bean呢，比如测试机/正式机环境可能使用远程方式访问某些API，而开发机环境使用本地方式进行开发，提高开发速度，这就需要profile了。 10. &lt;beans profile=”” /&gt;通过在beans标签上加上profile属性，这样当我们激活相应的profile时，此beans标签下的bean就会注册，如下所示： 123456789101112131415&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;beans profile=\"dev\"&gt; &lt;bean id=\"dataSource\" class=\"本地DataSource\"&gt; &lt;/bean&gt; &lt;/beans&gt; &lt;beans profile=\"test\"&gt; &lt;bean id=\"dataSource\" class=\"测试环境DataSource\"&gt; &lt;/bean&gt; &lt;/beans&gt; &lt;/beans&gt; 启动应用时设置相应的“spring.profiles.active”即可。另外，如果想指定一个默认的，可以使用指定（如果不是default，可以通过“spring.profiles.default”指定）。 11. @Profile()Java Config方式的Profile，功能等价于XML中的，使用方式如下： 12345678910@Profile(\"dev\") @Configuration @PropertySource(value = \"classpath:resources.properties\", ignoreResourceNotFound = false) public class AppConfig &#123; @Bean public PropertySourcesPlaceholderConfigurer propertySourcesPlaceholderConfigurer() &#123; return new PropertySourcesPlaceholderConfigurer(); &#125; &#125; Spring4提供了一个新的@Conditional注解，请参考http://jinnianshilongnian.iteye.com/blog/1989379。 12. @ActiveProfiles()在测试时，有时候不能通过系统启动参数/上下文参数等指定Profile，此时Spring测试框架提供了@ActiveProfiles（）注解，示例如下： 123456@ActiveProfiles(\"test\") @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = GenericConfig.class) public class GenricInjectTest &#123; …… &#125; 通过这种方式，我们就激活了test profile。 到此整个Spring的属性管理API就介绍完了，对于属性管理，核心是Environment，所以以后请使用Environment来进行属性管理吧。 原文出自：https://jinnianshilongnian.iteye.com/blog/2000183","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"PropertySource，Environment，Profile","slug":"PropertySource，Environment，Profile","permalink":"http://blog.shagle.cn/tags/PropertySource，Environment，Profile/"}]},{"title":"Spring PropertyPlaceholderHelper(占位符解析器)","slug":"Spring-PropertyPlaceholderHelper","date":"2019-01-08T08:20:03.000Z","updated":"2019-01-09T06:50:59.000Z","comments":true,"path":"2019/01/08/Spring-PropertyPlaceholderHelper/","link":"","permalink":"http://blog.shagle.cn/2019/01/08/Spring-PropertyPlaceholderHelper/","excerpt":"","text":"1. PropertyPlaceholderHelper作用：将字符串里的占位符内容，用我们配置的properties里的替换。这个是一个单纯的类，没有继承没有实现，而且也没简单，没有依赖Spring框架其他的任何类。个人感觉自己项目中可以拿来模仿用。 我们解析的过程： 1、这里先贴一下Spring框架里的全部代码 2、分块解析 3、跑测试看结果，加深理解 2. 分块解析下面这个是PropertyPlaceholderHelper占位解析的主要入口。其大致的过程是将占位的内容一块一块地取下来，通过递归将最内层的占位符先替换掉，然后跳出来替换外面的占位符。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455protected String parseStringValue(String strVal, PlaceholderResolver placeholderResolver, Set&lt;String&gt; visitedPlaceholders) &#123; StringBuilder result = new StringBuilder(strVal); //获取路径中占位符前缀的索引 int startIndex = strVal.indexOf(this.placeholderPrefix); //匹配到占位符前缀,进入循环体 while (startIndex != -1) &#123; int endIndex = findPlaceholderEndIndex(result, startIndex); if (endIndex != -1) &#123; //截取前缀占位符和后缀占位符之间的字符串placeholder String placeholder = result.substring(startIndex + this.placeholderPrefix.length(), endIndex); String originalPlaceholder = placeholder; if (!visitedPlaceholders.add(originalPlaceholder)) &#123; throw new IllegalArgumentException( \"Circular placeholder reference '\" + originalPlaceholder + \"' in property definitions\"); &#125; // 递归调用,继续解析placeholder placeholder = parseStringValue(placeholder, placeholderResolver, visitedPlaceholders); // 获取placeholder的值 String propVal = placeholderResolver.resolvePlaceholder(placeholder); if (propVal == null &amp;&amp; this.valueSeparator != null) &#123; int separatorIndex = placeholder.indexOf(this.valueSeparator); if (separatorIndex != -1) &#123; String actualPlaceholder = placeholder.substring(0, separatorIndex); String defaultValue = placeholder.substring(separatorIndex + this.valueSeparator.length()); propVal = placeholderResolver.resolvePlaceholder(actualPlaceholder); if (propVal == null) &#123; propVal = defaultValue; &#125; &#125; &#125; if (propVal != null) &#123; //对替换完成的value进行解析,防止properties的value值里也有占位符 propVal = parseStringValue(propVal, placeholderResolver, visitedPlaceholders); result.replace(startIndex, endIndex + this.placeholderSuffix.length(), propVal); if (logger.isTraceEnabled()) &#123; logger.trace(\"Resolved placeholder '\" + placeholder + \"'\"); &#125; //重新定位开始索引 startIndex = result.indexOf(this.placeholderPrefix, startIndex + propVal.length()); &#125; else if (this.ignoreUnresolvablePlaceholders) &#123; // Proceed with unprocessed value. startIndex = result.indexOf(this.placeholderPrefix, endIndex + this.placeholderSuffix.length()); &#125; else &#123; throw new IllegalArgumentException(\"Could not resolve placeholder '\" + placeholder + \"'\" + \" in string value \\\"\" + strVal + \"\\\"\"); &#125; visitedPlaceholders.remove(originalPlaceholder); &#125; else &#123; startIndex = -1; &#125; &#125; System.out.println(\"enter...\" + result); return result.toString();&#125; 下面这个方法是用来寻找占位符后缀索引的，需要注意的是withinNestedPlaceholder这个参数控制当我们获取到占位符后缀的时候是选择直接返回还是继续去获取占位符后缀。 123456789101112131415161718192021222324252627private int findPlaceholderEndIndex(CharSequence buf, int startIndex) &#123; //获取前缀后面一个字符的索引 int index = startIndex + this.placeholderPrefix.length(); int withinNestedPlaceholder = 0; //如果前缀后面还有字符的话 while (index &lt; buf.length()) &#123; //判断源字符串在index处是否与后缀匹配 if (substringMatch(buf, index, this.placeholderSuffix)) &#123; //如果匹配到后缀,但此时前缀数量&gt;后缀,则继续匹配后缀 if (withinNestedPlaceholder &gt; 0) &#123; withinNestedPlaceholder--; index = index + this.placeholderSuffix.length(); &#125; else &#123; return index; &#125; &#125; else if (substringMatch(buf, index, this.simplePrefix)) &#123; //判断源字符串在index处是否与前缀匹配,若匹配,说明前缀后面还是前缀,则把前缀长度累加到index上,继续循环寻找后缀 //withinNestedPlaceholder确保前缀和后缀成对出现后 withinNestedPlaceholder++; index = index + this.simplePrefix.length(); &#125; else &#123; //如果index出既不能和suffix又不能和simplePrefix匹配,则自增,继续循环 index++; &#125; &#125; return -1;&#125; 下面这个方法是用来判断str在index索引位置是否和substring匹配。 123456789private boolean substringMatch(CharSequence str, int index, CharSequence substring) &#123; for (int j = 0; j &lt; substring.length(); j++) &#123; int i = index + j; if (i &gt;= str.length() || str.charAt(i) != substring.charAt(j)) &#123; return false; &#125; &#125; return true;&#125; 3、测试test01.properties： 1234name=wangzhaage=18sex=manname18man=love main方法： 1234567891011121314151617181920212223242526272829@Testpublic void testPlace() throws Exception&#123; String a = \"&#123;name&#125;&#123;age&#125;&#123;sex&#125;\"; String b = \"&#123;name&#123;age&#125;&#123;sex&#125;&#125;\"; PropertyPlaceholderHelper propertyPlaceholderHelper = new PropertyPlaceholderHelper(\"&#123;\", \"&#125;\"); InputStream in = new BufferedInputStream(new FileInputStream(ResourceUtils.getFile(\"classpath:test01.properties\"))); ; Properties properties = new Properties(); properties.load(in); System.out.println(\"替换前:\" + a); System.out.println(\"替换后:\" + propertyPlaceholderHelper.replacePlaceholders(a, new PropertyPlaceholderHelper.PlaceholderResolver() &#123; @Override public String resolvePlaceholder(String placeholderName) &#123; String value = properties.getProperty(placeholderName); return value; &#125; &#125;)); System.out.println(\"====================================================\"); System.out.println(\"替换前:\" + b); System.out.println(\"替换后:\" + propertyPlaceholderHelper.replacePlaceholders(b, new PropertyPlaceholderHelper.PlaceholderResolver() &#123; @Override public String resolvePlaceholder(String placeholderName) &#123; String value = properties.getProperty(placeholderName); return value; &#125; &#125;));&#125; 测试结果：","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"占位符解析器","slug":"占位符解析器","permalink":"http://blog.shagle.cn/tags/占位符解析器/"}]},{"title":"java技术之System","slug":"java技术之System类","date":"2019-01-08T07:41:40.000Z","updated":"2019-01-08T11:46:59.000Z","comments":true,"path":"2019/01/08/java技术之System类/","link":"","permalink":"http://blog.shagle.cn/2019/01/08/java技术之System类/","excerpt":"","text":"1. 系统变量之System.getenv()和System.getProperty()Java提供了System类的静态方法getenv()和getProperty()用于返回系统相关的变量与属性，getenv方法返回的变量大多于系统相关，getProperty方法返回的变量大多与java程序有关。 System.getenv() 方法是获取指定的环境变量的值。 System.getenv(String str) 接收参数为任意字符串，当存在指定环境变量时即返回环境变量的值，否则返回null。 System.getProperty() 是获取系统的相关属性，包括文件编码、操作系统名称、区域、用户名等，此属性一般由jvm自动获取，不能设置。 System.getProperty(String str) 接收参数为任意字符串，当存在指定属性时即返回属性的值，否则返回null。 方法定义：12345678public static String getenv(String name) &#123; SecurityManager sm = getSecurityManager(); if (sm != null) &#123; sm.checkPermission(new RuntimePermission(\"getenv.\"+name)); &#125; return ProcessEnvironment.getenv(name);&#125; java.lang.System.getenv(String name)方法获取指定的环境变量的值。环境变量是依赖于系统的外部命名值。 环境变量应使用一个全局作用，或者当外部系统的接口需要一个环境变量(如PATH)。 下面的例子显示java.lang.System.getenv()方法的使用： 12345678910111213141516171819public static void main(String[] args)&#123; System.out.println(\"Java运行时环境版本:\"+System.getProperty(\"java.version\")); System.out.println(\"Java 运行时环境供应商:\"+System.getProperty(\"java.vendor\")); System.out.println(\"Java 供应商的URL:\"+System.getProperty(\"java.vendor.url\")); System.out.println(\"Java安装目录:\"+System.getProperty(\"java.home\")); System.out.println(\"Java 虚拟机规范版本:\"+System.getProperty(\"java.vm.specification.version\")); System.out.println(\"Java 类格式版本号:\"+System.getProperty(\"java.class.version\")); System.out.println(\"Java类路径:\"+System.getProperty(\"java.class.path\")); System.out.println(\"操作系统的名称:\"+System.getProperty(\"os.name\")); System.out.println(\"操作系统的架构:\"+System.getProperty(\"os.arch\")); System.out.println(\"操作系统的版本:\"+System.getProperty(\"os.version\")); System.out.println(\"用户的主目录:\"+System.getProperty(\"user.home\")); System.out.println(\"用户的当前工作目录:\"+System.getProperty(\"user.dir\")); System.out.println(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"); System.out.println(\"自定义变量getProperty CONF_LOCATION:\"+System.getProperty(\"conf.location\")); System.out.println(\"--------------------------------------------\"); System.out.println(\"自定义变量getenv CONF_LOCATION:\"+System.getenv(\"conf.location\"));&#125; 总结：它们返回的是都是map类型的键对值。 在测试项目中经常用在初始化测试环境。 1.1 System.getenv()123456789101112131415161718192021222324System.getenv()USERPROFILE ：用户目录USERDNSDOMAIN ：用户域PATHEXT ：可执行后缀JAVA_HOME ：Java安装目录TEMP ：用户临时文件目录SystemDrive ：系统盘符ProgramFiles ：默认程序目录USERDOMAIN ：帐户的域的名称ALLUSERSPROFILE ：用户公共目录SESSIONNAME ：Session名称TMP ：临时目录Path ：path环境变量CLASSPATH ：classpath环境变量PROCESSOR_ARCHITECTURE ：处理器体系结构OS ：操作系统类型PROCESSOR_LEVEL ：处理级别COMPUTERNAME ：计算机名Windir ：系统安装目录SystemRoot ：系统启动目录USERNAME ：用户名ComSpec ：命令行解释器可执行程序的准确路径APPDATA ：应用程序数据目录 1.2 System.getProperty()123456789101112131415161718192021222324252627282930System.getProperty()java.version Java ：运行时环境版本java.vendor Java ：运行时环境供应商java.vendor.url ：Java供应商的 URLjava.home &amp;nbsp;&amp;nbsp;：Java安装目录java.vm.specification.version： Java虚拟机规范版本java.vm.specification.vendor ：Java虚拟机规范供应商java.vm.specification.name &amp;nbsp; ：Java虚拟机规范名称java.vm.version ：Java虚拟机实现版本java.vm.vendor ：Java虚拟机实现供应商java.vm.name&amp;nbsp; ：Java虚拟机实现名称java.specification.version：Java运行时环境规范版本java.specification.vendor：Java运行时环境规范供应商java.specification.name ：Java运行时环境规范名称java.class.version ：Java类格式版本号java.class.path ：Java类路径java.library.path ：加载库时搜索的路径列表java.io.tmpdir ：默认的临时文件路径java.compiler ：要使用的 JIT编译器的名称java.ext.dirs ：一个或多个扩展目录的路径os.name ：操作系统的名称os.arch ：操作系统的架构os.version ：操作系统的版本file.separator ：文件分隔符path.separator ：路径分隔符line.separator ：行分隔符user.name ：用户的账户名称user.home ：用户的主目录user.dir：用户的当前工作目录","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"getEnv","slug":"getEnv","permalink":"http://blog.shagle.cn/tags/getEnv/"}]},{"title":"Spring Resource接口详解","slug":"Spring-Resource接口详解","date":"2019-01-08T02:40:49.000Z","updated":"2019-01-09T06:54:27.000Z","comments":true,"path":"2019/01/08/Spring-Resource接口详解/","link":"","permalink":"http://blog.shagle.cn/2019/01/08/Spring-Resource接口详解/","excerpt":"在日常程序开发中，处理外部资源是很繁琐的事情，我们可能需要处理URL资源、File资源资源、ClassPath相关资源、服务器相关资源（JBoss AS 5.x上的VFS资源）等等很多资源。因此处理这些资源需要使用不同的接口，这就增加了我们系统的复杂性；而且处理这些资源步骤都是类似的（打开资源、读取资源、关闭资源），因此如果能抽象出一个统一的接口来对这些底层资源进行统一访问，是不是很方便，而且使我们系统更加简洁，都是对不同的底层资源使用同一个接口进行访问。Spring 提供一个Resource接口来统一这些底层资源一致的访问，而且提供了一些便利的接口，从而能提供我们的生产力。","text":"在日常程序开发中，处理外部资源是很繁琐的事情，我们可能需要处理URL资源、File资源资源、ClassPath相关资源、服务器相关资源（JBoss AS 5.x上的VFS资源）等等很多资源。因此处理这些资源需要使用不同的接口，这就增加了我们系统的复杂性；而且处理这些资源步骤都是类似的（打开资源、读取资源、关闭资源），因此如果能抽象出一个统一的接口来对这些底层资源进行统一访问，是不是很方便，而且使我们系统更加简洁，都是对不同的底层资源使用同一个接口进行访问。Spring 提供一个Resource接口来统一这些底层资源一致的访问，而且提供了一些便利的接口，从而能提供我们的生产力。 1. Resource接口Spring的Resource接口代表底层外部资源，提供了对底层外部资源的一致性访问接口。 123public interface InputStreamSource &#123; InputStream getInputStream() throws IOException; &#125; 12345678910111213public interface Resource extends InputStreamSource &#123; boolean exists(); boolean isReadable(); boolean isOpen(); URL getURL() throws IOException; URI getURI() throws IOException; File getFile() throws IOException; long contentLength() throws IOException; long lastModified() throws IOException; Resource createRelative(String relativePath) throws IOException; String getFilename(); String getDescription(); &#125; InputStreamSource接口解析： getInputStream：每次调用都将返回一个新鲜的资源对应的java.io. InputStream字节流，调用者在使用完毕后必须关闭该资源。 Resource接口继承InputStreamSource接口，并提供一些便利方法： exists：返回当前Resource代表的底层资源是否存在，true表示存在。 isReadable：返回当前Resource代表的底层资源是否可读，true表示可读。 isOpen：返回当前Resource代表的底层资源是否已经打开，如果返回true，则只能被读取一次然后关闭以避免资源泄露；常见的Resource实现一般返回false。 getURL：如果当前Resource代表的底层资源能由java.util.URL代表，则返回该URL，否则抛出IOException。 getURI：如果当前Resource代表的底层资源能由java.util.URI代表，则返回该URI，否则抛出IOException。 getFile：如果当前Resource代表的底层资源能由java.io.File代表，则返回该File，否则抛出IOException。 contentLength：返回当前Resource代表的底层文件资源的长度，一般是值代表的文件资源的长度。 lastModified：返回当前Resource代表的底层资源的最后修改时间。 createRelative：用于创建相对于当前Resource代表的底层资源的资源，比如当前Resource代表文件资源“d:/test/”则createRelative（“test.txt”）将返回表文件资源“d:/test/test.txt”Resource资源。 getFilename：返回当前Resource代表的底层文件资源的文件路径，比如File资源“file://d:/test.txt”将返回“d:/test.txt”，而URL资源http://www.javass.cn将返回“”，因为只返回文件路径。 getDescription：返回当前Resource代表的底层资源的描述符，通常就是资源的全路径（实际文件名或实际URL地址）。 Resource接口提供了足够的抽象，足够满足我们日常使用。而且提供了很多内置Resource实现：ByteArrayResource、InputStreamResource 、FileSystemResource 、UrlResource 、ClassPathResource、ServletContextResource、VfsResource等。 2 内置Resource实现2.1 ByteArrayResourceByteArrayResource代表byte[]数组资源，对于getInputStream操作将返回一个ByteArrayInputStream。首先让我们看下使用ByteArrayResource如何处理byte数组资源： 123456789public class ResourceTest &#123; @Test public void testByteArrayResource() &#123; Resource resource = new ByteArrayResource(\"Hello World!\".getBytes()); if(resource.exists()) &#123; dumpStream(resource); &#125; &#125; &#125; 是不是很简单，让我们看下dumpStream实现： 1234567891011121314151617181920private void dumpStream(Resource resource) &#123; InputStream is = null; try &#123; //1.获取文件资源 is = resource.getInputStream(); //2.读取资源 byte[] descBytes = new byte[is.available()]; is.read(descBytes); System.out.println(new String(descBytes)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; //3.关闭资源 is.close(); &#125; catch (IOException e) &#123; &#125; &#125; &#125; 让我们来仔细看一下代码，dumpStream方法很抽象定义了访问流的三部曲：打开资源、读取资源、关闭资源，所以dunpStrean可以再进行抽象从而能在自己项目中使用；byteArrayResourceTest测试方法，也定义了基本步骤：定义资源、验证资源存在、访问资源。 ByteArrayResource可多次读取数组资源，即isOpen ()永远返回false。 2.2 InputStreamResourceInputStreamResource代表java.io.InputStream字节流，对于getInputStream操作将直接返回该字节流，因此只能读取一次该字节流，即“isOpen”永远返回true。让我们看下测试代码吧： 123456789@Test public void testInputStreamResource() &#123; ByteArrayInputStream bis = new ByteArrayInputStream(\"Hello World!\".getBytes()); Resource resource = new InputStreamResource(bis); if(resource.exists()) &#123; dumpStream(resource); &#125; Assert.assertEquals(true, resource.isOpen()); &#125; 测试代码几乎和ByteArrayResource测试完全一样，注意“isOpen”此处用于返回true。 2.3 FileSystemResourceFileSystemResource代表java.io.File资源，对于getInputStream操作将返回底层文件的字节流，“isOpen”将永远返回false，从而表示可多次读取底层文件的字节流。让我们看下测试代码吧： 123456789@Test public void testFileResource() &#123; File file = new File(\"d:/test.txt\"); Resource resource = new FileSystemResource(file); if(resource.exists()) &#123; dumpStream(resource); &#125; Assert.assertEquals(false, resource.isOpen()); &#125; 注意由于“isOpen”将永远返回false，所以可以多次调用dumpStream(resource)。 2.4 ClassPathResourceClassPathResource代表classpath路径的资源，将使用ClassLoader进行加载资源。classpath 资源存在于类路径中的文件系统中或jar包里，且“isOpen”永远返回false，表示可多次读取资源。 ClassPathResource加载资源替代了Class类和ClassLoader类的“getResource(String name)“和“getResourceAsStream(String name)“两个加载类路径资源方法，提供一致的访问方式。 ClassPathResource提供了三个构造器：12public ClassPathResource(String path) //使用默认的`ClassLoader`加载“path“类路径资源；public ClassPathResource(String path, ClassLoader classLoader) //使用指定的ClassLoader加载“path”类路径资源； 比如当前类路径是“cn.javass.spring.chapter4.ResourceTest”，而需要加载的资源路径是“cn/javass/spring/chapter4/test1.properties”，则将加载的资源在“cn/javass/spring/chapter4/test1.properties”；1public ClassPathResource(String path, Class&lt;?&gt; clazz) //使用指定的类加载“path”类路径资源，将加载相对于当前类的路径的资源； 比如当前类路径是“cn.javass.spring.chapter4.ResourceTest”，而需要加载的资源路径是“cn/javass/spring/chapter4/test1.properties”，则将加载的资源在“cn/javass/spring/chapter4/cn/javass/spring/chapter4/test1.properties”；而如果需要 加载的资源路径为“test1.properties”，将加载的资源为“cn/javass/spring/chapter4/test1.properties”。 让我们直接看测试代码吧： 1）使用默认的加载器加载资源，将加载当前ClassLoader类路径上相对于根路径的资源： 123456789@Test public void testClasspathResourceByDefaultClassLoader() throws IOException &#123; Resource resource = new ClassPathResource(\"cn/javass/spring/chapter4/test1.properties\"); if(resource.exists()) &#123; dumpStream(resource); &#125; System.out.println(\"path:\" + resource.getFile().getAbsolutePath()); Assert.assertEquals(false, resource.isOpen()); &#125; 2）使用指定的ClassLoader进行加载资源，将加载指定的ClassLoader类路径上相对于根路径的资源： 12345678910@Test public void testClasspathResourceByClassLoader() throws IOException &#123; ClassLoader cl = this.getClass().getClassLoader(); Resource resource = new ClassPathResource(\"cn/javass/spring/chapter4/test1.properties\" , cl); if(resource.exists()) &#123; dumpStream(resource); &#125; System.out.println(\"path:\" + resource.getFile().getAbsolutePath()); Assert.assertEquals(false, resource.isOpen()); &#125; 3）使用指定的类进行加载资源，将尝试加载相对于当前类的路径的资源： 1234567891011121314151617@Test public void testClasspathResourceByClass() throws IOException &#123; Class clazz = this.getClass(); Resource resource1 = new ClassPathResource(\"cn/javass/spring/chapter4/test1.properties\" , clazz); if(resource1.exists()) &#123; dumpStream(resource1); &#125; System.out.println(\"path:\" + resource1.getFile().getAbsolutePath()); Assert.assertEquals(false, resource1.isOpen()); Resource resource2 = new ClassPathResource(\"test1.properties\" , this.getClass()); if(resource2.exists()) &#123; dumpStream(resource2); &#125; System.out.println(\"path:\" + resource2.getFile().getAbsolutePath()); Assert.assertEquals(false, resource2.isOpen()); &#125; “resource1”将加载cn/javass/spring/chapter4/cn/javass/spring/chapter4/test1.properties资源；“resource2”将加载“cn/javass/spring/chapter4/test1.properties”； 4）加载jar包里的资源，首先在当前类路径下找不到，最后才到Jar包里找，而且在第一个Jar包里找到的将被返回：123456789@Test public void classpathResourceTestFromJar() throws IOException &#123; Resource resource = new ClassPathResource(\"overview.html\"); if(resource.exists()) &#123; dumpStream(resource); &#125; System.out.println(\"path:\" + resource.getURL().getPath()); Assert.assertEquals(false, resource.isOpen()); &#125; 如果当前类路径包含“overview.html”，在项目的“resources”目录下，将加载该资源，否则将加载Jar包里的“overview.html”，而且不能使用“resource.getFile()”，应该使用“resource.getURL()”，因为资源不存在于文件系统而是存在于jar包里，URL类似于“file:/C:/…/***.jar!/overview.html”。类路径一般都是相对路径，即相对于类路径或相对于当前类的路径，因此如果使用“/test1.properties”带前缀“/”的路径，将自动删除“/”得到“test1.properties”。 2.5 UrlResourceUrlResource代表URL资源，用于简化URL资源访问。“isOpen”永远返回false，表示可多次读取资源。UrlResource一般支持如下资源访问： http：通过标准的http协议访问web资源，如new UrlResource(“http://地址”)； ftp：通过ftp协议访问资源，如new UrlResource(“ftp://地址”)； file：通过file协议访问本地文件系统资源，如new UrlResource(“file:d:/test.txt”)；具体使用方法在此就不演示了，可以参考cn.javass.spring.chapter4.ResourceTest中urlResourceTest测试方法。 2.6 ServletContextResourceServletContextResource代表web应用资源，用于简化servlet容器的ServletContext接口的getResource操作和getResourceAsStream操作；在此就不具体演示了。 2.7 VfsResourceVfsResource代表Jboss 虚拟文件系统资源。 Jboss VFS(Virtual File System)框架是一个文件系统资源访问的抽象层，它能一致的访问物理文件系统、jar资源、zip资源、war资源等，VFS能把这些资源一致的映射到一个目录上，访问它们就像访问物理文件资源一样，而其实这些资源不存在于物理文件系统。在示例之前需要准备一些jar包，在此我们使用的是Jboss VFS3版本，可以下载最新的Jboss AS 6x，拷贝lib目录下的“jboss-logging.jar”和“jboss-vfs.jar”两个jar包拷贝到我们项目的lib目录中并添加到“Java Build Path”中的“Libaries”中。让我们看下示例（cn.javass.spring.chapter4.ResourceTest）： 1234567891011121314151617181920212223242526272829303132333435@Test public void testVfsResourceForRealFileSystem() throws IOException &#123; //1.创建一个虚拟的文件目录 VirtualFile home = VFS.getChild(\"/home\"); //2.将虚拟目录映射到物理的目录 VFS.mount(home, new RealFileSystem(new File(\"d:\"))); //3.通过虚拟目录获取文件资源 VirtualFile testFile = home.getChild(\"test.txt\"); //4.通过一致的接口访问 Resource resource = new VfsResource(testFile); if(resource.exists()) &#123; dumpStream(resource); &#125; System.out.println(\"path:\" + resource.getFile().getAbsolutePath()); Assert.assertEquals(false, resource.isOpen()); &#125; @Test public void testVfsResourceForJar() throws IOException &#123; //1.首先获取jar包路径 File realFile = new File(\"lib/org.springframework.beans-3.0.5.RELEASE.jar\"); //2.创建一个虚拟的文件目录 VirtualFile home = VFS.getChild(\"/home2\"); //3.将虚拟目录映射到物理的目录 VFS.mountZipExpanded(realFile, home, TempFileProvider.create(\"tmp\", Executors.newScheduledThreadPool(1))); //4.通过虚拟目录获取文件资源 VirtualFile testFile = home.getChild(\"META-INF/spring.handlers\"); Resource resource = new VfsResource(testFile); if(resource.exists()) &#123; dumpStream(resource); &#125; System.out.println(\"path:\" + resource.getFile().getAbsolutePath()); Assert.assertEquals(false, resource.isOpen()); &#125; 通过VFS，对于jar里的资源和物理文件系统访问都具有一致性，此处只是简单示例，如果需要请到Jboss官网深入学习。 3 ResourceLoader接口3.1 ResourceLoader接口ResourceLoader接口用于返回Resource对象；其实现可以看作是一个生产Resource的工厂类。 1234public interface ResourceLoader &#123; Resource getResource(String location); ClassLoader getClassLoader(); &#125; getResource接口用于根据提供的location参数返回相应的Resource对象；而getClassLoader则返回加载这些Resource的ClassLoader。 Spring提供了一个适用于所有环境的DefaultResourceLoader实现，可以返回ClassPathResource、UrlResource；还提供一个用于web环境的ServletContextResourceLoader，它继承了DefaultResourceLoader的所有功能，又额外提供了获取ServletContextResource的支持。 ResourceLoader在进行加载资源时需要使用前缀来指定需要加载：“classpath:path”表示返回ClasspathResource，“http://path”和“file:path”表示返回UrlResource资源，如果不加前缀则需要根据当前上下文来决定，DefaultResourceLoader默认实现可以加载classpath资源，如代码所示（cn.javass.spring.chapter4.ResourceLoaderTest）： 12345678910111213@Test public void testResourceLoad() &#123; ResourceLoader loader = new DefaultResourceLoader(); Resource resource = loader.getResource(\"classpath:cn/javass/spring/chapter4/test1.txt\"); //验证返回的是ClassPathResource Assert.assertEquals(ClassPathResource.class, resource.getClass()); Resource resource2 = loader.getResource(\"file:cn/javass/spring/chapter4/test1.txt\"); //验证返回的是ClassPathResource Assert.assertEquals(UrlResource.class, resource2.getClass()); Resource resource3 = loader.getResource(\"cn/javass/spring/chapter4/test1.txt\"); //验证返默认可以加载ClasspathResource Assert.assertTrue(resource3 instanceof ClassPathResource); &#125; 对于目前所有ApplicationContext都实现了ResourceLoader，因此可以使用其来加载资源。ClassPathXmlApplicationContext：不指定前缀将返回默认的ClassPathResource资源，否则将根据前缀来加载资源；FileSystemXmlApplicationContext：不指定前缀将返回FileSystemResource，否则将根据前缀来加载资源；WebApplicationContext：不指定前缀将返回ServletContextResource，否则将根据前缀来加载资源；其他：不指定前缀根据当前上下文返回Resource实现，否则将根据前缀来加载资源。 3.2 ResourceLoaderAware接口ResourceLoaderAware是一个标记接口，用于通过ApplicationContext上下文注入ResourceLoader。 123public interface ResourceLoaderAware &#123; void setResourceLoader(ResourceLoader resourceLoader); &#125; 让我们看下测试代码吧： 1） 首先准备测试Bean，我们的测试Bean还简单只需实现ResourceLoaderAware接口，然后通过回调将ResourceLoader保存下来就可以了： 1234567891011public class ResourceBean implements ResourceLoaderAware &#123; private ResourceLoader resourceLoader; @Override public void setResourceLoader(ResourceLoader resourceLoader) &#123; this.resourceLoader = resourceLoader; &#125; public ResourceLoader getResourceLoader() &#123; return resourceLoader; &#125; &#125; 2） 配置Bean定义（chapter4/resourceLoaderAware.xml）： Java代码 收藏代码1&lt;bean class=\"cn.javass.spring.chapter4.bean.ResourceBean\"/&gt; 3）测试(cn.javass.spring.chapter4.ResoureLoaderAwareTest)： 1234567@Test public void test() &#123; ApplicationContext ctx = new ClassPathXmlApplicationContext(\"chapter4/resourceLoaderAware.xml\"); ResourceBean resourceBean = ctx.getBean(ResourceBean.class); ResourceLoader loader = resourceBean.getResourceLoader(); Assert.assertTrue(loader instanceof ApplicationContext); &#125; 注意此处“loader instanceof ApplicationContext”，说明了ApplicationContext就是个ResoureLoader。由于上述实现回调接口注入ResourceLoader的方式属于侵入式，所以不推荐上述方法，可以采用更好的自动注入方式，如“byType”和“constructor”，此处就不演示了。 3.3 注入Resource通过回调或注入方式注入“ResourceLoader”，然后再通过“ResourceLoader”再来加载需要的资源对于只需要加载某个固定的资源是不是很麻烦，有没有更好的方法类似于前边实例中注入“java.io.File”类似方式呢？ Spring提供了一个PropertyEditor “ResourceEditor”用于在注入的字符串和Resource之间进行转换。因此可以使用注入方式注入Resource。 ResourceEditor完全使用ApplicationContext根据注入的路径字符串获取相应的Resource，说白了还是自己做还是容器帮你做的问题。 接下让我们看下示例： 1）准备Bean： 123456789public class ResourceBean3 &#123; private Resource resource; public Resource getResource() &#123; return resource; &#125; public void setResource(Resource resource) &#123; this.resource = resource; &#125; &#125; 2）准备配置文件（chapter4/ resourceInject.xml）： 123456&lt;bean id=\"resourceBean1\" class=\"cn.javass.spring.chapter4.bean.ResourceBean3\"&gt; &lt;property name=\"resource\" value=\"cn/javass/spring/chapter4/test1.properties\"/&gt; &lt;/bean&gt; &lt;bean id=\"resourceBean2\" class=\"cn.javass.spring.chapter4.bean.ResourceBean3\"&gt; &lt;property name=\"resource\" value=\"classpath:cn/javass/spring/chapter4/test1.properties\"/&gt; &lt;/bean&gt; 注意此处“resourceBean1”注入的路径没有前缀表示根据使用的ApplicationContext实现进行选择Resource实现。 3）让我们来看下测试代码（cn.javass.spring.chapter4.ResourceInjectTest）吧： 12345678@Test public void test() &#123; ApplicationContext ctx = new ClassPathXmlApplicationContext(\"chapter4/resourceInject.xml\"); ResourceBean3 resourceBean1 = ctx.getBean(\"resourceBean1\", ResourceBean3.class); ResourceBean3 resourceBean2 = ctx.getBean(\"resourceBean2\", ResourceBean3.class); Assert.assertTrue(resourceBean1.getResource() instanceof ClassPathResource); Assert.assertTrue(resourceBean2.getResource() instanceof ClassPathResource); &#125; 接下来一节让我们深入ApplicationContext对各种Resource的支持，及如何使用更便利的资源加载方式。 4. 加载资源4.1 使用路径通配符加载Resource前面介绍的资源路径都是非常简单的一个路径匹配一个资源，Spring还提供了一种更强大的Ant模式通配符匹配，从能一个路径匹配一批资源。 Ant路径通配符支持“？”、“*”、“**”，注意通配符匹配不包括目录分隔符“/”： ?：匹配一个字符，如config?.xml将匹配config1.xml； *：匹配零个或多个字符串，如cn/*/config.xml将匹配cn/javass/config.xml，但不匹配匹配cn/config.xml；而cn/config-*.xml将匹配cn/config-dao.xml； **：匹配路径中的零个或多个目录，如cn/**/config.xml将匹配cn/config.xml，也匹配cn/javass/spring/config.xml；而cn/javass/config-**.xml将匹配cn/javass/config-dao.xml，即把**当做两个*处理。 Spring提供AntPathMatcher来进行Ant风格的路径匹配。具体测试请参考cn.javass.spring.chapter4. AntPathMatcherTest。 Spring在加载类路径资源时除了提供前缀“classpath:”的来支持加载一个Resource，还提供一个前缀“classpath*:”来支持加载所有匹配的类路径Resource。 Spring提供ResourcePatternResolver接口来加载多个Resource，该接口继承了ResourceLoader并添加了“Resource[] getResources(String locationPattern)”用来加载多个Resource： 1234public interface ResourcePatternResolver extends ResourceLoader &#123; String CLASSPATH_ALL_URL_PREFIX = \"classpath*:\"; Resource[] getResources(String locationPattern) throws IOException; &#125; Spring提供了一个ResourcePatternResolver实现PathMatchingResourcePatternResolver，它是基于模式匹配的，默认使用AntPathMatcher进行路径匹配，它除了支持ResourceLoader支持的前缀外，还额外支持“classpath:”用于加载所有匹配的类路径Resource，ResourceLoader不支持前缀“classpath:”： 首先做下准备工作，在项目的“resources”创建“META-INF”目录，然后在其下创建一个“INDEX.LIST”文件。同时在“org.springframework.beans-3.0.5.RELEASE.jar”和“org.springframework.context-3.0.5.RELEASE.jar”两个jar包里也存在相同目录和文件。然后创建一个“LICENSE”文件，该文件存在于“com.springsource.cn.sf.cglib-2.2.0.jar”里。 一、“classpath”： 用于加载类路径（包括jar包）中的一个且仅一个资源；对于多个匹配的也只返回一个，所以如果需要多个匹配的请考虑“classpath*:”前缀； 12345678910@Test public void testClasspathPrefix() throws IOException &#123; ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); //只加载一个绝对匹配Resource，且通过ResourceLoader.getResource进行加载 Resource[] resources=resolver.getResources(\"classpath:META-INF/INDEX.LIST\"); Assert.assertEquals(1, resources.length); //只加载一个匹配的Resource，且通过ResourceLoader.getResource进行加载 resources = resolver.getResources(\"classpath:META-INF/*.LIST\"); Assert.assertTrue(resources.length == 1); &#125; 二、“classpath”： 用于加载类路径（包括jar包）中的所有匹配的资源。带通配符的classpath使用“ClassLoader”的“Enumeration getResources(String name)”方法来查找通配符之前的资源，然后通过模式匹配来获取匹配的资源。如“classpath:META-INF/.LIST”将首先加载通配符之前的目录“META-INF”，然后再遍历路径进行子路径匹配从而获取匹配的资源。 123456789101112@Test public void testClasspathAsteriskPrefix () throws IOException &#123; ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); //将加载多个绝对匹配的所有Resource //将首先通过ClassLoader.getResources(\"META-INF\")加载非模式路径部分 //然后进行遍历模式匹配 Resource[] resources=resolver.getResources(\"classpath*:META-INF/INDEX.LIST\"); Assert.assertTrue(resources.length &gt; 1); //将加载多个模式匹配的Resource resources = resolver.getResources(\"classpath*:META-INF/*.LIST\"); Assert.assertTrue(resources.length &gt; 1); &#125; 注意“resources.length &gt;1”说明返回多个Resource。不管模式匹配还是非模式匹配只要匹配的都将返回。 在“com.springsource.cn.sf.cglib-2.2.0.jar”里包含“asm-license.txt”文件，对于使用“classpath: asm-.txt”进行通配符方式加载资源将什么也加载不了“asm-license.txt”文件，注意一定是模式路径匹配才会遇到这种问题。这是由于“ClassLoader”的“getResources(String name)”方法的限制，对于name为“”的情况将只返回文件系统的类路径，不会包换jar包根路径。 123456789101112131415@Test public void testClasspathAsteriskPrefixLimit() throws IOException &#123; ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); //将首先通过ClassLoader.getResources(\"\")加载目录， //将只返回文件系统的类路径不返回jar的跟路径 //然后进行遍历模式匹配 Resource[] resources = resolver.getResources(\"classpath*:asm-*.txt\"); Assert.assertTrue(resources.length == 0); //将通过ClassLoader.getResources(\"asm-license.txt\")加载 //asm-license.txt存在于com.springsource.net.sf.cglib-2.2.0.jar resources = resolver.getResources(\"classpath*:asm-license.txt\"); Assert.assertTrue(resources.length &gt; 0); //将只加载文件系统类路径匹配的Resource resources = resolver.getResources(\"classpath*:LICENS*\"); Assert.assertTrue(resources.length == 1); &#125; 对于“resolver.getResources(“classpath:asm-.txt”);”，由于在项目“resources”目录下没有所以应该返回0个资源；“resolver.getResources(“classpath:asm-license.txt”);”将返回jar包里的Resource；“resolver.getResources(“classpath:LICENS*”);”，因为将只返回文件系统类路径资源，所以返回1个资源。 因此加载通配符路径时（即路径中包含通配符），必须包含一个根目录才能保证加载的资源是所有的，而不是部分。 三、“file”：加载一个或多个文件系统中的Resource。如“file:D:/*.txt”将返回D盘下的所有txt文件； 四、无前缀：通过ResourceLoader实现加载一个资源。 AppliacationContext提供的getResources方法将获取资源委托给ResourcePatternResolver实现，默认使用PathMatchingResourcePatternResolver。所有在此就无需介绍其使用方法了。 4.2 注入Resource数组Spring还支持注入Resource数组，直接看配置如下：123456789101112131415161718192021&lt;bean id=\"resourceBean1\" class=\"cn.javass.spring.chapter4.bean.ResourceBean4\"&gt; &lt;property name=\"resources\"&gt; &lt;array&gt; &lt;value&gt;cn/javass/spring/chapter4/test1.properties&lt;/value&gt; &lt;value&gt;log4j.xml&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"resourceBean2\" class=\"cn.javass.spring.chapter4.bean.ResourceBean4\"&gt; &lt;property name=\"resources\" value=\"classpath*:META-INF/INDEX.LIST\"/&gt; &lt;/bean&gt; &lt;bean id=\"resourceBean3\" class=\"cn.javass.spring.chapter# bean.ResourceBean4\"&gt; &lt;property name=\"resources\"&gt; &lt;array&gt; &lt;value&gt;cn/javass/spring/chapter4/test1.properties&lt;/value&gt; &lt;value&gt;classpath*:META-INF/INDEX.LIST&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; “resourceBean1”就不用多介绍了，传统实现方式；对于“resourceBean2”则使用前缀“classpath*”，看到这大家应该懂的，加载匹配多个资源；“resourceBean3”是混合使用的；测试代码在“cn.javass.spring.chapter4.ResourceInjectTest.testResourceArrayInject”。Spring通过ResourceArrayPropertyEditor来进行类型转换的，而它又默认使用“PathMatchingResourcePatternResolver”来进行把路径解析为Resource对象。所有大家只要会使用“PathMatchingResourcePatternResolver”，其它一些实现都是委托给它的，比如AppliacationContext的“getResources”方法等。 4.3 AppliacationContext实现对各种Resource的支持 一、ClassPathXmlApplicationContext：默认将通过classpath进行加载返回ClassPathResource，提供两类构造器方法：1234567891011public class ClassPathXmlApplicationContext &#123; //1）通过ResourcePatternResolver实现根据configLocation获取资源 public ClassPathXmlApplicationContext(String configLocation); public ClassPathXmlApplicationContext(String... configLocations)； public ClassPathXmlApplicationContext(String[] configLocations, ……); //2）通过直接根据path直接返回ClasspathResource public ClassPathXmlApplicationContext(String path, Class clazz); public ClassPathXmlApplicationContext(String[] paths, Class clazz); public ClassPathXmlApplicationContext(String[] paths, Class clazz, ……); &#125; 第一类构造器是根据提供的配置文件路径使用“ResourcePatternResolver ”的“getResources()”接口通过匹配获取资源；即如“classpath:config.xml”第二类构造器则是根据提供的路径和clazz来构造ClassResource资源。即采用“public ClassPathResource(String path, Class&lt;?&gt; clazz)”构造器获取资源。 二、FileSystemXmlApplicationContext：将加载相对于当前工作目录的“configLocation”位置的资源，注意在linux系统上不管“configLocation”是否带“/”，都作为相对路径；而在window系统上如“D:/resourceInject.xml”是绝对路径。因此在除非很必要的情况下，不建议使用该ApplicationContext。 1234567891011121314public class FileSystemXmlApplicationContext&#123; public FileSystemXmlApplicationContext(String configLocation); public FileSystemXmlApplicationContext(String... configLocations,……); &#125; //linux系统，以下全是相对于当前vm路径进行加载 new FileSystemXmlApplicationContext(\"chapter4/config.xml\"); new FileSystemXmlApplicationContext(\"/chapter4/confg.xml\"); //windows系统，第一个将相对于当前vm路径进行加载； //第二个则是绝对路径方式加载 new FileSystemXmlApplicationContext(\"chapter4/config.xml\"); new FileSystemXmlApplicationContext(\"d:/chapter4/confg.xml\"); 此处还需要注意：在linux系统上，构造器使用的是相对路径，而ctx.getResource()方法如果以“/”开头则表示获取绝对路径资源，而不带前导“/”将返回相对路径资源。如下：12345678//linux系统，第一个将相对于当前vm路径进行加载； //第二个则是绝对路径方式加载 ctx.getResource (\"chapter4/config.xml\"); ctx.getResource (\"/root/confg.xml\"); //windows系统，第一个将相对于当前vm路径进行加载； //第二个则是绝对路径方式加载 ctx.getResource (\"chapter4/config.xml\"); ctx.getResource (\"d:/chapter4/confg.xml\"); 因此如果需要加载绝对路径资源最好选择前缀“file”方式，将全部根据绝对路径加载。如在linux系统“ctx.getResource (“file:/root/confg.xml”);”","categories":[{"name":"I/O","slug":"I-O","permalink":"http://blog.shagle.cn/categories/I-O/"}],"tags":[{"name":"Resource","slug":"Resource","permalink":"http://blog.shagle.cn/tags/Resource/"}]},{"title":"关于InputStream类的available()方法","slug":"InputStream-available","date":"2019-01-08T02:33:09.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2019/01/08/InputStream-available/","link":"","permalink":"http://blog.shagle.cn/2019/01/08/InputStream-available/","excerpt":"要一次读取多个字节时，经常用到InputStream.available()方法，这个方法可以在读写操作前先得知数据流里有多少个字节可以读取。需要注意的是，如果这个方法用在从本地文件读取数据时，一般不会遇到问题，但如果是用于网络操作，就经常会遇到一些麻烦。比如，Socket通讯时，对方明明发来了1000个字节，但是自己的程序调用available()方法却只得到900，或者100，甚至是0，感觉有点莫名其妙，怎么也找不到原因。其实，这是因为网络通讯往往是间断性的，一串字节往往分几批进行发送。本地程序调用available()方法有时得到0，这可能是对方还没有响应，也可能是对方已经响应了，但是数据还没有送达本地。对方发送了1000个字节给你，也许分成3批到达，这你就要调用3次available()方法才能将数据总数全部得到。","text":"要一次读取多个字节时，经常用到InputStream.available()方法，这个方法可以在读写操作前先得知数据流里有多少个字节可以读取。需要注意的是，如果这个方法用在从本地文件读取数据时，一般不会遇到问题，但如果是用于网络操作，就经常会遇到一些麻烦。比如，Socket通讯时，对方明明发来了1000个字节，但是自己的程序调用available()方法却只得到900，或者100，甚至是0，感觉有点莫名其妙，怎么也找不到原因。其实，这是因为网络通讯往往是间断性的，一串字节往往分几批进行发送。本地程序调用available()方法有时得到0，这可能是对方还没有响应，也可能是对方已经响应了，但是数据还没有送达本地。对方发送了1000个字节给你，也许分成3批到达，这你就要调用3次available()方法才能将数据总数全部得到。 能否使用取决于实现了InputStream这个抽象类的具体子类中有没有实现available这个方法。如果实现了那么就可以取得大小，如果没有实现那么就获取不到。例如FileInputStream就实现了available方法，那么就可以用new byte[in.available()];这种方式。但是，网络编程的时候Socket中取到的InputStream，就没有实现这个方法，那么就不可以使用这种方式创建数组。 1. 错误实例如果这样写代码： 123int count = in.available(); byte[] b = new byte[count]; in.read(b); eg:在进行网络操作时往往出错，因为你调用available()方法时，对发发送的数据可能还没有到达，你得到的count是0。 2. 正确写法需要改成这样： 123456int count = 0; while (count == 0) &#123; count = in.available(); &#125; byte[] b = new byte[count]; in.read(b);","categories":[{"name":"I/O","slug":"I-O","permalink":"http://blog.shagle.cn/categories/I-O/"}],"tags":[{"name":"InputStream","slug":"InputStream","permalink":"http://blog.shagle.cn/tags/InputStream/"},{"name":"available","slug":"available","permalink":"http://blog.shagle.cn/tags/available/"}]},{"title":"Spring 源码分析bean的解析(3)","slug":"Spring源码分析-bean的解析（3）","date":"2019-01-08T02:07:49.000Z","updated":"2019-01-09T06:54:27.000Z","comments":true,"path":"2019/01/08/Spring源码分析-bean的解析（3）/","link":"","permalink":"http://blog.shagle.cn/2019/01/08/Spring源码分析-bean的解析（3）/","excerpt":"在很多情况下，当使用默认配置过于繁琐时候，解析工作或许是一个不得不考虑的负担。Spring 提供了可扩展 Scheme 的支持。大概需要以下几个步骤：","text":"在很多情况下，当使用默认配置过于繁琐时候，解析工作或许是一个不得不考虑的负担。Spring 提供了可扩展 Scheme 的支持。大概需要以下几个步骤： 自定义标签的解析自定义标签使用 创建一个需要扩展的组件 12345678910111213package io.github.binglau.bean;import lombok.Data;/** * 文件描述: */@Datapublic class User &#123; private String userName; private String email;&#125; 定义一个 XSD 文件描述组件内容 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;xsd:schema xmlns=\"http://www.binglau.com/schema/user\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" targetNamespace=\"http://www.binglau.com/schema/user\" elementFormDefault=\"qualified\"&gt; &lt;xsd:element name=\"user\"&gt; &lt;xsd:complexType&gt; &lt;xsd:attribute name=\"id\" type=\"xsd:string\"/&gt; &lt;xsd:attribute name=\"userName\" type=\"xsd:string\"/&gt; &lt;xsd:attribute name=\"email\" type=\"xsd:string\"/&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt;&lt;/xsd:schema&gt; 创建一个文件，实现 BeanDefinitionParser 接口，用来解析 XSD 文件中的定义和组件定义 123456789101112131415161718192021222324252627282930313233package io.github.binglau;import io.github.binglau.bean.User;import org.springframework.beans.factory.support.BeanDefinitionBuilder;import org.springframework.beans.factory.xml.AbstractSingleBeanDefinitionParser;import org.springframework.util.StringUtils;import org.w3c.dom.Element;/** * 文件描述: */public class UserBeanDefinitionParser extends AbstractSingleBeanDefinitionParser &#123; // Element 对应的类 @Override protected Class&lt;?&gt; getBeanClass(Element element) &#123; return User.class; &#125; // 从 element 中解析并提取对应的元素 @Override protected void doParse(Element element, BeanDefinitionBuilder builder) &#123; String userName = element.getAttribute(\"userName\"); String email = element.getAttribute(\"email\"); // 将提取的数据放入 BeanDefinitionBuilder 中，待到完成所有 bean 的解析后统一注册到 beanFactory 中 if (StringUtils.hasText(userName)) &#123; builder.addPropertyValue(\"userName\", userName); &#125; if (StringUtils.hasText(email)) &#123; builder.addPropertyValue(\"email\", email); &#125; &#125;&#125; 创建一个 Handler 文件，扩展自 NamespaceHandlerSupport，目的是将组件注册到 Spring 容器 1234567891011121314package io.github.binglau;import org.springframework.beans.factory.xml.NamespaceHandlerSupport;/** * 文件描述: */public class MyNamespaceHandler extends NamespaceHandlerSupport &#123; @Override public void init() &#123; registerBeanDefinitionParser(\"user\", new UserBeanDefinitionParser()); &#125;&#125; 编写 Spring.handlers 和 Spring.schemas 文件（resources/MATE-INF） 12345# Spring.handlershttp\\://www.binglau.com/schema/user=io.github.binglau.MyNamespaceHandler# Spring.schemashttp\\://www.binglau.com/schema/user.xsd=user-xsd.xsd 测试： 123456789101112&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:myname=\"http://www.binglau.com/schema/user\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd http://www.binglau.com/schema/user http://www.binglau.com/schema/user.xsd\"&gt; &lt;myname:user id=\"testbean\" userName=\"aaa\" email=\"bbb\"/&gt; &lt;bean id=\"testBean\" class=\"io.github.binglau.bean.TestBean\" /&gt;&lt;/beans&gt; 12345678910111213141516171819202122232425package io.github.binglau;import io.github.binglau.bean.User;import org.junit.Test;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.xml.XmlBeanFactory;import org.springframework.core.io.ClassPathResource;/** * 文件描述: */public class BeanFactoryTest &#123; @Test public void testSimpleLoad() &#123; BeanFactory context = new XmlBeanFactory(new ClassPathResource(\"beanFactory.xml\")); User user = (User)context.getBean(\"testbean\"); System.out.println(user); &#125;&#125;/**结果：User(userName=aaa, email=bbb)**/ 自定义标签解析12345678910111213141516171819202122232425/** * Parse the elements at the root level in the document: * \"import\", \"alias\", \"bean\". * @param root the DOM root element of the document */protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125;&#125; 其中的 delegate.parseCustomElement(ele) 既是对自定义标签的解析 BeanDefinitionParserDelegate.parseCustomElement 12345678910111213141516public BeanDefinition parseCustomElement(Element ele) &#123; return parseCustomElement(ele, null);&#125;// containingBd 为父类 bean，对顶层元素的解析应设置为 nullpublic BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; // 获取对应的命名空间 String namespaceUri = getNamespaceURI(ele); // 根据命名空间找到对应的 NamespaceHandler NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", ele); return null; &#125; // 调用自定义的 NamespaceHandler 进行解析 return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));&#125; 获取标签的命名空间直接调用 org.w3c.dom.Node 中的方法 123public String getNamespaceURI(Node node) &#123; return node.getNamespaceURI();&#125; 提取自定义标签处理器private final XmlReaderContext readerContext 即 new ClassPathResource(&quot;beanFactory.xml&quot;) 在 readerContext 初始化的时候其属性 namespaceHandlerResolver 已经被初始化为 DefaultNamespaceHandlerResolver 实例，所以，这里实际调用了 DefaultNamespaceHandlerResolver的方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Locate the &#123;@link NamespaceHandler&#125; for the supplied namespace URI * from the configured mappings. * @param namespaceUri the relevant namespace URI * @return the located &#123;@link NamespaceHandler&#125;, or &#123;@code null&#125; if none found */@Overridepublic NamespaceHandler resolve(String namespaceUri) &#123; // 获取所有已有配置的 handler 映射 Map&lt;String, Object&gt; handlerMappings = getHandlerMappings(); // 根据命名空间找到对应的信息 Object handlerOrClassName = handlerMappings.get(namespaceUri); if (handlerOrClassName == null) &#123; return null; &#125; else if (handlerOrClassName instanceof NamespaceHandler) &#123; // 已经做过解析的情况，直接从缓存读取 return (NamespaceHandler) handlerOrClassName; &#125; else &#123; // 没有做过解析，则返回的是类路径 String className = (String) handlerOrClassName; try &#123; // 使用反射 将类路径转换为类 Class&lt;?&gt; handlerClass = ClassUtils.forName(className, this.classLoader); if (!NamespaceHandler.class.isAssignableFrom(handlerClass)) &#123; throw new FatalBeanException(\"Class [\" + className + \"] for namespace [\" + namespaceUri + \"] does not implement the [\" + NamespaceHandler.class.getName() + \"] interface\"); &#125; // 初始化类 NamespaceHandler namespaceHandler = (NamespaceHandler) BeanUtils.instantiateClass(handlerClass); // 调用自定义的 NamespaceHandler 的初始化方法 namespaceHandler.init(); // 记录在缓存 handlerMappings.put(namespaceUri, namespaceHandler); return namespaceHandler; &#125; catch (ClassNotFoundException ex) &#123; throw new FatalBeanException(\"NamespaceHandler class [\" + className + \"] for namespace [\" + namespaceUri + \"] not found\", ex); &#125; catch (LinkageError err) &#123; throw new FatalBeanException(\"Invalid NamespaceHandler class [\" + className + \"] for namespace [\" + namespaceUri + \"]: problem with handler class file or dependent class\", err); &#125; &#125;&#125; 在上面的调用namespaceHandler.init();中参考之前的自定义标签使用 123public void init() &#123; registerBeanDefinitionParser(\"user\", new UserBeanDefinitionParser());&#125; 当得到自定义命名空间处理后回马上进行 BeanDefinitionParser 的注册以支持自定义标签 注册后，命名空间处理器就可以根据标签的不同来调用不同的解析器进行解析。getHandlerMappings 主要功能就是读取 Spring.handlers 配置文件并将配置文件缓存在 map 中。 1234567891011121314151617181920212223242526272829/** * Load the specified NamespaceHandler mappings lazily. */private Map&lt;String, Object&gt; getHandlerMappings() &#123; // 如果没有被缓存则开始进行缓存 if (this.handlerMappings == null) &#123; synchronized (this) &#123; if (this.handlerMappings == null) &#123; try &#123; // this.handlerMappingsLocation 在构造函数中被初始化为 META-INF/Spring.handlers Properties mappings = PropertiesLoaderUtils.loadAllProperties(this.handlerMappingsLocation, this.classLoader); if (logger.isDebugEnabled()) &#123; logger.debug(\"Loaded NamespaceHandler mappings: \" + mappings); &#125; Map&lt;String, Object&gt; handlerMappings = new ConcurrentHashMap&lt;String, Object&gt;(mappings.size()); // 将 Properties 格式文件合并到 Map 格式的 handlerMappings 中 CollectionUtils.mergePropertiesIntoMap(mappings, handlerMappings); this.handlerMappings = handlerMappings; &#125; catch (IOException ex) &#123; throw new IllegalStateException( \"Unable to load NamespaceHandler mappings from location [\" + this.handlerMappingsLocation + \"]\", ex); &#125; &#125; &#125; &#125; return this.handlerMappings;&#125; 标签解析NamespaceHandlerSupport#parse 12345678910111213141516171819202122232425/** * Parses the supplied &#123;@link Element&#125; by delegating to the &#123;@link BeanDefinitionParser&#125; that is * registered for that &#123;@link Element&#125;. */@Overridepublic BeanDefinition parse(Element element, ParserContext parserContext) &#123; // 寻找解析器并进行解析操作 return findParserForElement(element, parserContext).parse(element, parserContext);&#125;/** * Locates the &#123;@link BeanDefinitionParser&#125; from the register implementations using * the local name of the supplied &#123;@link Element&#125;. */private BeanDefinitionParser findParserForElement(Element element, ParserContext parserContext) &#123; // 获取元素名称，也就是 &lt;myname:user&gt; 中的 user，若在上面的示例中，则此时 localName 为 user String localName = parserContext.getDelegate().getLocalName(element); // 根据 user 找到对应的解析器，也就是在 // registerBeanDefinitionParser(\"user\", new UserBeanDefinitionParser()) 注册的解析器 BeanDefinitionParser parser = this.parsers.get(localName); if (parser == null) &#123; parserContext.getReaderContext().fatal( \"Cannot locate BeanDefinitionParser for element [\" + localName + \"]\", element); &#125; return parser;&#125; 而对于 parse 方法的处理 AbstractBeanDefinitionParser#parse 123456789101112131415161718192021222324252627282930313233343536@Overridepublic final BeanDefinition parse(Element element, ParserContext parserContext) &#123; // 真正的解析工作 AbstractBeanDefinition definition = parseInternal(element, parserContext); if (definition != null &amp;&amp; !parserContext.isNested()) &#123; try &#123; String id = resolveId(element, definition, parserContext); if (!StringUtils.hasText(id)) &#123; parserContext.getReaderContext().error( \"Id is required for element '\" + parserContext.getDelegate().getLocalName(element) + \"' when used as a top-level tag\", element); &#125; String[] aliases = null; if (shouldParseNameAsAliases()) &#123; String name = element.getAttribute(NAME_ATTRIBUTE); if (StringUtils.hasLength(name)) &#123; aliases = StringUtils.trimArrayElements(StringUtils.commaDelimitedListToStringArray(name)); &#125; &#125; // 将 AbstractBeanDefinition 转换为 BeanDefinitionHolder 并注册 BeanDefinitionHolder holder = new BeanDefinitionHolder(definition, id, aliases); registerBeanDefinition(holder, parserContext.getRegistry()); if (shouldFireEvents()) &#123; // 需要通知监听器则进行处理 BeanComponentDefinition componentDefinition = new BeanComponentDefinition(holder); postProcessComponentDefinition(componentDefinition); parserContext.registerComponent(componentDefinition); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; parserContext.getReaderContext().error(ex.getMessage(), element); return null; &#125; &#125; return definition;&#125; AbstractSingleBeanDefinitionParser#parseInternal 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Creates a &#123;@link BeanDefinitionBuilder&#125; instance for the * &#123;@link #getBeanClass bean Class&#125; and passes it to the * &#123;@link #doParse&#125; strategy method. * @param element the element that is to be parsed into a single BeanDefinition * @param parserContext the object encapsulating the current state of the parsing process * @return the BeanDefinition resulting from the parsing of the supplied &#123;@link Element&#125; * @throws IllegalStateException if the bean &#123;@link Class&#125; returned from * &#123;@link #getBeanClass(org.w3c.dom.Element)&#125; is &#123;@code null&#125; * @see #doParse */@Overrideprotected final AbstractBeanDefinition parseInternal(Element element, ParserContext parserContext) &#123; BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(); String parentName = getParentName(element); if (parentName != null) &#123; builder.getRawBeanDefinition().setParentName(parentName); &#125; // 获取自定义标签中的 class，此时会调用自定义解析器如 UserBeanDefinitionParser 中的 getBeanClass 方法 Class&lt;?&gt; beanClass = getBeanClass(element); if (beanClass != null) &#123; builder.getRawBeanDefinition().setBeanClass(beanClass); &#125; else &#123; // 若子类没有重写 getBeanClass 方法则尝试检查子类是否重写 getBeanClassName 方法 String beanClassName = getBeanClassName(element); if (beanClassName != null) &#123; builder.getRawBeanDefinition().setBeanClassName(beanClassName); &#125; &#125; builder.getRawBeanDefinition().setSource(parserContext.extractSource(element)); if (parserContext.isNested()) &#123; // 若存在父类则使用父类的 scope 属性 // Inner bean definition must receive same scope as containing bean. builder.setScope(parserContext.getContainingBeanDefinition().getScope()); &#125; if (parserContext.isDefaultLazyInit()) &#123; // Default-lazy-init applies to custom bean definitions as well. // 配置延迟加载 builder.setLazyInit(true); &#125; // 调用子类重写的 doParse 方法进行解析 doParse(element, parserContext, builder); return builder.getBeanDefinition();&#125;protected void doParse(Element element, ParserContext parserContext, BeanDefinitionBuilder builder) &#123; doParse(element, builder);&#125; 参考书籍《Spring源码深度解析》","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shagle.cn/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"http://blog.shagle.cn/tags/Java/"}]},{"title":"Spring 源码分析bean的解析(2)","slug":"Spring源码分析-bean的解析（2）","date":"2019-01-08T02:07:48.000Z","updated":"2019-01-09T06:54:27.000Z","comments":true,"path":"2019/01/08/Spring源码分析-bean的解析（2）/","link":"","permalink":"http://blog.shagle.cn/2019/01/08/Spring源码分析-bean的解析（2）/","excerpt":"","text":"默认标签的解析接上 parseDefaultElement(ele, delegate); DefaultBeanDefinitionDocumentReader#parseDefaultElement 12345678910111213141516171819private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; // import 标签解析 if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; // 解析 alias 标签 else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; processAliasRegistration(ele); &#125; // bean 的解析 else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; processBeanDefinition(ele, delegate); &#125; // beans 的解析 else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // recurse doRegisterBeanDefinitions(ele); &#125;&#125; Bean 标签的解析及注册1234567891011121314151617181920/** * Process the given bean element, parsing the bean definition * and registering it with the registry. */protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); // 1 if (bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); // 2 try &#123; // Register the final decorated instance. BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); // 3 &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex); &#125; // Send registration event. getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); // 4 &#125;&#125; 首先委托 BeanDefinitionDelegate 类的 parseBeanDefinitionElement 方法进行元素解析，返回 BeanDefinitionHolder 类型的实例 bdHolder，经过这个方法后， bdHolder 实例已经包含我们的配置文件中配置的各个属性了，例如 class、name、id、alias 之类的属性。 当返回的 bdHolder 不为空的情况下若存在默认标签的子节点下再有自定义属性，还需要再次对自定义标签进行解析。 解析完成之后，需要对解析后的 bdHolder 进行注册，同样，注册操作委托给了 BeanDefinitionReaderUtils 的 registerBeanDefinition 方法。 最后发出响应事件，通知想关的监听器，这个 bean 已经加载完成了 解析 BeanDefinitionBeanDefinitionDelegate#parseBeanDefinitionElement 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * Parses the supplied &#123;@code &lt;bean&gt;&#125; element. May return &#123;@code null&#125; * if there were errors during parse. Errors are reported to the * &#123;@link org.springframework.beans.factory.parsing.ProblemReporter&#125;. */public BeanDefinitionHolder parseBeanDefinitionElement(Element ele) &#123; return parseBeanDefinitionElement(ele, null);&#125;/** * Parses the supplied &#123;@code &lt;bean&gt;&#125; element. May return &#123;@code null&#125; * if there were errors during parse. Errors are reported to the * &#123;@link org.springframework.beans.factory.parsing.ProblemReporter&#125;. */public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, BeanDefinition containingBean) &#123; // 1 // 解析 id 属性 String id = ele.getAttribute(ID_ATTRIBUTE); // 解析 name 属性 String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); // 分割 name 属性 List&lt;String&gt; aliases = new ArrayList&lt;String&gt;(); if (StringUtils.hasLength(nameAttr)) &#123; String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS); aliases.addAll(Arrays.asList(nameArr)); &#125; String beanName = id; if (!StringUtils.hasText(beanName) &amp;&amp; !aliases.isEmpty()) &#123; beanName = aliases.remove(0); if (logger.isDebugEnabled()) &#123; logger.debug(\"No XML 'id' specified - using '\" + beanName + \"' as bean name and \" + aliases + \" as aliases\"); &#125; &#125; if (containingBean == null) &#123; checkNameUniqueness(beanName, aliases, ele); &#125; AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean); // 2 if (beanDefinition != null) &#123; if (!StringUtils.hasText(beanName)) &#123; // 3 // 如果不存在 beanName 那么根据 Spring 中提供的命名规则为当前 bean 生成对应的 beanName try &#123; if (containingBean != null) &#123; beanName = BeanDefinitionReaderUtils.generateBeanName( beanDefinition, this.readerContext.getRegistry(), true); &#125; else &#123; beanName = this.readerContext.generateBeanName(beanDefinition); // Register an alias for the plain bean class name, if still possible, // if the generator returned the class name plus a suffix. // This is expected for Spring 1.2/2.0 backwards compatibility. String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null &amp;&amp; beanName.startsWith(beanClassName) &amp;&amp; beanName.length() &gt; beanClassName.length() &amp;&amp; !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) &#123; aliases.add(beanClassName); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Neither XML 'id' nor 'name' specified - \" + \"using generated bean name [\" + beanName + \"]\"); &#125; &#125; catch (Exception ex) &#123; error(ex.getMessage(), ele); return null; &#125; &#125; String[] aliasesArray = StringUtils.toStringArray(aliases); return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); // 4 &#125; return null;&#125; 提取元素中的 id 以及 name 属性 进一步解析其他所有属性并统一封装至 GenericBeanDefinition 类型的实例中（下面的函数） 如果检测到 bean 没有指定 beanName ，那么使用默认规则为此 Bean 生成 beanName 将获取到的信息封装到 BeanDefinitionHolder 的实例中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/*parseBeanDefinitionElement*/ /** * Parse the bean definition itself, without regard to name or aliases. May return * &#123;@code null&#125; if problems occurred during the parsing of the bean definition. */ public AbstractBeanDefinition parseBeanDefinitionElement( Element ele, String beanName, BeanDefinition containingBean) &#123; this.parseState.push(new BeanEntry(beanName)); String className = null; if (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123; className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &#125; try &#123; String parent = null; // 解析parent 属性 if (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123; parent = ele.getAttribute(PARENT_ATTRIBUTE); &#125; // 创建用于承载属性的 AbstractBeanDefinition 类型的 GenericBeanDefinition AbstractBeanDefinition bd = createBeanDefinition(className, parent); // 硬编码解析默认 bean 的各种属性 parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); // 提取description bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); // 解析元数据 parseMetaElements(ele, bd); // 解析 lookup-override 属性 parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); // 解析 replaced-method 属性 parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); // 解析构造函数参数 parseConstructorArgElements(ele, bd); // 解析 property 子元素 parsePropertyElements(ele, bd); // 解析 qualifier 子元素 parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; &#125; catch (ClassNotFoundException ex) &#123; error(\"Bean class [\" + className + \"] not found\", ele, ex); &#125; catch (NoClassDefFoundError err) &#123; error(\"Class that bean class [\" + className + \"] depends on not found\", ele, err); &#125; catch (Throwable ex) &#123; error(\"Unexpected failure during bean definition parsing\", ele, ex); &#125; finally &#123; this.parseState.pop(); &#125; return null; &#125; 接下来来看看一些复杂标签的解析: 创建用于属性承载的 BeanDefinitionBeanDefinition 是一个接口，在 Spring 中存在三种实现，三种实现均继承了 AbstactBeanDefinition，其中 BeanDefinition 是配置文件中的 &lt;bean&gt; 元素标签在容器中的内部表示形式。&lt;bean&gt;元素标签拥有 class、scope、lazy-init 等配置属性。BeanDefinition则提供了相应的 beanClass、scope、lazyInit属性，BeanDefinition 和 &lt;bean&gt; 中的属性是一一对应的。 RootBeanDefinition 最常用的实现类，它对应一般性的 &lt;bean&gt; 元素标签 当前版本中， ConfigurationClassBeanDefinition 继承与此类 ChildBeanDefinition 配置文件中的子 &lt;bean&gt; GenericBeanDefinition 2.5 新加入的 bean 文件配置属性定义类，是一站式服务类。 在当前版本中，有ScannedGenericBeanDefinition，AnnotatedGenericBeanDefinition 继承与此类 Spring 通过 BeanDefinition 将配置文件中的 &lt;bean&gt; 配置信息转换为容器的内部表示，并将这些 BeanDefinition 注册到 BeanDefinitionRegistry 中。Spring 容器的 BeanDefinitionRegistry 就像是 Spring 配置信息的内存数据库，主要是以 map 的形式保存的，后续操作直接从 BeanDefinitionRegistry 中读取配置信息。 BeanDefinitionParserDelegate#createBeanDefinition 12345678910111213141516171819202122232425262728293031323334353637383940/** * Create a bean definition for the given class name and parent name. * @param className the name of the bean class * @param parentName the name of the bean's parent bean * @return the newly created bean definition * @throws ClassNotFoundException if bean class resolution was attempted but failed */protected AbstractBeanDefinition createBeanDefinition(String className, String parentName) throws ClassNotFoundException &#123; return BeanDefinitionReaderUtils.createBeanDefinition( parentName, className, this.readerContext.getBeanClassLoader());&#125;/** * Create a new GenericBeanDefinition for the given parent name and class name, * eagerly loading the bean class if a ClassLoader has been specified. * @param parentName the name of the parent bean, if any * @param className the name of the bean class, if any * @param classLoader the ClassLoader to use for loading bean classes * (can be &#123;@code null&#125; to just register bean classes by name) * @return the bean definition * @throws ClassNotFoundException if the bean class could not be loaded */public static AbstractBeanDefinition createBeanDefinition( String parentName, String className, ClassLoader classLoader) throws ClassNotFoundException &#123; GenericBeanDefinition bd = new GenericBeanDefinition(); // parentName 可能为空 bd.setParentName(parentName); if (className != null) &#123; if (classLoader != null) &#123; // 如果 classLoader 不为空，则使用已传入的 classLoader 同一虚拟机加载类对象，否则只是记录 className bd.setBeanClass(ClassUtils.forName(className, classLoader)); &#125; else &#123; bd.setBeanClassName(className); &#125; &#125; return bd;&#125; 解析各种属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110/** * Apply the attributes of the given bean element to the given bean * definition. * @param ele bean declaration element * @param beanName bean name * @param containingBean containing bean definition * @return a bean definition initialized according to the bean element attributes */public AbstractBeanDefinition parseBeanDefinitionAttributes(Element ele, String beanName, BeanDefinition containingBean, AbstractBeanDefinition bd) &#123; // 解析 singleton 属性。已废弃，使用 scope 设置 if (ele.hasAttribute(SINGLETON_ATTRIBUTE)) &#123; error(\"Old 1.x 'singleton' attribute in use - upgrade to 'scope' declaration\", ele); &#125; // 解析 scope 属性 // https://docs.spring.io/spring/docs/5.0.0.RELEASE/spring-framework-reference/core.html#beans-factory-scopes else if (ele.hasAttribute(SCOPE_ATTRIBUTE)) &#123; bd.setScope(ele.getAttribute(SCOPE_ATTRIBUTE)); &#125; else if (containingBean != null) &#123; // Take default from containing bean in case of an inner bean definition. // 在嵌入 beanDefinition 情况下且没有单独指定 scope 属性则使用父类默认的属性 bd.setScope(containingBean.getScope()); &#125; // 解析 absract 属性 // (抽象bean不能被实例化，只能被子类继承)。 if (ele.hasAttribute(ABSTRACT_ATTRIBUTE)) &#123; bd.setAbstract(TRUE_VALUE.equals(ele.getAttribute(ABSTRACT_ATTRIBUTE))); &#125; // 解析 lazy-init 属性 // 懒初始化，默认false ，即：非懒惰初始化。这是高效的，可以提前暴露错误（如果存在），如果是懒初始化，只有在call 时才初始化。 String lazyInit = ele.getAttribute(LAZY_INIT_ATTRIBUTE); if (DEFAULT_VALUE.equals(lazyInit)) &#123; lazyInit = this.defaults.getLazyInit(); &#125; // 若没有设置或设置成其他字符都会被设置为 false bd.setLazyInit(TRUE_VALUE.equals(lazyInit)); // 解析 autowire 属性 String autowire = ele.getAttribute(AUTOWIRE_ATTRIBUTE); bd.setAutowireMode(getAutowireMode(autowire)); // 解析 dependency-check 属性 String dependencyCheck = ele.getAttribute(DEPENDENCY_CHECK_ATTRIBUTE); bd.setDependencyCheck(getDependencyCheck(dependencyCheck)); // 解析 depends-on 属性 // 初始化该bean之前必须先初始化谁（name or id 指定） if (ele.hasAttribute(DEPENDS_ON_ATTRIBUTE)) &#123; String dependsOn = ele.getAttribute(DEPENDS_ON_ATTRIBUTE); bd.setDependsOn(StringUtils.tokenizeToStringArray(dependsOn, MULTI_VALUE_ATTRIBUTE_DELIMITERS)); &#125; // 解析 autowire-candidate 属性 String autowireCandidate = ele.getAttribute(AUTOWIRE_CANDIDATE_ATTRIBUTE); if (\"\".equals(autowireCandidate) || DEFAULT_VALUE.equals(autowireCandidate)) &#123; String candidatePattern = this.defaults.getAutowireCandidates(); if (candidatePattern != null) &#123; String[] patterns = StringUtils.commaDelimitedListToStringArray(candidatePattern); bd.setAutowireCandidate(PatternMatchUtils.simpleMatch(patterns, beanName)); &#125; &#125; else &#123; bd.setAutowireCandidate(TRUE_VALUE.equals(autowireCandidate)); &#125; // 解析 primary 属性 if (ele.hasAttribute(PRIMARY_ATTRIBUTE)) &#123; bd.setPrimary(TRUE_VALUE.equals(ele.getAttribute(PRIMARY_ATTRIBUTE))); &#125; // 解析 init-method 属性 if (ele.hasAttribute(INIT_METHOD_ATTRIBUTE)) &#123; String initMethodName = ele.getAttribute(INIT_METHOD_ATTRIBUTE); if (!\"\".equals(initMethodName)) &#123; bd.setInitMethodName(initMethodName); &#125; &#125; else &#123; if (this.defaults.getInitMethod() != null) &#123; bd.setInitMethodName(this.defaults.getInitMethod()); bd.setEnforceInitMethod(false); &#125; &#125; // 解析 destory-method 属性 if (ele.hasAttribute(DESTROY_METHOD_ATTRIBUTE)) &#123; String destroyMethodName = ele.getAttribute(DESTROY_METHOD_ATTRIBUTE); bd.setDestroyMethodName(destroyMethodName); &#125; else &#123; if (this.defaults.getDestroyMethod() != null) &#123; bd.setDestroyMethodName(this.defaults.getDestroyMethod()); bd.setEnforceDestroyMethod(false); &#125; &#125; // 解析 factory-method 属性 if (ele.hasAttribute(FACTORY_METHOD_ATTRIBUTE)) &#123; bd.setFactoryMethodName(ele.getAttribute(FACTORY_METHOD_ATTRIBUTE)); &#125; // 解析 factory-bean 属性 if (ele.hasAttribute(FACTORY_BEAN_ATTRIBUTE)) &#123; bd.setFactoryBeanName(ele.getAttribute(FACTORY_BEAN_ATTRIBUTE)); &#125; return bd;&#125; 简单复习一下 bean 的自动装配 @Autowired （如果设置参数 require = false 则会尝试匹配，无匹配这让 bean 处于未装配状态） primary（如果配置了的） @Qualifier 做限定 配合 @Autowired 使用指定需要装配哪个 bean 配合 @Component / @Bean 指定限定符，不然在 @Autowired 使用的时候就是默认 beanId 符合的类型 解析子元素 metameta: 元数据，当需要使用里面的信息时可以通过key获取 Finally, the bean definitions should contain matching qualifier values. This example also demonstrates that bean meta attributes may be used instead of the &lt;qualifier/&gt; sub-elements.If available, the &lt;qualifier/&gt; and its attributes would take precedence, but the autowiring mechanism will fallback on the values provided within the &lt;meta/&gt; tags if no such qualifier is present 123&lt;bean id=\"myTestBean\" class=\"bean.MyTestBean\"&gt; &lt;meta key=\"testStr\" value=\"test\"&gt;&lt;/bean&gt; 12345678910111213141516public void parseMetaElements(Element ele, BeanMetadataAttributeAccessor attributeAccessor) &#123; // 获取当前节点的所有子元素 NodeList nl = ele.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); // 提取 meta if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, META_ELEMENT)) &#123; Element metaElement = (Element) node; String key = metaElement.getAttribute(KEY_ATTRIBUTE); String value = metaElement.getAttribute(VALUE_ATTRIBUTE); BeanMetadataAttribute attribute = new BeanMetadataAttribute(key, value); attribute.setSource(extractSource(metaElement)); attributeAccessor.addMetadataAttribute(attribute); &#125; &#125;&#125; 解析子元素 lookup-method获取器注入，特殊方法注入，它是把一个方法声明为返回某种类型的 bean， 但实际要返回的 bean 是在配置文件里面配置的，此方法可用在设计有些可插拔的功能上，解除程序依赖。 简单来说就是，可以动态配置某个方法的返回值返回的 bean ... &lt;lookup-method name=&quot;方法名&quot; bean=&quot;需要方法返回的 beanId&quot;&gt; ... 1234567891011121314151617181920/** * Parse lookup-override sub-elements of the given bean element. */public void parseLookupOverrideSubElements(Element beanEle, MethodOverrides overrides) &#123; NodeList nl = beanEle.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); // 仅当在 Spring 默认 bean 的子元素且为 &lt;lookup-method 时有效 if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, LOOKUP_METHOD_ELEMENT)) &#123; Element ele = (Element) node; // 获取要修饰的方法 String methodName = ele.getAttribute(NAME_ATTRIBUTE); // 获取配置返回的 bean String beanRef = ele.getAttribute(BEAN_ELEMENT); LookupOverride override = new LookupOverride(methodName, beanRef); override.setSource(extractSource(ele)); overrides.addOverride(override); &#125; &#125;&#125; 解析子元素 replaced-method方法替换：可以在运行时用新的方法替换现有的方法。与之前的 look-up 不同的是，replaced-method 不但可以动态地替换返回实体 bean，而且还能动态地更改原有方法的逻辑。 需要实现 MethodReplacer 的 reimplement 方法，该方法替换其指定方法。 123456789101112131415161718192021222324252627282930/** * Parse replaced-method sub-elements of the given bean element. */public void parseReplacedMethodSubElements(Element beanEle, MethodOverrides overrides) &#123; NodeList nl = beanEle.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); // 识别标签 if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, REPLACED_METHOD_ELEMENT)) &#123; Element replacedMethodEle = (Element) node; // 提取需要替换方法 String name = replacedMethodEle.getAttribute(NAME_ATTRIBUTE); // 提权对应的新的替换方法 String callback = replacedMethodEle.getAttribute(REPLACER_ATTRIBUTE); ReplaceOverride replaceOverride = new ReplaceOverride(name, callback); // Look for arg-type match elements. List&lt;Element&gt; argTypeEles = DomUtils.getChildElementsByTagName(replacedMethodEle, ARG_TYPE_ELEMENT); for (Element argTypeEle : argTypeEles) &#123; // 记录参数 String match = argTypeEle.getAttribute(ARG_TYPE_MATCH_ATTRIBUTE); match = (StringUtils.hasText(match) ? match : DomUtils.getTextValue(argTypeEle)); if (StringUtils.hasText(match)) &#123; replaceOverride.addTypeIdentifier(match); &#125; &#125; replaceOverride.setSource(extractSource(replacedMethodEle)); overrides.addOverride(replaceOverride); &#125; &#125;&#125; 解析子元素 constructor-arg12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * Parse a constructor-arg element. */public void parseConstructorArgElement(Element ele, BeanDefinition bd) &#123; // 提取对应元素 String indexAttr = ele.getAttribute(INDEX_ATTRIBUTE); String typeAttr = ele.getAttribute(TYPE_ATTRIBUTE); String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); if (StringUtils.hasLength(indexAttr)) &#123; try &#123; int index = Integer.parseInt(indexAttr); if (index &lt; 0) &#123; error(\"'index' cannot be lower than 0\", ele); &#125; else &#123; try &#123; this.parseState.push(new ConstructorArgumentEntry(index)); // 解析 ele 对应的属性元素 Object value = parsePropertyValue(ele, bd, null); // 使用 ConstructorArgumentValues.ValueHolder 类型封装解析出来的元素 ConstructorArgumentValues.ValueHolder valueHolder = new ConstructorArgumentValues.ValueHolder(value); if (StringUtils.hasLength(typeAttr)) &#123; valueHolder.setType(typeAttr); &#125; if (StringUtils.hasLength(nameAttr)) &#123; valueHolder.setName(nameAttr); &#125; valueHolder.setSource(extractSource(ele)); // 不允许重复指定相同的参数 if (bd.getConstructorArgumentValues().hasIndexedArgumentValue(index)) &#123; error(\"Ambiguous constructor-arg entries for index \" + index, ele); &#125; else &#123; // 将封装的信息添加到当前 BeanDefinition 的 constructorArgumentValues 中的 indexedArgumentValue 属性中 bd.getConstructorArgumentValues().addIndexedArgumentValue(index, valueHolder); &#125; &#125; finally &#123; this.parseState.pop(); &#125; &#125; &#125; catch (NumberFormatException ex) &#123; error(\"Attribute 'index' of tag 'constructor-arg' must be an integer\", ele); &#125; &#125; else &#123; // 没有 index 属性则忽略去属性，自动寻找 try &#123; this.parseState.push(new ConstructorArgumentEntry()); // 解析 constructor-arg 元素 Object value = parsePropertyValue(ele, bd, null); ConstructorArgumentValues.ValueHolder valueHolder = new ConstructorArgumentValues.ValueHolder(value); if (StringUtils.hasLength(typeAttr)) &#123; valueHolder.setType(typeAttr); &#125; if (StringUtils.hasLength(nameAttr)) &#123; valueHolder.setName(nameAttr); &#125; valueHolder.setSource(extractSource(ele)); bd.getConstructorArgumentValues().addGenericArgumentValue(valueHolder); &#125; finally &#123; this.parseState.pop(); &#125; &#125;&#125; 解析构造函数配置中子元素的过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * Get the value of a property element. May be a list etc. * Also used for constructor arguments, \"propertyName\" being null in this case. */public Object parsePropertyValue(Element ele, BeanDefinition bd, String propertyName) &#123; String elementName = (propertyName != null) ? \"&lt;property&gt; element for property '\" + propertyName + \"'\" : \"&lt;constructor-arg&gt; element\"; // Should only have one child element: ref, value, list, etc. // 一个属性只能对应一种类型：ref、value、list等 NodeList nl = ele.getChildNodes(); Element subElement = null; for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); // 对应 description 或者 meta 不处理 if (node instanceof Element &amp;&amp; !nodeNameEquals(node, DESCRIPTION_ELEMENT) &amp;&amp; !nodeNameEquals(node, META_ELEMENT)) &#123; // Child element is what we're looking for. if (subElement != null) &#123; error(elementName + \" must not contain more than one sub-element\", ele); &#125; else &#123; subElement = (Element) node; &#125; &#125; &#125; // 解析 constructor-arg 上的 ref 属性 boolean hasRefAttribute = ele.hasAttribute(REF_ATTRIBUTE); // 解析 constructor-arg 上的 value 属性 boolean hasValueAttribute = ele.hasAttribute(VALUE_ATTRIBUTE); if ((hasRefAttribute &amp;&amp; hasValueAttribute) || ((hasRefAttribute || hasValueAttribute) &amp;&amp; subElement != null)) &#123; /** 在 constructor-arg 上不存在： 1. 同时既有 ref 属性又有 value 属性 2. 存在 ref 属性或者 value 属性且又有子元素 **/ error(elementName + \" is only allowed to contain either 'ref' attribute OR 'value' attribute OR sub-element\", ele); &#125; if (hasRefAttribute) &#123; // ref 属性的处理，使用 RuntimeBeanRefence 封装对应的 ref 名称 String refName = ele.getAttribute(REF_ATTRIBUTE); if (!StringUtils.hasText(refName)) &#123; error(elementName + \" contains empty 'ref' attribute\", ele); &#125; RuntimeBeanReference ref = new RuntimeBeanReference(refName); ref.setSource(extractSource(ele)); return ref; &#125; else if (hasValueAttribute) &#123; // value 属性的处理，使用 TypedStringValue 封装 TypedStringValue valueHolder = new TypedStringValue(ele.getAttribute(VALUE_ATTRIBUTE)); valueHolder.setSource(extractSource(ele)); return valueHolder; &#125; else if (subElement != null) &#123; // 解析子元素 return parsePropertySubElement(subElement, bd); &#125; else &#123; // Neither child element nor \"ref\" or \"value\" attribute found. // 即没有 ref 也没有 value 也没有子元素，报错 error(elementName + \" must specify a ref or value\", ele); return null; &#125;&#125; 所谓子元素 12345&lt;constructor-arg&gt; &lt;map&gt; &lt;entry key=\"key\" value=\"value\"/&gt; &lt;/map&gt;&lt;/constructor-arg&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public Object parsePropertySubElement(Element ele, BeanDefinition bd) &#123; return parsePropertySubElement(ele, bd, null);&#125;/** * Parse a value, ref or collection sub-element of a property or * constructor-arg element. * @param ele subelement of property element; we don't know which yet * @param defaultValueType the default type (class name) for any * &#123;@code &lt;value&gt;&#125; tag that might be created */public Object parsePropertySubElement(Element ele, BeanDefinition bd, String defaultValueType) &#123; if (!isDefaultNamespace(ele)) &#123; return parseNestedCustomElement(ele, bd); &#125; else if (nodeNameEquals(ele, BEAN_ELEMENT)) &#123; BeanDefinitionHolder nestedBd = parseBeanDefinitionElement(ele, bd); if (nestedBd != null) &#123; nestedBd = decorateBeanDefinitionIfRequired(ele, nestedBd, bd); &#125; return nestedBd; &#125; else if (nodeNameEquals(ele, REF_ELEMENT)) &#123; // A generic reference to any name of any bean. String refName = ele.getAttribute(BEAN_REF_ATTRIBUTE); boolean toParent = false; if (!StringUtils.hasLength(refName)) &#123; // 解析 local // A reference to the id of another bean in the same XML file. refName = ele.getAttribute(LOCAL_REF_ATTRIBUTE); if (!StringUtils.hasLength(refName)) &#123; // 解析 parent // A reference to the id of another bean in a parent context. refName = ele.getAttribute(PARENT_REF_ATTRIBUTE); toParent = true; if (!StringUtils.hasLength(refName)) &#123; error(\"'bean', 'local' or 'parent' is required for &lt;ref&gt; element\", ele); return null; &#125; &#125; &#125; if (!StringUtils.hasText(refName)) &#123; error(\"&lt;ref&gt; element contains empty target attribute\", ele); return null; &#125; RuntimeBeanReference ref = new RuntimeBeanReference(refName, toParent); ref.setSource(extractSource(ele)); return ref; &#125; // 对 idref 元素的解析 else if (nodeNameEquals(ele, IDREF_ELEMENT)) &#123; return parseIdRefElement(ele); &#125; // 对 value 子元素的解析 else if (nodeNameEquals(ele, VALUE_ELEMENT)) &#123; return parseValueElement(ele, defaultValueType); &#125; // 对 null 子元素的解析 else if (nodeNameEquals(ele, NULL_ELEMENT)) &#123; // It's a distinguished null value. Let's wrap it in a TypedStringValue // object in order to preserve the source location. TypedStringValue nullHolder = new TypedStringValue(null); nullHolder.setSource(extractSource(ele)); return nullHolder; &#125; // 解析 array 子元素 else if (nodeNameEquals(ele, ARRAY_ELEMENT)) &#123; return parseArrayElement(ele, bd); &#125; // 解析 list 子元素 else if (nodeNameEquals(ele, LIST_ELEMENT)) &#123; return parseListElement(ele, bd); &#125; // 解析 set 子元素 else if (nodeNameEquals(ele, SET_ELEMENT)) &#123; return parseSetElement(ele, bd); &#125; // 解析 map 子元素 else if (nodeNameEquals(ele, MAP_ELEMENT)) &#123; return parseMapElement(ele, bd); &#125; // 解析 parse 子元素 else if (nodeNameEquals(ele, PROPS_ELEMENT)) &#123; return parsePropsElement(ele); &#125; else &#123; error(\"Unknown property sub-element: [\" + ele.getNodeName() + \"]\", ele); return null; &#125;&#125; 解析子元素 property123456789101112131415161718192021222324252627282930313233343536373839/** * Parse property sub-elements of the given bean element. */public void parsePropertyElements(Element beanEle, BeanDefinition bd) &#123; NodeList nl = beanEle.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, PROPERTY_ELEMENT)) &#123; parsePropertyElement((Element) node, bd); &#125; &#125;&#125;/** * Parse a property element. */public void parsePropertyElement(Element ele, BeanDefinition bd) &#123; // 获取配置元素中 name 的值 String propertyName = ele.getAttribute(NAME_ATTRIBUTE); if (!StringUtils.hasLength(propertyName)) &#123; error(\"Tag 'property' must have a 'name' attribute\", ele); return; &#125; this.parseState.push(new PropertyEntry(propertyName)); try &#123; // 不允许多次对同一属性配置 if (bd.getPropertyValues().contains(propertyName)) &#123; error(\"Multiple 'property' definitions for property '\" + propertyName + \"'\", ele); return; &#125; Object val = parsePropertyValue(ele, bd, propertyName); PropertyValue pv = new PropertyValue(propertyName, val); parseMetaElements(ele, pv); pv.setSource(extractSource(ele)); bd.getPropertyValues().addPropertyValue(pv); &#125; finally &#123; this.parseState.pop(); &#125;&#125; 解析子元素 qualifier1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Parse qualifier sub-elements of the given bean element. */public void parseQualifierElements(Element beanEle, AbstractBeanDefinition bd) &#123; NodeList nl = beanEle.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, QUALIFIER_ELEMENT)) &#123; parseQualifierElement((Element) node, bd); &#125; &#125;&#125;/** * Parse a qualifier element. */public void parseQualifierElement(Element ele, AbstractBeanDefinition bd) &#123; String typeName = ele.getAttribute(TYPE_ATTRIBUTE); if (!StringUtils.hasLength(typeName)) &#123; error(\"Tag 'qualifier' must have a 'type' attribute\", ele); return; &#125; this.parseState.push(new QualifierEntry(typeName)); try &#123; AutowireCandidateQualifier qualifier = new AutowireCandidateQualifier(typeName); qualifier.setSource(extractSource(ele)); String value = ele.getAttribute(VALUE_ATTRIBUTE); if (StringUtils.hasLength(value)) &#123; qualifier.setAttribute(AutowireCandidateQualifier.VALUE_KEY, value); &#125; NodeList nl = ele.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, QUALIFIER_ATTRIBUTE_ELEMENT)) &#123; Element attributeEle = (Element) node; String attributeName = attributeEle.getAttribute(KEY_ATTRIBUTE); String attributeValue = attributeEle.getAttribute(VALUE_ATTRIBUTE); if (StringUtils.hasLength(attributeName) &amp;&amp; StringUtils.hasLength(attributeValue)) &#123; BeanMetadataAttribute attribute = new BeanMetadataAttribute(attributeName, attributeValue); attribute.setSource(extractSource(attributeEle)); qualifier.addMetadataAttribute(attribute); &#125; else &#123; error(\"Qualifier 'attribute' tag must have a 'name' and 'value'\", attributeEle); return; &#125; &#125; &#125; bd.addQualifier(qualifier); &#125; finally &#123; this.parseState.pop(); &#125;&#125; AbstractBeanDefinition 属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public abstract class AbstractBeanDefinition extends BeanMetadataAttributeAccessor implements BeanDefinition, Cloneable &#123; // 忽略常量 private volatile Object beanClass; // bean 的作用范围，对应 bean 属性 scope private String scope = SCOPE_DEFAULT; // 是否是抽象，对应 abstract private boolean abstractFlag = false; // 是否延迟加载，对应 lazy-init private boolean lazyInit = false; // 自动注入模式，对应 autowire private int autowireMode = AUTOWIRE_NO; // 依赖检查， 3.0 弃用 private int dependencyCheck = DEPENDENCY_CHECK_NONE; // 用来表示一个 bean 的实例化依靠另一个 bean 先实例化，对应 depend-on private String[] dependsOn; // autowire-candidate 属性设置为 false，这样容器在查找自动装配对象时， // 将不考虑该 bean，即它不会被考虑作为其他 bean 自动装配的候选者，但是该 bean 本身还是可以 // 使用自动装配来注入其他 bean 的。 // 对应 bean 属性 autowire-candidate private boolean autowireCandidate = true; // 自动装配时当出现多个 bean 候选者时，将作为首选者，对应 primary private boolean primary = false; // 用于记录 Qualifier，对应子元素 qualifier private final Map&lt;String, AutowireCandidateQualifier&gt; qualifiers = new LinkedHashMap&lt;String, AutowireCandidateQualifier&gt;(0); // 允许访问非公开的构造器和方法，程序设置 private boolean nonPublicAccessAllowed = true; /** 是否以一种宽松模式解析构造函数，默认为 true 如果为 false，则在如下情况 interface ITest&#123;&#125; class ITestImpl implements ITest&#123;&#125;; class Main&#123; Main(ITest i) &#123;&#125; Main(ITestImpl i) &#123;&#125; &#125; 抛出异常，因为 Spring 无法准确定位哪个构造函数 程序设置 **/ private boolean lenientConstructorResolution = true; /** 对应 bean 属性 factory-bean &lt;bean id=\"instanceFactoryBean\" class=\"xxx\"/&gt; &lt;bean id=\"currentTime\" factory-bean=\"instanceFactoryBean\" factory-method=\"createTime\"/&gt; **/ private String factoryBeanName; // 对应 factory-method private String factoryMethodName; // 记录构造函数注入属性，对于 constructor-arg private ConstructorArgumentValues constructorArgumentValues; // 普通属性集合 private MutablePropertyValues propertyValues; // 方法重写的持有者，记录 lookup-method、replaced-method 元素 private MethodOverrides methodOverrides = new MethodOverrides(); // 初始化方法，对应 init-method private String initMethodName; // 销毁方法，对应 destory-method private String destroyMethodName; // 是否执行 init-method，程序设定 private boolean enforceInitMethod = true; // 是否执行 destory-method，程序设置 private boolean enforceDestroyMethod = true; // 是否是用户定义的而不是应用程序本身定义的，创建 AOP 时候为 true，程序设置 private boolean synthetic = false; /** 定义这个 bean 的应用 APPLICATION: 用户 INFRASTRUCTURE：完全内部使用，与用户无光 SUPPORT: 某些复杂配置的一部分 程序设置 **/ private int role = BeanDefinition.ROLE_APPLICATION; // bean 的描述信息 private String description; // 这个 bean 定义的资源 private Resource resource; // ...各种 set/get&#125; 解析默认表情中的自定义标签元素之前的解析标签起始函数: 1234567891011121314151617181920/** * Process the given bean element, parsing the bean definition * and registering it with the registry. */protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); // 1 if (bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); // 2 try &#123; // Register the final decorated instance. BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); // 3 &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex); &#125; // Send registration event. getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); // 4 &#125;&#125; 接下来介绍 2 bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); 适用场景： 123&lt;bean id=\"test\" class=\"test.MyClass\"&gt; &lt;mybean:user username=\"aaa\" /&gt;&lt;/bean&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public BeanDefinitionHolder decorateBeanDefinitionIfRequired(Element ele, BeanDefinitionHolder definitionHolder) &#123; return decorateBeanDefinitionIfRequired(ele, definitionHolder, null);&#125;// containingBd 为父类的 bean，为了使用父类的 scope 属性public BeanDefinitionHolder decorateBeanDefinitionIfRequired( Element ele, BeanDefinitionHolder definitionHolder, BeanDefinition containingBd) &#123; BeanDefinitionHolder finalDefinition = definitionHolder; // Decorate based on custom attributes first. NamedNodeMap attributes = ele.getAttributes(); // 遍历所有的属性，看看是否有适用于修饰的属性 for (int i = 0; i &lt; attributes.getLength(); i++) &#123; Node node = attributes.item(i); finalDefinition = decorateIfRequired(node, finalDefinition, containingBd); &#125; // Decorate based on custom nested elements. NodeList children = ele.getChildNodes(); // 遍历所有的子节点，看看是否有使用于修饰的子元素 for (int i = 0; i &lt; children.getLength(); i++) &#123; Node node = children.item(i); if (node.getNodeType() == Node.ELEMENT_NODE) &#123; finalDefinition = decorateIfRequired(node, finalDefinition, containingBd); &#125; &#125; return finalDefinition;&#125;public BeanDefinitionHolder decorateIfRequired( Node node, BeanDefinitionHolder originalDef, BeanDefinition containingBd) &#123; // 获取自定义标签的命名空间 String namespaceUri = getNamespaceURI(node); // 对于非默认标签进行修饰 if (!isDefaultNamespace(namespaceUri)) &#123; // 根据命名空间找到对应的处理器 NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler != null) &#123; // 进行修饰 return handler.decorate(node, originalDef, new ParserContext(this.readerContext, this, containingBd)); &#125; else if (namespaceUri != null &amp;&amp; namespaceUri.startsWith(\"http://www.springframework.org/\")) &#123; error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", node); &#125; else &#123; // A custom namespace, not to be handled by Spring - maybe \"xml:...\". if (logger.isDebugEnabled()) &#123; logger.debug(\"No Spring NamespaceHandler found for XML schema namespace [\" + namespaceUri + \"]\"); &#125; &#125; &#125; return originalDef;&#125; 注册解析的 BeanDefinition123456789101112131415161718192021222324/** * Register the given bean definition with the given bean factory. * @param definitionHolder the bean definition including name and aliases * @param registry the bean factory to register with * @throws BeanDefinitionStoreException if registration failed */public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; // Register bean definition under primary name. // 使用 beanName 做唯一标识注册 String beanName = definitionHolder.getBeanName(); registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // Register aliases for bean name, if any. // 注册所有的别名 String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; for (String alias : aliases) &#123; registry.registerAlias(beanName, alias); &#125; &#125;&#125; 通过 beanName 注册 BeanDefinition12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394// DefaultListableBeanFactory@Overridepublic void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; Assert.hasText(beanName, \"Bean name must not be empty\"); Assert.notNull(beanDefinition, \"BeanDefinition must not be null\"); if (beanDefinition instanceof AbstractBeanDefinition) &#123; try &#123; /** 注册前的最后一次校验，这里的校验不同于之前的 XML 文件校验， 主要是对于 AbstractBeanDefinition 属性中的 methodOverrides 校验， 校验 methodOverrides 是否与工厂方法并存或者 methodOverrides 对应的方法根本不存在 **/ ((AbstractBeanDefinition) beanDefinition).validate(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, \"Validation of bean definition failed\", ex); &#125; &#125; BeanDefinition oldBeanDefinition; // 这个 beanDefinitionMap 是 ConcurrentHashMap，考虑并发 oldBeanDefinition = this.beanDefinitionMap.get(beanName); if (oldBeanDefinition != null) &#123; // 如果对应的 BeanName 已经注册且在配置中配置了 bean 不允许被覆盖，则抛出异常 if (!isAllowBeanDefinitionOverriding()) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, \"Cannot register bean definition [\" + beanDefinition + \"] for bean '\" + beanName + \"': There is already [\" + oldBeanDefinition + \"] bound.\"); &#125; else if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) &#123; // e.g. was ROLE_APPLICATION, now overriding with ROLE_SUPPORT or ROLE_INFRASTRUCTURE if (this.logger.isWarnEnabled()) &#123; this.logger.warn(\"Overriding user-defined bean definition for bean '\" + beanName + \"' with a framework-generated bean definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); &#125; &#125; else if (!beanDefinition.equals(oldBeanDefinition)) &#123; if (this.logger.isInfoEnabled()) &#123; this.logger.info(\"Overriding bean definition for bean '\" + beanName + \"' with a different definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); &#125; &#125; else &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Overriding bean definition for bean '\" + beanName + \"' with an equivalent definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); &#125; &#125; // 注册 beanDefinition this.beanDefinitionMap.put(beanName, beanDefinition); &#125; // 不属于 AbstractBeanDefinition 了 // 疑问，什么不属于 AbstactBeanDefinition 的 BeanDefinition 的实现？ else &#123; // if (hasBeanCreationStarted()) &#123; // Cannot modify startup-time collection elements anymore (for stable iteration) // 这里为什么还需要锁？ synchronized (this.beanDefinitionMap) &#123; this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String&gt; updatedDefinitions = new ArrayList&lt;String&gt;(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); // 这里需要锁！ this.beanDefinitionNames = updatedDefinitions; if (this.manualSingletonNames.contains(beanName)) &#123; Set&lt;String&gt; updatedSingletons = new LinkedHashSet&lt;String&gt;(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; &#125; &#125; &#125; else &#123; // Still in startup registration phase this.beanDefinitionMap.put(beanName, beanDefinition); // 记录 beanName this.beanDefinitionNames.add(beanName); this.manualSingletonNames.remove(beanName); &#125; this.frozenBeanDefinitionNames = null; &#125; if (oldBeanDefinition != null || containsSingleton(beanName)) &#123; // 清楚解析之前留下的对应 beanName 的缓存 resetBeanDefinition(beanName); &#125;&#125; 对 AbstractBeanDefinition 的校验。在解析 XML 文件的时候我们提过校验，但是此校验非彼校验，之前的校验时针对于 XML 格式的校验，而此时的校验时针是对于 AbstractBeanDefinition 的 methodOverrides 属性的。 对 beanName 已经注册的情况的处理。如果设置了不允许 bean 的覆盖，则需要抛出异常，否则直接覆盖 加入 map 缓存 清除解析之前留下的对应 beanName 的缓存 通过别名注册 BeanDefinition1234567891011121314151617181920212223242526@Overridepublic void registerAlias(String name, String alias) &#123; Assert.hasText(name, \"'name' must not be empty\"); Assert.hasText(alias, \"'alias' must not be empty\"); // 如果 beanName 与 alias 相同的话不记录 alias，并删除对应的 alias if (alias.equals(name)) &#123; this.aliasMap.remove(alias); &#125; else &#123; String registeredName = this.aliasMap.get(alias); if (registeredName != null) &#123; if (registeredName.equals(name)) &#123; // An existing alias - no need to re-register return; &#125; // 如果 alias 不允许被覆盖则抛出异常 if (!allowAliasOverriding()) &#123; throw new IllegalStateException(\"Cannot register alias '\" + alias + \"' for name '\" + name + \"': It is already registered for name '\" + registeredName + \"'.\"); &#125; &#125; // 当 A-&gt;B 存在时，若再次出现 A-&gt;C-&gt;B 时候则会抛出异常 checkForAliasCircle(name, alias); this.aliasMap.put(alias, name); &#125;&#125; alias 与 beanName 相同情况处理。若 alias 与 beanName 并名称相同则不需要处理并删除掉原有 alias。 alias 覆盖处理。若 aliasName 已经使用并已经指向了另一 beanName 则需要用户的设置进行处理。 alias 循环检查。当 A-&gt;B 存在时，若再次出现 A-&gt;C-&gt;B 时候则会抛出异常。 注册 alias。 通知监听器解析及注册完成// 扩展 alias 标签的解析123456789101112131415161718192021222324252627282930/** * Process the given alias element, registering the alias with the registry. */protected void processAliasRegistration(Element ele) &#123; // 获取 beanName String name = ele.getAttribute(NAME_ATTRIBUTE); // 获取 alias String alias = ele.getAttribute(ALIAS_ATTRIBUTE); boolean valid = true; if (!StringUtils.hasText(name)) &#123; getReaderContext().error(\"Name must not be empty\", ele); valid = false; &#125; if (!StringUtils.hasText(alias)) &#123; getReaderContext().error(\"Alias must not be empty\", ele); valid = false; &#125; if (valid) &#123; try &#123; // 注册 alias getReaderContext().getRegistry().registerAlias(name, alias); &#125; catch (Exception ex) &#123; getReaderContext().error(\"Failed to register alias '\" + alias + \"' for bean with name '\" + name + \"'\", ele, ex); &#125; // 别名注册后通知监听器做相应处理 getReaderContext().fireAliasRegistered(name, alias, extractSource(ele)); &#125;&#125; import 标签的解析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * Parse an \"import\" element and load the bean definitions * from the given resource into the bean factory. */protected void importBeanDefinitionResource(Element ele) &#123; // 获取 resource 属性 String location = ele.getAttribute(RESOURCE_ATTRIBUTE); // 如果不存在 resource 属性则不做任何处理 if (!StringUtils.hasText(location)) &#123; getReaderContext().error(\"Resource location must not be empty\", ele); return; &#125; // Resolve system properties: e.g. \"$&#123;user.dir&#125;\" // 解析系统属性，格式如：\"$&#123;user.dir&#125;\" location = getReaderContext().getEnvironment().resolveRequiredPlaceholders(location); Set&lt;Resource&gt; actualResources = new LinkedHashSet&lt;Resource&gt;(4); // Discover whether the location is an absolute or relative URI // 判定 location 是决定 URI 还是相对 RUI boolean absoluteLocation = false; try &#123; absoluteLocation = ResourcePatternUtils.isUrl(location) || ResourceUtils.toURI(location).isAbsolute(); &#125; catch (URISyntaxException ex) &#123; // cannot convert to an URI, considering the location relative // unless it is the well-known Spring prefix \"classpath*:\" &#125; // Absolute or relative? if (absoluteLocation) &#123; try &#123; int importCount = getReaderContext().getReader().loadBeanDefinitions(location, actualResources); if (logger.isDebugEnabled()) &#123; logger.debug(\"Imported \" + importCount + \" bean definitions from URL location [\" + location + \"]\"); &#125; &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error( \"Failed to import bean definitions from URL location [\" + location + \"]\", ele, ex); &#125; &#125; else &#123; // No URL -&gt; considering resource location as relative to the current file. // 如果是相对地址则根据相对地址计算出绝对地址 try &#123; int importCount; // Resource 存在多个子实现类，如 VfsResource，FileSystemResource 等, // 而每个 resource 的 createRelative 方式实现都不一样，所以这里先使用子类的方法尝试解析 Resource relativeResource = getReaderContext().getResource().createRelative(location); if (relativeResource.exists()) &#123; importCount = getReaderContext().getReader().loadBeanDefinitions(relativeResource); actualResources.add(relativeResource); &#125; else &#123; // 如果解析不成功，则使用默认的解析器 ResourcePatternResolver 进行解析 String baseLocation = getReaderContext().getResource().getURL().toString(); importCount = getReaderContext().getReader().loadBeanDefinitions( StringUtils.applyRelativePath(baseLocation, location), actualResources); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Imported \" + importCount + \" bean definitions from relative location [\" + location + \"]\"); &#125; &#125; catch (IOException ex) &#123; getReaderContext().error(\"Failed to resolve current resource location\", ele, ex); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(\"Failed to import bean definitions from relative location [\" + location + \"]\", ele, ex); &#125; &#125; // 解析后进行监听器激活处理 Resource[] actResArray = actualResources.toArray(new Resource[actualResources.size()]); getReaderContext().fireImportProcessed(location, actResArray, extractSource(ele));&#125; 获取 resource 属性所表示的路径 解析路径中的系统属性，格式如 “${user.dir}” 判定 location 是绝对路径还是相对路径 如果是绝对路径则递归调用 bean 的解析过程，进行另一次的解析 如果是相对路径则计算出绝对路径并进行解析 通知监听器，解析完成 嵌入式 beans 标签的解析递归调用解析 bean 12345678910111213141516171819202122232425262728293031323334/** * Register each bean definition within the given root &#123;@code &lt;beans/&gt;&#125; element. */protected void doRegisterBeanDefinitions(Element root) &#123; // Any nested &lt;beans&gt; elements will cause recursion in this method. In // order to propagate and preserve &lt;beans&gt; default-* attributes correctly, // keep track of the current (parent) delegate, which may be null. Create // the new (child) delegate with a reference to the parent for fallback purposes, // then ultimately reset this.delegate back to its original (parent) reference. // this behavior emulates a stack of delegates without actually necessitating one. BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) &#123; String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Skipped XML bean definition file due to specified profiles [\" + profileSpec + \"] not matching: \" + getReaderContext().getResource()); &#125; return; &#125; &#125; &#125; preProcessXml(root); parseBeanDefinitions(root, this.delegate); postProcessXml(root); this.delegate = parent;&#125; 参考书籍《Spring源码深度解析》","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shagle.cn/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"http://blog.shagle.cn/tags/Java/"}]},{"title":"Spring 资源访问利器","slug":"Spring-资源访问利器","date":"2019-01-08T02:07:47.000Z","updated":"2019-01-09T06:54:27.000Z","comments":true,"path":"2019/01/08/Spring-资源访问利器/","link":"","permalink":"http://blog.shagle.cn/2019/01/08/Spring-资源访问利器/","excerpt":"","text":"1. ResourceSpring 设计了一个Resource接口，它为应用提供了更强大的访问底层资源的能力。该接口拥有对应不同资源类型的实现类。 Resource 接口的主要方法： exists：返回当前Resource代表的底层资源是否存在，true表示存在。 isReadable：返回当前Resource代表的底层资源是否可读，true表示可读。 isOpen：返回当前Resource代表的底层资源是否已经打开，如果返回true，则只能被读取一次然后关闭以避免资源泄露；常见的Resource实现一般返回false。 getURL：如果当前Resource代表的底层资源能由java.util.URL代表，则返回该URL，否则抛出IOException。 getURI：如果当前Resource代表的底层资源能由java.util.URI代表，则返回该URI，否则抛出IOException。 getFile：如果当前Resource代表的底层资源能由java.io.File代表，则返回该File，否则抛出IOException。 contentLength：返回当前Resource代表的底层文件资源的长度，一般是值代表的文件资源的长度。 lastModified：返回当前Resource代表的底层资源的最后修改时间。 createRelative：用于创建相对于当前Resource代表的底层资源的资源，比如当前Resource代表文件资源“d:/test/”则createRelative（“test.txt”）将返回表文件资源“d:/test/test.txt”Resource资源。 getFilename：返回当前Resource代表的底层文件资源的文件路径，比如File资源“file://d:/test.txt”将返回“d:/test.txt”，而URL资源http://www.javass.cn将返回“”，因为只返回文件路径。 getDescription：返回当前Resource代表的底层资源的描述符，通常就是资源的全路径（实际文件名或实际URL地址）。 关于更多详细信息请参考 Resource 在Spring框架中起着不可或缺的作用，Spring框架使用Resource装载各种资源，这些资源包括配置文件资源、国际化属性文件资源等。Resource 的具体实现类如下图： ByteArrayResource 二进制数组表示的资源，二进制数组资源可以在内存中通过程序构造。 ClassPathResource 类路径下的资源，资源相当于类路径的方式表示。 FileSystemResource 文件系统资源，资源文件系统路径的方式表示。例如：D:/conf/bean.xml InputStreamResource 以输入流返回表示的资源。 ServletContextResource 为访问web上下文中的资源而设计的类，负责以相对于web应用根目录的路径加载资源，它支持以流和URL的方式访问，在war解包情况下，也可以通过File的方式访问，该类还可以直接从jar包中访问资源； UrlResource Url封装了java.net.URL ，它使用户能够访问任何可以通URL表示的资源，如文件系统的资源、HTTP资源、FTP资源等 Spring 的Resource接口及其实现类可以在脱离Spring框架的情况下使用，它比通过JDK访问资源的API更好用，更强大。 资源加载 资源地址表达式： 地址前缀 示例 对应资源类型 classpath： classpath:com/baobaotao/beanfactory/bean.xml 从类路径中加载资源，classpath:和classpath:等价，都是相对与类的跟路径。资源文件可以在标准的文件系统中，也可以在jar或者zip的类包中 file: file:/conf/com/baobaotao/beanfactory/bean.xml 使用URLResource从文件系统目录中装载资源，可采用绝对或相对路径。 http:// http://www.baobaotao/resource/bean.xml 使用UrlResource从web服务器中装载资源 ftp: ftp://www.baobaotao.com/resource/bean.xml 使用UrlResource从FTP服务器中装载资源 没有前缀 com/baobaotao/beanfatory/beans.xml 根据ApplicationContext具体实现类采用对应的类型的Resource Ant风格资源地址支持3种匹配符： ？：匹配文件名中的一个字符 ：匹配文件名中任意一个字符 ：匹配多层路径 下面是几个Ant风格的资源路径示例： classpath:com/t?xt.xml ：匹配com路径下com/text.xml ,com/tast.xml或者com/txst.xml； file:D:/conf/*.xml ：匹配文件系统D:/conf目录下所有以xml为后缀的文件； classpath:com/**/test.xml : 匹配com路径下（当前目录及其子孙目录）的test.xml文件； classpath:org/springframwork/*/.xml : 匹配类路径 org/springframwork 下所有的以xml位后缀的文件。 2. ResourceLoader 资源加载器spring定义了一套资源加载的接口 ResourceLoader 接口仅有一个getResource(String location)的方法，可以根据一个资源地址加载文件资源，不过，资源地址仅支持带资源类型前缀的表达式，不支持Ant风格的资源路径表达式。ResourcePatternResolver 扩展了ResourceLoader 接口，定义了一个新的接口方法：getResources（String locationPattern），该方法支持带资源类型前缀及Ant风格的资源路径的表达式。PathMatchingResourceResolver 是Spring提供了标准实现类。 分享一个案例，有一次帮朋友邮件一个1GB多的文件，做了分卷压缩，结果弄了一桌面的压缩文件。一个一个删除不是个很好的办法。不知道怎么的，脑子突然想出了这个方法，结果还是很奏效的。一下子个删除完了。 12345678910111213141516public class Test001 &#123; public static void main(String[] args) throws IOException &#123; ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); Resource[] resources = resolver.getResources(\"file:C:/Documents and Settings/Administrator/桌面/*.rar\"); System.out.println(resources.length); for (Resource resource : resources) &#123; System.out.println(\"delete *.rar \" + resource.getFile().delete()); System.out.println(resource.getFilename()); &#125; &#125;&#125;","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"Resource接口","slug":"Resource接口","permalink":"http://blog.shagle.cn/tags/Resource接口/"},{"name":"ResourceLoader","slug":"ResourceLoader","permalink":"http://blog.shagle.cn/tags/ResourceLoader/"}]},{"title":"Spring 源码分析bean的解析(1)","slug":"Spring源码分析-bean的解析（1）","date":"2019-01-08T02:07:47.000Z","updated":"2019-01-09T06:54:27.000Z","comments":true,"path":"2019/01/08/Spring源码分析-bean的解析（1）/","link":"","permalink":"http://blog.shagle.cn/2019/01/08/Spring源码分析-bean的解析（1）/","excerpt":"","text":"spring 源码解析我们一开始需要先定义一个 Bean 和一个 xml 12345678910111213// beanpackage io.github.binglau.bean;import lombok.Data;/** * 文件描述: */@Data // 简化 setter/getterpublic class TestBean &#123; private String testStr = \"test\";&#125; 123456789&lt;!-- beanFactory.xml --&gt;&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd\"&gt; &lt;bean id=\"testBean\" class=\"io.github.binglau.bean.TestBean\" /&gt;&lt;/beans&gt; 这时候我们大多数是这么来启动 IoC 的 12345678910111213141516171819202122package io.github.binglau;import io.github.binglau.bean.TestBean;import org.junit.Test;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.xml.XmlBeanFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.core.io.ClassPathResource;/** * 文件描述: */public class BeanFactoryTest &#123; @Test public void testSimpleLoad() &#123; ApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:beanFactory.xml\"); TestBean testBean = (TestBean) context.getBean(\"testBean\"); System.out.printf(\"test bean: %s\", testBean.getTestStr()); &#125;&#125; 现在让我们来看看 ApplicationContext 代表了什么 123456789101112131415161718192021222324package org.springframework.context;import org.springframework.beans.factory.HierarchicalBeanFactory;import org.springframework.beans.factory.ListableBeanFactory;import org.springframework.beans.factory.config.AutowireCapableBeanFactory;import org.springframework.core.env.EnvironmentCapable;import org.springframework.core.io.support.ResourcePatternResolver;public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver &#123; String getId(); String getApplicationName(); String getDisplayName(); long getStartupDate(); ApplicationContext getParent(); AutowireCapableBeanFactory getAutowireCapableBeanFactory() throws IllegalStateException;&#125; 其实所谓的 getBean 方法是定义在 ListableBeanFactory 接口所继承的 BeanFactory 接口中的。这样说来，我们应该是可以直接通过 BeanFactory 来调用 Bean 的，其实有一个根据 xml 来实现的 BeanFactory ，是这样调用的： 1234567891011121314151617181920212223package io.github.binglau;import io.github.binglau.bean.TestBean;import org.junit.Test;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.xml.XmlBeanFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.core.io.ClassPathResource;/** * 文件描述: */public class BeanFactoryTest &#123; @Test public void testSimpleLoad() &#123; BeanFactory context = new XmlBeanFactory(new ClassPathResource(\"beanFactory.xml\"));// ApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:beanFactory.xml\"); TestBean testBean = (TestBean) context.getBean(\"testBean\"); System.out.printf(\"test bean: %s\", testBean.getTestStr()); &#125;&#125; 好了，现在让我们开始进入 XmlBeanFactory 中来分析一下吧 XmlBeanFactory123456789101112131415161718192021222324package org.springframework.beans.factory.xml;import org.springframework.beans.BeansException;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.support.DefaultListableBeanFactory;import org.springframework.core.io.Resource;@Deprecated@SuppressWarnings(&#123;\"serial\", \"all\"&#125;)public class XmlBeanFactory extends DefaultListableBeanFactory &#123; private final XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(this); public XmlBeanFactory(Resource resource) throws BeansException &#123; this(resource, null); &#125; public XmlBeanFactory(Resource resource, BeanFactory parentBeanFactory) throws BeansException &#123; super(parentBeanFactory); this.reader.loadBeanDefinitions(resource); &#125;&#125; 这里我们可以看出，他是继承了 DefaultListableBeanFactory，而 DefaultListableBeanFactory 也是整个 bean 加载的核心部分，是 Spring 注册及加载 bean 的默认实现。我们先从全局角度来了解一下它 DefaultListableBeanFactory 的各个类功能： AliasRegistry: 定义对 alias 的简单增删改等操作 SimpleAliasRegistry: 主要使用 map 作为 alias 的缓存，并对接口 AliasRegistry 进行实现 SingletonBeanRegistry: 定义对单例的注册及获取 BeanFactory: 定义获取 bean 及 bean 的各种属性 DefaultSingletonBeanRegistry: 对接口 SingletonBeanRegistry 各函数的实现 HierarchicalBeanFactory: 继承 BeanFactory，也就是在 BeanFactory 定义的功能的基础上增加了对 parentFactory 的支持 BeanDefinitionRegistry: 定义对 BeanDefinition 的各种增删改操作 FactoryBeanRegistrySupport: 在 DefaultSingletonBeanRegistry 基础上增加了对 FactoryBean 的特殊处理功能 ConfigurableBeanFactory: 提供配置 Factory 的各种方法 ListableBeanFactory: 根据各种条件获取 bean 的配置清单 AbstractBeanFactory: 综合 FactoryBeanRegistrySupport 和 ConfigurableBeanFactory 的功能 AutowireCapableBeanFactory: 提供创建 bean、自动注入、初始化以及应用 bean 的后处理器 AbstractAutowireCapableBeanFactory: 综合 AbstractBeanFactory 并对接口 AutowireCapableBeanFactory 进行实现 ConfigurableListableBeanFactory: BeanFactory 配置清单，指定忽略类型及接口等 DefaultListableBeanFactory: 综合上面的所有功能，主要是对 Bean 注册后的处理 XmlFactoryBean 主要是针对 XML 文档对 DefaultListableBeanFactory 的个性化实现，唯一不同的也就是 XmlBeanDefinitionReader 类型的 reader。 XmlBeanDefinitionReader其中我们看到 XmlFactoryBean 构造器中第二句 this.reader.loadBeanDefinitions(resource);，但从名字来看它应该是加载 Bean 的主要执行者，而 reader 的定义在顶上 private final XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(this); 。所谓 XmlBeanDefinitionReader 主要是负责读取 Spring 配置文件信息。 这张图 Idea 生成有些许差别，于是就自己画了一下。 ResourceLoader：定义资源加载器，主要应用于根据给定的资源文件地址返回对应的 Resource BeanDefinitionReader: 主要定义资源文件读取并转换为 BeanDefinition 的各个功能 EnvironmentCapable：定义获取 Environment 方法 DocumentLoader：定义从资源文件加载到转换为 Document 的功能 AbstractBeanDefinitionReader：对 EnvironmentCapable、BeanDefinitionReader 类定义的功能进行实现 BeanDefinitionDocumentReader：定义读取 Document 并注册 BeanDefinition 功能 BeanDefinitionParserDelegate: 定义解析 Element 的各种方法 经过上面的分析，我们大概能得出 XML 配置文件读取的大致流程： 通过继承自 AbstractBeanDefinitionReader 中的方法，来使用 ResourceLoader 将资源文件路径转换为对应的 Resource 文件 通过 DocumentLoader 对 Resource 文件进行转换，将 Resource 文件转换为 Document 文件 通过实现接口 BeanDefinitionDocumentReader 的 DefaultBeanDefinitionDocumentReader 类对 Document 进行解析，并使用 BeanDefinitionParserDelegate 对 Element 进行解析 分析 XmlBeanFactoy这时候，让我们在回头看 BeanFactory context = new XmlBeanFactory(new ClassPathResource(&quot;beanFactory.xml&quot;)); 先从现有信息可以整理出下面这张时序图 配置文件封装首先看看 Resource 配置文件的加载，也就是 new ClassPathResource(&quot;beanFactory.xml&quot;) 在 Java 中，将不同来源的资源抽象成 URL，通过注册不同的 handler(URLStreamHandler)来处理不同来源的资源的读取逻辑，一般 handler 的类型使用不同前缀（协议，Protocol）来识别，如 “file:”、“http:”、“jar:” 等，然而 URL 没有默认定义相对 Classpath 或 ServletContext 等资源的 handler，虽然可以注册自己的 URLStreamHandler 来解析特定的URL前缀（协议），比如 “classpath:” ，然而这需要了解 URL 的实现机制，而且URL也没有提供一些基本的方法，如检查当前资源是否存在、检查当前资源是否可读等方法。 因而 Spring 对其内部使用到的资源实现了自己的抽象结构：Resource接口来封装底层资源。 其内部资源的抽象结构： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public interface InputStreamSource &#123; /** * Return an &#123;@link InputStream&#125; for the content of an underlying resource. * &lt;p&gt;It is expected that each call creates a &lt;i&gt;fresh&lt;/i&gt; stream. * &lt;p&gt;This requirement is particularly important when you consider an API such * as JavaMail, which needs to be able to read the stream multiple times when * creating mail attachments. For such a use case, it is &lt;i&gt;required&lt;/i&gt; * that each &#123;@code getInputStream()&#125; call returns a fresh stream. * @return the input stream for the underlying resource (must not be &#123;@code null&#125;) * @throws java.io.FileNotFoundException if the underlying resource doesn't exist * @throws IOException if the content stream could not be opened */ InputStream getInputStream() throws IOException;&#125;/**InputSteramSource 抽象了所有 Spring 内部使用到的底层资源：File、URL、Classpath 下的资源和 ByteArray 等、它只有一个方法定义：getInputStream()，该方法返回一个新的 InputStream 对象。**/public interface Resource extends InputStreamSource &#123; /** * 存在性 */ boolean exists(); /** * 可读性 */ boolean isReadable(); /** * 是否处于打开状态 */ boolean isOpen(); URL getURL() throws IOException; URI getURI() throws IOException; File getFile() throws IOException; long contentLength() throws IOException; long lastModified() throws IOException; /** * 基于当前资源创建一个相对资源的方法 */ Resource createRelative(String relativePath) throws IOException; String getFilename(); /** * 用于错误处理中的打印信息 */ String getDescription();&#125; 对于不同来源的资源都有其对应的实现： 其中 ClassPathResouce 的实现 12345678910111213141516171819202122/** * This implementation opens an InputStream for the given class path resource. * @see java.lang.ClassLoader#getResourceAsStream(String) * @see java.lang.Class#getResourceAsStream(String) */@Overridepublic InputStream getInputStream() throws IOException &#123; InputStream is; if (this.clazz != null) &#123; is = this.clazz.getResourceAsStream(this.path); &#125; else if (this.classLoader != null) &#123; is = this.classLoader.getResourceAsStream(this.path); &#125; else &#123; is = ClassLoader.getSystemResourceAsStream(this.path); &#125; if (is == null) &#123; throw new FileNotFoundException(getDescription() + \" cannot be opened because it does not exist\"); &#125; return is;&#125; 在 XmlFactoryBean 中，我们先调用了 super，现在看看 super 干了什么事情 123456789/** * Create a new AbstractAutowireCapableBeanFactory. */public AbstractAutowireCapableBeanFactory() &#123; super(); ignoreDependencyInterface(BeanNameAware.class); ignoreDependencyInterface(BeanFactoryAware.class); ignoreDependencyInterface(BeanClassLoaderAware.class);&#125; 这里有必要提及一下 ignoreDependencyInterface 方法。ignoreDependencyInterface 的主要功能是忽略给定接口的自动装配功能，那么，这样做的目的是什么呢？会产生什么样的效果呢？ 举例来说，当 A 中有属性 B，那么当 Spring 在获取 A 的 Bean 的时候如果其属性 B 还没有初始化，那么 Spring 会自动初始化 B，这也是 Spring 中提供的一个重要特性。但是，某些情况下，B 不会被初始化，其中的一种情况就是 B 实现了 BeanNameAware 接口。Spring 中是这样介绍的：自动装配时忽略给定的依赖接口，典型应用是通过其他方式解析 Application 上下文注册依赖，类似于 BeanFactory 通过 BeanFactoryAware 进行注入或者 ApplicationContext 通过 ApplicationContextAware 进行注入。 加载 Beanthis.reader.loadBeanDefinitions(resource) 的讲解，其时序图 封装资源文件。当进入 XmlBeanDefinitionReader 后首先对参数 Resource 使用 EncodedResource 类进行封装。 获取输入流。从 Resource 中获取对应的 InputStream 并构造 InputSource 通过构造的 InputSource 实例和 Resource 实例继续调用函数 doLoadBeanDefinitions 时序图中的逻辑实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Load bean definitions from the specified XML file. * @param encodedResource the resource descriptor for the XML file, * allowing to specify an encoding to use for parsing the file * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors */public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Assert.notNull(encodedResource, \"EncodedResource must not be null\"); if (logger.isInfoEnabled()) &#123; logger.info(\"Loading XML bean definitions from \" + encodedResource.getResource()); &#125; // 通过属性来记录已经加载的资源 Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException( \"Detected cyclic loading of \" + encodedResource + \" - check your import definitions!\"); &#125; try &#123; // 从 encodedResource 中获取已经封装的 Resource 对象并再次从 Resource 中获取其中的 inputStream InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; // InputSource 这个类并不来自于 Spring，它的全路径是 org.xml.sax.InputSource InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; // 真正进入逻辑核心部分 return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( \"IOException parsing XML document from \" + encodedResource.getResource(), ex); &#125; finally &#123; currentResources.remove(encodedResource); if (currentResources.isEmpty()) &#123; this.resourcesCurrentlyBeingLoaded.remove(); &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Actually load bean definitions from the specified XML file. * @param inputSource the SAX InputSource to read from * @param resource the resource descriptor for the XML file * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors * @see #doLoadDocument * @see #registerBeanDefinitions */ protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; Document doc = doLoadDocument(inputSource, resource); return registerBeanDefinitions(doc, resource); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (SAXParseException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"Line \" + ex.getLineNumber() + \" in XML document from \" + resource + \" is invalid\", ex); &#125; catch (SAXException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"XML document from \" + resource + \" is invalid\", ex); &#125; catch (ParserConfigurationException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Parser configuration exception parsing XML from \" + resource, ex); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"IOException parsing XML document from \" + resource, ex); &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), \"Unexpected exception parsing XML document from \" + resource, ex); &#125; &#125; /** * Actually load the specified document using the configured DocumentLoader. * @param inputSource the SAX InputSource to read from * @param resource the resource descriptor for the XML file * @return the DOM Document * @throws Exception when thrown from the DocumentLoader * @see #setDocumentLoader * @see DocumentLoader#loadDocument */ protected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception &#123; return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware()); &#125; doLoadBeanDefinitions 中做了三件事： 获取对 XML 文件的验证模型 加载 XML 文件，并得到对应的 Document 根据返回的 Document 注册 Bean 信息 获取 XML 的验证模式DTD 与 XSD 区别DTD （文档类型定义），保证 XML 文档格式正确的有效方法，可以通过比较 XML 文档和 DTD 文件来看文档是否符合规范，元素和标签使用是否正确。一个 DTD 文档包含：元素的定义规则，元素间关系的定义规则，元素可使用的属性，可使用的实体或符号规则。 XSD （XML Schemas Definition）。XML Scheme 描述了 XML 文档的结构。可以用一个指定的 XML Schema 来验证某个 XML 文档，以检查该 XML 文档是否符合其要求。文档设计者可以通过 XML Schema 指定一个 XML 文档所允许的结构和内容，并可据此检查一个 XML 文档是否是有效的。XML Schema 本身是一个 XML 文档，它符合 XML 语法结构。可以用通用的 XML 解析器解析它。 在使用 XML Schema 文档中 XML 实例文档进行检验，除了要声明名称空间外（xmlns = http://www.SpringFramework.org/schema/beans），还必须制定该名称空间所对应的 XML Schema 文档的存储位置。通过 schemaLocation 熟悉来指定名称空间所对应的 XML Schema 文档的存储位置，它包含两个部分，一部分是名称空的 URI，另一部分就是该名称空间所标识的 XML Shema 文件位置或 URL 地址(xsi:schemaLocation=”http://www.Springframework.org/schema/beans http://www.Springframework.org/schema/beans/Spring-beans.xsd&quot;) 验证模式的获取进入 Document doc = doLoadDocument(inputSource, resource);方法 1234protected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception &#123; return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware());&#125; 其中getValidationModeForResource(resource)就是获取验证模式。 1234567891011121314151617181920212223/** * Gets the validation mode for the specified &#123;@link Resource&#125;. If no explicit * validation mode has been configured then the validation mode is * &#123;@link #detectValidationMode detected&#125;. * &lt;p&gt;Override this method if you would like full control over the validation * mode, even when something other than &#123;@link #VALIDATION_AUTO&#125; was set. */protected int getValidationModeForResource(Resource resource) &#123; int validationModeToUse = getValidationMode(); // 如果手动指定了验证模式则使用指定的验证模式 if (validationModeToUse != VALIDATION_AUTO) &#123; return validationModeToUse; &#125; // 如果未指定则使用自动检测 int detectedMode = detectValidationMode(resource); if (detectedMode != VALIDATION_AUTO) &#123; return detectedMode; &#125; // Hmm, we didn't get a clear indication... Let's assume XSD, // since apparently no DTD declaration has been found up until // detection stopped (before finding the document's root tag). return VALIDATION_XSD;&#125; detectValidationMode 将自动检测验证模式工作委派给专门处理类 XmlValidationModeDetecotor，调用了 XmlValidationModeDetecotor 的 vaildationModeDetector 方法，具体代码如下： 1234567891011121314151617181920212223242526272829303132333435/** * Detects which kind of validation to perform on the XML file identified * by the supplied &#123;@link Resource&#125;. If the file has a &#123;@code DOCTYPE&#125; * definition then DTD validation is used otherwise XSD validation is assumed. * &lt;p&gt;Override this method if you would like to customize resolution * of the &#123;@link #VALIDATION_AUTO&#125; mode. */protected int detectValidationMode(Resource resource) &#123; if (resource.isOpen()) &#123; throw new BeanDefinitionStoreException( \"Passed-in Resource [\" + resource + \"] contains an open stream: \" + \"cannot determine validation mode automatically. Either pass in a Resource \" + \"that is able to create fresh streams, or explicitly specify the validationMode \" + \"on your XmlBeanDefinitionReader instance.\"); &#125; InputStream inputStream; try &#123; inputStream = resource.getInputStream(); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( \"Unable to determine validation mode for [\" + resource + \"]: cannot open InputStream. \" + \"Did you attempt to load directly from a SAX InputSource without specifying the \" + \"validationMode on your XmlBeanDefinitionReader instance?\", ex); &#125; try &#123; return this.validationModeDetector.detectValidationMode(inputStream); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(\"Unable to determine validation mode for [\" + resource + \"]: an error occurred whilst reading from the InputStream.\", ex); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * Detect the validation mode for the XML document in the supplied &#123;@link InputStream&#125;. * Note that the supplied &#123;@link InputStream&#125; is closed by this method before returning. * @param inputStream the InputStream to parse * @throws IOException in case of I/O failure * @see #VALIDATION_DTD * @see #VALIDATION_XSD */public int detectValidationMode(InputStream inputStream) throws IOException &#123; // Peek into the file to look for DOCTYPE. BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream)); try &#123; boolean isDtdValidated = false; String content; while ((content = reader.readLine()) != null) &#123; content = consumeCommentTokens(content); // 如果读取的行是空或者是注释则略过 if (this.inComment || !StringUtils.hasText(content)) &#123; continue; &#125; if (hasDoctype(content)) &#123; isDtdValidated = true; break; &#125; // 读取到 &lt; 开始符号，验证模式一定会在开始符号之前 if (hasOpeningTag(content)) &#123; // End of meaningful data... break; &#125; &#125; return (isDtdValidated ? VALIDATION_DTD : VALIDATION_XSD); &#125; catch (CharConversionException ex) &#123; // Choked on some character encoding... // Leave the decision up to the caller. return VALIDATION_AUTO; &#125; finally &#123; reader.close(); &#125;&#125;/** * Does the content contain the DTD DOCTYPE declaration? */private boolean hasDoctype(String content) &#123; return content.contains(DOCTYPE);&#125; 获取 Document123456789101112131415/** * Load the &#123;@link Document&#125; at the supplied &#123;@link InputSource&#125; using the standard JAXP-configured * XML parser. */@Overridepublic Document loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception &#123; DocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware); if (logger.isDebugEnabled()) &#123; logger.debug(\"Using JAXP provider [\" + factory.getClass().getName() + \"]\"); &#125; DocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler); return builder.parse(inputSource);&#125; EntityResolver 解释： 如果 SAX 应用程序需要实现自定义处理外部实体，则必须实现此接口并使用 setEntityResolver 方法向 SAX 驱动器注册一个实例。即防止下载 DTD 时候网络错误，提供一个寻找 DTD 声明的方法。 解析及注册 BeanDefinitions123456789101112131415161718192021222324252627282930313233343536373839/** * Register the bean definitions contained in the given DOM document. * Called by &#123;@code loadBeanDefinitions&#125;. * &lt;p&gt;Creates a new instance of the parser class and invokes * &#123;@code registerBeanDefinitions&#125; on it. * @param doc the DOM document * @param resource the resource descriptor (for context information) * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of parsing errors * @see #loadBeanDefinitions * @see #setDocumentReaderClass * @see BeanDefinitionDocumentReader#registerBeanDefinitions */public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; // 使用 DefaultBeanDefinitionDocumentReader 实例化 BeanDefinitionDocumentReader BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); // 在实例化 BeanDefinitionReader 时候会将 BeanDefinitionRegistry 传入，默认使用继承 DefaultListableBeanFactory 的子类 // 记录统计前 BeanDefinition 的加载个数 int countBefore = getRegistry().getBeanDefinitionCount(); // 加载及注册 bean documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); // 记录本次加载的 BeanDefinition 个数 return getRegistry().getBeanDefinitionCount() - countBefore;&#125;/** * This implementation parses bean definitions according to the \"spring-beans\" XSD * (or DTD, historically). * &lt;p&gt;Opens a DOM Document; then initializes the default settings * specified at the &#123;@code &lt;beans/&gt;&#125; level; then parses the contained bean definitions. */@Overridepublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; logger.debug(\"Loading bean definitions\"); Element root = doc.getDocumentElement(); // 重点：提取 root doRegisterBeanDefinitions(root);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Register each bean definition within the given root &#123;@code &lt;beans/&gt;&#125; element. */protected void doRegisterBeanDefinitions(Element root) &#123; // Any nested &lt;beans&gt; elements will cause recursion in this method. In // order to propagate and preserve &lt;beans&gt; default-* attributes correctly, // keep track of the current (parent) delegate, which may be null. Create // the new (child) delegate with a reference to the parent for fallback purposes, // then ultimately reset this.delegate back to its original (parent) reference. // this behavior emulates a stack of delegates without actually necessitating one. // 专门处理解析 BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) &#123; // 处理 profile 属性 String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if (logger.isInfoEnabled()) &#123; logger.info(\"Skipped XML bean definition file due to specified profiles [\" + profileSpec + \"] not matching: \" + getReaderContext().getResource()); &#125; return; &#125; &#125; &#125; // 解析前处理，留给子类实现 preProcessXml(root); parseBeanDefinitions(root, this.delegate); // 解析后处理，留给子类实现 postProcessXml(root); this.delegate = parent;&#125;/** * Parse the elements at the root level in the document: * \"import\", \"alias\", \"bean\". * @param root the DOM root element of the document */protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; // 对 beans 的处理 if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; // 默认标签解析 parseDefaultElement(ele, delegate); &#125; else &#123; // 自定义标签解析 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125;&#125; 参考书籍《Spring源码深度解析》","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://blog.shagle.cn/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"http://blog.shagle.cn/tags/Java/"}]},{"title":"java对象POJO和JavaBean的区别","slug":"java对象POJO和JavaBean的区别","date":"2019-01-07T05:27:14.000Z","updated":"2019-01-07T05:29:56.000Z","comments":true,"path":"2019/01/07/java对象POJO和JavaBean的区别/","link":"","permalink":"http://blog.shagle.cn/2019/01/07/java对象POJO和JavaBean的区别/","excerpt":"","text":"1.POJO“Plain Ordinary Java Object”，简单普通的java对象。主要用来指代那些没有遵循特定的java对象模型，约定或者框架的对象。POJO的内在含义是指那些:有一些private的参数作为对象的属性，然后针对每一个参数定义get和set方法访问的接口。没有从任何类继承、也没有实现任何接口，更没有被其它框架侵入的java对象。 1234567891011121314151617181920212223public class BasicInfoVo &#123; private String orderId; private Integer uid; public String getOrderId() &#123; return orderId; &#125; public void setOrderId(String orderId) &#123; this.orderId = orderId; &#125; public Integer getUid() &#123; return uid; &#125; public void setUid(Integer uid) &#123; this.uid = uid; &#125;&#125; 2.JavaBeanJavaBean 是一种JAVA语言写成的可重用组件。JavaBean符合一定规范编写的Java类，不是一种技术，而是一种规范。大家针对这种规范，总结了很多开发技巧、工具函数。符合这种规范的类，可以被其它的程序员或者框架使用。它的方法命名，构造及行为必须符合特定的约定： 所有属性为private。 这个类必须有一个公共的缺省构造函数。即是提供无参数的构造器。 这个类的属性使用getter和setter来访问，其他方法遵从标准命名规范。 这个类应是可序列化的。实现serializable接口。 因为这些要求主要是靠约定而不是靠实现接口，所以许多开发者把JavaBean看作遵从特定命名约定的POJO。 12345678910111213141516171819202122232425262728293031323334public class UserInfo implements java.io.Serializable&#123; //实现serializable接口。 private static final long serialVersionUID = 1L; private String name; private int age; //无参构造器 public UserInfo() &#123; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; //javabean当中可以有其它的方法 public void userInfoPrint()&#123; System.out.println(\"\"); &#125; &#125; 3. 两者有什么区别 POJO其实是比javabean更纯净的简单类或接口。POJO严格地遵守简单对象的概念，而一些JavaBean中往往会封装一些简单逻辑。 POJO主要用于数据的临时传递，它只能装载数据， 作为数据存储的载体，而不具有业务逻辑处理的能力。 Javabean虽然数据的获取与POJO一样，但是javabean当中可以有其它的方法。 原文链接：https://www.jianshu.com/p/224489dfdec8","categories":[{"name":"编程术语","slug":"编程术语","permalink":"http://blog.shagle.cn/categories/编程术语/"}],"tags":[{"name":"pojo","slug":"pojo","permalink":"http://blog.shagle.cn/tags/pojo/"},{"name":"javabean","slug":"javabean","permalink":"http://blog.shagle.cn/tags/javabean/"}]},{"title":"编程术语","slug":"编程术语","date":"2019-01-07T04:54:02.000Z","updated":"2019-01-07T04:55:44.000Z","comments":true,"path":"2019/01/07/编程术语/","link":"","permalink":"http://blog.shagle.cn/2019/01/07/编程术语/","excerpt":"","text":"编程思想总结 Spring思想 应用场景（特点） 一句话归纳 AOP AspectOrientedProgramming(面向切面编程)找出多个类中有一定规律的代码，开发时拆开，运行时再合并。面向切面编程，即面向规则编程。 解耦，专人做专事。 OOP ObjectOrientedProgramming（面向对象编程）归纳总结生活中一切事物。 封装、继承、多态。 BOP BeanOrientedProgramming（面向Bean编程）面向Bean（普通的java类）设计程序。 一切从Bean开始。 IOC InversionofControl（控制反转）将new对象的动作交给Spring管理，并由Spring保存已创建的对象（IOC容器）。 转交控制权（即控制权反转）。 DI/DL DependencyInjection（依赖注入）或者DependencyLookup（依赖查找）依赖注入、依赖查找，Spring不仅保存自己创建的对象，而且保存对象与对象之间的关系。注入即赋值，主要三种方式构造方法、set方法、直接赋值。 先理清关系再赋值。","categories":[{"name":"编程术语","slug":"编程术语","permalink":"http://blog.shagle.cn/categories/编程术语/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://blog.shagle.cn/tags/AOP/"},{"name":"OOP","slug":"OOP","permalink":"http://blog.shagle.cn/tags/OOP/"},{"name":"BOP","slug":"BOP","permalink":"http://blog.shagle.cn/tags/BOP/"},{"name":"IOC","slug":"IOC","permalink":"http://blog.shagle.cn/tags/IOC/"},{"name":"DI/DL","slug":"DI-DL","permalink":"http://blog.shagle.cn/tags/DI-DL/"}]},{"title":"spring 常用的设计模式","slug":"spring常用的设计模式","date":"2019-01-07T04:31:22.000Z","updated":"2019-01-09T06:54:27.000Z","comments":true,"path":"2019/01/07/spring常用的设计模式/","link":"","permalink":"http://blog.shagle.cn/2019/01/07/spring常用的设计模式/","excerpt":"","text":"1、简单工厂模式（Factory）应用场景：又叫做静态工厂方法（StaticFactoryMethod）模式，但不属于23种设计模式之一。简单工厂模式的实质是由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类。Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。 归类 特点 穷举 创建型模式 是复杂工厂模式的思维模型 批量生产、标准化 2、工厂方法模式（FactoryMethod）应用场景：通常由应用程序直接使用new创建新的对象，为了将对象的创建和使用相分离，采用工厂模式,即应用程序将对象的创建及初始化职责交给工厂对象。一般情况下,应用程序有自己的工厂对象来创建Bean.如果将应用程序自己的工厂对象交给Spring管理,那么Spring管理的就不是普通的Bean,而是工厂Bean。 归类 特点 穷举 创建型模式 对于调用者来说，隐藏了复杂的逻辑处理过程，调用者只关心执行结果。 对于工厂来说要对结果负责，保证生产出符合规范的产品。 流水线生产 3、单例模式（Singleton）应用场景：保证一个类仅有一个实例，并提供一个访问它的全局访问点。Spring中的单例模式完成了后半句话，即提供了全局的访问点BeanFactory。但没有从构造器级别去控制单例，这是因为Spring管理的是是任意的Java对象。Spring下默认的Bean均为单例。 归类 特点 穷举 创建型模式 保证从系统启动到系统终止，全过程只会产生一个实例。 当我们在应用中遇到功能性冲突的时候，需要使用单例模式。 配置文件、日历、OC容器 常用单例模式写法：饿汉式、懒汉式、注册式、序列化。 4、原型模式（Prototype）应用场景：原型模式就是从一个对象再创建另外一个可定制的对象，而且不需要知道任何创建的细节。所谓原型模式，就是Java中的克隆技术，以某个对象为原型。复制出新的对象。显然新的对象具备原型对象的特点，效率高（避免了重新执行构造过程步骤）。 归类 特点 穷举 创建型模式 首先有一个原型。 数据内容相同，但对象实例不同（完全两个个体）。 孙悟空吹毫毛 5、代理模式（Proxy）应用场景：为其他对象提供一种代理以控制对这个对象的访问。从结构上来看和Decorator模式类似，但Proxy是控制，更像是一种对功能的限制，而Decorator是增加职责。Spring的Proxy模式在AOP中有体现，比如JdkDynamicAopProxy和Cglib2AopProxy。 归类 特点 穷举 结构型模式 执行者、被代理人对于被代理人来说，这件事情是一定要做的，但是我自己又不想做或者没有时间做。对于代理人而言，需要获取到被代理的人个人资料，只是参与整个过程的某个或几个环节。 租房中介、售票黄牛、婚介、经纪人、快递、事务代理、非侵入式日志监听 6、策略模式（Strategy）应用场景：定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化。Spring中在实例化对象的时候用到Strategy模式，在SimpleInstantiationStrategy有使用。 归类 特点 穷举 行为型模式 最终执行结果是固定的。 执行过程和执行逻辑不一样。 旅游出行方式 7、模板方法模式（TemplateMethod）定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。TemplateMethod使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。TemplateMethod模式一般是需要继承的。这里想要探讨另一种对TemplateMethod的理解。Spring中的JdbcTemplate，在用这个类时并不想去继承这个类，因为这个类的方法太多，但是我们还是想用到JdbcTemplate已有的稳定的、公用的数据库连接，那么我们怎么办呢？我们可以把变化的东西抽出来作为一个参数传入JdbcTemplate的方法中。但是变化的东西是一段代码，而且这段代码会用到JdbcTemplate中的变量。怎么办？那我们就用回调对象吧。在这个回调对象中定义一个操纵JdbcTemplate中变量的方法，我们去实现这个方法，就把变化的东西集中到这里了。然后我们再传入这个回调对象到JdbcTemplate，从而完成了调用。这就是TemplateMethod不需要继承的另一种实现方式。 归类 特点 穷举 行为型模式 执行流程固定，但中间有些步骤有细微差别（运行时才确定）。可实现批量生产。 SpringORM数据模型 8、委派模式（Delegate）应用场景：不属于23种设计模式之一，是面向对象设计模式中常用的一种模式。这种模式的原理为类B和类A是两个互相没有任何关系的类，B具有和A一模一样的方法和属性；并且调用B中的方法，属性就是调用A中同名的方法和属性。B好像就是一个受A授权委托的中介。第三方的代码不需要知道A的存在，也不需要和A发生直接的联系，通过B就可以直接使用A的功能，这样既能够使用到A的各种功能，又能够很好的将A保护起来了，一举两得。 归类 特点 穷举 行为型模式 要和代理模式区分开来。持有被委托人的引用。不关心过程，只关心结果。 经理派发工作任务、Dispatcher 9、适配器模式（Adapter）SpringAOP模块对BeforeAdvice、AfterAdvice、ThrowsAdvice三种通知类型的支持实际上是借助适配器模式来实现的，这样的好处是使得框架允许用户向框架中加入自己想要支持的任何一种通知类型，上述三种通知类型是SpringAOP模块定义的，它们是AOP联盟定义的Advice的子类型。 归类 特点 穷举 结构型模式 注重兼容、转换。适配者与被适配这之间没有层级关系，也没有必然联系。满足has-a的关系。 编码解码、一拖三充电头、HDMI转VGA、Type-C转USB 10、装饰器模式（Decorator）应用场景：在我们的项目中遇到这样一个问题：我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。我们以往在Spring和Hibernate框架中总是配置一个数据源，因而SessionFactory的DataSource属性总是指向这个数据源并且恒定不变，所有DAO在使用SessionFactory的时候都是通过这个数据源访问数据库。但是现在，由于项目的需要，我们的DAO在访问SessionFactory的时候都不得不在多个数据源中不断切换，问题就出现了：如何让SessionFactory在执行数据持久化的时候，根据客户的需求能够动态切换不同的数据源？我们能不能在Spring的框架下通过少量修改得到解决？是否有什么设计模式可以利用呢？首先想到在Spring的ApplicationContext中配置所有的DataSource。这些DataSource可能是各种不同类型的，比如不同的数据库：Oracle、SQLServer、MySQL等，也可能是不同的数据源：比如Apache提供的org.apache.commons.dbcp.BasicDataSource、Spring提供的org.springframework.jndi.JndiObjectFactoryBean等。然后SessionFactory根据客户的每次请求，将DataSource属性设置成不同的数据源，以到达切换数据源的目的。Spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。基本上都是动态地给一个对象添加一些额外的职责。 归类 特点 穷举 结构型模式 1、注重覆盖、扩展。2、装饰器和被装饰器都实现同一个接口，主要目的是为了扩展之后依旧保留OOP关系（同宗同源）。3、满足is-a的关系。 IO流包装、数据源包装、简历包装 11、观察者模式（Observer）应用场景：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。Spring中Observer模式常用的地方是Listener的实现。如ApplicationListener。 归类 特点 穷举 行为型模式 一般由两个角色组成：发布者和订阅者（观察者）。观察者通常有一个回调，也可以没有。 监听器、日志收集、短信通知、邮件通知 12、各设计模式对比及编程思想总结 设计模式 一句话归纳 工厂模式（Factory） 只对结果负责，不要三无产品。 单例模式（Singleton） 保证独一无二。 适配器模式（Adapter） 需要一个转换头（兼容）。 装饰器模式（Decorator） 需要包装，但不改变本质(同宗同源)。 代理模式（Proxy） 办事要求人，所以找代理。 观察者模式（Observer） 完成时通知我。 策略模式（Strategy） 我行我素，达到目的就行。 模板模式（Template） 流程标准化，原料自己加。 委派模式（Delegate） 干活是你的（普通员工），功劳是我的（项目经理）。 原型模式（Prototype） 拔一根猴毛，吹出千万个。","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blog.shagle.cn/tags/设计模式/"}]},{"title":"设计模式六大原则","slug":"设计模式六大原则","date":"2019-01-07T03:22:59.000Z","updated":"2019-01-07T04:22:59.000Z","comments":true,"path":"2019/01/07/设计模式六大原则/","link":"","permalink":"http://blog.shagle.cn/2019/01/07/设计模式六大原则/","excerpt":"","text":"1. 设计模式6大原则1.1.类单一职责一个类只负责一项职责，不要存在多余一个职责导致类的变更。 比如：类A负责两个不同的职责，b,c职责。由于b职责需求发生变化而需要改变A类，原本运行正常的c职责出现故障。 what: 这个由字面意思就很好理解了，顾名思义，功能要单一。 准确的解释是：就一个类而言，应该仅有一个引起它变化的原因。 why： 我们在做编程的时候，很自然给一个类加各种各样的功能，这就意味着，无论任何需求要来，都需要改这个窗体类，这样维护麻烦，不能复用，缺乏灵活性。 1.2.里氏替换原则 1.子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 2.子类中可以增加自己特有的方法。 3.当子类的方法重载父类的方法时，方法的前置条件（即方法的形参）要比父类方法的输入参数更宽松。 4.当子类的方法实现父类的抽象方法时，方法的后置条件（即方法的返回值）要比父类更严格。 总之尽量不要重写父类已经实现的方法，可以用接口其它方法绕过去。 what： 白话：一个软件实体如果使用的是一个父类的话，那么一定适用于其他子类，而且它觉察不出父类对象和子类对象的区别。也就是说，在软件里面，把父类都替换成它的子类，程序的行为没有变化。简单来说：子类型必须能够替换掉它们的父类型。这就好像是继承时理解的概念 why： 只有当子类可以替换掉父类，软件单位的功能不受到影响时，父类才能真正被复用，而子类也能够在父类的基础上增加新的行为。 1.3.依赖倒置原则高层模块不应该依赖底层模块，都应该依赖抽象；抽象不应该依赖细节，细节应该依赖抽象。 总之：多用抽象的接口来描述要做的动作，降低实现这个动作的事务之间的耦合度。（各自拥有各自的接口，不要放在一起使用，降低耦合性） what： 高层模块不应该依赖于底层模块，两个都应该依赖抽象。 抽象不应该依赖细节，细节应该依赖于抽象。 说白了，就是针对接口编程，不要对实现编程。 why： 如果我们将高层模块依赖了低层模块，那么想再次利用高层模块时，就没有办法复用了，因为高层模块是与低层模块的访问数据库绑在一起的。如果都依赖与抽象，也就是接口或抽象类，那么只要接口是稳定的，更改任何一个模块都不会造成影响， 1.4.接口隔离原则客户端不应该依赖它不需要的接口；一个类对另一个类的依赖建立在最小的接口上。 总之就是一个接口尽量完功能的单一，不要让一个接口承担过多的责任。 what： 一个类对另外一个类的依赖应该建立在最小接口上。即建立单一接口，只建立需要的，剔除多余的。 why： 一个接口代表一个角色，不应当将不同的角色都交给一个接口。没有关系的接口合并在一起，形成一个臃肿的大接口，这是对角色和接口的污染。“不应该强迫客户依赖于它们不用的方法。 1.5.迪米特法则经查最早是在1987年由美国Northeastern University的Ian Holland提出。一个类尽量封装自己，除了对外提供public方法之外，其它的不对外泄露信息。至于自己的成员变量和参数打交道，不与其它打交道。 what： 迪米特法则根据字面难以推敲出什么意思，1987年秋天由美国Northeastern University的Ian Holland提出，被UML的创始者之一Booch等普及。后来，因为在经典著作《 The Pragmatic Programmer》而广为人知。 它又叫做最少知识原则。如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用，如果其中一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。 它首先强调的前提是：在类的结构设计上，每一个类都应该尽量降低成员的访问权限。也就是说，一个类包装好自己的private状态，不需要让别的类知道字段或行为就不要public。迪米特法则的核心思想是强调了类之间的松耦合。 why： 类之间的耦合越弱，越有利于复用，一个处在弱耦合的类被修改，不会对有关系的类造成波及。信息的隐藏促进了软件的复用。 1.6，开闭原则对扩展开放，修改关闭。 尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化。 what： 开放-封闭原则，对什么开放？对什么封闭呢？这个原则其实是有两个特征，一个是说“对于扩展是开放的(open for extention)“，另一个是说”对于更改是封闭的(colsed for modification)”。 why： 设计软件要容易维护又不容易出问题的最好的办法，就是多扩展，少修改。我们在做任何系统的时候，都不要指望一开始需求确定了，就永不再变，这是不科学也是不现实的想法。既然需求一定会变化，那么在设计软件时可以相对容易修改。不至于说，新需求一来，就推到整个程序。那么怎样设计才能面对需求的改变却可以保持相对稳定，从而使得系统可以在第一个版本以后不断推出新的版本呢？这就是开放-封闭原则带给我们的答案。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://blog.shagle.cn/categories/设计模式/"}],"tags":[{"name":"设计模式六大原则","slug":"设计模式六大原则","permalink":"http://blog.shagle.cn/tags/设计模式六大原则/"}]},{"title":"idea快捷键","slug":"idea快捷键","date":"2019-01-02T01:19:27.000Z","updated":"2019-01-11T01:29:52.000Z","comments":true,"path":"2019/01/02/idea快捷键/","link":"","permalink":"http://blog.shagle.cn/2019/01/02/idea快捷键/","excerpt":"","text":"1.Mac 键盘符号说明⌘ == Command⇧ == Shift⇪ == Caps Lock⌥ == Option⌃ == Control↩ == Return/Enter⌫ == Delete⌦ == 向前删除键（Fn+Delete）↑ == 上箭头↓ == 下箭头← == 左箭头→ == 右箭头⇞ == Page Up（Fn+↑）⇟ == Page Down（Fn+↓）Home == Fn + ←End == Fn + →⇥ == 右制表符（Tab键）⇤ == 左制表符（Shift+Tab）⎋ == Escape (Esc)⏏ == 电源开关键 2.idea 快捷键⌥⇧⌘U: 打开class的UML设计窗口⌃T：重构上下文列表窗口，如修改名字，修改方法签名，移动代码等⌃H: 获得一个有层级关系的子类关系列表,或者 通过顶部菜单：Navigate —–&gt; Type Hierarchy快速查看您最近对项目的更改⌥⇧C : 快速查看最近对项目的修改⇧⌘⏎: 使用⇧⌘⏎完成当前语句，如if，do-while，try-catch，return（或方法调用）到语法正确的构造中（例如添加花括号）。","categories":[{"name":"工具","slug":"工具","permalink":"http://blog.shagle.cn/categories/工具/"}],"tags":[{"name":"idea","slug":"idea","permalink":"http://blog.shagle.cn/tags/idea/"}]},{"title":"算法之位运算","slug":"算法之位运算","date":"2018-12-27T06:09:15.000Z","updated":"2018-12-27T06:23:02.000Z","comments":true,"path":"2018/12/27/算法之位运算/","link":"","permalink":"http://blog.shagle.cn/2018/12/27/算法之位运算/","excerpt":"","text":"1. 什么是位运算程序中的所有数在计算机内存中都是以二进制的形式储存的。位运算说穿了，就是直接对整数在内存中的二进制位进行操作。比如，and运算本来是一个逻辑运算符，但整数与整数之间也可以进行and运算。举个例子，6的二进制是110，11的二进制是1011，那么6 and 11的结果就是2，它是二进制对应位进行逻辑运算的结果（0表示False，1表示True，空位都当0处理）：1110 AND 1011 --&gt; 0010(b) --&gt; 2(d) 由于位运算直接对内存数据进行操作，不需要转成十进制，因此处理速度非常快。当然有人会说，这个快了有什么用，计算6 and 11没有什么实际意义啊。本文就将告诉你，位运算到底可以干什么，有些什么经典应用，以及如何用位运算优化你的程序。 2. 位运算基础基本的位操作符有与、或、异或、取反、左移、右移这6种，它们的运算规则如下所示: 符号 描述 运算规则 &amp; 与 两个位都为1时，结果才为1 丨 或 两个位都为0时，结果才为0 ^ 异或 两个位相同为0，相异为1 ~ 取反 0变1，1变0 &lt;&lt; 左移 各二进位全部左移若干位，高位丢弃，低位补0 &gt;&gt; 右移 各二进位全部右移若干位，对无符号数，高位补0，有符号数，各编译器处理方法不一样，有的补符号位（算术右移），有的补0（逻辑右移） 需要注意以下几点： 这6种操作符，只有~取反是单目操作符，其它5种都是双目操作符； 位操作只能用于整形数据，对float和double类型进行位操作会被编译器报错； 移位操作都是采取算术移位操作，算术移位是相对于逻辑移位，它们在左移操作中都一样，低位补0即可，但在右移中逻辑移位的高位补0而算术移位的高位是补符号位。如下面代码会输出-4和3；123a, b = -15, 15puts a &gt;&gt; 2puts b &gt;&gt; 2 因为15=0000 1111(二进制)，右移二位，最高位由符号位填充将得到0000 0011即3。-15 = 1111 0001(二进制)，右移二位，最高位由符号位填充将得到1111 1100即-4。 位操作符的运算优先级比较低，因为尽量使用括号来确保运算顺序，否则很可能会得到莫明其妙的结果。比如要得到像1，3，5，9这些2^i+1的数字。写成a = 1 &lt;&lt; i + 1是不对的，程序会先执行i + 1，再执行左移操作。应该写成a = (1 &lt;&lt; i) + 1; 另外位操作还有一些复合操作符，如&amp;=、|=、 ^=、&lt;&lt;=、&gt;&gt;=。3. 常用位操作小技巧下面对位操作的一些常见应用作个总结，有判断奇偶、交换两数、变换符号及求绝对值。这些小技巧应用易记，应当熟练掌握。3.1 判断奇偶只要根据最未位是0还是1来决定，为0就是偶数，为1就是奇数。因此可以用if ((a &amp; 1) == 0)代替if (a % 2 == 0)来判断a是不是偶数。 下面程序输出0到100之间的所有奇数。 3.2 交换两数123100.times do |i| puts i if i &amp; 1end 一般交换函数的写法是：1234567def swap(a, b) if a != b c = a a = b b = c endend 注：ruby中这么写简直就是蠢，a, b = b, a即可，这里方便举例。 可以用位操作来实现交换两数而不用第三方变量：1234567def swap(a, b) if a != b a ^= b b ^= a a ^= b endend 可以这样理解： a ^= b 即a = (a ^ b); b ^= a 即b = b ^ (a ^ b)，由于^运算满足交换律，b ^ (a ^ b)=b ^ b ^ a。由于一个数和自己异或的结果为0并且任何数与0异或都会不变的，所以此时b被赋上了a的值; a ^= b 就是a = a ^ b，由于前面二步可知a = (a ^ b)，b = a，所以a = a ^ b即a = (a ^ b) ^ a。故a会被赋上b的值。再来个实例说明下以加深印象。a = 13, b = 6:a的二进制为 13 = 8 + 4 + 1 = 1101(二进制)b的二进制为 6 = 4 + 2 = 110(二进制) a ^= b a = 1101 ^ 110 = 1011; b ^= a b = 110 ^ 1011 = 1101; 即b == 13 a ^= b a = 1011 ^ 1101 = 110; 即a == 6 3.3 变换符号变换符号就是正数变成负数，负数变成正数。如对于-11和11，可以通过下面的变换方法将-11变成11:1231111 0101(二进制)取反-&gt; 0000 1010(二进制) 加1-&gt; 0000 1011(二进制) 同样可以这样的将11变成-111230000 1011(二进制)取反-&gt; 1111 0100(二进制)加1-&gt; 1111 0101(二进制) 因此变换符号只需要取反后加1即可。完整代码如下：123def sign_reversal(n) return ~n + 1end 3.4 求绝对值位操作也可以用来求绝对值，对于负数可以通过对其取反后加1来得到正数。对-6可以这样：1231111 1010(二进制)取反-&gt;0000 0101(二进制)加1-&gt; 0000 0110(二进制) 来得到6。因此先移位来取符号位，i = a &gt;&gt; 31;要注意如果a为正数，i等于0，为负数，i等于-1。然后对i进行判断——如果i等于0，直接返回；否之，返回~a + 1。完整代码如下：1234def my_abs(n) i = n &gt;&gt; 31 return i == 0 ? n : (~n + 1)end 现在再分析下。对于任何数，与0异或都会保持不变，与-1即0xFFFFFFFF异或就相当于取反。因此，n与i异或后再减i（因为i为0或-1，所以减i即是要么加0要么加1）也可以得到绝对值。所以可以对上面代码优化下：1234def my_abs(n) i = a &gt;&gt; 31 return ((a ^ i) - i)end 注意这种方法没用任何判断表达式，而且有些笔面试题就要求这样做，因此建议读者记住该方法。 4. 两个位运算的实例4.1 Single Number4.1.1 原题一个数组中除了一个数字出现过一次外，其余的数字都出现了两次，找出那个只出现一次的数字。 注意点： 算法时间杂度要求为O(n) 空间复杂度为O(1)例子: 输入: nums = [1, 2, 3, 4, 3, 2, 1]输出: 4 4.1.2 解题思路非常常见的一道算法题，将所有数字进行异或操作即可。对于异或操作明确以下三点： 一个整数与自己异或的结果是0 一个整数与0异或的结果是自己 异或操作满足交换律，即a^b=b^a所以对所有数字进行异或操作后剩下的就是那个只出现一次的数字。 4.1.3 AC源码1234567def single_number(nums) res = 0 nums.each do |num| res ^= num end resend 4.2 Power Of Two4.2.1 原题这道题让我们判断一个数是否为2的次方数，而且要求时间和空间复杂度都为常数。 4.2.2 解题思路比较下x - 1和x的关系试试？以x=4为例。120100 ==&gt; 40011 ==&gt; 3 两个数进行按位与就为0了！如果不是2的整数幂则无上述关系，反证法可证之。 4.2.3 AC源码123def is_power_of_two(n) return (n &gt; 0 and not (n &amp; n-1))end","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.shagle.cn/categories/算法/"}],"tags":[{"name":"位运算","slug":"位运算","permalink":"http://blog.shagle.cn/tags/位运算/"}]},{"title":"算法之进制转换","slug":"算法之进制转换","date":"2018-12-27T05:34:32.000Z","updated":"2018-12-27T05:55:45.000Z","comments":true,"path":"2018/12/27/算法之进制转换/","link":"","permalink":"http://blog.shagle.cn/2018/12/27/算法之进制转换/","excerpt":"","text":"1. 十进制转换成二进制1.1 正整数转二进制要点：除二取余，倒序排列，高位补零。 方法：将正的十进制数除以二，得到的商再除以二，依次类推直至商为0或1时为止，然后在旁边标出各步的余数，最后倒着写出来，高位补零。 注：计算机内部表示数的字节单位是定长的，如8位，16位，或32位。所以，位数不够时，高位补零。 1.2 负整数转二进制方法：先将对应的正整数转换成二进制后，对二进制取反，然后对结果再加1。 1.3 小数转二进制方法：对小数点以后的数×2，取结果的整数部分，然后再用小数部分再×2，再取结果的整数部分……以此类推，直到小数部分为0或者位数足够为止。然后把取的整数部分按先后次序排列，就构成了二进制小数部分的序列。 注： 如果小数的整数部分有大于0的整数时，将整数转换成二进制，小数转换成二进制，然后加在一起。 2、二进制转换成十进制2.1 整数二进制转换为十进制方法：首先将二进制数补齐位数，首位如果是0就代表是正整数，如果首位是1则代表是负整数。 若首位是0的正整数，补齐位数以后，将二进制中的位数分别与对应的值相乘，然后相加得到的就为十进制。 若二进制补足位数后首位为1时，就需要先取反再换算。 2.2 小数二进制转换为十进制方法：将二进制中的位数分别与对应的值相乘，然后相加，得到的值即为换算后的十进制。 参考：如何从十进制转换为二进制 原文出自：https://blog.csdn.net/weixin_42061048/article/details/80140472","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.shagle.cn/categories/算法/"}],"tags":[{"name":"进制转换","slug":"进制转换","permalink":"http://blog.shagle.cn/tags/进制转换/"}]},{"title":"算法之红黑树","slug":"算法之红黑树","date":"2018-12-27T02:24:28.000Z","updated":"2018-12-27T04:04:05.000Z","comments":true,"path":"2018/12/27/算法之红黑树/","link":"","permalink":"http://blog.shagle.cn/2018/12/27/算法之红黑树/","excerpt":"","text":"1.红黑树简介红黑树是一种自平衡的二叉查找树，是一种高效的查找树。它是由 Rudolf Bayer 于1978年发明，在当时被称为对称二叉 B 树(symmetric binary B-trees)。后来，在1978年被 Leo J. Guibas 和 Robert Sedgewick 修改为如今的红黑树。红黑树具有良好的效率，它可在 O(logN) 时间内完成查找、增加、删除等操作。因此，红黑树在业界应用很广泛，比如 Java 中的 TreeMap，JDK 1.8 中的 HashMap、C++ STL 中的 map 均是基于红黑树结构实现的。考虑到红黑树是一种被广泛应用的数据结构，所以我们很有必要去弄懂它。 2.红黑树的性质学过二叉查找树的同学都知道，普通的二叉查找树在极端情况下可退化成链表，此时的增删查效率都会比较低下。为了避免这种情况，就出现了一些自平衡的查找树，比如 AVL，红黑树等。这些自平衡的查找树通过定义一些性质，将任意节点的左右子树高度差控制在规定范围内，以达到平衡状态。以红黑树为例，红黑树通过如下的性质定义实现自平衡： 节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点（简称黑高）。 有了上面的几个性质作为限制，即可避免二叉查找树退化成单链表的情况。但是，仅仅避免这种情况还不够，这里还要考虑某个节点到其每个叶子节点路径长度的问题。如果某些路径长度过长，那么，在对这些路径上的及诶单进行增删查操作时，效率也会大大降低。这个时候性质4和性质5用途就凸显了，有了这两个性质作为约束，即可保证任意节点到其每个叶子节点路径最长不会超过最短路径的2倍。原因如下： 当某条路径最短时，这条路径必然都是由黑色节点构成。当某条路径长度最长时，这条路径必然是由红色和黑色节点相间构成（性质4限定了不能出现两个连续的红色节点）。而性质5又限定了从任一节点到其每个叶子节点的所有路径必须包含相同数量的黑色节点。此时，在路径最长的情况下，路径上红色节点数量 = 黑色节点数量。该路径长度为两倍黑色节点数量，也就是最短路径长度的2倍。举例说明一下，请看下图： 上图画出了从根节点 M 出发的到其叶子节点的最长和最短路径。这里偷懒只画出了两条最长路径，实际上最长路径有4条，分别为： M -&gt; Q -&gt; O -&gt; N M -&gt; Q -&gt; O -&gt; p M -&gt; Q -&gt; Y -&gt; X M -&gt; Q -&gt; Y -&gt; Z 长度为4，最短路径为 M -&gt; E，长度为2。最长路径的长度正好为最短路径长度的2倍。 前面说了关于红黑树的一些性质，这里还需要补充一些其他方面的东西。在红黑树简介一节中说到红黑树被发明出来的时候并不叫红黑树，而是叫做对称二叉 B 树，从名字中可发现红黑树和 B 树（这里指的是2-3树）或许有一定的关联，事实也正是如此。如果对红黑树的性质稍加修改，就能让红黑树和B树形成一一对应的关系。关于红黑树和 B 树关系的细节这里不展开说明了，有兴趣的同学可以参考《算法》第4版，那本书上讲的很透彻。 3.红黑树操作红黑树的基本操作和其他树形结构一样，一般都包括查找、插入、删除等操作。前面说到，红黑树是一种自平衡的二叉查找树，既然是二叉查找树的一种，那么查找过程和二叉查找树一样，比较简单，这里不再赘述。相对于查找操作，红黑树的插入和删除操作就要复杂的多。尤其是删除操作，要处理的情况比较多，不过大家如果静下心来去看，会发现其实也没想的那么难。好了，废话就说到这，接下来步入正题吧。 3.1 旋转操作在分析插入和删除操作前，这里需要插个队，先说明一下旋转操作，这个操作在后续操作中都会用得到。旋转操作分为左旋和右旋，左旋是将某个节点旋转为其右孩子的左孩子，而右旋是节点旋转为其左孩子的右孩子。这话听起来有点绕，所以还是请看下图：上图包含了左旋和右旋的示意图，这里以右旋为例进行说明，右旋节点 M 的步骤如下： 将节点 M 的左孩子引用指向节点 E 的右孩子 将节点 E 的右孩子引用指向节点 M，完成旋转上面分析了右旋操作，左旋操作与此类似，大家有兴趣自己画图试试吧，这里不再赘述了。旋转操作本身并不复杂，这里先分析到这吧。 3.2 插入红黑树的插入过程和二叉查找树插入过程基本类似，不同的地方在于，红黑树插入新节点后，需要进行调整，以满足红黑树的性质。性质1规定红黑树节点的颜色要么是红色要么是黑色，那么在插入新节点时，这个节点应该是红色还是黑色呢？答案是红色，原因也不难理解。如果插入的节点是黑色，那么这个节点所在路径比其他路径多出一个黑色节点，这个调整起来会比较麻烦（参考红黑树的删除操作，就知道为啥多一个或少一个黑色节点时，调整起来这么麻烦了）。如果插入的节点是红色，此时所有路径上的黑色节点数量不变，仅可能会出现两个连续的红色节点的情况。这种情况下，通过变色和旋转进行调整即可，比之前的简单多了。 接下来，将分析插入红色节点后红黑树的情况。这里假设要插入的节点为 N，N 的父节点为 P，祖父节点为 G，叔叔节点为 U。插入红色节点后，会出现5种情况，分别如下： 3.2.1 情况一插入的新节点 N 是红黑树的根节点，这种情况下，我们把节点 N 的颜色由红色变为黑色，性质2（根是黑色）被满足。同时 N 被染成黑色后，红黑树所有路径上的黑色节点数量增加一个，性质5（从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点）仍然被满足。 3.2.2 情况二N 的父节点是黑色，这种情况下，性质4（每个红色节点必须有两个黑色的子节点）和性质5没有受到影响，不需要调整。 3.2.3 情况三N 的父节点是红色（节点 P 为红色，其父节点必然为黑色），叔叔节点 U 也是红色。由于 P 和 N 均为红色，所有性质4被打破，此时需要进行调整。这种情况下，先将 P 和 U 的颜色染成黑色，再将 G 的颜色染成红色。此时经过 G 的路径上的黑色节点数量不变，性质5仍然满足。但需要注意的是 G 被染成红色后，可能会和它的父节点形成连续的红色节点，此时需要递归向上调整。 3.2.4 情况四N 的父节点为红色，叔叔节点为黑色。节点 N 是 P 的右孩子，且节点 P 是 G 的左孩子。此时先对节点 P 进行左旋，调整 N 与 P 的位置。接下来按照情况五进行处理，以恢复性质4。 3.2.5 情况五N 的父节点为红色，叔叔节点为黑色。N 是 P 的左孩子，且节点 P 是 G 的左孩子。此时对 G 进行右旋，调整 P 和 G 的位置，并互换颜色。经过这样的调整后，性质4被恢复，同时也未破坏性质5。 3.2.6 插入总结上面五种情况中，情况一和情况二比较简单，情况三、四、五稍复杂。但如果细心观察，会发现这三种情况的区别在于叔叔节点的颜色，如果叔叔节点为红色，直接变色即可。如果叔叔节点为黑色，则需要选选择，再交换颜色。当把这三种情况的图画在一起就区别就比较容易观察了，如下图： 3.3 删除相较于插入操作，红黑树的删除操作则要更为复杂一些。删除操作首先要确定待删除节点有几个孩子，如果有两个孩子，不能直接删除该节点。而是要先找到该节点的前驱（该节点左子树中最大的节点）或者后继（该节点右子树中最小的节点），然后将前驱或者后继的值复制到要删除的节点中，最后再将前驱或后继删除。由于前驱和后继至多只有一个孩子节点，这样我们就把原来要删除的节点有两个孩子的问题转化为只有一个孩子节点的问题，问题被简化了一些。我们并不关心最终被删除的节点是否是我们开始想要删除的那个节点，只要节点里的值最终被删除就行了，至于树结构如何变化，这个并不重要。 红黑树删除操作的复杂度在于删除节点的颜色，当删除的节点是红色时，直接拿其孩子节点补空位即可。因为删除红色节点，性质5（从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点）仍能够被满足。当删除的节点是黑色时，那么所有经过该节点的路径上的黑节点数量少了一个，破坏了性质5。如果该节点的孩子为红色，直接拿孩子节点替换被删除的节点，并将孩子节点染成黑色，即可恢复性质5。但如果孩子节点为黑色，处理起来就要复杂的多。分为6种情况，下面会展开说明。 在展开说明之前，我们先做一些假设，方便说明。这里假设最终被删除的节点为X（至多只有一个孩子节点），其孩子节点为N，X的兄弟节点为S，S的左节点为SL，右节点为 SR。接下来讨论是建立在节点 X 被删除，节点 N 替换X的基础上进行的。这里说明把被删除的节点X特地拎出来说一下的原因是防止大家误以为节点N会被删除，不然后面就会看不明白。 3.3.1 情况一 N 是新的根。在这种情形下，我们就做完了。我们从所有路径去除了一个黑色节点，而新根是黑色的，所以性质都保持着。上面是维基百科中关于红黑树删除的情况一说明，由于没有配图，看的有点晕。经过思考，我觉得可能会是下面这种情形： 要删除的节点 X 是根节点，且左右孩子节点均为空节点，此时将节点 X 用空节点替换完成删除操作。 可能还有其他情形，大家如果知道，烦请告知。 3.3.2 情况二S 为红色，其他节点为黑色。这种情况下可以对 N 的父节点进行左旋操作，然后互换 P 与 S 颜色。但这并未结束，经过节点 P 和 N 的路径删除前有3个黑色节点（P -&gt; X -&gt; N），现在只剩两个了（P -&gt; N）。比未经过 N 的路径少一个黑色节点，性质5仍不满足，还需要继续调整。不过此时可以按照情况四、五、六进行调整。 3.3.2 情况三N 的父节点，兄弟节点 S 和 S 的孩子节点均为黑色。这种情况下可以简单的把 S 染成红色，所有经过 S 的路径比之前少了一个黑色节点，这样经过 N 的路径和经过 S 的路径黑色节点数量一致了。但经过 P 的路径比不经过 P 的路径少一个黑色节点，此时需要从情况一开始对 P 进行平衡处理。 3.3.4 情况四N 的父节点为红色，叔叔节点为黑色。节点 N 是 P 的右孩子，且节点 P 是 G 的左孩子。此时先对节点 P 进行左旋，调整 N 与 P 的位置。接下来按照情况五进行处理，以恢复性质4。 这里需要特别说明一下，上图中的节点 N 并非是新插入的节点。当 P 为红色时，P 有两个孩子节点，且孩子节点均为黑色，这样从 G 出发到各叶子节点路径上的黑色节点数量才能保持一致。既然 P 已经有两个孩子了，所以 N 不是新插入的节点。情况四是由以 N 为根节点的子树中插入了新节点，经过调整后，导致 N 被变为红色，进而导致了情况四的出现。考虑下面这种情况（PR 节点就是上图的 N 节点）： 3.3.5 情况五S 为黑色，S 的左孩子为红色，右孩子为黑色。N 的父节点颜色可红可黑，且 N 是 P 左孩子。这种情况下对 S 进行右旋操作，并互换 S 和 SL 的颜色。此时，所有路径上的黑色数量仍然相等，N 兄弟节点的由 S 变为了 SL，而 SL 的右孩子变为红色。接下来我们到情况六继续分析。 3.3.6 情况六S 为黑色，S 的右孩子为红色。N 的父节点颜色可红可黑，且 N 是其父节点左孩子。这种情况下，我们对 P 进行左旋操作，并互换 P 和 S 的颜色，并将 SR 变为黑色。因为 P 变为黑色，所以经过 N 的路径多了一个黑色节点，经过 N 的路径上的黑色节点与删除前的数量一致。对于不经过 N 的路径，则有以下两种情况： 该路径经过 N 新的兄弟节点 SL ，那它之前必然经过 S 和 P。而 S 和 P 现在只是交换颜色，对于经过 SL 的路径不影响。 该路径经过 N 新的叔叔节点 SR，那它之前必然经过 P、 S 和 SR，而现在它只经过 S 和 SR。在对 P 进行左旋，并与 S 换色后，经过 SR 的路径少了一个黑色节点，性质5被打破。另外，由于 S 的颜色可红可黑，如果 S 是红色的话，会与 SR 形成连续的红色节点，打破性质4（每个红色节点必须有两个黑色的子节点）。此时仅需将 SR 由红色变为黑色即可同时恢复性质4和性质5（从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。）。 3.3.7 删除总结红黑树删除的情况比较多，大家刚开始看的时候可能会比较晕。可能会产生这样的疑问，为啥红黑树会有这种删除情况，为啥又会有另一种情况，它们之间有什么联系和区别？和大家一样，我刚开始看的时候也有这样的困惑，直到我把所有情况对应的图形画在一起时，拨云见日，一切都明了了。此时天空中出现了4个字，原来如此、原来如此、原来如此。所以，请看图吧： 4.总结红黑树是一种重要的二叉树，应用广泛，但在很多数据结构相关的书本中出现的次数并不多。很多书中要么不说，要么就一笔带过，并不会进行详细的分析，这可能是因为红黑树比较复杂的缘故。我在学习红黑树的时候也找了很多资料，但总体感觉讲的都不太好。尤其是在我学习删除操作的时候，很多资料是实在人看不下去，看的我很痛苦。直到我看到维基百科上关于红黑树的分析时，很是欣喜。这篇文章分析的很有条理，言简意赅，比很多资料好了太多。本文对红黑树的分析也主要参考了维基百科中的红黑树分析，并对维基百科中容易让人产生疑问和误解的地方进行了说明。同时维基百科中文版红黑树文中的图片较为模糊，这里我重新进行了绘制。需要说明的是，维基百科中文版无法打开了，文中关于维基百科的链接都是英文版的。另外在给大家推荐一个数据结构可视化的网站，里面包含常见数据结构可视化过程，地址为：t.cn/RZFgryr。 另外，由于红黑树本身比较复杂，实现也较为复杂。在写这篇文章之前，我曾尝试过用 Java 语言实现红黑树的增删操作，最终只写出了新增节点操作，删除没做出来。而且自己写的新增逻辑实在太繁琐，写的不好看，没法拿出来 show。所以最后把 Java 中的 TreeMap 增删相关源码拷出来，按照自己的需求把源码修改了一下，也勉强算是实现了红黑树吧。代码放到了 github 上，传送门 -&gt; RBTree.java。 最后，如果你也在学习红黑树，希望这篇文章能够帮助到你。另外，由于红黑树本身比较复杂，加之本人水平有限，难免会出一些错误。如果有错，还望大家指出来，我们共同讨论。 参考 《算法》第四版 红黑树 – 维基百科 原文出自：https://www.tianxiaobo.com/2018/01/11/%E7%BA%A2%E9%BB%91%E6%A0%91%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.shagle.cn/categories/算法/"}],"tags":[]},{"title":"算法之时间复杂度 O(log n)","slug":"算法之时间复杂度","date":"2018-12-27T02:10:54.000Z","updated":"2018-12-27T02:21:25.000Z","comments":true,"path":"2018/12/27/算法之时间复杂度/","link":"","permalink":"http://blog.shagle.cn/2018/12/27/算法之时间复杂度/","excerpt":"","text":"预先知道算法的复杂度是一回事，了解其后的原理是另一件事情。 不管你是计算机科班出身还是想有效解决最优化问题，如果想要用自己的知识解决实际问题，你都必须理解时间复杂度。 先从简单直观的 O(1) 和 O(n) 复杂度说起。O(1) 表示一次操作即可直接取得目标元素（比如字典或哈希表），O(n) 意味着先要检查 n 个元素来搜索目标，但是 O(log n) 是什么意思呢？ 你第一次听说 O(log n) 时间复杂度可能是在学二分搜索算法的时候。二分搜索一定有某种行为使其时间复杂度为 log n。我们来看看是二分搜索是如何实现的。 因为在最好情况下二分搜索的时间复杂度是 O(1)，最坏情况（平均情况）下 O(log n)，我们直接来看最坏情况下的例子。已知有 16 个元素的有序数组。 举个最坏情况的例子，比如我们要找的是数字 13。 十六个元素的有序数组 选中间的元素作为中心点（长度的一半） 13 小于中心点，所以不用考虑数组的后一半 重复这个过程，每次都寻找子数组的中间元素 每次和中间元素比较都会使搜索范围减半。 所以为了从 16 个元素中找到目标元素，我们需要把数组平均分割 4 次，也就是说， 归纳一下 分子和分母代入指数 等式两边同时乘以 2^k 最终结果 现在来看看「对数」的定义： 为使某数（底数）等于一给定数而必须取的乘幂的幂指数。 也就是说可以写成这种形式 对数形式 所以 log n 的确是有意义的，不是吗？没有其他什么可以表示这种行为。 就这样吧，我希望我讲得这些你都搞懂了。在从事计算机科学相关的工作时，了解这类知识总是有用的（而且很有趣）。说不定就因为你知道算法的原理，你成了小组里能找出问题的最优解的人呢，谁知道呢。祝好运！","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.shagle.cn/categories/算法/"}],"tags":[{"name":"O(log n)","slug":"O-log-n","permalink":"http://blog.shagle.cn/tags/O-log-n/"},{"name":"O(1)","slug":"O-1","permalink":"http://blog.shagle.cn/tags/O-1/"},{"name":"O(n)","slug":"O-n","permalink":"http://blog.shagle.cn/tags/O-n/"}]},{"title":"Java技术之Java线程池的使用","slug":"Java技术之Java线程池的使用","date":"2018-12-26T02:00:00.000Z","updated":"2018-12-26T07:41:46.000Z","comments":true,"path":"2018/12/26/Java技术之Java线程池的使用/","link":"","permalink":"http://blog.shagle.cn/2018/12/26/Java技术之Java线程池的使用/","excerpt":"","text":"1. 前言在Java中，我们可以利用多线程来最大化地压榨CPU多核计算的能力。但是，线程本身是把双刃剑，我们需要知道它的利弊，才能在实际系统中游刃有余地运用。 在进入主题之前，我们先了解一下线程池的基本概念。 线程池，本质上是一种对象池，用于管理线程资源。在任务执行前，需要从线程池中拿出线程来执行。在任务执行完成之后，需要把线程放回线程池。通过线程的这种反复利用机制，可以有效地避免直接创建线程所带来的坏处。 我们先来看看线程池带来了哪些好处。 降低资源的消耗。线程本身是一种资源，创建和销毁线程会有CPU开销；创建的线程也会占用一定的内存。 提高任务执行的响应速度。任务执行时，可以不必等到线程创建完之后再执行。 提高线程的可管理性。线程不能无限制地创建，需要进行统一的分配、调优和监控。 接下来，我们看看不使用线程池有哪些坏处。 频繁的线程创建和销毁会占用更多的CPU和内存 频繁的线程创建和销毁会对GC产生比较大的压力 线程太多，线程切换带来的开销将不可忽视 线程太少，多核CPU得不到充分利用，是一种浪费 因此，我们有必要对线程池进行比较完整地说明，以便能对线程池进行正确地治理。 2. 线程池实现原理 通过上图，我们看到了线程池的主要处理流程。我们的关注点在于，任务提交之后是怎么执行的。大致如下： 判断核心线程池是否已满，如果不是，则创建线程执行任务 如果核心线程池满了，判断队列是否满了，如果队列没满，将任务放在队列中 如果队列满了，则判断线程池是否已满，如果没满，创建线程执行任务 如果线程池也满了，则按照拒绝策略对任务进行处理 在jdk里面，我们可以将处理流程描述得更清楚一点。来看看ThreadPoolExecutor的处理流程。 我们将概念做一下映射。 corePool -&gt; 核心线程池 maximumPool -&gt; 线程池 BlockQueue -&gt; 队列 RejectedExecutionHandler -&gt; 拒绝策略 3. 入门级例子为了更直观地理解线程池，我们通过一个例子来宏观地了解一下线程池用法。 123456789101112131415public class ThreadPoolTest &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 10; i++) &#123; executor.submit(() -&gt; &#123; System.out.println(\"thread id is: \" + Thread.currentThread().getId()); try &#123; Thread.sleep(1000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; &#125;&#125; 在这个例子中，我们首先创建了一个固定长度为5的线程池。然后使用循环的方式往线程池中提交了10个任务，每个任务休眠1秒。在任务休眠之前，将任务所在的线程id进行打印输出。 所以，理论上只会打印5个不同的线程id，且每个线程id会被打印2次。是不是这样的呢？检验真理最好的方式就是运行一下。我们看看执行结果如何。 4. ExecutorsExecutors是一个线程池工厂，提供了很多的工厂方法，我们来看看它大概能创建哪些线程池。 12345678910// 创建单一线程的线程池public static ExecutorService newSingleThreadExecutor();// 创建固定数量的线程池public static ExecutorService newFixedThreadPool(int nThreads);// 创建带缓存的线程池public static ExecutorService newCachedThreadPool();// 创建定时调度的线程池public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize);// 创建流式（fork-join）线程池public static ExecutorService newWorkStealingPool(); 4.1. 创建单一线程的线程池故名思意，这个线程池只有一个线程。若多个任务被提交到此线程池，那么会被缓存到队列（队列长度为Integer.MAX_VALUE）。当线程空闲的时候，按照FIFO的方式进行处理。 4.2. 创建固定数量的线程池和创建单一线程的线程池类似，只是这儿可以并行处理任务的线程数更多一些罢了。若多个任务被提交到此线程池，会有下面的处理过程。 如果线程的数量未达到指定数量，则创建线程来执行任务 如果线程池的数量达到了指定数量，并且有线程是空闲的，则取出空闲线程执行任务 如果没有线程是空闲的，则将任务缓存到队列（队列长度为Integer.MAX_VALUE）。当线程空闲的时候，按照FIFO的方式进行处理 4.3. 创建带缓存的线程池这种方式创建的线程池，核心线程池的长度为0，线程池最大长度为Integer.MAX_VALUE。由于本身使用SynchronousQueue作为等待队列的缘故，导致往队列里面每插入一个元素，必须等待另一个线程从这个队列删除一个元素。 4.4. 创建定时调度的线程池和上面3个工厂方法返回的线程池类型有所不同，它返回的是ScheduledThreadPoolExecutor类型的线程池。平时我们实现定时调度功能的时候，可能更多的是使用第三方类库，比如：quartz等。但是对于更底层的功能，我们仍然需要了解。 我们写一个例子来看看如何使用。 1234567891011121314151617181920212223242526272829public class ThreadPoolTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService executor = Executors.newScheduledThreadPool(2); // 定时调度，每个调度任务会至少等待`period`的时间， // 如果任务执行的时间超过`period`，则等待的时间为任务执行的时间 executor.scheduleAtFixedRate(() -&gt; &#123; try &#123; Thread.sleep(10000); System.out.println(System.currentTimeMillis() / 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;, 0, 2, TimeUnit.SECONDS); // 定时调度，第二个任务执行的时间 = 第一个任务执行时间 + `delay` executor.scheduleWithFixedDelay(() -&gt; &#123; try &#123; Thread.sleep(5000); System.out.println(System.currentTimeMillis() / 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;, 0, 2, TimeUnit.SECONDS); // 定时调度，延迟`delay`后执行，且只执行一次 executor.schedule(() -&gt; System.out.println(\"5 秒之后执行 schedule\"), 5, TimeUnit.SECONDS); &#125;&#125; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)，定时调度，每个调度任务会至少等待period的时间，如果任务执行的时间超过period，则等待的时间为任务执行的时间 scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)，定时调度，第二个任务执行的时间 = 第一个任务执行时间 + delay schedule(Runnable command, long delay, TimeUnit unit)，定时调度，延迟delay后执行，且只执行一次 5.手动创建线程池理论上，我们可以通过Executors来创建线程池，这种方式非常简单。但正是因为简单，所以限制了线程池的功能。比如：无长度限制的队列，可能因为任务堆积导致OOM，这是非常严重的bug，应尽可能地避免。怎么避免？归根结底，还是需要我们通过更底层的方式来创建线程池。 抛开定时调度的线程池不管，我们看看ThreadPoolExecutor。它提供了好几个构造方法，但是最底层的构造方法却只有一个。那么，我们就从这个构造方法着手分析。 1234567891011121314151617181920/** * @param corePoolSize 线程池基本大小，核心线程池大小，活动线程小于corePoolSize则直接创建，大于等于则先加到workQueue中， * 队列满了才创建新的线程。当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程， * 等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads()方法， * 线程池会提前创建并启动所有基本线程。 * @param maximumPoolSize 最大线程数，超过就reject；线程池允许创建的最大线程数。如果队列满了， * 并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务 * @param keepAliveTime * 线程池的工作线程空闲后，保持存活的时间。所以，如果任务很多，并且每个任务执行的时间比较短，可以调大时间，提高线程的利用率 * @param unit 线程活动保持时间的单位）：可选的单位有天（DAYS）、小时（HOURS）、分钟（MINUTES）、 * 毫秒（MILLISECONDS）、微秒（MICROSECONDS，千分之一毫秒）和纳秒（NANOSECONDS，千分之一微秒） * @param workQueue 工作队列，线程池中的工作线程都是从这个工作队列源源不断的获取任务进行执行 */public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler); 这个构造方法有7个参数，我们逐一来进行分析。 corePoolSize，线程池中的核心线程数 maximumPoolSize，线程池中的最大线程数 keepAliveTime，空闲时间，当线程池数量超过核心线程数时，多余的空闲线程存活的时间，即：这些线程多久被销毁。 unit，空闲时间的单位，可以是毫秒、秒、分钟、小时和天，等等 workQueue，等待队列，线程池中的线程数超过核心线程数时，任务将放在等待队列，它是一个BlockingQueue类型的对象 ArrayBlockingQueue，基于数组结构的有界队列，此队列按FIFO原则对任务进行排序。如果队列满了还有任务进来，则调用拒绝策略。 LinkedBlockingQueue，基于链表结构的无界队列，此队列按FIFO原则对任务进行排序。因为它是无界的，根本不会满，所以采用此队列后线程池将忽略拒绝策略（handler）参数；同时还将忽略最大线程数（maximumPoolSize）等参数。ps:但是查看jdk8源码发现，该策略也是有边界的，边界最大值为：Integer.MAX_VALUE SynchronousQueue，不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作将一直处于阻塞状态。该队列也是Executors.newCachedThreadPool()的默认队列 PriorityBlockingQueue，带优先级的无界阻塞队列通常情况下，我们需要指定阻塞队列的上界（比如1024）。另外，如果执行的任务很多，我们可能需要将任务进行分类，然后将不同分类的任务放到不同的线程池中执行。 threadFactory，线程工厂，我们可以使用它来创建一个线程 handler，拒绝策略，所谓拒绝策略，就是当线程池满了、队列也满了的时候，我们对任务采取的措施。或者丢弃、或者执行、或者其他… CallerRunsPolicy // 在调用者线程执行 AbortPolicy // 直接抛出RejectedExecutionException异常 DiscardPolicy // 任务直接丢弃，不做任何处理 DiscardOldestPolicy // 丢弃队列里最旧的那个任务，再尝试执行当前任务这四种策略各有优劣，比较常用的是DiscardPolicy，但是这种策略有一个弊端就是任务执行的轨迹不会被记录下来。所以，我们往往需要实现自定义的拒绝策略， 通过实现RejectedExecutionHandler接口的方式。 这些参数里面，基本类型的参数都比较简单，我们不做进一步的分析。我们更关心的是workQueue、threadFactory和handler，接下来我们将进一步分析。 5.1. 线程工厂-threadFactoryThreadFactory是一个接口，只有一个方法。既然是线程工厂，那么我们就可以用它生产一个线程对象。来看看这个接口的定义。 123456789101112public interface ThreadFactory &#123; /** * Constructs a new &#123;@code Thread&#125;. Implementations may also initialize * priority, name, daemon status, &#123;@code ThreadGroup&#125;, etc. * * @param r a runnable to be executed by new thread instance * @return constructed thread, or &#123;@code null&#125; if the request to * create a thread is rejected */ Thread newThread(Runnable r);&#125; Executors的实现使用了默认的线程工厂-DefaultThreadFactory。它的实现主要用于创建一个线程，线程的名字为pool-{poolNum}-thread-{threadNum}。 1234567891011121314151617181920212223242526static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; &#125; public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125;&#125; 很多时候，我们需要自定义线程名字。我们只需要自己实现ThreadFactory，用于创建特定场景的线程即可。 6.提交任务的几种方式往线程池中提交任务，主要有两种方法，execute()和submit()。 6.1 executeexecute()用于提交不需要返回结果的任务，我们看一个例子。 1234public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(2); executor.execute(() -&gt; System.out.println(\"hello\"));&#125; 6.2 execute 关键方法源码分析12345678910111213141516171819202122232425262728293031323334353637public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /** * 1. 判断当前的线程数是否小于corePoolSize; 如果是，使用入参任务通过addWord方法创建一个新的线程， * 如果能完成新线程创建exexute方法结束，成功提交任务 * 2. 在第一步没有完成任务提交；状态为运行并且能否成功加入任务到工作队列后，再进行一次check，如果状态 * 在任务加入队列后变为了非运行（有可能是在执行到这里线程池shutdown了），非运行状态下当然是需要 * reject；然后再判断当前线程数是否为0（有可能这个时候线程数变为了0），如是，新增一个线程； * 3. 如果不能加入任务到工作队列，将尝试使用任务新增一个线程，如果失败，则是线程池已经shutdown或者线程池 * 已经达到饱和状态，所以reject这个他任务 */ int c = ctl.get(); // 工作线程数小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) &#123; // 直接启动新线程，true表示会再次检查workerCount是否小于corePoolSize if (addWorker(command, true)) return; c = ctl.get(); &#125; // 如果工作线程数大于等于核心线程数 // 线程的的状态未RUNNING并且队列not full if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 再次检查线程的运行状态，如果不是RUNNING直接从队列中移除 int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) // 移除成功，拒绝该非运行的任务 reject(command); else if (workerCountOf(recheck) == 0) // 防止了SHUTDOWN状态下没有活动线程了，但是队列里还有任务没执行这种特殊情况。 // 添加一个null任务是因为SHUTDOWN状态下，线程池不再接受新任务 addWorker(null, false); &#125; else if (!addWorker(command, false)) // 如果队列满了或者是非运行的任务都拒绝执行 reject(command);&#125; 下面我们继续看看addWorker是如何实现的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091private boolean addWorker(Runnable firstTask, boolean core) &#123; // java标签 retry: // 死循环 for (;;) &#123; int c = ctl.get(); // 获取当前线程状态 int rs = runStateOf(c); // Check if queue empty only if necessary. // 这个逻辑判断有点绕可以改成 // rs &gt;= shutdown &amp;&amp; (rs != shutdown || firstTask != null || workQueue.isEmpty()) // 逻辑判断成立可以分为以下几种情况均不接受新任务 // 1、rs &gt; shutdown:--不接受新任务 // 2、rs &gt;= shutdown &amp;&amp; firstTask != null:--不接受新任务 // 3、rs &gt;= shutdown &amp;&amp; workQueue.isEmppty:--不接受新任务 // 逻辑判断不成立 // 1、rs==shutdown&amp;&amp;firstTask != null:此时不接受新任务，但是仍会执行队列中的任务 // 2、rs==shotdown&amp;&amp;firstTask == null:会执行addWork(null,false) // 防止了SHUTDOWN状态下没有活动线程了，但是队列里还有任务没执行这种特殊情况。 // 添加一个null任务是因为SHUTDOWN状态下，线程池不再接受新任务 if (rs &gt;= SHUTDOWN &amp;&amp;! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp;! workQueue.isEmpty())) return false; // 死循环 // 如果线程池状态为RUNNING并且队列中还有需要执行的任务 for (;;) &#123; // 获取线程池中线程数量 int wc = workerCountOf(c); // 如果超出容量或者最大线程池容量不在接受新任务 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 线程安全增加工作线程数 if (compareAndIncrementWorkerCount(c)) // 跳出retry break retry; c = ctl.get(); // Re-read ctl // 如果线程池状态发生变化，重新循环 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; // 走到这里说明工作线程数增加成功 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; final ReentrantLock mainLock = this.mainLock; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; // 加锁 mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); int rs = runStateOf(c); // RUNNING状态 || SHUTDONW状态下清理队列中剩余的任务 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; // 检查线程状态 if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 将新启动的线程添加到线程池中 workers.add(w); // 更新线程池线程数且不超过最大值 int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // 启动新添加的线程，这个线程首先执行firstTask，然后不停的从队列中取任务执行 if (workerAdded) &#123; //执行ThreadPoolExecutor的runWoker方法 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; // 线程启动失败，则从wokers中移除w并递减wokerCount if (! workerStarted) // 递减wokerCount会触发tryTerminate方法 addWorkerFailed(w); &#125; return workerStarted;&#125; addWorker之后是runWorker,第一次启动会执行初始化传进来的任务firstTask；然后会从workQueue中取任务执行，如果队列为空则等待keepAliveTime这么长时间123456789101112131415161718192021222324252627282930313233343536373839404142434445final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; // 允许中断 w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 如果getTask返回null那么getTask中会将workerCount递减，如果异常了这个递减操作会在processWorkerExit中处理 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 我们看下getTask是如何执行的 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? // 死循环 retry: for (;;) &#123; // 获取线程池状态 int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 1.rs &gt; SHUTDOWN 所以rs至少等于STOP,这时不再处理队列中的任务 // 2.rs = SHUTDOWN 所以rs&gt;=STOP肯定不成立，这时还需要处理队列中的任务除非队列为空 // 这两种情况都会返回null让runWoker退出while循环也就是当前线程结束了，所以必须要decrement if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; // 递减workerCount值 decrementWorkerCount(); return null; &#125; // 标记从队列中取任务时是否设置超时时间 boolean timed; // Are workers subject to culling? // 1.RUNING状态 // 2.SHUTDOWN状态，但队列中还有任务需要执行 for (;;) &#123; int wc = workerCountOf(c); // 1.core thread允许被超时，那么超过corePoolSize的的线程必定有超时 // 2.allowCoreThreadTimeOut == false &amp;&amp; wc &gt; // corePoolSize时，一般都是这种情况，core thread即使空闲也不会被回收，只要超过的线程才会 timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 从addWorker可以看到一般wc不会大于maximumPoolSize，所以更关心后面半句的情形： // 1. timedOut == false 第一次执行循环， 从队列中取出任务不为null方法返回 或者 // poll出异常了重试 // 2.timeOut == true &amp;&amp; timed == // false:看后面的代码workerQueue.poll超时时timeOut才为true， // 并且timed要为false，这两个条件相悖不可能同时成立（既然有超时那么timed肯定为true） // 所以超时不会继续执行而是return null结束线程。 if (wc &lt;= maximumPoolSize &amp;&amp; !(timedOut &amp;&amp; timed)) break; // workerCount递减，结束当前thread if (compareAndDecrementWorkerCount(c)) return null; c = ctl.get(); // Re-read ctl // 需要重新检查线程池状态，因为上述操作过程中线程池可能被SHUTDOWN if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; try &#123; // 1.以指定的超时时间从队列中取任务 // 2.core thread没有超时 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true;// 超时 &#125; catch (InterruptedException retry) &#123; timedOut = false;// 线程被中断重试 &#125; &#125;&#125; 下面我们看下processWorkerExit是如何工作的 1234567891011121314151617181920212223242526272829303132333435private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 正常的话再runWorker的getTask方法workerCount已经被减一了 if (completedAbruptly) decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 累加线程的completedTasks completedTaskCount += w.completedTasks; // 从线程池中移除超时或者出现异常的线程 workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 尝试停止线程池 tryTerminate(); int c = ctl.get(); // runState为RUNNING或SHUTDOWN if (runStateLessThan(c, STOP)) &#123; // 线程不是异常结束 if (!completedAbruptly) &#123; // 线程池最小空闲数，允许core thread超时就是0，否则就是corePoolSize int min = allowCoreThreadTimeOut ? 0 : corePoolSize; // 如果min == 0但是队列不为空要保证有1个线程来执行队列中的任务 if (min == 0 &amp;&amp; !workQueue.isEmpty()) min = 1; // 线程池还不为空那就不用担心了 if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; // 1.线程异常退出 // 2.线程池为空，但是队列中还有任务没执行，看addWoker方法对这种情况的处理 addWorker(null, false); &#125;&#125; tryTerminate : processWorkerExit方法中会尝试调用tryTerminate来终止线程池。这个方法在任何可能导致线程池终止的动作后执行：比如减少wokerCount或SHUTDOWN状态下从队列中移除任务。 123456789101112131415161718192021222324252627282930313233343536373839404142final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); // 以下状态直接返回： // 1.线程池还处于RUNNING状态 // 2.SHUTDOWN状态但是任务队列非空 // 3.runState &gt;= TIDYING 线程池已经停止了或在停止了 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; !workQueue.isEmpty())) return; // 只能是以下情形会继续下面的逻辑：结束线程池。 // 1.SHUTDOWN状态，这时不再接受新任务而且任务队列也空了 // 2.STOP状态，当调用了shutdownNow方法 // workerCount不为0则还不能停止线程池,而且这时线程都处于空闲等待的状态 // 需要中断让线程“醒”过来，醒过来的线程才能继续处理shutdown的信号。 if (workerCountOf(c) != 0) &#123; // Eligible to terminate // runWoker方法中w.unlock就是为了可以被中断,getTask方法也处理了中断。 // ONLY_ONE:这里只需要中断1个线程去处理shutdown信号就可以了。 interruptIdleWorkers(ONLY_ONE); return; &#125; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 进入TIDYING状态 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; // 子类重载：一些资源清理工作 terminated(); &#125; finally &#123; // TERMINATED状态 ctl.set(ctlOf(TERMINATED, 0)); // 继续awaitTermination termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125; shutdown这个方法会将runState置为SHUTDOWN，会终止所有空闲的线程。shutdownNow方法将runState置为STOP。和shutdown方法的区别，这个方法会终止所有的线程。主要区别在于shutdown调用的是interruptIdleWorkers这个方法，而shutdownNow实际调用的是Worker类的interruptIfStarted方法：他们的实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // 线程池状态设为SHUTDOWN，如果已经至少是这个状态那么则直接返回 advanceRunState(SHUTDOWN); // 注意这里是中断所有空闲的线程：runWorker中等待的线程被中断 → 进入processWorkerExit → // tryTerminate方法中会保证队列中剩余的任务得到执行。 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();&#125;public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); // STOP状态：不再接受新任务且不再执行队列中的任务。 advanceRunState(STOP); // 中断所有线程 interruptWorkers(); // 返回队列中还没有被执行的任务。 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks;&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; // w.tryLock能获取到锁，说明该线程没有在运行，因为runWorker中执行任务会先lock， // 因此保证了中断的肯定是空闲的线程。 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125;void interruptIfStarted() &#123; Thread t; // 初始化时state == -1 if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125;&#125; 6.2 submitsubmit()用于提交一个需要返回果的任务。该方法返回一个Future对象，通过调用这个对象的get()方法，我们就能获得返回结果。get()方法会一直阻塞，直到返回结果返回。另外，我们也可以使用它的重载方法get(long timeout, TimeUnit unit)，这个方法也会阻塞，但是在超时时间内仍然没有返回结果时，将抛出异常TimeoutException。 12345678public static void main(String[] args) throws Exception &#123; ExecutorService executor = Executors.newFixedThreadPool(2); Future&lt;Long&gt; future = executor.submit(() -&gt; &#123; System.out.println(\"task is executed\"); return System.currentTimeMillis(); &#125;); System.out.println(\"task execute time is: \" + future.get());&#125; 7.关闭线程池在线程池使用完成之后，我们需要对线程池中的资源进行释放操作，这就涉及到关闭功能。我们可以调用线程池对象的shutdown()和shutdownNow()方法来关闭线程池。 这两个方法都是关闭操作，又有什么不同呢？ shutdown()会将线程池状态置为SHUTDOWN，不再接受新的任务，同时会等待线程池中已有的任务执行完成再结束。 shutdownNow()会将线程池状态置为SHUTDOWN，对所有线程执行interrupt()操作，清空队列，并将队列中的任务返回回来。 另外，关闭线程池涉及到两个返回boolean的方法，isShutdown()和isTerminated，分别表示是否关闭和是否终止。 8.如何正确配置线程池的参数前面我们讲到了手动创建线程池涉及到的几个参数，那么我们要如何设置这些参数才算是正确的应用呢？实际上，需要根据任务的特性来分析。 任务的性质：CPU密集型、IO密集型和混杂型 任务的优先级：高中低 任务执行的时间：长中短 任务的依赖性：是否依赖数据库或者其他系统资源 不同的性质的任务，我们采取的配置将有所不同。在《Java并发编程实践》中有相应的计算公式。 通常来说，如果任务属于CPU密集型，那么我们可以将线程池数量设置成CPU的个数，以减少线程切换带来的开销。如果任务属于IO密集型，我们可以将线程池数量设置得更多一些，比如CPU个数*2。 PS：我们可以通过Runtime.getRuntime().availableProcessors()来获取CPU的个数。 9.线程池监控如果系统中大量用到了线程池，那么我们有必要对线程池进行监控。利用监控，我们能在问题出现前提前感知到，也可以根据监控信息来定位可能出现的问题。 那么我们可以监控哪些信息？又有哪些方法可用于我们的扩展支持呢？ 首先，ThreadPoolExecutor自带了一些方法。 long getTaskCount()，获取已经执行或正在执行的任务数 long getCompletedTaskCount()，获取已经执行的任务数 int getLargestPoolSize()，获取线程池曾经创建过的最大线程数，根据这个参数，我们可以知道线程池是否满过 int getPoolSize()，获取线程池线程数 int getActiveCount()，获取活跃线程数（正在执行任务的线程数） 其次，ThreadPoolExecutor留给我们自行处理的方法有3个，它在ThreadPoolExecutor中为空实现（也就是什么都不做）。 protected void beforeExecute(Thread t, Runnable r) // 任务执行前被调用 protected void afterExecute(Runnable r, Throwable t) // 任务执行后被调用 protected void terminated() // 线程池结束后被调用 针对这3个方法，我们写一个例子。 123456789101112131415161718public class ThreadPoolTest &#123; public static void main(String[] args) &#123; ExecutorService executor = new ThreadPoolExecutor(1, 1, 1, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1)) &#123; @Override protected void beforeExecute(Thread t, Runnable r) &#123; System.out.println(\"beforeExecute is called\"); &#125; @Override protected void afterExecute(Runnable r, Throwable t) &#123; System.out.println(\"afterExecute is called\"); &#125; @Override protected void terminated() &#123; System.out.println(\"terminated is called\"); &#125; &#125;; executor.submit(() -&gt; System.out.println(\"this is a task\")); executor.shutdown(); &#125;&#125; 输出结果如下： 1234beforeExecute is calledthis is a taskafterExecute is calledterminated is called 10.一个特殊的问题任何代码在使用的时候都可能遇到问题，线程池也不例外。楼主在现实的系统中就遇到过很奇葩的问题。我们来看一个例子。 12345678910111213141516171819202122public class ThreadPoolTest &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 5; i++) &#123; executor.submit(new DivTask(100, i)); &#125; &#125; static class DivTask implements Runnable &#123; int a, b; public DivTask(int a, int b) &#123; this.a = a; this.b = b; &#125; @Override public void run() &#123; double result = a / b; System.out.println(result); &#125; &#125;&#125; 该代码执行的结果如下。 我们循环了5次，理论上应该有5个结果被输出。可是最终的执行结果却很让人很意外–只有4次输出。我们进一步分析发现，当第一次循环，除数为0时，理论上应该抛出异常才对，但是这儿却没有，异常被莫名其妙地吞掉了！ 这又是为什么呢？ 我们进一步看看submit()方法，这个方法是一个非阻塞方法，有一个返回对象，返回的是Future对象。那么我们就猜测，会不会是因为没有对Future对象做处理导致的。 我们将代码微调一下，重新运行，异常信息终于打印出来了。 12345678for (int i = 0; i &lt; 5; i++) &#123; Future future= executor.submit(new DivTask(100, i)); try &#123; future.get(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; PS：在使用submit()的时候一定要注意它的返回对象Future，为了避免任务执行异常被吞掉的问题，我们需要调用Future.get()方法。另外，使用execute()将不会出现这种问题。 11.总结通过这篇文章，我们已经对Java线程池有了一个比较全面和深入的理解。根据前人的经验，我们需要注意下面几点： 尽量使用手动的方式创建线程池，避免使用Executors工厂类 根据场景，合理设置线程池的各个参数，包括线程池数量、队列、线程工厂和拒绝策略 在调线程池submit()方法的时候，一定要尽量避免任务执行异常被吞掉的问题 12.参考链接 https://www.jianshu.com/p/0424d339c85c http://www.cnblogs.com/superfj/p/7544971.html 书籍-Java并发编程的艺术 书籍-Java并发编程实践 原文出自：https://www.jianshu.com/p/7ab4ae9443b9","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"},{"name":"多线程","slug":"Java技术/多线程","permalink":"http://blog.shagle.cn/categories/Java技术/多线程/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"http://blog.shagle.cn/tags/线程池/"}]},{"title":"算法之HashTable原理详解","slug":"算法之哈希表原理详解","date":"2018-12-25T07:17:07.000Z","updated":"2018-12-25T07:22:11.000Z","comments":true,"path":"2018/12/25/算法之哈希表原理详解/","link":"","permalink":"http://blog.shagle.cn/2018/12/25/算法之哈希表原理详解/","excerpt":"","text":"1. 什么是哈希表？哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。 记录的存储位置=f(关键字) 这里的对应关系f称为散列函数，又称为哈希（Hash函数），采用散列技术将记录存储在一块连续的存储空间中，这块连续存储空间称为散列表或哈希表（Hash table）。 哈希表hashtable(key，value) 就是把Key通过一个固定的算法函数既所谓的哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里。（或者：把任意长度的输入（又叫做预映射， pre-image），通过散列算法，变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，而不可能从散列值来唯一的确定输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。） 而当使用哈希表进行查询的时候，就是再次使用哈希函数将key转换为对应的数组下标，并定位到该空间获取value，如此一来，就可以充分利用到数组的定位性能进行数据定位。 数组的特点是：寻址容易，插入和删除困难； 而链表的特点是：寻址困难，插入和删除容易。 那么我们能不能综合两者的特性，做出一种寻址容易，插入删除也容易的数据结构？答案是肯定的，这就是我们要提起的哈希表，哈希表有多种不同的实现方法，我接下来解释的是最常用的一种方法——拉链法，我们可以理解为“链表的数组”，如图： 左边很明显是个数组，数组的每个成员包括一个指针，指向一个链表的头，当然这个链表可能为空，也可能元素很多。我们根据元素的一些特征把元素分配到不同的链表中去，也是根据这些特征，找到正确的链表，再从链表中找出这个元素。 2. Hash的应用 1、Hash主要用于信息安全领域中加密算法，它把一些不同长度的信息转化成杂乱的128位的编码,这些编码值叫做Hash值. 也可以说，Hash就是找到一种数据内容和数据存放地址之间的映射关系。 2、查找：哈希表，又称为散列，是一种更加快捷的查找技术。我们之前的查找，都是这样一种思路：集合中拿出来一个元素，看看是否与我们要找的相等，如果不等，缩小范围，继续查找。而哈希表是完全另外一种思路：当我知道key值以后，我就可以直接计算出这个元素在集合中的位置，根本不需要一次又一次的查找！ 举一个例子，假如我的数组A中，第i个元素里面装的key就是i，那么数字3肯定是在第3个位置，数字10肯定是在第10个位置。哈希表就是利用利用这种基本的思想，建立一个从key到位置的函数，然后进行直接计算查找。 3、Hash表在海量数据处理中有着广泛应用。 Hash Table的查询速度非常的快，几乎是O(1)的时间复杂度。 hash就是找到一种数据内容和数据存放地址之间的映射关系。 散列法：元素特征转变为数组下标的方法。 我想大家都在想一个很严重的问题：“如果两个字符串在哈希表中对应的位置相同怎么办？”,毕竟一个数组容量是有限的，这种可能性很大。解决该问题的方法很多，我首先想到的就是用“链表”。我遇到的很多算法都可以转化成链表来解决，只要在哈希表的每个入口挂一个链表，保存所有对应的字符串就OK了。 散列表的查找步骤当存储记录时，通过散列函数计算出记录的散列地址当查找记录时，我们通过同样的是散列函数计算记录的散列地址，并按此散列地址访问该记录 关键字——散列函数（哈希函数）——散列地址 优点：一对一的查找效率很高； 缺点：一个关键字可能对应多个散列地址；需要查找一个范围时，效果不好。 散列冲突：不同的关键字经过散列函数的计算得到了相同的散列地址。 好的散列函数=计算简单+分布均匀（计算得到的散列地址分布均匀） 哈希表是种数据结构，它可以提供快速的插入操作和查找操作。 优缺点 优点：不论哈希表中有多少数据，查找、插入、删除（有时包括删除）只需要接近常量的时间即0(1）的时间级。实际上，这只需要几条机器指令。 哈希表运算得非常快，在计算机程序中，如果需要在一秒种内查找上千条记录通常使用哈希表（例如拼写检查器)哈希表的速度明显比树快，树的操作通常需要O(N)的时间级。哈希表不仅速度快，编程实现也相对容易。 如果不需要有序遍历数据，并且可以提前预测数据量的大小。那么哈希表在速度和易用性方面是无与伦比的。 缺点：它是基于数组的，数组创建后难于扩展，某些哈希表被基本填满时，性能下降得非常严重，所以程序员必须要清楚表中将要存储多少数据（或者准备好定期地把数据转移到更大的哈希表中，这是个费时的过程）。 元素特征转变为数组下标的方法就是散列法。散列法当然不止一种，下面列出三种比较常用的： 1，除法散列法最直观的一种，上图使用的就是这种散列法，公式： 1 index = value % 16 学过汇编的都知道，求模数其实是通过一个除法运算得到的，所以叫“除法散列法”。 2，平方散列法求index是非常频繁的操作，而乘法的运算要比除法来得省时（对现在的CPU来说，估计我们感觉不出来），所以我们考虑把除法换成乘法和一个位移操作。公式： 1index = (value * value) &gt;&gt; 28 （右移，除以2^28。记法：左移变大，是乘。右移变小，是除。） 如果数值分配比较均匀的话这种方法能得到不错的结果，但我上面画的那个图的各个元素的值算出来的index都是0——非常失败。也许你还有个问题，value如果很大，value * value不会溢出吗？答案是会的，但我们这个乘法不关心溢出，因为我们根本不是为了获取相乘结果，而是为了获取index。","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.shagle.cn/categories/算法/"}],"tags":[{"name":"Hash","slug":"Hash","permalink":"http://blog.shagle.cn/tags/Hash/"}]},{"title":"算法之Hash算法简介","slug":"算法之Hash算法简介","date":"2018-12-25T06:24:11.000Z","updated":"2018-12-25T06:57:48.000Z","comments":true,"path":"2018/12/25/算法之Hash算法简介/","link":"","permalink":"http://blog.shagle.cn/2018/12/25/算法之Hash算法简介/","excerpt":"","text":"1. Hash是什么，它的作用先举个例子。我们每个活在世上的人，为了能够参与各种社会活动，都需要一个用于识别自己的标志。也许你觉得名字或是身份证就足以代表你这个人，但是这种代表性非常脆弱，因为重名的人很多，身份证也可以伪造。最可靠的办法是把一个人的所有基因序列记录下来用来代表这个人，但显然，这样做并不实际。而指纹看上去是一种不错的选择，虽然一些专业组织仍然可以模拟某个人的指纹，但这种代价实在太高了。 而对于在互联网世界里传送的文件来说，如何标志一个文件的身份同样重要。比如说我们下载一个文件，文件的下载过程中会经过很多网络服务器、路由器的中转，如何保证这个文件就是我们所需要的呢？我们不可能去一一检测这个文件的每个字节，也不能简单地利用文件名、文件大小这些极容易伪装的信息，这时候，我们就需要一种指纹一样的标志来检查文件的可靠性，这种指纹就是我们现在所用的Hash算法(也叫散列算法)。 散列算法（Hash Algorithm），又称哈希算法，杂凑算法，是一种从任意文件中创造小的数字「指纹」的方法。与指纹一样，散列算法就是一种以较短的信息来保证文件唯一性的标志，这种标志与文件的每一个字节都相关，而且难以找到逆向规律。因此，当原有文件发生改变时，其标志值也会发生改变，从而告诉文件使用者当前的文件已经不是你所需求的文件。 这种标志有何意义呢？之前文件下载过程就是一个很好的例子，事实上，现在大部分的网络部署和版本控制工具都在使用散列算法来保证文件可靠性。而另一方面，我们在进行文件系统同步、备份等工具时，使用散列算法来标志文件唯一性能帮助我们减少系统开销，这一点在很多云存储服务器中都有应用。 当然，作为一种指纹，散列算法最重要的用途在于给证书、文档、密码等高安全系数的内容添加加密保护。这一方面的用途主要是得益于散列算法的不可逆性，这种不可逆性体现在，你不仅不可能根据一段通过散列算法得到的指纹来获得原有的文件，也不可能简单地创造一个文件并让它的指纹与一段目标指纹相一致。散列算法的这种不可逆性维持着很多安全框架的运营，而这也将是本文讨论的重点。 2. Hash算法有什么特点一个优秀的 hash 算法，将能实现： 正向快速：给定明文和 hash 算法，在有限时间和有限资源内能计算出 hash 值。 逆向困难：给定（若干） hash 值，在有限时间内很难（基本不可能）逆推出明文。 输入敏感：原始输入信息修改一点信息，产生的 hash 值看起来应该都有很大不同。 冲突避免：很难找到两段内容不同的明文，使得它们的 hash 值一致（发生冲突）。即对于任意两个不同的数据块，其hash值相同的可能性极小；对于一个给定的数据块，找到和它hash值相同的数据块极为困难。 但在不同的使用场景中，如数据结构和安全领域里，其中对某一些特点会有所侧重。 2.1 Hash在管理数据结构中的应用在用到hash进行管理的数据结构中，就对速度比较重视，对抗碰撞不太看中，只要保证hash均匀分布就可以。比如hashmap，hash值（key）存在的目的是加速键值对的查找，key的作用是为了将元素适当地放在各个桶里，对于抗碰撞的要求没有那么高。换句话说，hash出来的key，只要保证value大致均匀的放在不同的桶里就可以了。但整个算法的set性能，直接与hash值产生的速度有关，所以这时候的hash值的产生速度就尤为重要，以JDK中的String.hashCode()方法为例：12345678910111213public int hashCode() &#123; int h = hash; //hash default value : 0 if (h == 0 &amp;&amp; value.length &gt; 0) &#123; //value : char storage char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125; 很简洁的一个乘加迭代运算，在不少的hash算法中，使用的是异或+加法进行迭代，速度和前者差不多。 2.2 Hash在在密码学中的应用在密码学中，hash算法的作用主要是用于消息摘要和签名，换句话说，它主要用于对整个消息的完整性进行校验。举个例子，我们登陆知乎的时候都需要输入密码，那么知乎如果明文保存这个密码，那么黑客就很容易窃取大家的密码来登陆，特别不安全。那么知乎就想到了一个方法，使用hash算法生成一个密码的签名，知乎后台只保存这个签名值。由于hash算法是不可逆的，那么黑客即便得到这个签名，也丝毫没有用处；而如果你在网站登陆界面上输入你的密码，那么知乎后台就会重新计算一下这个hash值，与网站中储存的原hash值进行比对，如果相同，证明你拥有这个账户的密码，那么就会允许你登陆。银行也是如此，银行是万万不敢保存用户密码的原文的，只会保存密码的hash值而而已。在这些应用场景里，对于抗碰撞和抗篡改能力要求极高，对速度的要求在其次。一个设计良好的hash算法，其抗碰撞能力是很高的。以MD5为例，其输出长度为128位，设计预期碰撞概率为，这是一个极小极小的数字——而即便是在MD5被王小云教授破解之后，其碰撞概率上限也高达，也就是说，至少需要找次才能有1/2的概率来找到一个与目标文件相同的hash值。而对于两个相似的字符串，MD5加密结果如下： 12MD5(\"version1\") = \"966634ebf2fc135707d6753692bf4b1e\";MD5(\"version2\") = \"2e0e95285f08a07dea17e7ee111b21c8\"; 可以看到仅仅一个比特位的改变，二者的MD5值就天差地别了 ps : 其实把hash算法当成是一种加密算法，这是不准确的，我们知道加密总是相对于解密而言的，没有解密何谈加密呢，HASH的设计以无法解为目的的。并且如果我们不附加一个随机的salt值，HASH口令是很容易被字典攻击入侵的。 3. Hash算法是如何实现的？密码学和信息安全发展到现在，各种加密算法和散列算法已经不是只言片语所能解释得了的。在这里我们仅提供几个简单的概念供大家参考。 作为散列算法，首要的功能就是要使用一种算法把原有的体积很大的文件信息用若干个字符来记录，还要保证每一个字节都会对最终结果产生影响。那么大家也许已经想到了，求模这种算法就能满足我们的需要。 事实上，求模算法作为一种不可逆的计算方法，已经成为了整个现代密码学的根基。只要是涉及到计算机安全和加密的领域，都会有模计算的身影。散列算法也并不例外，一种最原始的散列算法就是单纯地选择一个数进行模运算，比如以下程序。 12345678910111213# 构造散列函数def hash(a): return a % 8# 测试散列函数功能print(hash(233))print(hash(234))print(hash(235))# 输出结果- 1- 2- 3 很显然，上述的程序完成了一个散列算法所应当实现的初级目标：用较少的文本量代表很长的内容（求模之后的数字肯定小于8）。但也许你已经注意到了，单纯使用求模算法计算之后的结果带有明显的规律性，这种规律将导致算法将能难保证不可逆性。所以我们将使用另外一种手段，那就是异或。 再来看下面一段程序，我们在散列函数中加入一个异或过程。 12345678910111213# 构造散列函数def hash(a): return (a % 8) ^ 5# 测试散列函数功能print(hash(233))print(hash(234))print(hash(235))# 输出结果- 4- 7- 6 很明显的，加入一层异或过程之后，计算之后的结果规律性就不是那么明显了。 当然，大家也许会觉得这样的算法依旧很不安全，如果用户使用连续变化的一系列文本与计算结果相比对，就很有可能找到算法所包含的规律。但是我们还有其他的办法。比如在进行计算之前对原始文本进行修改，或是加入额外的运算过程（如移位），比如以下程序。 12345678910111213# 构造散列函数def hash(a): return (a + 2 + (a &lt;&lt; 1)) % 8 ^ 5# 测试散列函数功能print(hash(233))print(hash(234))print(hash(235))# 输出结果- 0- 5- 6 这样处理得到的散列算法就很难发现其内部规律，也就是说，我们并不能很轻易地给出一个数，让它经过上述散列函数运算之后的结果等于4——除非我们去穷举测试。 上面的算法是不是很简单？事实上，下面我们即将介绍的常用算法MD5和SHA1，其本质算法就是这么简单，只不过会加入更多的循环和计算，来加强散列函数的可靠性。 4. Hash有哪些流行的算法目前流行的 Hash 算法包括 MD5、SHA-1 和 SHA-2。 MD4（RFC 1320）是 MIT 的 Ronald L. Rivest 在 1990 年设计的，MD 是 Message Digest 的缩写。其输出为 128 位。MD4 已证明不够安全。 MD5（RFC 1321）是 Rivest 于1991年对 MD4 的改进版本。它对输入仍以 512 位分组，其输出是 128 位。MD5 比 MD4 复杂，并且计算速度要慢一点，更安全一些。MD5 已被证明不具备”强抗碰撞性”。 SHA （Secure Hash Algorithm）是一个 Hash 函数族，由 NIST（National Institute of Standards and Technology）于 1993 年发布第一个算法。目前知名的 SHA-1 在 1995 年面世，它的输出为长度 160 位的 hash 值，因此抗穷举性更好。SHA-1 设计时基于和 MD4 相同原理，并且模仿了该算法。SHA-1 已被证明不具”强抗碰撞性”。 为了提高安全性，NIST 还设计出了 SHA-224、SHA-256、SHA-384，和 SHA-512 算法（统称为 SHA-2），跟 SHA-1 算法原理类似。SHA-3 相关算法也已被提出。 可以看出，上面这几种流行的算法，它们最重要的一点区别就是”强抗碰撞性”。 5. 那么，何谓Hash算法的「碰撞」？你可能已经发现了，在实现算法章节的第一个例子，我们尝试的散列算法得到的值一定是一个不大于8的自然数，因此，如果我们随便拿9个数去计算，肯定至少会得到两个相同的值，我们把这种情况就叫做散列算法的「碰撞」（Collision）。 这很容易理解，因为作为一种可用的散列算法，其位数一定是有限的，也就是说它能记录的文件是有限的——而文件数量是无限的，两个文件指纹发生碰撞的概率永远不会是零。 但这并不意味着散列算法就不能用了，因为凡事都要考虑代价，买光所有彩票去中一次头奖是毫无意义的。现代散列算法所存在的理由就是，它的不可逆性能在较大概率上得到实现，也就是说，发现碰撞的概率很小，这种碰撞能被利用的概率更小。 随意找到一组碰撞是有可能的，只要穷举就可以。散列算法得到的指纹位数是有限的，比如MD5算法指纹字长为128位，意味着只要我们穷举21282128次，就肯定能得到一组碰撞——当然，这个时间代价是难以想象的，而更重要的是，仅仅找到一组碰撞并没有什么实际意义。更有意义的是，如果我们已经有了一组指纹，能否找到一个原始文件，让它的散列计算结果等于这组指纹。如果这一点被实现，我们就可以很容易地篡改和伪造网络证书、密码等关键信息。 你也许已经听过MD5已经被破解的新闻——但事实上，即便是MD5这种已经过时的散列算法，也很难实现逆向运算。我们现在更多的还是依赖于海量字典来进行尝试，也就是通过已经知道的大量的文件——指纹对应关系，搜索某个指纹所对应的文件是否在数据库里存在。 5.1 MD5的实际碰撞案例下面让我们来看看一个真实的碰撞案例。我们之所以说MD5过时，是因为它在某些时候已经很难表现出散列算法的某些优势——比如在应对文件的微小修改时，散列算法得到的指纹结果应当有显著的不同，而下面的程序说明了MD5并不能实现这一点。 1234567891011121314import hashlib# 两段HEX字节串，注意它们有细微差别a = bytearray.fromhex(\"0e306561559aa787d00bc6f70bbdfe3404cf03659e704f8534c00ffb659c4c8740cc942feb2da115a3f4155cbb8607497386656d7d1f34a42059d78f5a8dd1ef\")b = bytearray.fromhex(\"0e306561559aa787d00bc6f70bbdfe3404cf03659e744f8534c00ffb659c4c8740cc942feb2da115a3f415dcbb8607497386656d7d1f34a42059d78f5a8dd1ef\")# 输出MD5，它们的结果一致print(hashlib.md5(a).hexdigest())print(hashlib.md5(b).hexdigest())### a和b输出结果都为：cee9a457e790cf20d4bdaa6d69f01e41cee9a457e790cf20d4bdaa6d69f01e41 而诸如此类的碰撞案例还有很多，上面只是原始文件相对较小的一个例子。事实上现在我们用智能手机只要数秒就能找到MD5的一个碰撞案例，因此，MD5在数年前就已经不被推荐作为应用中的散列算法方案，取代它的是SHA家族算法，也就是安全散列算法（Secure Hash Algorithm，缩写为SHA） 所以，对于一些大的商业机构来说， MD5 和 SHA1 已经不够安全，推荐至少使用 SHA2-256 算法。 6. Hash在Java中的应用6.1 HashMap的复杂度在介绍HashMap的实现之前，先考虑一下，HashMap与ArrayList和LinkedList在数据复杂度上有什么区别。下图是他们的性能对比图： 获取 查找 添加/删除 空间 ArrayList O(1) O(1) O(N） O(N) LinkedList O(N) O(N) O(1) O(N) HashMap O(N/Bucket_size) O(N/Bucket_size) O(N/Bucket_size) O(N) 可以看出HashMap整体上性能都非常不错，但是不稳定，为O(N/Buckets)，N就是以数组中没有发生碰撞的元素，Buckets是因碰撞产生的链表。 注：发生碰撞实际上是非常稀少的，所以N/Bucket_size约等于1 HashMap是对Array与Link的折衷处理，Array与Link可以说是两个速度方向的极端，Array注重于数据的获取，而处理修改（添加/删除）的效率非常低；Link由于是每个对象都保持着下一个对象的指针，查找某个数据需要遍历之前所有的数据，所以效率比较低，而在修改操作中比较快。 6.2 HashMap的实现本文以JDK8的API实现进行分析 6.2.1 对key进行Hash计算在JDK8中，由于使用了红黑树来处理大的链表开销，所以hash这边可以更加省力了，只用计算hashCode并移动到低位就可以了。 12345static final int hash(Object key) &#123; int h; //计算hashCode，并无符号移动到低位 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 举个例子: 363771819^(363771819 &gt;&gt;&gt; 16) 12340001 0101 1010 1110 1011 0111 1010 1011(363771819)0000 0000 0000 0000 0001 0101 1010 1110(5550) XOR--------------------------------------- =0001 0101 1010 1110 1010 0010 0000 0101(363766277) 这样做可以实现了高地位更加均匀地混到一起。 下面给出在Java中几个常用的哈希码(hashCode)的算法。 Object类的hashCode. 返回对象的经过处理后的内存地址，由于每个对象的内存地址都不一样，所以哈希码也不一样。这个是native方法，取决于JVM的内部设计，一般是某种C地址的偏移。 String类的hashCode. 根据String类包含的字符串的内容，根据一种特殊算法返回哈希码，只要字符串的内容相同，返回的哈希码也相同。 Integer等包装类，返回的哈希码就是Integer对象里所包含的那个整数的数值，例如Integer i1=new Integer(100), i1.hashCode的值就是100 。由此可见，2个一样大小的Integer对象，返回的哈希码也一样。 int，char这样的基础类，它们不需要hashCode，如果需要存储时，将进行自动装箱操作，计算方法同上。 6.2.2 获取到数组的index的位置计算了Hash，我们现在要把它插入数组中了1i = (tab.length - 1) &amp; hash； 通过位运算，确定了当前的位置，因为HashMap数组的大小总是2^n，所以实际的运算就是 (0xfff…ff) &amp; hash ，这里的tab.length-1相当于一个mask，滤掉了大于当前长度位的hash，使每个i都能插入到数组中。 6.2.3 生成包装类这个对象是一个包装类，Node1234567static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; //getter and setter .etc.&#125; 6.2.4 插入包装类到数组(1). 如果输入当前的位置是空的，就插进去，如图，左为插入前，右为插入后12345678910110 0| |1 -&gt; null 1 - &gt; null| |2 -&gt; null 2 - &gt; null| | ..-&gt; null ..- &gt; null| | i -&gt; null i - &gt; new node| |n -&gt; null n - &gt; null (2). 如果当前位置已经有了node，且它们发生了碰撞，则新的放到前面，旧的放到后面，这叫做链地址法处理冲突。12345678910110 0| |1 -&gt; null 1 - &gt; null| |2 -&gt; null 2 - &gt; null| | ..-&gt; null ..- &gt; null| | i -&gt; old i - &gt; new - &gt; old| |n -&gt; null n - &gt; null 我们可以发现，失败的hashCode算法会导致HashMap的性能由数组下降为链表，所以想要避免发生碰撞，就要提高hashCode结果的均匀性。 6.3 扩容如果当表中的75%已经被占用，即视为需要扩容了1(threshold = capacity * load factor ) &lt; size 它主要有两个步骤： 6.3.1 容量加倍左移1位，就是扩大到两倍，用位运算取代了乘法运算12newCap = oldCap &lt;&lt; 1;newThr = oldThr &lt;&lt; 1; 6.3.2 遍历计算Hash123456789101112131415161718192021222324252627282930313233343536373839404142434445for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //如果发现当前有Bucket if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //如果这里没有碰撞 if (e.next == null) //重新计算Hash，分配位置 newTab[e.hash &amp; (newCap - 1)] = e; //这个见下面的新特性介绍，如果是树，就填入树 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //如果是链表，就保留顺序....目前就看懂这点 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125;&#125; 由此可以看出扩容需要遍历并重新赋值，成本非常高，所以选择一个好的初始容量非常重要。 6.4 扩容如何提升性能？ 解决扩容损失：如果知道大致需要的容量，把初始容量设置好以解决扩容损失； 比如我现在有1000个数据，需要 1000/0.75 = 1333 个坑位，又 1024 &lt; 1333 &lt; 2048，所以最好使用2048作为初始容量。 解决碰撞损失：使用高效的HashCode与loadFactor，这个…由于JDK8的高性能出现，这儿问题也不大了。 6.5 HashMap与HashTable的主要区别在很多的Java基础书上都已经说过了，他们的主要区别其实就是Table全局加了线程同步保护 HashTable线程更加安全，代价就是因为它粗暴的添加了同步锁，所以会有性能损失。 其实有更好的concurrentHashMap可以替代HashTable，一个是方法级，一个是Class级。6.6 在Android中使用SparseArray代替HashMap官方推荐使用SparseArray([spɑ:s][ə’reɪ],稀疏的数组)或者LongSparseArray代替HashMap。官方总结有一下几点好处： SparseArray使用基本类型(Primitive)中的int作为Key，不需要Pair 7. 总结「The Algorithm Design Manual」一书中提到，雅虎的 Chief Scientist ，Udi Manber 曾说过，在 yahoo 所应用的算法中，最重要的三个是：Hash，Hash 和 Hash。其实从上文中所举的git用sha1判断文件更改，密码用MD5生成摘要后加盐等等对Hash的应用可看出，Hash的在计算机世界扮演着多么重要的角色。另书中还举了一个很有趣的显示中例子： 一场拍卖会中，物品是价高者得，如果每个人只有一次出价机会，同时提交自己的价格后，最后一起公布，出价最高则胜出。这种形式存在作弊的可能，如果有出价者能 hack 进后台，然后将自己的价格改为最高价 +1，则能以最低的代价获得胜利。如何杜绝这种作弊呢？ 答案很简单，参与者都提交自身出价的 hash 值就可以了，即使有人能黑进后台也无法得知明文价格，等到公布之时，再对比原出价与 hash 值是否对应即可。是不是很巧妙？ 是的，上面的做法，与上文提到的网站上储存密码用MD5 值而非明文，是同一种思想，殊途同归。 可以看到无论是密码学、数据结构、现实生活中的应用，到处可以看到Hash的影子，通过这篇文章的介绍，相信你不仅知其名，也能懂其意。 8. Referencehttps://jizhi.im/blog/post/sha1decrypthttp://www.jianshu.com/p/e54047b2b563https://www.zhihu.com/question/26762707Hash 函数及其重要性http://mp.weixin.qq.com/s/oRLkR7jplqO2qhHtUeTMIA","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.shagle.cn/categories/算法/"}],"tags":[{"name":"Hash","slug":"Hash","permalink":"http://blog.shagle.cn/tags/Hash/"}]},{"title":"算法之LRU缓存淘汰","slug":"算法之LRU缓存淘汰","date":"2018-12-25T02:51:30.000Z","updated":"2018-12-25T03:00:49.000Z","comments":true,"path":"2018/12/25/算法之LRU缓存淘汰/","link":"","permalink":"http://blog.shagle.cn/2018/12/25/算法之LRU缓存淘汰/","excerpt":"","text":"1. LRU1.1. 原理LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 1.2. 实现最常见的实现是使用一个链表保存缓存数据，详细算法实现如下： 1.新数据插入到链表头部； 2.每当缓存命中（即缓存数据被访问），则将数据移到链表头部； 3.当链表满的时候，将链表尾部的数据丢弃。 1.3. 分析【命中率】 当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。 【复杂度】 实现简单。 【代价】 命中时需要遍历链表，找到命中的数据块索引，然后需要将数据移到头部。 2. LRU-K2.1. 原理LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。 2.2. 实现相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。详细实现如下： 数据第一次被访问，加入到访问历史列表； 如果数据在访问历史列表里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰； 当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除，将数据移到缓存队列中，并缓存此数据，缓存队列重新按照时间排序； 缓存数据队列中被再次访问后，重新排序； 需要淘汰数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K次访问离现在最久”的数据。 LRU-K具有LRU的优点，同时能够避免LRU的缺点，实际应用中LRU-2是综合各种因素后最优的选择，LRU-3或者更大的K值命中率会高，但适应性差，需要大量的数据访问才能将历史访问记录清除掉。 2.3. 分析【命中率】 LRU-K降低了“缓存污染”带来的问题，命中率比LRU要高。 【复杂度】 LRU-K队列是一个优先级队列，算法复杂度和代价比较高。 【代价】 由于LRU-K还需要记录那些被访问过、但还没有放入缓存的对象，因此内存消耗会比LRU要多；当数据量很大的时候，内存消耗会比较可观。 LRU-K需要基于时间进行排序（可以需要淘汰时再排序，也可以即时排序），CPU消耗比LRU要高。 3. Two queues（2Q）3.1. 原理Two queues（以下使用2Q代替）算法类似于LRU-2，不同点在于2Q将LRU-2算法中的访问历史队列（注意这不是缓存数据的）改为一个FIFO缓存队列，即：2Q算法有两个缓存队列，一个是FIFO队列，一个是LRU队列。 3.2. 实现当数据第一次访问时，2Q算法将数据缓存在FIFO队列里面，当数据第二次被访问时，则将数据从FIFO队列移到LRU队列里面，两个队列各自按照自己的方法淘汰数据。详细实现如下： 新访问的数据插入到FIFO队列； 如果数据在FIFO队列中一直没有被再次访问，则最终按照FIFO规则淘汰； 如果数据在FIFO队列中被再次访问，则将数据移到LRU队列头部； 如果数据在LRU队列再次被访问，则将数据移到LRU队列头部； LRU队列淘汰末尾的数据。 注：上图中FIFO队列比LRU队列短，但并不代表这是算法要求，实际应用中两者比例没有硬性规定。 3.3. 分析【命中率】 2Q算法的命中率要高于LRU。 【复杂度】 需要两个队列，但两个队列本身都比较简单。 【代价】 FIFO和LRU的代价之和。 2Q算法和LRU-2算法命中率类似，内存消耗也比较接近，但对于最后缓存的数据来说，2Q会减少一次从原始存储读取数据或者计算数据的操作。 4. Multi Queue（MQ）4.1. 原理MQ算法根据访问频率将数据划分为多个队列，不同的队列具有不同的访问优先级，其核心思想是：优先缓存访问次数多的数据。 4.2. 实现MQ算法将缓存划分为多个LRU队列，每个队列对应不同的访问优先级。访问优先级是根据访问次数计算出来的，例如 详细的算法结构图如下，Q0，Q1….Qk代表不同的优先级队列，Q-history代表从缓存中淘汰数据，但记录了数据的索引和引用次数的队列： 如上图，算法详细描述如下： 新插入的数据放入Q0； 每个队列按照LRU管理数据； 当数据的访问次数达到一定次数，需要提升优先级时，将数据从当前队列删除，加入到高一级队列的头部； 为了防止高优先级数据永远不被淘汰，当数据在指定的时间里访问没有被访问时，需要降低优先级，将数据从当前队列删除，加入到低一级的队列头部； 需要淘汰数据时，从最低一级队列开始按照LRU淘汰；每个队列淘汰数据时，将数据从缓存中删除，将数据索引加入Q-history头部； 如果数据在Q-history中被重新访问，则重新计算其优先级，移到目标队列的头部； Q-history按照LRU淘汰数据的索引。 4.3. 分析【命中率】 MQ降低了“缓存污染”带来的问题，命中率比LRU要高。 【复杂度】 MQ需要维护多个队列，且需要维护每个数据的访问时间，复杂度比LRU高。 【代价】 MQ需要记录每个数据的访问时间，需要定时扫描所有队列，代价比LRU要高。 注：虽然MQ的队列看起来数量比较多，但由于所有队列之和受限于缓存容量的大小，因此这里多个队列长度之和和一个LRU队列是一样的，因此队列扫描性能也相近。 5. LRU类算法对比由于不同的访问模型导致命中率变化较大，此处对比仅基于理论定性分析，不做定量分析。 对比点 对比 命中率 LRU-2 &gt; MQ(2) &gt; 2Q &gt; LRU 复杂度 LRU-2 &gt; MQ(2) &gt; 2Q &gt; LRU 代价 LRU-2 &gt; MQ(2) &gt; 2Q &gt; LRU 实际应用中需要根据业务的需求和对数据的访问情况进行选择，并不是命中率越高越好。例如：虽然LRU看起来命中率会低一些，且存在”缓存污染“的问题，但由于其简单和代价小，实际应用中反而应用更多。 java中最简单的LRU算法实现，就是利用jdk的LinkedHashMap，覆写其中的removeEldestEntry(Map.Entry)方法即可 如果你去看LinkedHashMap的源码可知，LRU算法是通过双向链表来实现，当某个位置被命中，通过调整链表的指向将该位置调整到头位置，新加入的内容直接放在链表头，如此一来，最近被命中的内容就向链表头移动，需要替换时，链表最后的位置就是最近最少使用的位置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import java.util.ArrayList; import java.util.Collection; import java.util.LinkedHashMap; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; import java.util.Map; /** * 类说明：利用LinkedHashMap实现简单的缓存， 必须实现removeEldestEntry方法，具体参见JDK文档 * * @author dennis * * @param &lt;K&gt; * @param &lt;V&gt; */ public class LRULinkedHashMap&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int maxCapacity; private static final float DEFAULT_LOAD_FACTOR = 0.75f; private final Lock lock = new ReentrantLock(); public LRULinkedHashMap(int maxCapacity) &#123; super(maxCapacity, DEFAULT_LOAD_FACTOR, true); this.maxCapacity = maxCapacity; &#125; @Override protected boolean removeEldestEntry(java.util.Map.Entry&lt;K, V&gt; eldest) &#123; return size() &gt; maxCapacity; &#125; @Override public boolean containsKey(Object key) &#123; try &#123; lock.lock(); return super.containsKey(key); &#125; finally &#123; lock.unlock(); &#125; &#125; @Override public V get(Object key) &#123; try &#123; lock.lock(); return super.get(key); &#125; finally &#123; lock.unlock(); &#125; &#125; @Override public V put(K key, V value) &#123; try &#123; lock.lock(); return super.put(key, value); &#125; finally &#123; lock.unlock(); &#125; &#125; public int size() &#123; try &#123; lock.lock(); return super.size(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void clear() &#123; try &#123; lock.lock(); super.clear(); &#125; finally &#123; lock.unlock(); &#125; &#125; public Collection&lt;Map.Entry&lt;K, V&gt;&gt; getAll() &#123; try &#123; lock.lock(); return new ArrayList&lt;Map.Entry&lt;K, V&gt;&gt;(super.entrySet()); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; 5.1 基于双链表 的LRU实现:传统意义的LRU算法是为每一个Cache对象设置一个计数器，每次Cache命中则给计数器+1，而Cache用完，需要淘汰旧内容，放置新内容时，就查看所有的计数器，并将最少使用的内容替换掉。 它的弊端很明显，如果Cache的数量少，问题不会很大， 但是如果Cache的空间过大，达到10W或者100W以上，一旦需要淘汰，则需要遍历所有计算器，其性能与资源消耗是巨大的。效率也就非常的慢了。 它的原理： 将Cache的所有位置都用双连表连接起来，当一个位置被命中之后，就将通过调整链表的指向，将该位置调整到链表头的位置，新加入的Cache直接加到链表头中。 这样，在多次进行Cache操作后，最近被命中的，就会被向链表头方向移动，而没有命中的，而想链表后面移动，链表尾则表示最近最少使用的Cache。 当需要替换内容时候，链表的最后位置就是最少被命中的位置，我们只需要淘汰链表最后的部分即可。 上面说了这么多的理论， 下面用代码来实现一个LRU策略的缓存。 我们用一个对象来表示Cache，并实现双链表， 123456789101112131415public class LRUCache &#123; /** * 链表节点 * @author Administrator * */ class CacheNode &#123; …… &#125; private int cacheSize;//缓存大小 private Hashtable nodes;//缓存容器 private int currentSize;//当前缓存对象数量 private CacheNode first;//(实现双链表)链表头 private CacheNode last;//(实现双链表)链表尾&#125; 下面给出完整的实现，这个类也被Tomcat所使用（ org.apache.tomcat.util.collections.LRUCache），但是在tomcat6.x版本中，已经被弃用，使用另外其他的缓存类来替代它。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129public class LRUCache &#123; /** * 链表节点 * @author Administrator * */ class CacheNode &#123; CacheNode prev;//前一节点 CacheNode next;//后一节点 Object value;//值 Object key;//键 CacheNode() &#123; &#125; &#125; public LRUCache(int i) &#123; currentSize = 0; cacheSize = i; nodes = new Hashtable(i);//缓存容器 &#125; /** * 获取缓存中对象 * @param key * @return */ public Object get(Object key) &#123; CacheNode node = (CacheNode) nodes.get(key); if (node != null) &#123; moveToHead(node); return node.value; &#125; else &#123; return null; &#125; &#125; /** * 添加缓存 * @param key * @param value */ public void put(Object key, Object value) &#123; CacheNode node = (CacheNode) nodes.get(key); if (node == null) &#123; //缓存容器是否已经超过大小. if (currentSize &gt;= cacheSize) &#123; if (last != null)//将最少使用的删除 nodes.remove(last.key); removeLast(); &#125; else &#123; currentSize++; &#125; node = new CacheNode(); &#125; node.value = value; node.key = key; //将最新使用的节点放到链表头，表示最新使用的. moveToHead(node); nodes.put(key, node); &#125; /** * 将缓存删除 * @param key * @return */ public Object remove(Object key) &#123; CacheNode node = (CacheNode) nodes.get(key); if (node != null) &#123; if (node.prev != null) &#123; node.prev.next = node.next; &#125; if (node.next != null) &#123; node.next.prev = node.prev; &#125; if (last == node) last = node.prev; if (first == node) first = node.next; &#125; return node; &#125; public void clear() &#123; first = null; last = null; &#125; /** * 删除链表尾部节点 * 表示 删除最少使用的缓存对象 */ private void removeLast() &#123; //链表尾不为空,则将链表尾指向null. 删除连表尾（删除最少使用的缓存对象） if (last != null) &#123; if (last.prev != null) last.prev.next = null; else first = null; last = last.prev; &#125; &#125; /** * 移动到链表头，表示这个节点是最新使用过的 * @param node */ private void moveToHead(CacheNode node) &#123; if (node == first) return; if (node.prev != null) node.prev.next = node.next; if (node.next != null) node.next.prev = node.prev; if (last == node) last = node.prev; if (first != null) &#123; node.next = first; first.prev = node; &#125; first = node; node.prev = null; if (last == null) last = first; &#125; private int cacheSize; private Hashtable nodes;//缓存容器 private int currentSize; private CacheNode first;//链表头 private CacheNode last;//链表尾&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.shagle.cn/categories/算法/"}],"tags":[{"name":"LRU","slug":"LRU","permalink":"http://blog.shagle.cn/tags/LRU/"}]},{"title":"分布式之基于Zookeeper的分布式锁实现","slug":"分布式之基于Zookeeper的分布式锁实现","date":"2018-12-24T09:31:31.000Z","updated":"2018-12-24T09:50:22.000Z","comments":true,"path":"2018/12/24/分布式之基于Zookeeper的分布式锁实现/","link":"","permalink":"http://blog.shagle.cn/2018/12/24/分布式之基于Zookeeper的分布式锁实现/","excerpt":"","text":"1. 背景最近在学习 Zookeeper，在刚开始接触 Zookeeper 的时候，完全不知道 Zookeeper 有什么用。且很多资料都是将 Zookeeper 描述成一个“类 Unix/Linux 文件系统”的中间件，导致我很难将类 Unix/Linux 文件系统的 Zookeeper 和分布式应用联系在一起。后来在粗读了《ZooKeeper 分布式过程协同技术详解》和《从Paxos到Zookeeper 分布式一致性原理与实践》两本书，并动手写了一些 CURD demo 后，初步对 Zookeeper 有了一定的了解。不过比较肤浅，为了进一步加深对 Zookeeper 的认识，我利用空闲时间编写了本篇文章对应的 demo – 基于 Zookeeper 的分布式锁实现。通过编写这个分布式锁 demo，使我对 Zookeeper 的 watcher 机制、Zookeeper 的用途等有了更进一步的认识。不过我所编写的分布式锁还是比较简陋的，实现的也不够优美，仅仅是个练习，仅供参考使用。好了，题外话就说到这里，接下来我们就来聊聊基于 Zookeeper 的分布式锁实现。 2. 独占锁和读写锁的实现在本章，我将分别说明独占锁和读写锁详细的实现过程，并配以相应的流程图帮助大家了解实现的过程。这里先说说独占锁的实现。 2.1 独占锁的实现独占锁又称排它锁，从字面意思上很容易理解他们的用途。即如果某个操作 O1 对访问资源 R1 的过程加锁，在操作 O1 结束对资源 R1 访问前，其他操作不允许访问资源 R1。以上算是对独占锁的简单定义了，那么这段定义在 Zookeeper 的“类 Unix/Linux 文件系统”的结构中是怎样实现的呢？在锁答案前，我们先看张图：图1 独占锁的 Zookeeper 节点结构 如上图，对于独占锁，我们可以将资源 R1 看做是 lock 节点，操作 O1 访问资源 R1 看做创建 lock 节点，释放资源 R1 看做删除 lock 节点。这样我们就将独占锁的定义对应于具体的 Zookeeper 节点结构，通过创建 lock 节点获取锁，删除节点释放锁。详细的过程如下： 1.多个客户端竞争创建 lock 临时节点 2.其中某个客户端成功创建 lock 节点，其他客户端对 lock 节点设置 watcher 3.持有锁的客户端删除 lock 节点或该客户端崩溃，由 Zookeeper 删除 lock 节点 4.其他客户端获得 lock 节点被删除的通知 5.重复上述4个步骤，直至无客户端在等待获取锁了上面即独占锁具体的实现步骤，理解起来并不复杂，这里不再赘述。图2 获取独占锁流程图2.2 读写锁的实现说完独占锁的实现，这节来说说读写锁的实现。读写锁包含一个读锁和写锁，操作 O1 对资源 R1 加读锁，且获得了锁，其他操作可同时对资源 R1 设置读锁，进行共享读操作。如果操作 O1 对资源 R1 加写锁，且获得了锁，其他操作再对资源 R1 设置不同类型的锁都会被阻塞。总结来说，读锁具有共享性，而写锁具有排他性。那么在 Zookeeper 中，我们可以用怎样的节点结构实现上面的操作呢？图3 读写锁的 Zookeeper 节点结构 在 Zookeeper 中，由于读写锁和独占锁的节点结构不同，读写锁的客户端不用再去竞争创建 lock 节点。所以在一开始，所有的客户端都会创建自己的锁节点。如果不出意外，所有的锁节点都能被创建成功，此时锁节点结构如图3所示。之后，客户端从 Zookeeper 端获取 /share_lock 下所有的子节点，并判断自己能否获取锁。如果客户端创建的是读锁节点，获取锁的条件（满足其中一个即可）如下： 1.自己创建的节点序号排在所有其他子节点前面 2.自己创建的节点前面无写锁节点 3.如果客户端创建的是写锁节点，由于写锁具有排他性。所以获取锁的条件要简单一些，只需确定自己创建的锁节点是否排在其他子节点前面即可。 不同于独占锁，读写锁的实现稍微复杂一下。读写锁有两种实现方式，各有异同，接下来就来说说这两种实现方式。 2.2.1 读写锁的第一种实现第一种实现是对 /share_lock 节点设置 watcher，当 /share_lock 下的子节点被删除时，未获取锁的客户端收到 /share_lock 子节点变动的通知。在收到通知后，客户端重新判断自己创建的子节点是否可以获取锁，如果失败，再次等待通知。详细流程如下： 1.所有客户端创建自己的锁节点 2.从 Zookeeper 端获取 /share_lock 下所有的子节点，并对 /share_lock 节点设置 watcher 3.判断自己创建的锁节点是否可以获取锁，如果可以，持有锁。否则继续等待 4.持有锁的客户端删除自己的锁节点，其他客户端收到 /share_lock 子节点变动的通知 5.重复步骤2、3、4，直至无客户端在等待获取锁了上述步骤对于的流程图如下：图4 获取读写锁实现1流程图 上面获取读写锁流程并不复杂，但却存在性能问题。以图3所示锁节点结构为例，第一个锁节点 host1-W-0000000001 被移除后，Zookeeper 会将 /share_lock 子节点变动的通知分发给所有的客户端。但实际上，该子节点变动通知除了能影响 host2-R-0000000002 节点对应的客户端外，分发给其他客户端则是在做无用功，因为其他客户端即使获取了通知也无法获取锁。所以这里需要做一些优化，优化措施是让客户端只在自己关心的节点被删除时，再去获取锁。 2.2.2 读写锁的第二种实现在了解读写锁第一种实现的弊端后，我们针对这一实现进行优化。这里客户端不再对 /share_lock 节点进行监视，而只对自己关心的节点进行监视。还是以图3的锁节点结构进行举例说明，host2-R-0000000002 对应的客户端 C2 只需监视 host1-W-0000000001 节点是否被删除即可。而 host3-W-0000000003 对应的客户端 C3 只需监视 host2-R-0000000002 节点是否被删除即可，只有 host2-R-0000000002 节点被删除，客户端 C3 才能获取锁。而 host1-W-0000000001 节点被删除时，产生的通知对于客户端 C3 来说是无用的，即使客户端 C3 响应了通知也没法获取锁。这里总结一下，不同客户端关心的锁节点是不同的。如果客户端创建的是读锁节点，那么客户端只需找出比读锁节点序号小的最后一个的写锁节点，并设置 watcher 即可。而如果是写锁节点，则更简单，客户端仅需对该节点的上一个节点设置 watcher 即可。详细的流程如下： 1.所有客户端创建自己的锁节点 2.从 Zookeeper 端获取 /share_lock 下所有的子节点 3.判断自己创建的锁节点是否可以获取锁，如果可以，持有锁。否则对自己关心的锁节点设置 watcher 4.持有锁的客户端删除自己的锁节点，某个客户端收到该节点被删除的通知，并获取锁 5.重复步骤4，直至无客户端在等待获取锁了上述步骤对于的流程图如下：图5 获取读写锁实现2流程图3. 写在最后本文较为详细的描述了基于 Zookeeper 分布式锁的实现过程，并根据上面描述的两种锁原理实现了较为简单的分布式锁 demo，代码放在了 github 上，需要的朋友自取。因为这只是一个简单的 demo，代码实现的并不优美，仅供参考。最后，如果你觉得文章还不错的话，欢迎点赞。如果有不妥的地方，也请提出来，我会虚心改之。好了，最后祝大家生活愉快，再见。 4. 参考 《ZooKeeper 分布式过程协同技术详解》 《从Paxos到Zookeeper 分布式一致性原理与实践》","categories":[{"name":"分布式","slug":"分布式","permalink":"http://blog.shagle.cn/categories/分布式/"},{"name":"Zookeeper","slug":"分布式/Zookeeper","permalink":"http://blog.shagle.cn/categories/分布式/Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://blog.shagle.cn/tags/Zookeeper/"},{"name":"分布式锁","slug":"分布式锁","permalink":"http://blog.shagle.cn/tags/分布式锁/"}]},{"title":"Java技术之HashMap源码详细分析","slug":"Java技术之HashMap源码详细分析","date":"2018-12-24T08:47:52.000Z","updated":"2018-12-24T09:22:20.000Z","comments":true,"path":"2018/12/24/Java技术之HashMap源码详细分析/","link":"","permalink":"http://blog.shagle.cn/2018/12/24/Java技术之HashMap源码详细分析/","excerpt":"","text":"","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[]},{"title":"Java技术之LinkedList源码分析","slug":"Java技术之LinkedList源码分析","date":"2018-12-24T07:55:09.000Z","updated":"2018-12-25T02:02:46.000Z","comments":true,"path":"2018/12/24/Java技术之LinkedList源码分析/","link":"","permalink":"http://blog.shagle.cn/2018/12/24/Java技术之LinkedList源码分析/","excerpt":"","text":"1.概述LinkedList是 Java 集合框架中一个重要的实现，其底层采用的双向链表结构。和 ArrayList 一样，LinkedList也支持空值和重复值。由于LinkedList基于链表实现，存储元素过程中，无需像 ArrayList 那样进行扩容。但有得必有失，LinkedList存储元素的节点需要额外的空间存储前驱和后继的引用。另一方面，LinkedList在链表头部和尾部插入效率比较高，但在指定位置进行插入时，效率一般。原因是，在指定位置插入需要定位到该位置处的节点，此操作的时间复杂度为O(N)。最后，LinkedList是非线程安全的集合类，并发环境下，多个线程同时操作 LinkedList，会引发不可预知的错误。 以上是对LinkedList的简单介绍，接下来，我将会对LinkedList常用操作展开分析，继续往下看吧。 2.继承体系2.1 LinkedList属性LinkedList本身的 的属性比较少，主要有三个，一个是size，表名当前有多少个节点；一个是first代表第一个节点；一个是last代表最后一个节点。1234567891011public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable&#123; //当前有多少个节点 transient int size = 0; //第一个节点 transient Node&lt;E&gt; first; //最后一个节点 transient Node&lt;E&gt; last; //省略内部类和方法。。&#125; LinkedList的继承体系较为复杂，继承自 AbstractSequentialList，同时又实现了 List 和 Deque 接口。继承体系图如下（删除了部分实现的接口）：LinkedList继承自 AbstractSequentialList，AbstractSequentialList 又是什么呢？从实现上，AbstractSequentialList 提供了一套基于顺序访问的接口。通过继承此类，子类仅需实现部分代码即可拥有完整的一套访问某种序列表（比如链表）的接口。深入源码，AbstractSequentialList 提供的方法基本上都是通过 ListIterator 实现的，比如：123456789101112131415161718public E get(int index) &#123; try &#123; return listIterator(index).next(); &#125; catch (NoSuchElementException exc) &#123; throw new IndexOutOfBoundsException(\"Index: \"+index); &#125;&#125;public void add(int index, E element) &#123; try &#123; listIterator(index).add(element); &#125; catch (NoSuchElementException exc) &#123; throw new IndexOutOfBoundsException(\"Index: \"+index); &#125;&#125;// 留给子类实现public abstract ListIterator&lt;E&gt; listIterator(int index); 所以只要继承类实现了 listIterator 方法，它不需要再额外实现什么即可使用。对于随机访问集合类一般建议继承 AbstractList 而不是 AbstractSequentialList。LinkedList和其父类一样，也是基于顺序访问。所以LinkedList继承了 AbstractSequentialList，但LinkedList并没有直接使用父类的方法，而是重新实现了一套的方法。 另外，LinkedList还实现了 Deque (double ended queue)，Deque 又继承自 Queue 接口。这样LinkedList就具备了队列的功能。比如，我们可以这样使用： 1Queue&lt;T&gt; queue = new LinkedList&lt;&gt;(); 除此之外，我们基于LinkedList还可以实现一些其他的数据结构，比如栈，以此来替换 Java 集合框架中的 Stack 类（该类实现的不好，《Java 编程思想》一书的作者也对此类进行了吐槽）。 关于LinkedList继承体系先说到这，下面进入源码分析部分。 3.源码分析3.1 查找LinkedList底层基于链表结构，无法向 ArrayList 那样随机访问指定位置的元素。LinkedList查找过程要稍麻烦一些，需要从链表头结点（或尾节点）向后查找，时间复杂度为 O(N)。相关源码如下：1234567891011121314151617181920212223public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125;Node&lt;E&gt; node(int index) &#123; /* * 则从头节点开始查找，否则从尾节点查找 * 查找位置 index 如果小于节点数量的一半， */ if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; // 循环向后查找，直至 i == index for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 上面的代码比较简单，主要是通过遍历的方式定位目标位置的节点。获取到节点后，取出节点存储的值返回即可。这里面有个小优化，即通过比较 index 与节点数量 size/2 的大小，决定从头结点还是尾节点进行查找。查找操作的代码没什么复杂的地方，这里先讲到这里。 3.2 遍历链表的遍历过程也很简单，和上面查找过程类似，我们从头节点往后遍历就行了。但对于LinkedList的遍历还是需要注意一些，不然可能会导致代码效率低下。通常情况下，我们会使用 foreach 遍历 LinkedList，而 foreach 最终转换成迭代器形式。所以分析LinkedList的遍历的核心就是它的迭代器实现，相关代码如下：1234567891011121314151617181920212223242526272829303132333435public ListIterator&lt;E&gt; listIterator(int index) &#123; checkPositionIndex(index); return new ListItr(index);&#125;private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; /** 构造方法将 next 引用指向指定位置的节点 */ ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; // 调用 next 方法后，next 引用都会指向他的后继节点 nextIndex++; return lastReturned.item; &#125; // 省略部分方法&#125; 上面的方法很简单，大家应该都能很快看懂，这里就不多说了。下面来说说遍历LinkedList需要注意的一个点。 我们都知道LinkedList不擅长随机位置访问，如果大家用随机访问的方式遍历 LinkedList，效率会很差。比如下面的代码：12345678List&lt;Integet&gt; list = new LinkedList&lt;&gt;();list.add(1)list.add(2)......for (int i = 0; i &lt; list.size(); i++) &#123; Integet item = list.get(i); // do something&#125; 当链表中存储的元素很多时，上面的遍历方式对于效率来说就是灾难。原因在于，通过上面的方式每获取一个元素，LinkedList都需要从头节点（或尾节点）进行遍历，效率不可谓不低。在我的电脑（MacBook Pro Early 2015, 2.7 GHz Intel Core i5）实测10万级的数据量，耗时约7秒钟。20万级的数据量耗时达到了约34秒的时间。50万级的数据量耗时约250秒。从测试结果上来看，上面的遍历方式在大数据量情况下，效率很差。大家在日常开发中应该尽量避免这种用法。 3.3 插入LinkedList除了实现了 List 接口相关方法，还实现了 Deque 接口的很多方法，所以我们有很多种方式插入元素。但这里，我只打算分析 List 接口中相关的插入方法，其他的方法大家自己看吧。LinkedList插入元素的过程实际上就是链表链入节点的过程，学过数据结构的同学对此应该都很熟悉了。这里简单分析一下，先看源码吧：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** 在链表尾部插入元素 */public boolean add(E e) &#123; linkLast(e); return true;&#125;/** 在链表指定位置插入元素 */public void add(int index, E element) &#123; checkPositionIndex(index); // 判断 index 是不是链表尾部位置，如果是，直接将元素节点插入链表尾部即可 if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;/** 将元素节点插入到链表尾部 */void linkLast(E e) &#123; final Node&lt;E&gt; l = last; // 创建节点，并指定节点前驱为链表尾节点 last，后继引用为空 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // 将 last 引用指向新节点 last = newNode; // 判断尾节点是否为空，为空表示当前链表还没有节点 if (l == null) first = newNode; else l.next = newNode; // 让原尾节点后继引用 next 指向新的尾节点 size++; modCount++;&#125;/** 将元素节点插入到 succ 之前的位置 */void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; // 1. 初始化节点，并指明前驱和后继节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // 2. 将 succ 节点前驱引用 prev 指向新节点 succ.prev = newNode; // 判断尾节点是否为空，为空表示当前链表还没有节点 if (pred == null) first = newNode; else pred.next = newNode; // 3. succ 节点前驱的后继引用指向新节点 size++; modCount++;&#125; 上面是插入过程的源码，我对源码进行了比较详细的注释，应该不难看懂。上面两个 add 方法只是对操作链表的方法做了一层包装，核心逻辑在 linkBefore 和 linkLast 中。这里以 linkBefore 为例，它的逻辑流程如下： 1.创建新节点，并指明新节点的前驱和后继 2.将 succ 的前驱引用指向新节点 3.如果 succ 的前驱不为空，则将 succ 前驱的后继引用指向新节点 对应于下图：以上就是插入相关的源码分析，并不复杂，就不多说了。继续往下分析。 3.4 删除如果大家看懂了上面的插入源码分析，那么再看删除操作实际上也很简单了。删除操作通过解除待删除节点与前后节点的链接，即可完成任务。过程比较简单，看源码吧：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; // 遍历链表，找到要删除的节点 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); // 将节点从链表中移除 return true; &#125; &#125; &#125; return false;&#125;public E remove(int index) &#123; checkElementIndex(index); // 通过 node 方法定位节点，并调用 unlink 将节点从链表中移除 return unlink(node(index));&#125;/** 将某个节点从链表中移除 */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // prev 为空，表明删除的是头节点 if (prev == null) &#123; first = next; &#125; else &#123; // 将 x 的前驱的后继指向 x 的后继 prev.next = next; // 将 x 的前驱引用置空，断开与前驱的链接 x.prev = null; &#125; // next 为空，表明删除的是尾节点 if (next == null) &#123; last = prev; &#125; else &#123; // 将 x 的后继的前驱指向 x 的前驱 next.prev = prev; // 将 x 的后继引用置空，断开与后继的链接 x.next = null; &#125; // 将 item 置空，方便 GC 回收 x.item = null; size--; modCount++; return element;&#125; 和插入操作一样，删除操作方法也是对底层方法的一层保证，核心逻辑在底层 unlink 方法中。所以长驱直入，直接分析 unlink 方法吧。unlink 方法的逻辑如下（假设删除的节点既不是头节点，也不是尾节点）： 1.将待删除节点 x 的前驱的后继指向 x 的后继 2.将待删除节点 x 的前驱引用置空，断开与前驱的链接 3.将待删除节点 x 的后继的前驱指向 x 的前驱 4.将待删除节点 x 的后继引用置空，断开与后继的链接 对应下图：结合上图，理解LinkedList删除操作应该不难。好了，LinkedList的删除源码分析就讲到这。 4.总结通过上面的分析，大家对LinkedList的底层实现应该很清楚了。总体来看LinkedList的源码并不复杂，大家耐心看一下，一般都能看懂。同时，通过本文，向大家展现了使用LinkedList的一个坑，希望大家在开发中尽量避免。下面是对LinkedList总结","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"LinkedList","slug":"LinkedList","permalink":"http://blog.shagle.cn/tags/LinkedList/"}]},{"title":"Java技术之System.arrayCopy方法详解","slug":"Java技术之System-arrayCopy方法详解","date":"2018-12-24T07:18:39.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/24/Java技术之System-arrayCopy方法详解/","link":"","permalink":"http://blog.shagle.cn/2018/12/24/Java技术之System-arrayCopy方法详解/","excerpt":"看 JDK 源码的时候，Java 开发设计者在对数组的复制时，通常都会使用 System.arraycopy() 方法。","text":"看 JDK 源码的时候，Java 开发设计者在对数组的复制时，通常都会使用 System.arraycopy() 方法。 其实对数组的复制，有四种方法： for clone System.arraycopy arrays.copyof 本文章主要分析 System.arraycopy() ，带着几个问题去看这个方法： 深复制，还是浅复制 String 的一维数组和二维数组复制是否有区别 线程安全，还是不安全 高效还是低效 System.arraycopy() 的 API ：1234567public static void arraycopy( Object src, //源数组 int srcPos, //源数组的起始位置 Object dest, //目标数组 int destPos, //目标数组的起始位置 int length //复制长度 ) 1. 深复制还是浅复制代码：对象数组的复制：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class SystemArrayCopyTestCase &#123; public static void main(String[] args) &#123; User[] users = new User[] &#123; new User(1, \"seven\", \"seven@qq.com\"), new User(2, \"six\", \"six@qq.com\"), new User(3, \"ben\", \"ben@qq.com\") &#125;;// 初始化对象数组 User[] target = new User[users.length];// 新建一个目标对象数组 System.arraycopy(users, 0, target, 0, users.length);// 实现复制 System.out.println(\"源对象与目标对象的物理地址是否一样：\" + (users[0] == target[0] ? \"浅复制\" : \"深复制\")); //浅复制 target[0].setEmail(\"admin@sina.com\"); System.out.println(\"修改目标对象的属性值后源对象users：\"); for (User user : users) &#123; System.out.println(user); &#125; // // // &#125;&#125;class User &#123; private Integer id; private String username; private String email; // 无参构造函数 public User() &#123; &#125; // 有参的构造函数 public User(Integer id, String username, String email) &#123; super(); this.id = id; this.username = username; this.email = email; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125; @Override public String toString() &#123; return \"User [id=\" + id + \", username=\" + username + \", email=\" + email + \"]\"; &#125;&#125; 图示：对象复制的图示所以，得出的结论是，System.arraycopy() 在拷贝数组的时候，采用的使用潜复制，复制结果是一维的引用变量传递给副本的一维数组，修改副本时，会影响原来的数组。 2. 一维数组和多维数组的复制的区别代码：一维数组的复制123456789101112131415161718String[] st = &#123;\"A\",\"B\",\"C\",\"D\",\"E\"&#125;;String[] dt = new String[5];System.arraycopy(st, 0, dt, 0, 5);//改变dt的值dt[3] = \"M\";dt[4] = \"V\";System.out.println(\"两个数组地址是否相同：\" + (st == dt)); //falsefor(String str : st)&#123; System.out.print(\" \" + str +\" \"); // A B C D E &#125;System.out.println(); for(String str : dt)&#123; System.out.print(\" \" + str +\" \"); // A B C M V &#125; 使用该方法对一维数组在进行复制之后，目标数组修改不会影响原数据，这种复制属性值传递，修改副本不会影响原来的值。 但是，请重点看以下代码：1234567891011121314String[] st = &#123;\"A\",\"B\",\"C\",\"D\",\"E\"&#125;;String[] dt = new String[5];System.arraycopy(st, 0, dt, 0, 5);for(String str : st)&#123; System.out.print(\" \" + str +\" \"); // A B C D E &#125;System.out.println(); for(String str : dt)&#123; System.out.print(\" \" + str +\" \"); // A B C D E &#125;System.out.println(\"数组内对应位置的String地址是否相同:\" + st[0] == dt[0]); // true 既然是属性值传递，为什么 st[0] == dt[0] 会相等呢? 我们再深入验证一下：12345678910111213141516String[] st = &#123;\"A\",\"B\",\"C\",\"D\",\"E\"&#125;;String[] dt = new String[5];System.arraycopy(st, 0, dt, 0, 5);dt[0] = \"F\" ;for(String str : st)&#123; System.out.print(\" \" + str +\" \"); // A B C D E &#125;System.out.println(); for(String str : dt)&#123; System.out.print(\" \" + str +\" \"); // F B C D E &#125;System.out.println(\"数组内对应位置的String地址是否相同:\" + st[0] == dt[0]); // false 为什么会出现以上的情况呢？ 通过以上两段代码可以推断，在System.arraycopy()进行复制的时候，首先检查了字符串常量池是否存在该字面量，一旦存在，则直接返回对应的内存地址，如不存在，则在内存中开辟空间保存对应的对象。 代码：二维数组的复制1234567891011121314151617181920212223242526272829303132333435363738394041String[][] s1 = &#123; &#123;\"A1\",\"B1\",\"C1\",\"D1\",\"E1\"&#125;, &#123;\"A2\",\"B2\",\"C2\",\"D2\",\"E2\"&#125;, &#123;\"A3\",\"B3\",\"C3\",\"D3\",\"E3\"&#125; &#125;;String[][] s2 = new String[s1.length][s1[0].length]; System.arraycopy(s1, 0, s2, 0, s2.length); for(int i = 0;i &lt; s1.length ;i++)&#123; for(int j = 0; j&lt; s1[0].length ;j++)&#123; System.out.print(\" \" + s1[i][j] + \" \"); &#125; System.out.println(); &#125; // A1 B1 C1 D1 E1 // A2 B2 C2 D2 E2 // A3 B3 C3 D3 E3 s2[0][0] = \"V\";s2[0][1] = \"X\";s2[0][2] = \"Y\";s2[0][3] = \"Z\";s2[0][4] = \"U\";System.out.println(\"----修改值后----\"); for(int i = 0;i &lt; s1.length ;i++)&#123; for(int j = 0; j&lt; s1[0].length ;j++)&#123; System.out.print(\" \" + s1[i][j] + \" \"); &#125; System.out.println(); &#125; // Z Y X Z U // A2 B2 C2 D2 E2 // A3 B3 C3 D3 E3 上述代码是对二维数组进行复制，数组的第一维装的是一个一维数组的引用，第二维里是元素数值。对二维数组进行复制后后，第一维的引用被复制给新数组的第一维，也就是两个数组的第一维都指向相同的“那些数组”。而这时改变其中任何一个数组的元素的值，其实都修改了“那些数组”的元素的值，所以原数组和新数组的元素值都一样了。 3. 线程安全，还是不安全代码：多线程对数组进行复制 (java中System.arraycopy是线程安全的吗？ ) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class ArrayCopyThreadSafe &#123; private static int[] arrayOriginal = new int[1024 * 1024 * 10]; private static int[] arraySrc = new int[1024 * 1024 * 10]; private static int[] arrayDist = new int[1024 * 1024 * 10]; private static ReentrantLock lock = new ReentrantLock(); private static void modify() &#123; for (int i = 0; i &lt; arraySrc.length; i++) &#123; arraySrc[i] = i + 1; &#125; &#125; private static void copy() &#123; System.arraycopy(arraySrc, 0, arrayDist, 0, arraySrc.length); &#125; private static void init() &#123; for (int i = 0; i &lt; arraySrc.length; i++) &#123; arrayOriginal[i] = i; arraySrc[i] = i; arrayDist[i] = 0; &#125; &#125; private static void doThreadSafeCheck() throws Exception &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(\"run count: \" + (i + 1)); init(); Condition condition = lock.newCondition(); new Thread(new Runnable() &#123; @Override public void run() &#123; lock.lock(); condition.signalAll(); lock.unlock(); copy(); &#125; &#125;).start(); lock.lock(); // 这里使用 Condition 来保证拷贝线程先已经运行了. condition.await(); lock.unlock(); Thread.sleep(2); // 休眠2毫秒, 确保拷贝操作已经执行了, 才执行修改操作. modify(); if (!Arrays.equals(arrayOriginal, arrayDist)) &#123; throw new RuntimeException(\"System.arraycopy is not thread safe\"); &#125; &#125; &#125; public static void main(String[] args) throws Exception &#123; doThreadSafeCheck(); &#125;&#125; 这个例子的具体操作是: 1.arrayOriginal 和 arraySrc 初始化时是相同的, 而 arrayDist 是全为零的. 2.启动一个线程运行 copy() 方法来拷贝 arraySrc 到 arrayDist 中. 3.在主线程执行 modify() 操作, 修改 arraySrc 的内容. 为了确保 copy() 操作先于 modify() 操作, 我使用 Condition, 并且延时了两毫秒, 以此来保证执行拷贝操作(即System.arraycopy) 先于修改操作. 4.根据第三点, 如果 System.arraycopy 是线程安全的, 那么先执行拷贝操作, 再执行修改操作时, 不会影响复制结果, 因此 arrayOriginal 必然等于 arrayDist; 而如果 System.arraycopy 是线程不安全的, 那么 arrayOriginal 不等于 arrayDist. 根据上面的推理, 运行一下程序, 有如下输出: 12345run count: 1run count: 2Exception in thread &quot;main&quot; java.lang.RuntimeException: System.arraycopy is not thread safe at com.test.ArrayCopyThreadSafe.doThreadSafeCheck(ArrayCopyThreadSafe.java:62) at com.test.ArrayCopyThreadSafe.main(ArrayCopyThreadSafe.java:68) 所以，System.arraycopy是不安全的。 4. 高效还是低效代码：for vs System.arraycopy 复制数组 1234567891011121314151617181920String[] srcArray = new String[1000000];String[] forArray = new String[srcArray.length];String[] arrayCopyArray = new String[srcArray.length];//初始化数组for(int index = 0 ; index &lt; srcArray.length ; index ++)&#123; srcArray[index] = String.valueOf(index);&#125;long forStartTime = System.currentTimeMillis();for(int index = 0 ; index &lt; srcArray.length ; index ++)&#123; forArray[index] = srcArray[index];&#125;long forEndTime = System.currentTimeMillis();System.out.println(\"for方式复制数组：\" + (forEndTime - forStartTime));long arrayCopyStartTime = System.currentTimeMillis();System.arraycopy(srcArray,0,arrayCopyArray,0,srcArray.length);long arrayCopyEndTime = System.currentTimeMillis();System.out.println(\"System.arraycopy复制数组：\" + (arrayCopyEndTime - arrayCopyStartTime)); 通过以上代码，当测试数组的范围比较小的时候，两者相差的时间无几，当测试数组的长度达到百万级别，System.arraycopy的速度优势就开始体现了，根据对底层的理解，System.arraycopy是对内存直接进行复制，减少了for循环过程中的寻址时间，从而提高了效能。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"System.arrayCopy","slug":"System-arrayCopy","permalink":"http://blog.shagle.cn/tags/System-arrayCopy/"}]},{"title":"Java技术之ArrayList源码分析","slug":"Java技术之ArrayList源码分析","date":"2018-12-24T05:34:35.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/24/Java技术之ArrayList源码分析/","link":"","permalink":"http://blog.shagle.cn/2018/12/24/Java技术之ArrayList源码分析/","excerpt":"概述 ArrayList是一种变长的集合类，基于定长数组实现。ArrayList允许空值和重复元素，当往ArrayList中添加的元素数量大于其底层数组容量时，其会通过扩容机制重新生成一个更大的数组。另外，由于ArrayList底层基于数组实现，所以其可以保证在O(1)复杂度下完成随机查找操作。其他方面，ArrayList是非线程安全类，并发环境下，多个线程同时操作ArrayList，会引发不可预知的错误。 ArrayList是大家最为常用的集合类，作为一个变长集合类，其核心是扩容机制。所以只要知道它是怎么扩容的，以及基本的操作是怎样实现就够了。本文后续内容也将围绕这些点展开叙述。","text":"概述 ArrayList是一种变长的集合类，基于定长数组实现。ArrayList允许空值和重复元素，当往ArrayList中添加的元素数量大于其底层数组容量时，其会通过扩容机制重新生成一个更大的数组。另外，由于ArrayList底层基于数组实现，所以其可以保证在O(1)复杂度下完成随机查找操作。其他方面，ArrayList是非线程安全类，并发环境下，多个线程同时操作ArrayList，会引发不可预知的错误。 ArrayList是大家最为常用的集合类，作为一个变长集合类，其核心是扩容机制。所以只要知道它是怎么扩容的，以及基本的操作是怎样实现就够了。本文后续内容也将围绕这些点展开叙述。 2.源码分析2.1 ArrayList属性ArrayList属性主要就是当前数组长度size，以及存放数组的对象elementData数组，除此之外还有一个经常用到的属性就是从AbstractList继承过来的modCount属性，代表ArrayList集合的修改次数。12345678910111213141516171819public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, Serializable &#123; // 序列化id private static final long serialVersionUID = 8683452581122892189L; // 默认初始的容量 private static final int DEFAULT_CAPACITY = 10; // 一个空对象 private static final Object[] EMPTY_ELEMENTDATA = new Object[0]; // 一个空对象，如果使用默认构造函数创建，则默认对象内容默认是该值 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = new Object[0]; // 当前数据对象存放地方，当前对象不参与序列化 transient Object[] elementData; // 当前数组长度 private int size; // 数组最大长度 private static final int MAX_ARRAY_SIZE = 2147483639; // 省略方法。。&#125; 2.2 构造方法ArrayList有三个个构造方法，一个是无参，另一个需传入初始容量值，还有一个是通过Collection构造的。大家平时最常用的是无参构造方法，相关代码如下：1234567891011121314151617181920212223242526 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125;&#125;public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125;public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 上面的代码比较简单，两个构造方法做的事情并不复杂，目的都是初始化底层数组elementData。区别在于无参构造方法会将elementData初始化一个空数组，插入元素时，扩容将会按默认值重新初始化数组。而有参的构造方法则会将elementData初始化为参数值大小（&gt;= 0）的数组。带Collection参数的构造函数： 1）将collection对象转换成数组，然后将数组的地址的赋给elementData。 2）更新size的值，同时判断size的大小，如果是size等于0，直接将空对象EMPTY_ELEMENTDATA的地址赋给elementData 3）如果size的值大于0，则执行Arrays.copy方法，把collection对象的内容（可以理解为深拷贝）copy到elementData中。 注意：this.elementData = arg0.toArray(); 这里执行的简单赋值时浅拷贝，所以要执行Arrays,copy 做深拷贝 一般情况下，我们用默认的构造方法即可。倘若在可知道将会向ArrayList插入多少元素的情况下，应该使用有参构造方法。按需分配，避免浪费。 2.3 插入对于数组（线性表）结构，插入操作分为两种情况。一种是在元素序列尾部插入，另一种是在元素序列其他位置插入。ArrayList的源码里也体现了这两种插入情况，如下：12345678910111213141516171819202122/** 在元素序列尾部插入 */public boolean add(E e) &#123; // 1. 检测是否需要扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // 2. 将新元素插入序列尾部 elementData[size++] = e; return true;&#125;/** 在元素序列 index 位置处插入 */public void add(int index, E element) &#123; rangeCheckForAdd(index); // 1. 检测是否需要扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // 2. 将 index 及其之后的所有元素都向后移一位 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 3. 将新元素插入至 index 处 elementData[index] = element; size++;&#125; 对于在元素序列尾部插入，这种情况比较简单，只需两个步骤即可： 检测数组是否有足够的空间插入将新元素插入至序列尾部如下图：如果是在元素序列指定位置（假设该位置合理）插入，则情况稍微复杂一点，需要三个步骤： 检测数组是否有足够的空间将 index 及其之后的所有元素向后移一位将新元素插入至 index 处如下图：从上图可以看出，将新元素插入至序列指定位置，需要先将该位置及其之后的元素都向后移动一位，为新元素腾出位置。这个操作的时间复杂度为O(N)，频繁移动元素可能会导致效率问题，特别是集合中元素数量较多时。在日常开发中，若非所需，我们应当尽量避免在大集合中调用第二个插入方法。 以上是ArrayList插入相关的分析，上面的分析以及配图均未体现扩容机制。那么下面就来简单分析一下ArrayList的扩容机制。对于变长数据结构，当结构中没有空余空间可供使用时，就需要进行扩容。在ArrayList中，当空间用完，其会按照原数组空间的1.5倍进行扩容。相关源码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243/** 计算最小容量,确保添加的元素有地方存储，当第一次添加元素的时候this.size+1 的值是1，所以第一次添加的时候会将当前`elementData`数组的长度变为10： */private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125;/** 扩容的入口方法 */private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;/** 将修改次数（modCount）自增1，判断是否需要扩充数组长度,判断条件就是用当前所需的数组最小长度与数组的长度对比，如果大于0，则增长数组长度。 */private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;/** 扩容的核心方法 ,如果当前的数组已使用空间（size）加1之后 大于数组长度，则增大数组容量，扩大为原来的1.5倍。*/private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // newCapacity = oldCapacity + oldCapacity / 2 = oldCapacity * 1.5 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 扩容 elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); // 如果最小容量超过 MAX_ARRAY_SIZE，则将数组容量扩容至 Integer.MAX_VALUE return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 总结： 1）确保数插入的位置小于等于当前数组长度，并且不小于0，否则抛出异常 2）确保数组已使用长度（size）加1之后足够存下 下一个数据 3）修改次数（modCount）标识自增1，如果当前数组已使用长度（size）加1后的大于当前的数组长度，则调用grow方法，增长数组 4）grow方法会将当前数组的长度变为原来容量的1.5倍。 5）确保有足够的容量之后，使用System.arraycopy 将需要插入的位置（index）后面的元素统统往后移动一位。 6）将新的数据内容存放到数组的指定位置（index）上 2.4 删除不同于插入操作，ArrayList没有无参删除方法。所以其只能删除指定位置的元素或删除指定元素，这样就无法避免移动元素（除非从元素序列的尾部删除）。相关代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** 删除指定位置的元素 */public E remove(int index) &#123; rangeCheck(index); modCount++; // 返回被删除的元素值 E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) // 将 index + 1 及之后的元素向前移动一位，覆盖被删除值 System.arraycopy(elementData, index+1, elementData, index, numMoved); // 将最后一个元素置空，并将 size 值减1 elementData[--size] = null; // clear to let GC do its work return oldValue;&#125;E elementData(int index) &#123; return (E) elementData[index];&#125;/** 删除指定元素，若元素重复，则只删除下标最小的元素 */public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; // 遍历数组，查找要删除元素的位置 for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;/** 快速删除，不做边界检查，也不返回删除的元素值 */private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; 上面的删除方法并不复杂，这里以第一个删除方法为例，删除一个元素步骤如下： 获取指定位置 index 处的元素值将 index + 1 及之后的元素向前移动一位将最后一个元素置空，并将 size 值减 1返回被删除值，完成删除操作如下图：上面就是删除指定位置元素的分析，并不是很复杂。 现在，考虑这样一种情况。我们往ArrayList插入大量元素后，又删除很多元素，此时底层数组会空闲处大量的空间。因为ArrayList没有自动缩容机制，导致底层数组大量的空闲空间不能被释放，造成浪费。对于这种情况，ArrayList也提供了相应的处理方法，如下：123456789/** 将数组容量缩小至元素数量 */public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125;&#125; 通过上面的方法，我们可以手动触发ArrayList的缩容机制。这样就可以释放多余的空间，提高空间利用率。 总结： 根据索引remove 1）判断索引有没有越界 2）自增修改次数 3）将指定位置（index）上的元素保存到oldValue 4）将指定位置（index）上的元素都往前移动一位 5）将最后面的一个元素置空，好让垃圾回收器回收 6）将原来的值oldValue返回 注意：调用这个方法不会缩减数组的长度，只是将最后一个数组元素置空而已。 根据对象remove 循环遍历所有对象，得到对象所在索引位置，然后调用fastRemove方法，执行remove操作 2.5 遍历ArrayList实现了 RandomAccess 接口（该接口是个标志性接口），表明它具有随机访问的能力。ArrayList底层基于数组实现，所以它可在常数阶的时间内完成随机访问，效率很高。对ArrayList进行遍历时，一般情况下，我们喜欢使用 foreach 循环遍历，但这并不是推荐的遍历方式。ArrayList具有随机访问的能力，如果在一些效率要求比较高的场景下，更推荐下面这种方式：123for (int i = 0; i &lt; list.size(); i++) &#123; list.get(i);&#125; 至于原因也不难理解，foreach 最终会被转换成迭代器遍历的形式，效率不如上面的遍历方式。 2.6 iterator方法interator方法返回的是一个内部类，由于内部类的创建默认含有外部的this指针，所以这个内部类可以调用到外部类的属性。123public Iterator&lt;E&gt; iterator() &#123; return new Itr();&#125; 一般的话，调用完iterator之后，我们会使用iterator做遍历，这里使用next做遍历的时候有个需要注意的地方，就是调用next的时候，可能会引发ConcurrentModificationException，当修改次数，与期望的修改次数（调用iterator方法时候的修改次数）不一致的时候，会发生该异常，详细我们看一下代码实现：123456789101112@SuppressWarnings(\"unchecked\")public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i];&#125; expectedModCount这个值是在用户调用ArrayList的iterator方法时候确定的，但是在这之后用户add，或者remove了ArrayList的元素，那么modCount就会改变，那么这个值就会不相等，将会引发ConcurrentModificationException异常，这个是在多线程使用情况下，比较常见的一个异常。1234final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125; 2.7 System.arraycopy 方法 参数 说明 src 原数组 srcPos 原数组 dest 目标数组 destPos 目标数组的起始位置 length 要复制的数组元素的数目 2.8 Arrays.copyOf方法original - 要复制的数组newLength - 要返回的副本的长度newType - 要返回的副本的类型其实Arrays.copyOf底层也是调用System.arraycopy实现的源码如下：1234567//基本数据类型（其他类似byte，short···）public static int[] copyOf(int[] original, int newLength) &#123; int[] copy = new int[newLength]; System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;&#125; 3.其他细节3.1 快速失败机制在 Java 集合框架中，很多类都实现了快速失败机制。该机制被触发时，会抛出并发修改异常ConcurrentModificationException，这个异常大家在平时开发中多多少少应该都碰到过。关于快速失败机制，ArrayList的注释里对此做了解释，这里引用一下： The iterators returned by this class’s iterator() and listIterator(int) methods are fail-fast if the list is structurally modified at any time after the iterator is created, in any way except through the iterator’s own ListIterator remove() or ListIterator add(Object) methods, the iterator will throw aConcurrentModificationException. Thus, in the face of concurrent modification, the iterator fails quickly and cleanly, rather than risking arbitrary, non-deterministic behavior at an undetermined time in the future. 上面注释大致意思是，ArrayList迭代器中的方法都是均具有快速失败的特性，当遇到并发修改的情况时，迭代器会快速失败，以避免程序在将来不确定的时间里出现不确定的行为。 以上就是 Java 集合框架中引入快速失败机制的原因，并不难理解，这里不多说了。 3.2 关于遍历时删除遍历时删除是一个不正确的操作，即使有时候代码不出现异常，但执行逻辑也会出现问题。关于这个问题，阿里巴巴 Java 开发手册里也有所提及。这里引用一下： 【强制】不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁。 相关代码（稍作修改）如下：12345678910List&lt;String&gt; a = new ArrayList&lt;String&gt;(); a.add(\"1\"); a.add(\"2\"); for (String temp : a) &#123; System.out.println(temp); if(\"1\".equals(temp))&#123; a.remove(temp); &#125; &#125;&#125; 相信有些朋友应该看过这个，并且也执行过上面的程序。上面的程序执行起来不会虽不会出现异常，但代码执行逻辑上却有问题，只不过这个问题隐藏的比较深。我们把 temp 变量打印出来，会发现只打印了数字1，2没打印出来。初看这个执行结果确实很让人诧异，不明原因。如果死抠上面的代码，我们很难找出原因，此时需要稍微转换一下思路。我们都知道 Java 中的 foreach 是个语法糖，编译成字节码后会被转成用迭代器遍历的方式。所以我们可以把上面的代码转换一下，等价于下面形式： 1234567891011List&lt;String&gt; a = new ArrayList&lt;&gt;();a.add(\"1\");a.add(\"2\");Iterator&lt;String&gt; it = a.iterator();while (it.hasNext()) &#123; String temp = it.next(); System.out.println(\"temp: \" + temp); if(\"1\".equals(temp))&#123; a.remove(temp); &#125;&#125; 这个时候，我们再去分析一下ArrayList的迭代器源码就能找出原因。123456789101112131415161718192021222324252627282930private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings(\"unchecked\") public E next() &#123; // 并发修改检测，检测不通过则抛出异常 checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; // 省略不相关的代码&#125; 我们一步一步执行一下上面的代码，第一次进入 while 循环时，一切正常，元素 1 也被删除了。但删除元素 1 后，就无法再进入 while 循环，此时 it.hasNext() 为 false。原因是删除元素 1 后，元素计数器 size = 1，而迭代器中的 cursor 也等于 1，从而导致 it.hasNext() 返回false。归根结底，上面的代码段没抛异常的原因是，循环提前结束，导致 next 方法没有机会抛异常。不信的话，大家可以把代码稍微修改一下，即可发现问题：123456789101112List&lt;String&gt; a = new ArrayList&lt;&gt;();a.add(\"1\");a.add(\"2\");a.add(\"3\");Iterator&lt;String&gt; it = a.iterator();while (it.hasNext()) &#123; String temp = it.next(); System.out.println(\"temp: \" + temp); if(\"1\".equals(temp))&#123; a.remove(temp); &#125;&#125; 以上是关于遍历时删除的分析，在日常开发中，我们要避免上面的做法。正确的做法使用迭代器提供的删除方法，而不是直接删除。 4.总结ArrayList自己实现了序列化和反序列化的方法，因为它自己实现了 private void writeObject(java.io.ObjectOutputStream s)和 private void readObject(java.io.ObjectInputStream s) 方法 ArrayList基于数组方式实现，无容量的限制（会扩容） 添加元素时可能要扩容（所以最好预判一下），删除元素时不会减少容量（若希望减少容量，trimToSize()），删除元素时，将删除掉的位置元素置为null，下次gc就会回收这些元素所占的内存空间。 线程不安全add(int index, E element)：添加元素到数组中指定位置的时候，需要将该位置及其后边所有的元素都整块向后复制一位 get(int index)：获取指定位置上的元素时，可以通过索引直接获取（O(1)）remove(Object o)需要遍历数组 remove(int index)不需要遍历数组，只需判断index是否符合条件即可，效率比remove(Object o)高*contains(E)需要遍历数组 使用iterator遍历可能会引发多线程异常","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"ArrayList","slug":"ArrayList","permalink":"http://blog.shagle.cn/tags/ArrayList/"}]},{"title":"Java并发之熔断Sentinel","slug":"Java并发之熔断Sentinel","date":"2018-12-22T13:32:30.000Z","updated":"2018-12-22T13:33:14.000Z","comments":true,"path":"2018/12/22/Java并发之熔断Sentinel/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java并发之熔断Sentinel/","excerpt":"","text":"","categories":[{"name":"Java并发","slug":"Java并发","permalink":"http://blog.shagle.cn/categories/Java并发/"}],"tags":[{"name":"Sentinel","slug":"Sentinel","permalink":"http://blog.shagle.cn/tags/Sentinel/"},{"name":"熔断","slug":"熔断","permalink":"http://blog.shagle.cn/tags/熔断/"}]},{"title":"Java技术之LockSupport","slug":"Java技术之LockSupport","date":"2018-12-22T13:30:52.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/22/Java技术之LockSupport/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java技术之LockSupport/","excerpt":"LockSupport是JDK中比较底层的类，用来创建锁和其他同步工具类的基本线程阻塞原语。","text":"LockSupport是JDK中比较底层的类，用来创建锁和其他同步工具类的基本线程阻塞原语。 Java锁和同步器框架的核心AQS:AbstractQueuedSynchronizer，就是通过调用LockSupport.park()和LockSupport.unpark()实现线程的阻塞和唤醒的。LockSupport很类似于二元信号量(只有1个许可证可供使用)，如果这个许可还没有被占用，当前线程获取许可并继续执行；如果许可已经被占用，当前线程阻塞，等待获取许可。 LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程，而且park()和unpark()不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”问题。因为park() 和 unpark()有许可的存在；调用 park() 的线程和另一个试图将其 unpark() 的线程之间的竞争将保持活性。 LockSupport函数列表12345678910111213141516// 返回提供给最近一次尚未解除阻塞的 park 方法调用的 blocker 对象，如果该调用不受阻塞，则返回 null。static Object getBlocker(Thread t)// 为了线程调度，禁用当前线程，除非许可可用。static void park()// 为了线程调度，在许可可用之前禁用当前线程。static void park(Object blocker)// 为了线程调度禁用当前线程，最多等待指定的等待时间，除非许可可用。static void parkNanos(long nanos)// 为了线程调度，在许可可用前禁用当前线程，并最多等待指定的等待时间。static void parkNanos(Object blocker, long nanos)// 为了线程调度，在指定的时限前禁用当前线程，除非许可可用。static void parkUntil(long deadline)// 为了线程调度，在指定的时限前禁用当前线程，除非许可可用。static void parkUntil(Object blocker, long deadline)// 如果给定线程的许可尚不可用，则使其可用。static void unpark(Thread thread) 说明:LockSupport是通过调用Unsafe函数中的接口实现阻塞和解除阻塞的。","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"LockSupport","slug":"LockSupport","permalink":"http://blog.shagle.cn/tags/LockSupport/"}]},{"title":"Java8注解","slug":"Java8注解","date":"2018-12-22T13:29:21.000Z","updated":"2018-12-22T13:38:58.000Z","comments":true,"path":"2018/12/22/Java8注解/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java8注解/","excerpt":"","text":"1. 目录 1.目录 2.元注解 3.@Retention 实例 说明 4.@Documented 实例 5.@Target 实例 说明 6.@Inherited 实例 说明 7.@Repeatable 实例 8.代码地址 9.系列导航 2. 元注解适用于其他注释的注释称为元注释。在 java.lang.annotation 中定义了几个元注释类型。 3. @Retention指定标记的注解如何存储: 属性 说明 RetentionPolicy.SOURCE 标记的注释只保留在源层中，编译器将忽略它。 RetentionPolicy.CLASS 编译器在编译时保留标记的注释，但是Java虚拟机(JVM)会忽略它。 RetentionPolicy.RUNTIME 标记的注释由JVM保留，以便运行时环境可以使用它。 3.1 实例123@Retention(RetentionPolicy.RUNTIME)public @interface MetadataDemo &#123;&#125; 3.2 说明 RetentionPolicy.RUNTIME运行时注解应该是使用最多的。 RetentionPolicy.SOURCE一般用于编译时注解的定义，比如 lombok 相关的注解。 4. @Documented@Documented 注解表明，无论何时使用指定的注释，都应该使用Javadoc工具对这些元素进行文档化。(默认情况下，注释不包含在Javadoc中。)有关更多信息，请参见Javadoc工具页。 实例1234@Retention(RetentionPolicy.CLASS)@Documentedpublic @interface MetadataDemo &#123;&#125; 5. @Target@Target批注标记另一个批注，以限制批注可以应用于何种Java元素。目标注释指定以下元素类型之一作为其值: 属性 说明 ElementType.ANNOTATION_TYPE 应用于注解类型 ElementType.CONSTRUCTOR 可以应用于构造函数 ElementType.FIELD 可以应用于字段或属性。 ElementType.LOCAL_VARIABLE 可以应用于一个局部变量 ElementType.METHOD 可以应用于方法级注释 ElementType.PACKAGE 应用于包声明 ElementType.PARAMETER 应用于方法的参数 ElementType.TYPE 应用于类的任何元素 5.1 实例12345@Retention(RetentionPolicy.CLASS)@Documented@Target(ElementType.METHOD)public @interface MetadataDemo &#123;&#125; 5.2 说明指定我们注解的应用范围非常重要。一般最常用的是 ElementType.TYPE 和 ElementType.METHOD 6. @Inherited@Inherited 表明注解类型可以从超类继承。(这在默认情况下是不对的。)当用户查询注释类型而该类没有对此类型的注释时，将查询类的超类以获取注释类型。此注释仅应用于类声明。 实例123456@Retention(RetentionPolicy.CLASS)@Documented@Target(ElementType.METHOD)@Inheritedpublic @interface MetadataDemo &#123;&#125; 说明 当一个类继承了拥有此注解的类时，即使当前类没有任何注解。只要父类的注解拥有(@Inherited)属性，则在子类中可以获取到此注解。 7. @Repeatable在Java SE 8中引入的 @Repeatable 注解表明标记的注解可以多次应用于相同的声明或类型使用。有关更多信息，请参见重复注释。 实例 Repeats.java 12345@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface Repeats &#123; Repeat[] value();&#125; Repeat.java 1234@Repeatable(value = Repeats.class)public @interface Repeat &#123; String value();&#125; RepeatDemo.java 1234567public class RepeatDemo &#123; @Repeat(value = \"tag\") @Repeat(value = \"tag2\") public void method() &#123; &#125;&#125; 8. 代码地址annotation metadata系列导航 原文：https://blog.csdn.net/ryo1060732496/article/details/80891093","categories":[{"name":"Java8","slug":"Java8","permalink":"http://blog.shagle.cn/categories/Java8/"}],"tags":[{"name":"java8","slug":"java8","permalink":"http://blog.shagle.cn/tags/java8/"},{"name":"annotation","slug":"annotation","permalink":"http://blog.shagle.cn/tags/annotation/"}]},{"title":"spring cloud ribbon 源码分析","slug":"spring-cloud-ribbon","date":"2018-12-22T13:25:32.000Z","updated":"2019-01-09T06:54:27.000Z","comments":true,"path":"2018/12/22/spring-cloud-ribbon/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-cloud-ribbon/","excerpt":"友情提示：本文较长，请选择一个较为舒适的姿势来阅读 “友情提示：本文较长，请选择一个较为舒适的姿势来阅读”)友情提示：本文较长，请选择一个较为舒适的姿势来阅读","text":"友情提示：本文较长，请选择一个较为舒适的姿势来阅读 “友情提示：本文较长，请选择一个较为舒适的姿势来阅读”)友情提示：本文较长，请选择一个较为舒适的姿势来阅读 1. @LoadBalanced 注解在之前介绍使用Ribbon进行服务消费的时候，我们用到了RestTemplate，但是熟悉Spring的同学们是否产生过这样的疑问：RestTemplate不是Spring自己就有的吗？跟Ribbon的客户端负载均衡又有什么关系呢？下面在本文，我们来看RestTemplate和Ribbon是如何联系起来并实现客户端负载均衡的。 首先，回顾一下之前的消费者示例：我们是如何实现客户端负载均衡的？仔细观察一下代码之前的代码，我们可以发现在消费者的例子中，可能就是这个注解@LoadBalanced是之前没有接触过的，并且从命名上来看也与负载均衡相关。我们不妨以此为线索来看看源码实现的机制。 从@LoadBalanced注解源码的注释中，我们可以知道该注解用来给RestTemplate标记，以使用负载均衡的客户端（LoadBalancerClient）来配置它。 通过搜索LoadBalancerClient，我们可以发现这是Spring Cloud中定义的一个接口： 123456789public interface LoadBalancerClient &#123; ServiceInstance choose(String serviceId); &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException; URI reconstructURI(ServiceInstance instance, URI original); &#125; 从该接口中，我们可以通过定义的抽象方法来了解到客户端负载均衡器中应具备的几种能力： ServiceInstance choose(String serviceId)：根据传入的服务名serviceId，从负载均衡器中挑选一个对应服务的实例。 T execute(String serviceId, LoadBalancerRequest request) throws IOException：使用从负载均衡器中挑选出的服务实例来执行请求内容。 URI reconstructURI(ServiceInstance instance, URI original)：为系统构建一个合适的“host:port”形式的URI。在分布式系统中，我们使用逻辑上的服务名称作为host来构建URI（替代服务实例的“host:port”形式）进行请求，比如：http://myservice/path/to/service。在该操作的定义中，前者ServiceInstance对象是带有host和port的具体服务实例，而后者URI对象则是使用逻辑服务名定义为host的URI，而返回的URI内容则是通过ServiceInstance的服务实例详情拼接出的具体“host:post”形式的请求地址。 顺着LoadBalancerClient接口的所属包org.springframework.cloud.client.loadbalancer，我们对其内容进行整理，可以得出如下图的关系： 从类的命名上我们初步判断LoadBalancerAutoConfiguration为实现客户端负载均衡器的自动化配置类。通过查看源码，我们可以验证这一点假设： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Configuration@ConditionalOnClass(RestTemplate.class)@ConditionalOnBean(LoadBalancerClient.class)public class LoadBalancerAutoConfiguration &#123; @LoadBalanced @Autowired(required = false) private List&lt;RestTemplate&gt; restTemplates = Collections.emptyList(); @Bean public SmartInitializingSingleton loadBalancedRestTemplateInitializer( final List&lt;RestTemplateCustomizer&gt; customizers) &#123; return new SmartInitializingSingleton() &#123; @Override public void afterSingletonsInstantiated() &#123; for (RestTemplate restTemplate : LoadBalancerAutoConfiguration.this.restTemplates) &#123; for (RestTemplateCustomizer customizer : customizers) &#123; customizer.customize(restTemplate); &#125; &#125; &#125; &#125;; &#125; @Bean @ConditionalOnMissingBean public RestTemplateCustomizer restTemplateCustomizer( final LoadBalancerInterceptor loadBalancerInterceptor) &#123; return new RestTemplateCustomizer() &#123; @Override public void customize(RestTemplate restTemplate) &#123; List&lt;ClientHttpRequestInterceptor&gt; list = new ArrayList&lt;&gt;( restTemplate.getInterceptors()); list.add(loadBalancerInterceptor); restTemplate.setInterceptors(list); &#125; &#125;; &#125; @Bean public LoadBalancerInterceptor ribbonInterceptor( LoadBalancerClient loadBalancerClient) &#123; return new LoadBalancerInterceptor(loadBalancerClient); &#125;&#125; 从LoadBalancerAutoConfiguration类头上的注解可以知道Ribbon实现的负载均衡自动化配置需要满足下面两个条件： @ConditionalOnClass(RestTemplate.class)：RestTemplate类必须存在于当前工程的环境中。 @ConditionalOnBean(LoadBalancerClient.class)：在Spring的Bean工程中有必须有LoadBalancerClient的实现Bean。 在该自动化配置类中，主要做了下面三件事： 创建了一个LoadBalancerInterceptor的Bean，用于实现对客户端发起请求时进行拦截，以实现客户端负载均衡。 创建了一个RestTemplateCustomizer的Bean，用于给RestTemplate增加LoadBalancerInterceptor拦截器。 维护了一个被@LoadBalanced注解修饰的RestTemplate对象列表，并在这里进行初始化，通过调用RestTemplateCustomizer的实例来给需要客户端负载均衡的RestTemplate增加LoadBalancerInterceptor拦截器。 接下来，我们看看LoadBalancerInterceptor拦截器是如何将一个普通的RestTemplate变成客户端负载均衡的： 123456789101112131415161718192021222324252627282930313233343536373839404142public class LoadBalancerInterceptor implements ClientHttpRequestInterceptor &#123; private LoadBalancerClient loadBalancer; public LoadBalancerInterceptor(LoadBalancerClient loadBalancer) &#123; this.loadBalancer = loadBalancer; &#125; @Override public ClientHttpResponse intercept(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException &#123; final URI originalUri = request.getURI(); String serviceName = originalUri.getHost(); return this.loadBalancer.execute(serviceName, new LoadBalancerRequest&lt;ClientHttpResponse&gt;() &#123; @Override public ClientHttpResponse apply(final ServiceInstance instance) throws Exception &#123; HttpRequest serviceRequest = new ServiceRequestWrapper(request, instance); return execution.execute(serviceRequest, body); &#125; &#125;); &#125; private class ServiceRequestWrapper extends HttpRequestWrapper &#123; private final ServiceInstance instance; public ServiceRequestWrapper(HttpRequest request, ServiceInstance instance) &#123; super(request); this.instance = instance; &#125; @Override public URI getURI() &#123; URI uri = LoadBalancerInterceptor.this.loadBalancer.reconstructURI( this.instance, getRequest().getURI()); return uri; &#125; &#125;&#125; 通过源码以及之前的自动化配置类，我们可以看到在拦截器中注入了LoadBalancerClient的实现。当一个被@LoadBalanced注解修饰的RestTemplate对象向外发起HTTP请求时，会被LoadBalancerInterceptor类的intercept函数所拦截。由于我们在使用RestTemplate时候采用了服务名作为host，所以直接从HttpRequest的URI对象中通过getHost()就可以拿到服务名，然后调用execute函数去根据服务名来选择实例并发起实际的请求。 分析到这里，LoadBalancerClient还只是一个抽象的负载均衡器接口，所以我们还需要找到它的具体实现类来进一步分析。通过查看ribbon的源码，我们可以很容易的在org.springframework.cloud.netflix.ribbon包下找到对应的实现类：RibbonLoadBalancerClient。 12345678910111213141516171819202122232425262728public &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request) throws IOException &#123; ILoadBalancer loadBalancer = getLoadBalancer(serviceId); Server server = getServer(loadBalancer); if (server == null) &#123; throw new IllegalStateException(\"No instances available for \" + serviceId); &#125; RibbonServer ribbonServer = new RibbonServer(serviceId, server, isSecure(server, serviceId), serverIntrospector(serviceId).getMetadata(server)); RibbonLoadBalancerContext context = this.clientFactory .getLoadBalancerContext(serviceId); RibbonStatsRecorder statsRecorder = new RibbonStatsRecorder(context, server); try &#123; T returnVal = request.apply(ribbonServer); statsRecorder.recordStats(returnVal); return returnVal; &#125; catch (IOException ex) &#123; statsRecorder.recordStats(ex); throw ex; &#125; catch (Exception ex) &#123; statsRecorder.recordStats(ex); ReflectionUtils.rethrowRuntimeException(ex); &#125; return null;&#125; 可以看到，在execute函数的实现中，第一步做的就是通过getServer根据传入的服务名serviceId去获得具体的服务实例：123456protected Server getServer(ILoadBalancer loadBalancer) &#123; if (loadBalancer == null) &#123; return null; &#125; return loadBalancer.chooseServer(\"default\"); &#125; 通过getServer函数的实现源码，我们可以看到这里获取具体服务实例的时候并没有使用LoadBalancerClient接口中的choose函数，而是使用了ribbon自身的ILoadBalancer接口中定义的chooseServer函数。 我们先来认识一下ILoadBalancer接口： 123456789101112131415161718192021222324252627282930313233343536373839404142public interface ILoadBalancer &#123; public void addServers(List&lt;Server&gt; newServers); public Server chooseServer(Object key); public void markServerDown(Server server); public List&lt;Server&gt; getReachableServers(); public List&lt;Server&gt; getAllServers();&#125;``` 可以看到，在该接口中定义了一个软负载均衡器需要的一系列抽象操作（未例举过期函数）：* `addServers`：向负载均衡器中维护的实例列表增加服务实例。* `chooseServer`：通过某种策略，从负载均衡器中挑选出一个具体的服务实例。* `markServerDown`：用来通知和标识负载均衡器中某个具体实例已经停止服务，不然负载均衡器在下一次获取服务实例清单前都会认为服务实例均是正常服务的。* `getReachableServers`：获取当前正常服务的实例列表。* `getAllServers`：获取所有已知的服务实例列表，包括正常服务和停止服务的实例。在该接口定义中涉及到的`Server`对象定义的是一个传统的服务端节点，在该类中存储了服务端节点的一些元数据信息，包括：host、port以及一些部署信息等。![](ribbon-code-2.png)而对于该接口的实现，我们可以整理出如上图所示的结构。我们可以看到`BaseLoadBalancer`类实现了基础的负载均衡，而`DynamicServerListLoadBalancer`和`ZoneAwareLoadBalancer`在负载均衡的策略上做了一些功能的扩展。那么在整合Ribbon的时候Spring Cloud默认采用了哪个具体实现呢？我们通过`RibbonClientConfiguration`配置类，可以知道在整合时默认采用了`ZoneAwareLoadBalancer`来实现负载均衡器。```java@Bean@ConditionalOnMissingBeanpublic ILoadBalancer ribbonLoadBalancer(IClientConfig config, ServerList&lt;Server&gt; serverList, ServerListFilter&lt;Server&gt; serverListFilter, IRule rule, IPing ping) &#123; ZoneAwareLoadBalancer&lt;Server&gt; balancer = LoadBalancerBuilder.newBuilder() .withClientConfig(config).withRule(rule).withPing(ping) .withServerListFilter(serverListFilter).withDynamicServerList(serverList) .buildDynamicServerListLoadBalancer(); return balancer;&#125; 下面，我们再回到RibbonLoadBalancerClient的execute函数逻辑，在通过ZoneAwareLoadBalancer的chooseServer函数获取了负载均衡策略分配到的服务实例对象Server之后，将其内容包装成RibbonServer对象（该对象除了存储了服务实例的信息之外，还增加了服务名serviceId、是否需要使用HTTPS等其他信息），然后使用该对象再回调LoadBalancerInterceptor请求拦截器中LoadBalancerRequest的apply(final ServiceInstance instance)函数，向一个实际的具体服务实例发起请求，从而实现一开始以服务名为host的URI请求，到实际访问host:post形式的具体地址的转换。 apply(final ServiceInstance instance)函数中传入的ServiceInstance接口是对服务实例的抽象定义。在该接口中暴露了服务治理系统中每个服务实例需要提供的一些基本信息，比如：serviceId、host、port等，具体定义如下：1234567891011121314public interface ServiceInstance &#123; String getServiceId(); String getHost(); int getPort(); boolean isSecure(); URI getUri(); Map&lt;String, String&gt; getMetadata(); &#125; 而上面提到的具体包装Server服务实例的RibbonServer对象就是ServiceInstance接口的实现，可以看到它除了包含了Server对象之外，还存储了服务名、是否使用https标识以及一个Map类型的元数据集合。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849protected static class RibbonServer implements ServiceInstance &#123; private final String serviceId; private final Server server; private final boolean secure; private Map&lt;String, String&gt; metadata; protected RibbonServer(String serviceId, Server server) &#123; this(serviceId, server, false, Collections.&lt;String, String&gt; emptyMap()); &#125; protected RibbonServer(String serviceId, Server server, boolean secure, Map&lt;String, String&gt; metadata) &#123; this.serviceId = serviceId; this.server = server; this.secure = secure; this.metadata = metadata; &#125; // 省略实现ServiceInstance的一些获取Server信息的get函数 // ...&#125;``` 那么`apply(final ServiceInstance instance)`函数，在接收到了具体`ServiceInstance`实例后，是如何通过`LoadBalancerClient`接口中的`reconstructURI`操作来组织具体请求地址的呢？@Override public ClientHttpResponse apply(final ServiceInstance instance) throws Exception &#123; HttpRequest serviceRequest = new ServiceRequestWrapper(request, instance); return execution.execute(serviceRequest, body); &#125; 从`apply`的实现中，我们可以看到它具体执行的时候，还传入了`ServiceRequestWrapper`对象，该对象继承了`HttpRequestWrapper`并重写了`getURI`函数，重写后的`getURI`会通过调用`LoadBalancerClient`接口的`reconstructURI`函数来重新构建一个URI来进行访问。```javaprivate class ServiceRequestWrapper extends HttpRequestWrapper &#123; private final ServiceInstance instance; // ... @Override public URI getURI() &#123; URI uri = LoadBalancerInterceptor.this.loadBalancer.reconstructURI( this.instance, getRequest().getURI()); return uri; &#125;&#125; 在LoadBalancerInterceptor拦截器中，ClientHttpRequestExecution的实例具体执行execution.execute(serviceRequest, body)时，会调用InterceptingClientHttpRequest下InterceptingRequestExecution类的execute函数，具体实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public ClientHttpResponse execute(HttpRequest request, byte[] body) throws IOException &#123; if (this.iterator.hasNext()) &#123; ClientHttpRequestInterceptor nextInterceptor = this.iterator.next(); return nextInterceptor.intercept(request, body, this); &#125; else &#123; ClientHttpRequest delegate = requestFactory.createRequest(request.getURI(), request.getMethod()); delegate.getHeaders().putAll(request.getHeaders()); if (body.length &gt; 0) &#123; StreamUtils.copy(body, delegate.getBody()); &#125; return delegate.execute(); &#125;&#125;``` 可以看到在创建请求的时候`requestFactory.createRequest(request.getURI(), request.getMethod());`，这里`request.getURI()`会调用之前介绍的`ServiceRequestWrapper`对象中重写的`getURI`函数。此时，它就会使用`RibbonLoadBalancerClient`中实现的`reconstructURI`来组织具体请求的服务实例地址。```javapublic URI reconstructURI(ServiceInstance instance, URI original) &#123; Assert.notNull(instance, \"instance can not be null\"); String serviceId = instance.getServiceId(); RibbonLoadBalancerContext context = this.clientFactory .getLoadBalancerContext(serviceId); Server server = new Server(instance.getHost(), instance.getPort()); boolean secure = isSecure(server, serviceId); URI uri = original; if (secure) &#123; uri = UriComponentsBuilder.fromUri(uri).scheme(\"https\").build().toUri(); &#125; return context.reconstructURIWithServer(server, uri);&#125;``` 从`reconstructURI`函数中，我们可以看到，它通过`ServiceInstance`实例对象的`serviceId`，从`SpringClientFactory`类的`clientFactory`对象中获取对应`serviceId`的负载均衡器的上下文`RibbonLoadBalancerContext`对象。然后根据`ServiceInstance`中的信息来构建具体服务实例信息的`Server`对象，并使用`RibbonLoadBalancerContext`对象的`reconstructURIWithServer`函数来构建服务实例的URI。为了帮助理解，简单介绍一下上面提到的`SpringClientFactory`和`RibbonLoadBalancerContext`：* `SpringClientFactory`类是一个用来创建客户端负载均衡器的工厂类，该工厂会为每一个不同名的ribbon客户端生成不同的Spring上下文。* `RibbonLoadBalancerContext`类是`LoadBalancerContext`的子类，该类用于存储一些被负载均衡器使用的上下文内容和Api操作（`reconstructURIWithServer`就是其中之一）。从`reconstructURIWithServer`的实现中我们可以看到，它同`reconstructURI`的定义类似。只是`reconstructURI`的第一个保存具体服务实例的参数使用了Spring Cloud定义的`ServiceInstance`，而`reconstructURIWithServer`中使用了Netflix中定义的`Server`，所以在`RibbonLoadBalancerClient`实现`reconstructURI`时候，做了一次转换，使用`ServiceInstance`的host和port信息来构建了一个`Server`对象来给`reconstructURIWithServer`使用。从`reconstructURIWithServer`的实现逻辑中，我们可以看到，它从`Server`对象中获取host和port信息，然后根据以服务名为host的`URI`对象original中获取其他请求信息，将两者内容进行拼接整合，形成最终要访问的服务实例的具体地址。```javapublic class LoadBalancerContext implements IClientConfigAware &#123; ... public URI reconstructURIWithServer(Server server, URI original) &#123; String host = server.getHost(); int port = server .getPort(); if (host.equals(original.getHost()) &amp;&amp; port == original.getPort()) &#123; return original; &#125; String scheme = original.getScheme(); if (scheme == null) &#123; scheme = deriveSchemeAndPortFromPartialUri(original).first(); &#125; try &#123; StringBuilder sb = new StringBuilder(); sb.append(scheme).append(\"://\"); if (!Strings.isNullOrEmpty(original.getRawUserInfo())) &#123; sb.append(original.getRawUserInfo()).append(\"@\"); &#125; sb.append(host); if (port &gt;= 0) &#123; sb.append(\":\").append(port); &#125; sb.append(original.getRawPath()); if (!Strings.isNullOrEmpty(original.getRawQuery())) &#123; sb.append(\"?\").append(original.getRawQuery()); &#125; if (!Strings.isNullOrEmpty(original.getRawFragment())) &#123; sb.append(\"#\").append(original.getRawFragment()); &#125; URI newURI = new URI(sb.toString()); return newURI; &#125; catch (URISyntaxException e) &#123; throw new RuntimeException(e); &#125; &#125; ...&#125; 另外，从RibbonLoadBalancerClient的execute的函数逻辑中，我们还能看到在回调拦截器中，执行具体的请求之后，ribbon还通过RibbonStatsRecorder对象对服务的请求还进行了跟踪记录，这里不再展开说明，有兴趣的读者可以继续研究。 分析到这里，我们已经可以大致理清Spring Cloud中使用Ribbon实现客户端负载均衡的基本脉络。了解了它是如何通过LoadBalancerInterceptor拦截器对RestTemplate的请求进行拦截，并利用Spring Cloud的负载均衡器LoadBalancerClient将以逻辑服务名为host的URI转换成具体的服务实例的过程。同时通过分析LoadBalancerClient的Ribbon实现RibbonLoadBalancerClient，可以知道在使用Ribbon实现负载均衡器的时候，实际使用的还是Ribbon中定义的ILoadBalancer接口的实现，自动化配置会采用ZoneAwareLoadBalancer的实例来进行客户端负载均衡实现。 2 负载均衡器通过之前的分析，我们已经对Spring Cloud如何使用Ribbon有了基本的了解。虽然Spring Cloud中定义了LoadBalancerClient为负载均衡器的接口，并且针对Ribbon实现了RibbonLoadBalancerClient，但是它在具体实现客户端负载均衡时，则是通过Ribbon的ILoadBalancer接口实现。在上一节分析时候，我们对该接口的实现结构已经做了一些简单的介绍，下面我们根据ILoadBalancer接口的实现类逐个看看它都是如何实现客户端负载均衡的。 2.1 AbstractLoadBalancerAbstractLoadBalancer是ILoadBalancer接口的抽象实现。在该抽象类中定义了一个关于服务实例的分组枚举类ServerGroup，它包含了三种不同类型：ALL-所有服务实例、STATUS_UP-正常服务的实例、STATUS_NOT_UP-停止服务的实例；实现了一个chooseServer()函数，该函数通过调用接口中的chooseServer(Object key)实现，其中参数key为null，表示在选择具体服务实例时忽略key的条件判断；最后还定义了两个抽象函数，getServerList(ServerGroup serverGroup)定义了根据分组类型来获取不同的服务实例列表，getLoadBalancerStats()定义了获取LoadBalancerStats对象的方法，LoadBalancerStats对象被用来存储负载均衡器中各个服务实例当前的属性和统计信息，这些信息非常有用，我们可以利用这些信息来观察负载均衡器的运行情况，同时这些信息也是用来制定负载均衡策略的重要依据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public abstract class AbstractLoadBalancer implements ILoadBalancer &#123; public enum ServerGroup&#123; ALL, STATUS_UP, STATUS_NOT_UP &#125; public Server chooseServer() &#123; return chooseServer(null); &#125; public abstract List&lt;Server&gt; getServerList(ServerGroup serverGroup); public abstract LoadBalancerStats getLoadBalancerStats();&#125;``` ## 2.2 BaseLoadBalancer`BaseLoadBalancer`类是Ribbon负载均衡器的基础实现类，在该类中定义很多关于均衡负载器相关的基础内容：* 定义并维护了两个存储服务实例`Server`对象的列表。一个用于存储所有服务实例的清单，一个用于存储正常服务的实例清单。```java @Monitor(name = PREFIX + \"AllServerList\", type = DataSourceType.INFORMATIONAL) protected volatile List&lt;Server&gt; allServerList = Collections .synchronizedList(new ArrayList&lt;Server&gt;()); @Monitor(name = PREFIX + \"UpServerList\", type = DataSourceType.INFORMATIONAL) protected volatile List&lt;Server&gt; upServerList = Collections .synchronizedList(new ArrayList&lt;Server&gt;()); ``` * 定义了之前我们提到的用来存储负载均衡器各服务实例属性和统计信息的`LoadBalancerStats`对象。 * 定义了检查服务实例是否正常服务的`IPing`对象，在`BaseLoadBalancer`中默认为null，需要在构造时注入它的具体实现。* 定义了检查服务实例操作的执行策略对象`IPingStrategy`，在`BaseLoadBalancer`中默认使用了该类中定义的静态内部类`SerialPingStrategy`实现。根据源码，我们可以看到该策略采用线性遍历ping服务实例的方式实现检查。该策略在当我们实现的`IPing`速度不理想，或是`Server`列表过大时，可能变的不是很为理想，这时候我们需要通过实现`IPingStrategy`接口并实现`pingServers(IPing ping, Server[] servers)`函数去扩展ping的执行策略。```javaprivate static class SerialPingStrategy implements IPingStrategy &#123; @Override public boolean[] pingServers(IPing ping, Server[] servers) &#123; int numCandidates = servers.length; boolean[] results = new boolean[numCandidates]; if (logger.isDebugEnabled()) &#123; logger.debug(\"LoadBalancer: PingTask executing [\" + numCandidates + \"] servers configured\"); &#125; for (int i = 0; i &lt; numCandidates; i++) &#123; results[i] = false; try &#123; if (ping != null) &#123; results[i] = ping.isAlive(servers[i]); &#125; &#125; catch (Throwable t) &#123; logger.error(\"Exception while pinging Server:\" + servers[i], t); &#125; &#125; return results; &#125;&#125;``` * 定义了负载均衡的处理规则`IRule`对象，从`BaseLoadBalancer`中`chooseServer(Object key)`的实现源码，我们可以知道负载均衡器实际进行服务实例选择任务是委托给了`IRule`实例中的`choose`函数来实现。而在这里，默认初始化了`RoundRobinRule`为`IRule`的实现对象。`RoundRobinRule`实现了最基本且常用的线性负载均衡规则。```javapublic Server chooseServer(Object key) &#123; if (counter == null) &#123; counter = createCounter(); &#125; counter.increment(); if (rule == null) &#123; return null; &#125; else &#123; try &#123; return rule.choose(key); &#125; catch (Throwable t) &#123; return null; &#125; &#125;&#125; 启动ping任务：在BaseLoadBalancer的默认构造函数中，会直接启动一个用于定时检查Server是否健康的任务。该任务默认的执行间隔为：10秒。 实现了ILoadBalancer接口定义的负载均衡器应具备的一系列基本操作： addServers(List newServers)：向负载均衡器中增加新的服务实例列表，该实现将原本已经维护着的所有服务实例清单allServerList和新传入的服务实例清单newServers都加入到newList中，然后通过调用setServersList函数对newList进行处理，在BaseLoadBalancer中实现的时候会使用新的列表覆盖旧的列表。而之后介绍的几个扩展实现类对于服务实例清单更新的优化都是对setServersList函数的重写来实现的。 12345678910111213141516171819202122232425262728293031323334353637public void addServers(List&lt;Server&gt; newServers) &#123; if (newServers != null &amp;&amp; newServers.size() &gt; 0) &#123; try &#123; ArrayList&lt;Server&gt; newList = new ArrayList&lt;Server&gt;(); newList.addAll(allServerList); newList.addAll(newServers); setServersList(newList); &#125; catch (Exception e) &#123; logger.error(\"Exception while adding Servers\", e); &#125; &#125;&#125;``` * `chooseServer(Object key)`：挑选一个具体的服务实例，在上面介绍`IRule`的时候，已经做了说明，这里不再赘述。 * `markServerDown(Server server)`：标记某个服务实例暂停服务。```javapublic void markServerDown(Server server) &#123; if (server == null) &#123; return; &#125; if (!server.isAlive()) &#123; return; &#125; logger.error(\"LoadBalancer: markServerDown called on [\" + server.getId() + \"]\"); server.setAlive(false); notifyServerStatusChangeListener(singleton(server));&#125;``` * `getReachableServers()`：获取可用的服务实例列表。由于`BaseLoadBalancer`中单独维护了一个正常服务的实例清单，所以直接返回即可。 ```java public List&lt;Server&gt; getReachableServers() &#123; return Collections.unmodifiableList(upServerList); &#125; getAllServers()：获取所有的服务实例列表。由于BaseLoadBalancer中单独维护了一个所有服务的实例清单，所以也直接返回它即可。 123public List&lt;Server&gt; getAllServers() &#123; return Collections.unmodifiableList(allServerList); &#125; 2.3 DynamicServerListLoadBalancerDynamicServerListLoadBalancer类继承于BaseLoadBalancer类，它是对基础负载均衡器的扩展。在该负载均衡器中，实现了服务实例清单的在运行期的动态更新能力；同时，它还具备了对服务实例清单的过滤功能，也就是说我们可以通过过滤器来选择性的获取一批服务实例清单。下面我们具体来看看在该类中增加了一些什么内容： 2.3.1 ServerList从DynamicServerListLoadBalancer的成员定义中，我们马上可以发现新增了一个关于服务列表的操作对象：ServerList&lt;T&gt; serverListImpl。其中泛型T从类名中对于T的限定DynamicServerListLoadBalancer&lt;T extends Server&gt;可以获知它是一个Server的子类，即代表了一个具体的服务实例的扩展类。而ServerList接口定义如下所示：123456public interface ServerList&lt;T extends Server\\&gt; &#123; public List&lt;T&gt; getInitialListOfServers(); public List&lt;T&gt; getUpdatedListOfServers(); &#125; 它定义了两个抽象方法：getInitialListOfServers用于获取初始化的服务实例清单，而getUpdatedListOfServers用于获取更新的服务实例清单。那么该接口的实现有哪些呢？通过搜索源码，我们可以整出如下图的结构： 从图中我们可以看到有很多个ServerList的实现类，那么在DynamicServerListLoadBalancer中的ServerList默认配置到底使用了哪个具体实现呢？既然在该负载均衡器中需要实现服务实例的动态更新，那么势必需要ribbon具备访问eureka来获取服务实例的能力，所以我们从Spring Cloud整合ribbon与eureka的包org.springframework.cloud.netflix.ribbon.eureka下探索，可以找到配置类EurekaRibbonClientConfiguration，在该类中可以找到看到下面创建ServerList实例的内容： 123456789101112131415161718192021222324252627282930313233343536373839404142@Bean@ConditionalOnMissingBeanpublic ServerList&lt;?&gt; ribbonServerList(IClientConfig config) &#123; DiscoveryEnabledNIWSServerList discoveryServerList = new DiscoveryEnabledNIWSServerList( config); DomainExtractingServerList serverList = new DomainExtractingServerList( discoveryServerList, config, this.approximateZoneFromHostname); return serverList;&#125;``` 可以看到，这里创建的是一个`DomainExtractingServerList`实例，从下面它的源码中我们可以看到在它内部还定义了一个`ServerList list`。同时，`DomainExtractingServerList`类中对`getInitialListOfServers`和`getUpdatedListOfServers`的具体实现，其实委托给了内部定义的`ServerList list`对象，而该对象是通过创建`DomainExtractingServerList`时候，由构造函数传入的`DiscoveryEnabledNIWSServerList`实现的。```javapublic class DomainExtractingServerList implements ServerList&lt;DiscoveryEnabledServer&gt; &#123; private ServerList&lt;DiscoveryEnabledServer&gt; list; private IClientConfig clientConfig; private boolean approximateZoneFromHostname; public DomainExtractingServerList(ServerList&lt;DiscoveryEnabledServer&gt; list, IClientConfig clientConfig, boolean approximateZoneFromHostname) &#123; this.list = list; this.clientConfig = clientConfig; this.approximateZoneFromHostname = approximateZoneFromHostname; &#125; @Override public List&lt;DiscoveryEnabledServer&gt; getInitialListOfServers() &#123; List&lt;DiscoveryEnabledServer&gt; servers = setZones(this.list .getInitialListOfServers()); return servers; &#125; @Override public List&lt;DiscoveryEnabledServer&gt; getUpdatedListOfServers() &#123; List&lt;DiscoveryEnabledServer&gt; servers = setZones(this.list .getUpdatedListOfServers()); return servers; &#125; ...&#125; 那么DiscoveryEnabledNIWSServerList是如何实现这两个服务实例的获取的呢？我们从源码中可以看到这两个方法都是通过该类中的一个私有函数obtainServersViaDiscovery来通过服务发现机制来实现服务实例的获取。 123456789101112131415161718192021222324252627282930313233343536373839404142@Overridepublic List&lt;DiscoveryEnabledServer&gt; getInitialListOfServers()&#123; return obtainServersViaDiscovery();&#125;@Overridepublic List&lt;DiscoveryEnabledServer&gt; getUpdatedListOfServers()&#123; return obtainServersViaDiscovery();&#125;``` 而`obtainServersViaDiscovery`的实现逻辑如下，主要依靠`EurekaClient`从服务注册中心中获取到具体的服务实例`InstanceInfo`列表（`EurekaClient`的具体实现，我们在分析Eureka的源码时已经做了详细的介绍，这里传入的`vipAddress`可以理解为逻辑上的服务名，比如“USER-SERVICE”）。接着，对这些服务实例进行遍历，将状态为“UP”（正常服务）的实例转换成`DiscoveryEnabledServer`对象，最后将这些实例组织成列表返回。```javaprivate List&lt;DiscoveryEnabledServer&gt; obtainServersViaDiscovery() &#123; List&lt;DiscoveryEnabledServer&gt; serverList = new ArrayList&lt;DiscoveryEnabledServer&gt;(); if (eurekaClientProvider == null || eurekaClientProvider.get() == null) &#123; logger.warn(\"EurekaClient has not been initialized yet, returning an empty list\"); return new ArrayList&lt;DiscoveryEnabledServer&gt;(); &#125; EurekaClient eurekaClient = eurekaClientProvider.get(); if (vipAddresses!=null)&#123; for (String vipAddress : vipAddresses.split(\",\")) &#123; List&lt;InstanceInfo&gt; listOfInstanceInfo = eurekaClient.getInstancesByVipAddress( vipAddress, isSecure, targetRegion); for (InstanceInfo ii : listOfInstanceInfo) &#123; if (ii.getStatus().equals(InstanceStatus.UP)) &#123; // 省略了一些实例信息的加工逻辑 DiscoveryEnabledServer des = new DiscoveryEnabledServer(ii, isSecure, shouldUseIpAddr); des.setZone(DiscoveryClient.getZone(ii)); serverList.add(des); &#125; &#125; if (serverList.size()&gt;0 &amp;&amp; prioritizeVipAddressBasedServers)&#123; break; &#125; &#125; &#125; return serverList;&#125; 在DiscoveryEnabledNIWSServerList中通过EurekaClient从服务注册中心获取到最新的服务实例清单后，返回的List到了DomainExtractingServerList类中，将继续通过setZones函数进行处理，而这里的处理具体内容如下，主要完成将DiscoveryEnabledNIWSServerList返回的List列表中的元素，转换成内部定义的DiscoveryEnabledServer的子类对象DomainExtractingServer，在该对象的构造函数中将为服务实例对象设置一些必要的属性，比如id、zone、isAliveFlag、readyToServe等信息。 123456789101112131415161718192021222324252627private List&lt;DiscoveryEnabledServer&gt; setZones(List&lt;DiscoveryEnabledServer&gt; servers) &#123; List&lt;DiscoveryEnabledServer&gt; result = new ArrayList&lt;&gt;(); boolean isSecure = this.clientConfig.getPropertyAsBoolean( CommonClientConfigKey.IsSecure, Boolean.TRUE); boolean shouldUseIpAddr = this.clientConfig.getPropertyAsBoolean( CommonClientConfigKey.UseIPAddrForServer, Boolean.FALSE); for (DiscoveryEnabledServer server : servers) &#123; result.add(new DomainExtractingServer(server, isSecure, shouldUseIpAddr, this.approximateZoneFromHostname)); &#125; return result;&#125;``` ### 2.3.2 ServerListUpdater通过上面的分析我们已经知道了Ribbon与Eureka整合后，如何实现从Eureka Server中获取服务实例清单。那么它又是如何触发向Eureka Server去获取服务实例清单以及如何在获取到服务实例清单后更新本地的服务实例清单的呢？继续来看`DynamicServerListLoadBalancer`中的实现内容，我们可以很容易的找到下面定义的关于`ServerListUpdater`的内容：```javaprotected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() &#123; @Override public void doUpdate() &#123; updateListOfServers(); &#125;&#125;;protected volatile ServerListUpdater serverListUpdater; 根据该接口的命名，我们基本就能猜到，这个对象实现的是对ServerList的更新，所以可以称它为“服务更新器”，从下面的源码中可以看到，在ServerListUpdater内部还定义了一个UpdateAction接口，上面定义的updateAction对象就是以匿名内部类的方式创建了一个它的具体实现，其中doUpdate实现的内容就是对ServerList的具体更新操作。除此之外，“服务更新器”中还定义了一系列控制它和获取它一些信息的操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public interface ServerListUpdater &#123; public interface UpdateAction &#123; void doUpdate(); &#125; // 启动服务更新器，传入的UpdateAction对象为更新操作的具体实现。 void start(UpdateAction updateAction); // 停止服务更新器 void stop(); // 获取最近的更新时间戳 String getLastUpdate(); // 获取上一次更新到现在的时间间隔，单位为毫秒 long getDurationSinceLastUpdateMs(); // 获取错过的更新周期数 int getNumberMissedCycles(); // 获取核心线程数 int getCoreThreads();&#125;``` 而`ServerListUpdater`的实现类不多，具体下图所示。![](ribbon-code-4.png)根据两个类的注释，我们可以很容易的知道它们的作用分别是：* `PollingServerListUpdater`：动态服务列表更新的默认策略，也就是说`DynamicServerListLoadBalancer`负载均衡器中的默认实现就是它，它通过定时任务的方式进行服务列表的更新。* `EurekaNotificationServerListUpdater`：该更新器也可服务于`DynamicServerListLoadBalancer`负载均衡器，但是它的触发机制与`PollingServerListUpdater`不同，它需要利用Eureka的事件监听器来驱动服务列表的更新操作。下面我们来详细看看它默认实现的`PollingServerListUpdater`。先从用于启动“服务更新器”的`start`函数源码看起，具体如下。我们可以看到`start`函数的实现内容验证了之前提到的：以定时任务的方式进行服务列表的更新。它先创建了一个`Runnable`的线程实现，在该实现中调用了上面提到的具体更新服务实例列表的方法`updateAction.doUpdate()`，最后再为这个`Runnable`的线程实现启动了一个定时任务来执行。```java@Overridepublic synchronized void start(final UpdateAction updateAction) &#123; if (isActive.compareAndSet(false, true)) &#123; final Runnable wrapperRunnable = new Runnable() &#123; @Override public void run() &#123; if (!isActive.get()) &#123; if (scheduledFuture != null) &#123; scheduledFuture.cancel(true); &#125; return; &#125; try &#123; updateAction.doUpdate(); lastUpdated = System.currentTimeMillis(); &#125; catch (Exception e) &#123; logger.warn(\"Failed one update cycle\", e); &#125; &#125; &#125;; scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay( wrapperRunnable, initialDelayMs, refreshIntervalMs, TimeUnit.MILLISECONDS ); &#125; else &#123; logger.info(\"Already active, no-op\"); &#125;&#125; 继续看PollingServerListUpdater的其他内容，我们可以找到用于启动定时任务的2个重要参数initialDelayMs和refreshIntervalMs的默认定义分别为1000和30*1000，单位为毫秒。也就是说更新服务实例在初始化之后延迟1秒后开始执行，并以30秒为周期重复执行。除了这些内容之外，我们还能看到它还会记录最后更新时间、是否存活等信息，同时也实现了ServerListUpdater中定义的一些其他操作内容，这些操作相对比较简单，这里不再具体说明，有兴趣的读者可以自己查看源码了解其实现原理。 2.3.3 ServerListFilter在了解了更新服务实例的定时任务是如何启动的之后，我们继续回到updateAction.doUpdate()调用的具体实现位置，在DynamicServerListLoadBalancer中，它的实际实现委托给了updateListOfServers函数，具体实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361public void updateListOfServers() &#123; List&lt;T&gt; servers = new ArrayList&lt;T&gt;(); if (serverListImpl != null) &#123; servers = serverListImpl.getUpdatedListOfServers(); LOGGER.debug(\"List of Servers for &#123;&#125; obtained from Discovery client: &#123;&#125;\", getIdentifier(), servers); if (filter != null) &#123; servers = filter.getFilteredListOfServers(servers); LOGGER.debug(\"Filtered List of Servers for &#123;&#125; obtained from Discovery client: &#123;&#125;\", getIdentifier(), servers); &#125; &#125; updateAllServerList(servers);&#125;``` 可以看到，这里终于用到了我们之前提到的`ServerList`的`getUpdatedListOfServers`，通过之前的介绍我们已经可以知道这一步实现了从Eureka Server中获取服务可用实例的列表。在获得了服务实例列表之后，这里又将引入一个新的对象`filter`，追朔该对象的定义，我们可以找到它是`ServerListFilter`定义的。`ServerListFilter`接口非常简单，该接口中之定义了一个方法`List getFilteredListOfServers(List servers)`，主要用于实现对服务实例列表的过滤，通过传入的服务实例清单，根据一些规则返回过滤后的服务实例清单。该接口的实现如下图所示：![](ribbon-code-6.png)其中，除了`ZonePreferenceServerListFilter`的实现是Spring Cloud Netflix中对Ribbon的扩展实现外，其他均是Netflix Ribbon中的实现类。我们可以分别看看这些过滤器实现都有什么特点：* `AbstractServerListFilter`：这是一个抽象过滤器，在这里定义了过滤时需要的一个重要依据对象`LoadBalancerStats`，我们在之前介绍过的，该对象存储了关于负载均衡器的一些属性和统计信息等。```javapublic abstract class AbstractServerListFilter&lt;T extends Server&gt; implements ServerListFilter&lt;T&gt; &#123; private volatile LoadBalancerStats stats; public void setLoadBalancerStats(LoadBalancerStats stats) &#123; this.stats = stats; &#125; public LoadBalancerStats getLoadBalancerStats() &#123; return stats; &#125;&#125;``` * `ZoneAffinityServerListFilter`：该过滤器基于“区域感知（Zone Affinity）”的方式实现服务实例的过滤，也就是说它会根据提供服务的实例所处区域（Zone）与消费者自身的所处区域（Zone）进行比较，过滤掉那些不是同处一个区域的实例。```javapublic List&lt;T&gt; getFilteredListOfServers(List&lt;T&gt; servers) &#123; if (zone != null &amp;&amp; (zoneAffinity || zoneExclusive) &amp;&amp; servers !=null &amp;&amp; servers.size() &gt; 0)&#123; List&lt;T&gt; filteredServers = Lists.newArrayList(Iterables.filter( servers, this.zoneAffinityPredicate.getServerOnlyPredicate())); if (shouldEnableZoneAffinity(filteredServers)) &#123; return filteredServers; &#125; else if (zoneAffinity) &#123; overrideCounter.increment(); &#125; &#125; return servers;&#125;``` 从上面的源码中我们可以看到，对于服务实例列表的过滤是通过`Iterables.filter(servers, this.zoneAffinityPredicate.getServerOnlyPredicate())`来实现的，其中判断依据由`ZoneAffinityPredicate`实现服务实例与消费者的Zone比较。而在过滤之后，这里并不会马上返回过滤的结果，而是通过`shouldEnableZoneAffinity`函数来判断是否要启用“区域感知”的功能，从下面`shouldEnableZoneAffinity`的实现中，我们可以看到，它使用了`LoadBalancerStats`的`getZoneSnapshot`方法来获取这些过滤后的同区域实例的基础指标（包含了：实例数量、断路器断开数、活动请求数、实例平均负载等），根据一系列的算法求出下面的几个评价值并与设置的阈值对比（下面的为默认值），若有一个条件符合，就不启用“区域感知”过滤的服务实例清单。这一算法实现对于集群出现区域故障时，依然可以依靠其他区域的实例进行正常服务提供了完善的高可用保障。同时，通过这里的介绍，我们也可以关联着来理解之前介绍Eureka的时候提到的对于区域分配设计来保证跨区域故障的高可用问题。* blackOutServerPercentage：故障实例百分比（断路器断开数 / 实例数量） &gt;= 0.8* activeReqeustsPerServer：实例平均负载 &gt;= 0.6* availableServers：可用实例数（实例数量 - 断路器断开数） &lt; 2```javaprivate boolean shouldEnableZoneAffinity(List&lt;T&gt; filtered) &#123; if (!zoneAffinity &amp;&amp; !zoneExclusive) &#123; return false; &#125; if (zoneExclusive) &#123; return true; &#125; LoadBalancerStats stats = getLoadBalancerStats(); if (stats == null) &#123; return zoneAffinity; &#125; else &#123; logger.debug(\"Determining if zone affinity should be enabled with given server list: &#123;&#125;\", filtered); ZoneSnapshot snapshot = stats.getZoneSnapshot(filtered); double loadPerServer = snapshot.getLoadPerServer(); int instanceCount = snapshot.getInstanceCount(); int circuitBreakerTrippedCount = snapshot.getCircuitTrippedCount(); if (((double) circuitBreakerTrippedCount) / instanceCount &gt;= blackOutServerPercentageThreshold.get() || loadPerServer &gt;= activeReqeustsPerServerThreshold.get() || (instanceCount - circuitBreakerTrippedCount) &lt; availableServersThreshold.get()) &#123; logger.debug(\"zoneAffinity is overriden. blackOutServerPercentage: &#123;&#125;, activeReqeustsPerServer: &#123;&#125;, availableServers: &#123;&#125;\", new Object[] &#123;(double) circuitBreakerTrippedCount / instanceCount, loadPerServer, instanceCount - circuitBreakerTrippedCount&#125;); return false; &#125; else &#123; return true; &#125; &#125;&#125;``` * `DefaultNIWSServerListFilter`：该过滤器完全继承自`ZoneAffinityServerListFilter`，是默认的NIWS（Netflix Internal Web Service）过滤器。 * `ServerListSubsetFilter`：该过滤器也继承自`ZoneAffinityServerListFilter`，它非常适用于拥有大规模服务器集群(上百或更多)的系统。因为它可以产生一个“区域感知”结果的子集列表，同时它还能够通过比较服务实例的通信失败数量和并发连接数来判定该服务是否健康来选择性的从服务实例列表中剔除那些相对不够健康的实例。该过滤器的实现主要分为三步： 1. 获取“区域感知”的过滤结果，来作为候选的服务实例清单 2. 从当前消费者维护的服务实例子集中剔除那些相对不够健康的实例（同时也将这些实例从候选清单中剔除，防止第三步的时候又被选入），不够健康的标准如下： a. 服务实例的并发连接数超过客户端配置的值，默认为`0`，配置参数为：`&lt;clientName&gt;.&lt;nameSpace&gt;.ServerListSubsetFilter.eliminationConnectionThresold` b. 服务实例的失败数超过客户端配置的值，默认为`0`，配置参数为：`&lt;clientName&gt;.&lt;nameSpace&gt;.ServerListSubsetFilter.eliminationFailureThresold` c. 如果按符合上面任一规则的服务实例剔除后，剔除比例小于客户端默认配置的百分比，默认为`0.1`（10%），配置参数为：`&lt;clientName&gt;.&lt;nameSpace&gt;.ServerListSubsetFilter.forceEliminatePercent`。那么就先对剩下的实例列表进行健康排序，再开始从最不健康实例进行剔除，直到达到配置的剔除百分比。 3. 在完成剔除后，清单已经少了至少10%（默认值）的服务实例，最后通过随机的方式从候选清单中选出一批实例加入到清单中，以保持服务实例子集与原来的数量一致，而默认的实例子集数量为`20`，其配置参数为：`&lt;clientName&gt;.&lt;nameSpace&gt;.ServerListSubsetFilter.size`。* `ZonePreferenceServerListFilter`：Spring Cloud整合时新增的过滤器。若使用Spring Cloud整合Eureka和Ribbon时会默认使用该过滤器。它实现了通过配置或者Eureka实例元数据的所属区域（Zone）来过滤出同区域的服务实例。如下面的源码所示，它的实现非常简单，首先通过父类`ZoneAffinityServerListFilter`的过滤器来获得“区域感知”的服务实例列表，然后遍历这个结果取出根据消费者配置预设的区域Zone来进行过滤，如果过滤的结果是空的就直接返回父类获取的结果，如果不为空就返回通过消费者配置的Zone过滤后的结果。 ```java@Overridepublic List&lt;Server&gt; getFilteredListOfServers(List&lt;Server&gt; servers) &#123; List&lt;Server&gt; output = super.getFilteredListOfServers(servers); if (this.zone != null &amp;&amp; output.size() == servers.size()) &#123; List&lt;Server&gt; local = new ArrayList&lt;Server&gt;(); for (Server server : output) &#123; if (this.zone.equalsIgnoreCase(server.getZone())) &#123; local.add(server); &#125; &#125; if (!local.isEmpty()) &#123; return local; &#125; &#125; return output;&#125;``` ## 2.4 ZoneAwareLoadBalancer`ZoneAwareLoadBalancer`负载均衡器是对`DynamicServerListLoadBalancer`的扩展。在`DynamicServerListLoadBalancer`中，我们可以看到它并没有重写选择具体服务实例的`chooseServer`函数，所以它依然会采用在`BaseLoadBalancer`中实现的算法，使用`RoundRobinRule`规则，以线性轮询的方式来选择调用的服务实例，该算法实现简单并没有区域（Zone）的概念，所以它会把所有实例视为一个Zone下的节点来看待，这样就会周期性的产生跨区域（Zone）访问的情况，由于跨区域会产生更高的延迟，这些实例主要以防止区域性故障实现高可用为目的而不能作为常规访问的实例，所以在多区域部署的情况下会有一定的性能问题，而该负载均衡器则可以避免这样的问题。那么它是如何实现的呢？首先，在`ZoneAwareLoadBalancer`中，我们可以发现，它并没有重写`setServersList`，说明实现服务实例清单的更新主逻辑没有修改。但是我们可以发现它重写了这个函数：`setServerListForZones(Map&lt;String, List&lt;Server&gt;&gt; zoneServersMap)`。看到这里可能会有一些陌生，因为它并不是接口中定义的必备函数，所以我们不妨去父类`DynamicServerListLoadBalancer`中寻找一下该函数，我们可以找到下面的定义了：```javapublic void setServersList(List lsrv) &#123; super.setServersList(lsrv); List&lt;T&gt; serverList = (List&lt;T&gt;) lsrv; Map&lt;String, List&lt;Server&gt;&gt; serversInZones = new HashMap&lt;String, List&lt;Server&gt;&gt;(); ... setServerListForZones(serversInZones);&#125;protected void setServerListForZones(Map&lt;String, List&lt;Server&gt;&gt; zoneServersMap) &#123; LOGGER.debug(\"Setting server list for zones: &#123;&#125;\", zoneServersMap); getLoadBalancerStats().updateZoneServerMapping(zoneServersMap);&#125;``` `setServerListForZones`函数的调用位于更新服务实例清单函数`setServersList`的最后，同时从其实现内容来看，它在父类`DynamicServerListLoadBalancer`中的作用是根据按区域Zone分组的实例列表，为负载均衡器中的`LoadBalancerStats`对象创建`ZoneStats`并放入`Map zoneStatsMap`集合中，每一个区域Zone会对应一个`ZoneStats`，它用于存储每个Zone的一些状态和统计信息。在`ZoneAwareLoadBalancer`中对`setServerListForZones`的重写如下：```javaprotected void setServerListForZones(Map&lt;String, List&lt;Server&gt;&gt; zoneServersMap) &#123; super.setServerListForZones(zoneServersMap); if (balancers == null) &#123; balancers = new ConcurrentHashMap&lt;String, BaseLoadBalancer&gt;(); &#125; for (Map.Entry&lt;String, List&lt;Server&gt;&gt; entry: zoneServersMap.entrySet()) &#123; String zone = entry.getKey().toLowerCase(); getLoadBalancer(zone).setServersList(entry.getValue()); &#125; for (Map.Entry&lt;String, BaseLoadBalancer&gt; existingLBEntry: balancers.entrySet()) &#123; if (!zoneServersMap.keySet().contains(existingLBEntry.getKey())) &#123; existingLBEntry.getValue().setServersList(Collections.emptyList()); &#125; &#125;&#125;``` 可以看到，在该实现中创建了一个`ConcurrentHashMap()`类型的`balancers`对象，它将用来存储每个Zone区域对应的负载均衡器，而具体的负载均衡器的创建则是通过下面的第一个循环中调用`getLoadBalancer`函数来完成，同时在创建负载均衡器的时候会创建它的规则（如果当前实现中没有`IRULE`的实例，就创建一个`AvailabilityFilteringRule`规则；如果已经有具体实例，就clone一个），在创建完负载均衡器后又马上调用`setServersList`函数为其设置对应Zone区域的实例清单。而第二个循环则是对Zone区域中实例清单的检查，看看是否有Zone区域下已经没有实例了，是的话就将`balancers`中对应Zone区域的实例列表清空，该操作的作用是为了后续选择节点时，防止过时的Zone区域统计信息干扰具体实例的选择算法。在了解了该负载均衡器是如何扩展服务实例清单的实现后，我们来具体看看它是如何挑选服务实例，来实现对区域的识别的：```javapublic Server chooseServer(Object key) &#123; if (!ENABLED.get() || getLoadBalancerStats().getAvailableZones().size() &lt;= 1) &#123; logger.debug(\"Zone aware logic disabled or there is only one zone\"); return super.chooseServer(key); &#125; Server server = null; try &#123; LoadBalancerStats lbStats = getLoadBalancerStats(); Map&lt;String, ZoneSnapshot&gt; zoneSnapshot = ZoneAvoidanceRule.createSnapshot(lbStats); logger.debug(\"Zone snapshots: &#123;&#125;\", zoneSnapshot); ... Set&lt;String&gt; availableZones = ZoneAvoidanceRule.getAvailableZones(zoneSnapshot, triggeringLoad.get(), triggeringBlackoutPercentage.get()); logger.debug(\"Available zones: &#123;&#125;\", availableZones); if (availableZones != null &amp;&amp; availableZones.size() &lt; zoneSnapshot.keySet().size()) &#123; String zone = ZoneAvoidanceRule.randomChooseZone(zoneSnapshot, availableZones); logger.debug(\"Zone chosen: &#123;&#125;\", zone); if (zone != null) &#123; BaseLoadBalancer zoneLoadBalancer = getLoadBalancer(zone); server = zoneLoadBalancer.chooseServer(key); &#125; &#125; &#125; catch (Throwable e) &#123; logger.error(\"Unexpected exception when choosing server using zone aware logic\", e); &#125; if (server != null) &#123; return server; &#125; else &#123; logger.debug(\"Zone avoidance logic is not invoked.\"); return super.chooseServer(key); &#125;&#125;``` 从源码中我们可以看到，只有当负载均衡器中维护的实例所属Zone区域个数大于1的时候才会执行这里的选择策略，否则还是将使用父类的实现。当Zone区域个数大于1个的时候，它的实现步骤主要如下：* 调用`ZoneAvoidanceRule`中的静态方法`createSnapshot(lbStats)`，为当前负载均衡器中所有的Zone区域分别创建快照，保存在`Map zoneSnapshot`中，这些快照中的数据将用于后续的算法。* 调用`ZoneAvoidanceRule`中的静态方法`getAvailableZones(zoneSnapshot, triggeringLoad.get(), triggeringBlackoutPercentage.get())`，来获取可用的Zone区域集合，在该函数中会通过Zone区域快照中的统计数据来实现可用区的挑选。 * 首先它会剔除符合这些规则的Zone区域：所属实例数为零的Zone区域；Zone区域内实例平均负载小于零，或者实例故障率（断路器断开次数/实例数）大于等于阈值（默认为0.99999）。 * 然后根据Zone区域的实例平均负载来计算出最差的Zone区域，这里的最差指的是实例平均负载最高的Zone区域。 * 如果在上面的过程中没有符合剔除要求的区域，同时实例最大平均负载小于阈值（默认为20%），就直接返回所有Zone区域为可用区域。否则，从最坏Zone区域集合中随机的选择一个，将它从可用Zone区域集合中剔除。* 当获得的可用Zone区域集合不为空，并且个数小于Zone区域总数，就随机的选择一个Zone区域。* 在确定了某个Zone区域后，则获取对应Zone区域的服务均衡器，并调用`chooseServer`来选择具体的服务实例，而在`chooseServer`中将使用`IRule`接口的`choose`函数来选择具体的服务实例。在这里`IRule`接口的实现会使用`ZoneAvoidanceRule`来挑选出具体的服务实例。# 3 负载均衡策略--------------------------通过上面的源码解读，我们已经对Ribbon实现的负载均衡器以及其中包含的服务实例过滤器、服务实例信息的存储对象、区域的信息快照等都有了深入的认识和理解，但是对于负载均衡器中的服务实例选择策略只是讲解了几个默认实现的内容，而对于`IRule`的其他实现还没有详细的解读，下面我们来看看在Ribbon中共提供了那些负载均衡的策略实现。![](ribbon-code-5.png)如上图所示，我们可以看到在Ribbon中实现了非常多的选择策略，其中也包含了我们在前面内容中提到过的：`RoundRobinRule`和`ZoneAvoidanceRule`。下面我们来详细的解读一下`IRule`接口的各个实现。## 3.1 AbstractLoadBalancerRule负载均衡策略的抽象类，在该抽象类中定义了负载均衡器`ILoadBalancer`对象，该对象能够在具体实现选择服务策略时，获取到一些负载均衡器中维护的信息来作为分配依据，并以此设计一些算法来实现针对特定场景的高效策略。```javapublic abstract class AbstractLoadBalancerRule implements IRule, IClientConfigAware &#123; private ILoadBalancer lb; @Override public void setLoadBalancer(ILoadBalancer lb)&#123; this.lb = lb; &#125; @Override public ILoadBalancer getLoadBalancer()&#123; return lb; &#125;&#125;``` ## 3.2 RandomRule该策略实现了从服务实例清单中随机选择一个服务实例的功能。它的具体实现如下，可以看到`IRule`接口的`choose(Object key)`函数实现，委托给了该类中的`choose(ILoadBalancer lb, Object key)`，该方法增加了一个负载均衡器对象的参数。从具体的实现上看，它会使用传入的负载均衡器来获得可用实例列表`upList`和所有实例列表`allList`，并通过`rand.nextInt(serverCount)`函数来获取一个随机数，并将该随机数作为upList的索引值来返回具体实例。同时，具体的选择逻辑在一个`while (server == null)`循环之内，而根据选择逻辑的实现，正常情况下每次选择都应该能够选出一个服务实例，如果出现死循环获取不到服务实例时，则很有可能存在并发的Bug。```java@Overridepublic Server choose(Object key) &#123; return choose(getLoadBalancer(), key);&#125;public Server choose(ILoadBalancer lb, Object key) &#123; ... Server server = null; while (server == null) &#123; if (Thread.interrupted()) &#123; return null; &#125; List&lt;Server&gt; upList = lb.getReachableServers(); List&lt;Server&gt; allList = lb.getAllServers(); int serverCount = allList.size(); if (serverCount == 0) &#123; return null; &#125; int index = rand.nextInt(serverCount); server = upList.get(index); if (server == null) &#123; Thread.yield(); continue; &#125; if (server.isAlive()) &#123; return (server); &#125; server = null; Thread.yield(); &#125; return server;&#125;``` ## 3.3 RoundRobinRule该策略实现了按照线性轮询的方式依次选择每个服务实例的功能。它的具体实现如下，其详细结构与`RandomRule`非常类似。除了循环条件不同外，就是从可用列表中获取所谓的逻辑不同。从循环条件中，我们可以看到增加了一个`count`计数变量，该变量会在每次循环之后累加，也就是说如果一直选择不到server超过10次，那么就会结束尝试，并打印一个警告信息`No available alive servers after 10 tries from load balancer: ...`。而线性轮询的实现则是通过`AtomicInteger nextServerCyclicCounter`对象实现，每次进行实例选择时通过调用`incrementAndGetModulo`函数实现递增。```javapublic Server choose(ILoadBalancer lb, Object key) &#123; ... Server server = null; int count = 0; while (server == null &amp;&amp; count++ &lt; 10) &#123; List&lt;Server&gt; reachableServers = lb.getReachableServers(); List&lt;Server&gt; allServers = lb.getAllServers(); int upCount = reachableServers.size(); int serverCount = allServers.size(); if ((upCount == 0) || (serverCount == 0)) &#123; log.warn(\"No up servers available from load balancer: \" + lb); return null; &#125; int nextServerIndex = incrementAndGetModulo(serverCount); server = allServers.get(nextServerIndex); if (server == null) &#123; Thread.yield(); continue; &#125; if (server.isAlive() &amp;&amp; (server.isReadyToServe())) &#123; return (server); &#125; server = null; &#125; if (count &gt;= 10) &#123; log.warn(\"No available alive servers after 10 tries from load balancer: \" + lb); &#125; return server;&#125;``` ## 3.4 RetryRule该策略实现了一个具备重试机制的实例选择功能。从下面的实现中我们可以看到，在其内部还定义了一个`IRule`对象，默认使用了`RoundRobinRule`实例。而在`choose`方法中的则实现了对内部定义的策略进行反复尝试的策略，若期间能够选择到具体的服务实例就返回，若选择不到就根据设置的尝试结束时间为阈值（`maxRetryMillis`参数定义的值 \\+ `choose`方法开始执行的时间戳），当超过该阈值后就返回null。```javapublic class RetryRule extends AbstractLoadBalancerRule &#123; IRule subRule = new RoundRobinRule(); long maxRetryMillis = 500; ... public Server choose(ILoadBalancer lb, Object key) &#123; long requestTime = System.currentTimeMillis(); long deadline = requestTime + maxRetryMillis; Server answer = null; answer = subRule.choose(key); if (((answer == null) || (!answer.isAlive())) &amp;&amp; (System.currentTimeMillis() &lt; deadline)) &#123; InterruptTask task = new InterruptTask(deadline - System.currentTimeMillis()); while (!Thread.interrupted()) &#123; answer = subRule.choose(key); if (((answer == null) || (!answer.isAlive())) &amp;&amp; (System.currentTimeMillis() &lt; deadline)) &#123; Thread.yield(); &#125; else &#123; break; &#125; &#125; task.cancel(); &#125; if ((answer == null) || (!answer.isAlive())) &#123; return null; &#125; else &#123; return answer; &#125; &#125; ...&#125; 3.5 WeightedResponseTimeRule该策略是对RoundRobinRule的扩展，增加了根据实例的运行情况来计算权重，并根据权重来挑选实例，以达到更优的分配效果，它的实现主要有三个核心内容： 3.5.1 定时任务WeightedResponseTimeRule策略在初始化的时候会通过serverWeightTimer.schedule(new DynamicServerWeightTask(), 0, serverWeightTaskTimerInterval)启动一个定时任务，用来为每个服务实例计算权重，该任务默认30秒执行一次。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class DynamicServerWeightTask extends TimerTask &#123; public void run() &#123; ServerWeight serverWeight = new ServerWeight(); try &#123; serverWeight.maintainWeights(); &#125; catch (Throwable t) &#123; logger.error(\"Throwable caught while running DynamicServerWeightTask for \" + name, t); &#125; &#125;&#125;``` ### 3.5.2 权重计算在源码中我们可以轻松找到用于存储权重的对象：`List&lt;Double&gt; accumulatedWeights = new ArrayList&lt;Double&gt;()`，该List中每个权重值所处的位置对应了负载均衡器维护的服务实例清单中所有实例在清单中的位置。维护实例权重的计算过程通过`maintainWeights`函数实现，具体如下源码所示：```javapublic void maintainWeights() &#123; ILoadBalancer lb = getLoadBalancer(); ... try &#123; logger.info(\"Weight adjusting job started\"); AbstractLoadBalancer nlb = (AbstractLoadBalancer) lb; LoadBalancerStats stats = nlb.getLoadBalancerStats(); ... // 计算所有实例的平均响应时间的总和：totalResponseTime double totalResponseTime = 0; for (Server server : nlb.getAllServers()) &#123; // this will automatically load the stats if not in cache ServerStats ss = stats.getSingleServerStat(server); totalResponseTime += ss.getResponseTimeAvg(); &#125; // 逐个计算每个实例的权重：weightSoFar + totalResponseTime - 实例的平均响应时间 Double weightSoFar = 0.0; List&lt;Double&gt; finalWeights = new ArrayList&lt;Double&gt;(); for (Server server : nlb.getAllServers()) &#123; ServerStats ss = stats.getSingleServerStat(server); double weight = totalResponseTime - ss.getResponseTimeAvg(); weightSoFar += weight; finalWeights.add(weightSoFar); &#125; setWeights(finalWeights); &#125; catch (Throwable t) &#123; logger.error(\"Exception while dynamically calculating server weights\", t); &#125; finally &#123; serverWeightAssignmentInProgress.set(false); &#125;&#125; 该函数的实现主要分为两个步骤： 根据LoadBalancerStats中记录的每个实例的统计信息，累加所有实例的平均响应时间，得到总平均响应时间totalResponseTime，该值会用于后续的计算。 为负载均衡器中维护的实例清单逐个计算权重（从第一个开始），计算规则为：weightSoFar + totalResponseTime - 实例的平均响应时间，其中weightSoFar初始化为零，并且每计算好一个权重需要累加到weightSoFar上供下一次计算使用。totalResponseTime则的上计算结果。 举个简单的例子来理解这个计算过程：假设有4个实例A、B、C、D，他们的平均响应时间为：10、40、80、100，所以总响应时间是10 + 40 + 80 + 100 = 230，每个实例的权重为总响应时间与实例自身的平均响应时间的差的累积获得，所以实例A、B、C、D的权重分别为： 实例A：230 - 10 = 220 实例B：220 + （230 - 40）= 410 实例C：410 + （230 - 80）= 560 实例D：560 + （230 - 100）= 690 需要注意的是，这里的权重值只是表示了各实例权重区间的上限，并非某个实例的优先级，所以不是数值越大被选中的概率就越大。那么什么是权重区间呢？以上面例子的计算结果为例，它实际上是为这4个实例构建了4个不同的区间，每个实例的区间下限是上一个实例的区间上限，而每个实例的区间上限则是我们上面计算并存储于List accumulatedWeights中的权重值，其中第一个实例的下限默认为零。所以，根据上面示例的权重计算结果，我们可以得到每个实例的权重区间： 实例A：[0, 220] 实例B：(220, 410] 实例C：(410, 560] 实例D：(560，690) 我们不难发现，实际上每个区间的宽度就是：总的平均响应时间 - 实例的平均响应时间，所以实例的平均响应时间越短、权重区间的宽度越大，而权重区间的宽度越大被选中的概率就越高。可能很多读者会问，这些区间边界的开闭是如何确定的呢？为什么不那么规则？下面我们会通过实例选择算法的解读来解释。 3.5.3 实例选择WeightedResponseTimeRule选择实例的实现与之前介绍的算法结构类似，下面是它主体的算法（省略了循环体和一些判断等处理）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public Server choose(ILoadBalancer lb, Object key) &#123; ... List&lt;Double&gt; currentWeights = accumulatedWeights; ... List&lt;Server&gt; allList = lb.getAllServers(); int serverCount = allList.size(); if (serverCount == 0) &#123; return null; &#125; int serverIndex = 0; // 获取最后一个实例的权重 double maxTotalWeight = currentWeights.size() == 0 ? 0 : currentWeights.get(currentWeights.size() - 1); if (maxTotalWeight &lt; 0.001d) &#123; // 如果最后一个实例的权重值小于0.001，则采用父类实现的线性轮询的策略 server = super.choose(getLoadBalancer(), key); if(server == null) &#123; return server; &#125; &#125; else &#123; // 如果最后一个实例的权重值大于等于0.001，就产生一个[0, maxTotalWeight)的随机数 double randomWeight = random.nextDouble() * maxTotalWeight; int n = 0; for (Double d : currentWeights) &#123; // 遍历维护的权重清单，若权重大于等于随机得到的数值，就选择这个实例 if (d &gt;= randomWeight) &#123; serverIndex = n; break; &#125; else &#123; n++; &#125; &#125; server = allList.get(serverIndex); &#125; ... return server;&#125;``` 从源码中，我们可以看到，选择实例的核心过程就两步：* 生产一个`[0, 最大权重值)`区间内的随机数。* 遍历权重列表，比较权重值与随机数的大小，如果权重值大于等于随机数，就拿当前权重列表的索引值去服务实例列表中获取具体实例。这就是在上一节中提到的服务实例会根据权重区间挑选的原理，而权重区间边界的开闭原则根据算法，正常应该每个区间为`(x, y]`的形式，但是第一个实例和最后一个实例为什么不同呢？由于随机数的最小取值可以为`0`，所以第一个实例的下限是闭区间，同时随机数的最大值取不到最大权重值，所以最后一个实例的上限是开区间。若继续以上面的数据为例，进行服务实例的选择，则该方法会从`[0, 690)`区间中选出一个随机数，比如选出的随机数为230，由于该值位于第二个区间，所以此时就会选择实例B来进行请求。## 3.6 ClientConfigEnabledRoundRobinRule该策略较为特殊，我们一般不直接使用它。因为它本身并没有实现什么特殊的处理逻辑，正如下面的源码所示，在它的内部定义了一个`RoundRobinRule`策略，而`choose`函数的实现也正是使用了`RoundRobinRule`的线性轮询机制，所以它实现的功能实际上与`RoundRobinRule`相同，那么定义它有什么特殊的用处呢？虽然我们不会直接使用该策略，但是通过继承该策略，那么默认的`choose`就实现了线性轮询机制，在子类中做一些高级策略时通常都有可能会存在一些无法实施的情况，那么就可以通过父类的实现作为备选。在后文中我们将继续介绍的高级策略均是基于`ClientConfigEnabledRoundRobinRule`的扩展。```javapublic class ClientConfigEnabledRoundRobinRule extends AbstractLoadBalancerRule &#123; RoundRobinRule roundRobinRule = new RoundRobinRule(); ... @Override public Server choose(Object key) &#123; if (roundRobinRule != null) &#123; return roundRobinRule.choose(key); &#125; else &#123; throw new IllegalArgumentException( \"This class has not been initialized with the RoundRobinRule class\"); &#125; &#125;&#125; 3.7 BestAvailableRule该策略继承自ClientConfigEnabledRoundRobinRule，在实现中它注入了负载均衡器的统计对象：LoadBalancerStats，同时在具体的choose算法中利用LoadBalancerStats保存的实例统计信息来选择满足要求的实例。从如下源码中我们可以看到，它通过遍历负载均衡器中维护的所有服务实例，会过滤掉故障的实例，并找出并发请求数最小的一个，所以该策略的特性是选出最空闲的实例。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public Server choose(Object key) &#123; if (loadBalancerStats == null) &#123; return super.choose(key); &#125; List&lt;Server&gt; serverList = getLoadBalancer().getAllServers(); int minimalConcurrentConnections = Integer.MAX_VALUE; long currentTime = System.currentTimeMillis(); Server chosen = null; for (Server server: serverList) &#123; ServerStats serverStats = loadBalancerStats.getSingleServerStat(server); if (!serverStats.isCircuitBreakerTripped(currentTime)) &#123; int concurrentConnections = serverStats.getActiveRequestsCount(currentTime); if (concurrentConnections &lt; minimalConcurrentConnections) &#123; minimalConcurrentConnections = concurrentConnections; chosen = server; &#125; &#125; &#125; if (chosen == null) &#123; return super.choose(key); &#125; else &#123; return chosen; &#125;&#125;``` 同时，由于该算法的核心依据是统计对象`loadBalancerStats`，当其为空的时候，该策略是无法执行的。所以从源码中我们可以看到，当`loadBalancerStats`为空的时候，它会采用父类的线性轮询策略，正如我们在介绍`ClientConfigEnabledRoundRobinRule`时那样，它的子类在无法满足实现高级策略时候，可以使用线性轮询策略的特性。后面将要介绍的策略因为也都继承自`ClientConfigEnabledRoundRobinRule`，所以他们都会具有这样的特性。## 3.8 PredicateBasedRule这是一个抽象策略，它也继承了`ClientConfigEnabledRoundRobinRule`，从其命名中可以猜出他是一个基于`Predicate`实现的策略，`Predicate`是Google Guava Collection工具对集合进行过滤的条件接口。如下源码所示，它定义了一个抽象函数`getPredicate`来获取`AbstractServerPredicate`对象的实现，而在`choose`函数中，通过`AbstractServerPredicate`的`chooseRoundRobinAfterFiltering`函数来选出具体的服务实例。从该函数的命名我们也大致能猜出它的基础逻辑：先通过子类中实现的`Predicate`逻辑来过滤一部分服务实例，然后再以线性轮询的方式从过滤后的实例清单中选出一个。```javapublic abstract class PredicateBasedRule extends ClientConfigEnabledRoundRobinRule &#123; public abstract AbstractServerPredicate getPredicate(); @Override public Server choose(Object key) &#123; ILoadBalancer lb = getLoadBalancer(); Optional&lt;Server&gt; server = getPredicate().chooseRoundRobinAfterFiltering(lb.getAllServers(), key); if (server.isPresent()) &#123; return server.get(); &#125; else &#123; return null; &#125; &#125;&#125; 通过下面AbstractServerPredicate的源码片段，可以证实我们上面所做的猜测。在上面choose函数中调用的chooseRoundRobinAfterFiltering方法先通过内部定义的getEligibleServers函数来获取备选的实例清单（实现了过滤），如果返回的清单为空，则用Optional.absent()来表示不存在，反之则以线性轮询的方式从备选清单中获取一个实例。 1234567891011121314151617181920212223242526public abstract class AbstractServerPredicate implements Predicate&lt;PredicateKey&gt; &#123; ... public Optional&lt;Server&gt; chooseRoundRobinAfterFiltering(List&lt;Server&gt; servers, Object loadBalancerKey) &#123; List&lt;Server&gt; eligible = getEligibleServers(servers, loadBalancerKey); if (eligible.size() == 0) &#123; return Optional.absent(); &#125; return Optional.of(eligible.get(nextIndex.getAndIncrement() % eligible.size())); &#125; public List&lt;Server&gt; getEligibleServers(List&lt;Server&gt; servers, Object loadBalancerKey) &#123; if (loadBalancerKey == null) &#123; return ImmutableList.copyOf(Iterables.filter(servers, this.getServerOnlyPredicate())); &#125; else &#123; List&lt;Server&gt; results = Lists.newArrayList(); for (Server server: servers) &#123; if (this.apply(new PredicateKey(loadBalancerKey, server))) &#123; results.add(server); &#125; &#125; return results; &#125; &#125;&#125; 在了解了整体逻辑之后，我们来详细看看实现过滤功能的getEligibleServers函数。从源码上看，它的实现结构非常简单清晰，通过遍历服务清单，使用this.apply方法来判断实例是否需要保留，是就添加到结果列表中。 可能到这里，不熟悉Google Guava Collections集合工具的读者会比较困惑，这个apply在AbstractServerPredicate中并找不到它的定义，那么它是如何实现过滤的呢？实际上，AbstractServerPredicate实现了com.google.common.base.Predicate接口，而apply方法是该接口中的定义，主要用来实现过滤条件的判断逻辑，它输入的参数则是过滤条件需要用到的一些信息（比如源码中的new PredicateKey(loadBalancerKey, server))，它传入了关于实例的统计信息和负载均衡器的选择算法传递过来的key）。既然在AbstractServerPredicate中我们未能找到apply的实现，所以这里的chooseRoundRobinAfterFiltering函数只是定义了一个模板策略：“先过滤清单，再轮询选择”。对于如何过滤，则需要我们在AbstractServerPredicate的子类去实现apply方法来确定具体的过滤策略了。 后面我们将要介绍的两个策略就是基于此抽象策略实现，只是它们使用了不同的Predicate实现来完成过滤逻辑以达到不同的实例选择效果。 Google Guava Collections是一个对Java Collections Framework增强和扩展的一个开源项目。虽然Java Collections Framework已经能够 满足了我们大多数情况下使用集合的要求，但是当遇到一些特殊的情况我们的代码会比较冗长且容易出错。Guava Collections 可以帮助我们的让集合操作代码更为简短精炼并大大增强代码的可读性。 3.9 AvailabilityFilteringRule该策略继承自上面介绍的抽象策略PredicateBasedRule，所以它也继承了“先过滤清单，再轮询选择”的基本处理逻辑，其中过滤条件使用了AvailabilityPredicate： 1234567891011121314151617181920public class AvailabilityPredicate extends AbstractServerPredicate &#123; ... public boolean apply(@Nullable PredicateKey input) &#123; LoadBalancerStats stats = getLBStats(); if (stats == null) &#123; return true; &#125; return !shouldSkipServer(stats.getSingleServerStat(input.getServer())); &#125; private boolean shouldSkipServer(ServerStats stats) &#123; if ((CIRCUIT_BREAKER_FILTERING.get() &amp;&amp; stats.isCircuitBreakerTripped()) || stats.getActiveRequestsCount() &gt;= activeConnectionsLimit.get()) &#123; return true; &#125; return false; &#125;&#125; 从上述源码中，我们可以知道它的主要过滤逻辑位于shouldSkipServer方法中，它主要判断服务实例的两项内容： 是否故障，即断路器是否生效已断开 实例的并发请求数大于阈值，默认值为$2^{31}$ - 1，该配置我们可通过参数..ActiveConnectionsLimit来修改其中只要有一个满足apply就返回false（代表该节点可能存在故障或负载过高），都不满足就返回true。 在该策略中，除了实现了上面的过滤方法之外，对于choose的策略也做了一些改进优化，所以父类的实现对于它来说只是一个备用选项，其具体实现如下： public Server choose(Object key) { int count = 0; Server server = roundRobinRule.choose(key); while (count++ &lt;= 10) { if (predicate.apply(new PredicateKey(server))) { return server; } server = roundRobinRule.choose(key); } return super.choose(key); } 可以看到，它并没有像父类中那样，先遍历所有的节点进行过滤，然后在过滤后的集合中选择实例。而是先线性的方式选择一个实例，接着用过滤条件来判断该实例是否满足要求，若满足就直接使用该实例，若不满足要求就再选择下一个实例，并检查是否满足要求，如此循环进行，当这个过程重复了10次还是没有找到符合要求的实例，就采用父类的实现方案。 简单的说，该策略通过线性抽样的方式直接尝试寻找可用且较空闲的实例来使用，优化了父类每次都要遍历所有实例的开销。 3.10 ZoneAvoidanceRule该策略我们在介绍负载均衡器ZoneAwareLoadBalancer时已经提到过了，它也是PredicateBasedRule的具体实现类。在之前的介绍中主要针对ZoneAvoidanceRule中用于选择Zone区域策略的一些静态函数，比如：createSnapshot、getAvailableZones。在这里我们将详细的看看ZoneAvoidanceRule作为服务实例过滤条件的实现原理。从下面ZoneAvoidanceRule的源码片段中我们可以看到，它使用了CompositePredicate来进行服务实例清单的过滤。这是一个组合过滤条件，在其构造函数中，它以ZoneAvoidancePredicate为主过滤条件，AvailabilityPredicate为次过滤条件初始化了组合过滤条件的实例。 public class ZoneAvoidanceRule extends PredicateBasedRule { ... private CompositePredicate compositePredicate; public ZoneAvoidanceRule() { super(); ZoneAvoidancePredicate zonePredicate = new ZoneAvoidancePredicate(this); AvailabilityPredicate availabilityPredicate = new AvailabilityPredicate(this); compositePredicate = createCompositePredicate(zonePredicate, availabilityPredicate); } ... } ZoneAvoidanceRule在实现的时候并没有像AvailabilityFilteringRule那样重写choose函数来优化，所以它完全遵循了父类的过滤主逻辑：“先过滤清单，再轮询选择”。其中过滤清单的条件就是我们上面提到的以ZoneAvoidancePredicate为主过滤条件、AvailabilityPredicate为次过滤条件的组合过滤条件CompositePredicate。从CompositePredicate的源码片段中，我们可以看到它定义了一个主过滤条件AbstractServerPredicate delegate以及一组次过滤条件列表List fallbacks，所以它的次过滤列表是可以拥有多个的，并且由于它采用了List存储所以次过滤条件是按顺序执行的。 public class CompositePredicate extends AbstractServerPredicate { private AbstractServerPredicate delegate; private List&lt;AbstractServerPredicate&gt; fallbacks = Lists.newArrayList(); private int minimalFilteredServers = 1; private float minimalFilteredPercentage = 0; @Override public List&lt;Server&gt; getEligibleServers(List&lt;Server&gt; servers, Object loadBalancerKey) { List&lt;Server&gt; result = super.getEligibleServers(servers, loadBalancerKey); Iterator&lt;AbstractServerPredicate&gt; i = fallbacks.iterator(); while (!(result.size() &gt;= minimalFilteredServers &amp;&amp; result.size() &gt; (int) (servers.size() * minimalFilteredPercentage)) &amp;&amp; i.hasNext()) { AbstractServerPredicate predicate = i.next(); result = predicate.getEligibleServers(servers, loadBalancerKey); } return result; } } 再来看看获取过滤结果的实现函数getEligibleServers中，它的处理逻辑如下： 使用主过滤条件对所有实例过滤并返回过滤后的实例清单 依次使用次过滤条件列表中的过滤条件对主过滤条件的结果进行过滤 每次过滤之后（包括主过滤条件和次过滤条件），都需要判断下面两个条件，只要有一个符合就不再进行过滤，将当前结果返回供线性轮询算法选择： 过滤后的实例总数 &gt;= 最小过滤实例数（minimalFilteredServers，默认为1） 过滤后的实例比例 > 最小过滤百分比（minimalFilteredPercentage，默认为0） 本文转自:http://blog.didispace.com/springcloud-sourcecode-ribbon/ RibbonClientConfiguration ribbon 配置 RibbonAutoConfiguration spring-cloud 扩展ribbon客户端(LoadBalancerClient)相关配置 LoadBalancerAutoConfiguration spring-cloud 扩展RestTemplate(带@LoadBalanced)的配置","categories":[{"name":"ribbon","slug":"ribbon","permalink":"http://blog.shagle.cn/categories/ribbon/"}],"tags":[{"name":"ribbon","slug":"ribbon","permalink":"http://blog.shagle.cn/tags/ribbon/"},{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/tags/spring/"}]},{"title":"Ribbon","slug":"Ribbon","date":"2018-12-22T13:24:19.000Z","updated":"2018-12-22T13:24:50.000Z","comments":true,"path":"2018/12/22/Ribbon/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Ribbon/","excerpt":"","text":"1.简介 Ribbon是一个客户端IPC库，在云中经过实战测试。它提供以下功能 负载均衡 容错 异步和反应模型中的多协议（HTTP，TCP，UDP）支持 缓存和批处理 12345&lt;dependency&gt; &lt;groupId&gt;com.netflix.ribbon&lt;/groupId&gt; &lt;artifactId&gt;ribbon&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt; ribbon：在其他功能区模块和Hystrix之上集成负载平衡，容错，缓存/批处理的APIribbon-loadbalancer：负载均衡器API，可以单独使用，也可以与其他模块一起使用ribbon-eureka：使用Eureka客户端为云提供动态服务器列表的APIribbon-transport：使用具有负载平衡功能的RxNetty传输支持HTTP，TCP和UDP协议的客户端ribbon-httpclient：构建在与负载均衡器集成的Apache HttpClient之上的REST客户端（不建议使用并由功能块模块替换）ribbon-example：示例ribbon-core：客户端配置API和其他共享API 2.入门 最简单的入门方法是使用属性驱动的工厂来创建具有负载均衡器的客户端实例，在如下所示的ribbon-httpclient 示例应用程序中基础用法，描述如下 2.1 属性文件（sample-client.properties）1234567891011121314151617181920# 同一服务器上的最大重试次数（不包括第一次尝试）sample-client.ribbon.MaxAutoRetries=1# 要重试的下一个服务器的最大数量（不包括第一个服务器）sample-client.ribbon.MaxAutoRetriesNextServer=1# 是否可为改机器重试所有操作sample-client.ribbon.OkToRetryOnAllOperations=true# 刷新服务器列表时间间隔sample-client.ribbon.ServerListRefreshInterval=2000# Apache HttpClient 连接超时时间sample-client.ribbon.ConnectTimeout=3000# Apache HttpClient 读超时时间sample-client.ribbon.ReadTimeout=3000# 初始服务器列表，可以通过Archaius属性在运行期间动态更新sample-client.ribbon.listOfServers=www.microsoft.com:80,www.yahoo.com:80,www.google.com:80 配置格式是：1&lt;clientName&gt;.&lt;nameSpace&gt;.&lt;propertyName&gt;=&lt;value&gt; 后面将在工厂中使用clientName创建客户端，nameSpace是可选的，默认情况下为ribbon。CommonClientConfigKey中提供了公共属性名称。 2.2 代码12345678910111213141516171819202122public static void main(String[] args) throws Exception &#123; ConfigurationManager.loadPropertiesFromResources(\"sample-client.properties\"); // 1 System.out.println(ConfigurationManager.getConfigInstance().getProperty(\"sample-client.ribbon.listOfServers\")); RestClient client = (RestClient) ClientFactory.getNamedClient(\"sample-client\"); // 2 HttpClientRequest request = HttpClientRequest.newBuilder().setUri(new URI(\"/\")).build(); // 3 for (int i = 0; i &lt; 20; i++) &#123; HttpClientResponse response = client.executeWithLoadBalancer(request); // 4 System.out.println(\"Status code for \" + response.getRequestedURI() + \" :\" + response.getStatus()); &#125; ZoneAwareLoadBalancer lb = (ZoneAwareLoadBalancer) client.getLoadBalancer(); System.out.println(lb.getLoadBalancerStats()); ConfigurationManager.getConfigInstance().setProperty( \"sample-client.ribbon.listOfServers\", \"www.linkedin.com:80,www.google.com:80\"); // 5 System.out.println(\"changing servers ...\"); Thread.sleep(3000); // 6 for (int i = 0; i &lt; 20; i++) &#123; HttpClientResponse response = client.executeWithLoadBalancer(request); System.out.println(\"Status code for \" + response.getRequestedURI() + \" : \" + response.getStatus()); response.releaseResources(); &#125; System.out.println(lb.getLoadBalancerStats()); // 7&#125; 笔记： 1.使用Archaius ConfigurationManager加载属性文件。 2.使用ClientFactory创建负载均衡器客户端。 3.使用构建器构建http请求。请注意，我们只需提供URI的路径部分（“/”）。一旦负载均衡器选择了服务器，客户端就会计算完整的URI。 4.调用client.executeWithLoadBalancer（）API，而不是execute（）API。 5.从配置中动态更改服务器池。 6.等到服务器列表刷新（属性文件中定义的2秒参考间隔） 6.打印出负载均衡器记录的服务器统计信息。 负载均衡器统计信息包含大量用于监视的信息，并用作负载均衡器算法的输入。以下是输出中的示例： 123456Zone stats: &#123;unknown=[Zone:unknown; Instance count:2; Active connections count: 0; Circuit breaker tripped count: 0; Active connections per server: 0.0;]&#125;,Server stats: [[Server:www.microsoft.com:80; Zone:UNKNOWN; Total Requests:6; Successive connection failure:0; Total blackout seconds:0; Last connection made:Fri Jan 25 14:52:18 PST 2013; First connection made: Fri Jan 25 14:52:15 PST 2013; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:129.83333333333334; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:33.0; max resp time:530.0; stddev resp time:179.30180949697325], [Server:www.google.com:80; Zone:UNKNOWN; Total Requests:17; Successive connection failure:0; Total blackout seconds:0; Last connection made:Fri Jan 25 14:52:23 PST 2013; First connection made: Fri Jan 25 14:52:14 PST 2013; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:67.6470588235294; 90 percentile resp time:50.0; 95 percentile resp time:50.0; min resp time:45.0; max resp time:384.0; stddev resp time:79.12234842799629], [Server:www.yahoo.com:80; Zone:UNKNOWN; Total Requests:7; Successive connection failure:0; Total blackout seconds:0; Last connection made:Fri Jan 25 14:52:18 PST 2013; First connection made: Fri Jan 25 14:52:13 PST 2013; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:561.1428571428571; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:445.0; max resp time:879.0; stddev resp time:132.42618274930024], [Server:www.linkedin.com:80; Zone:UNKNOWN; Total Requests:10; Successive connection failure:0; Total blackout seconds:0; Last connection made:Fri Jan 25 14:52:23 PST 2013; First connection made: Fri Jan 25 14:52:22 PST 2013; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:94.6; 90 percentile resp time:404.0; 95 percentile resp time:404.0; min resp time:53.0; max resp time:404.0; stddev resp time:103.25037530198135]] 3.开发指南3.1 客户端配置选项配置客户端和负载均衡器的最简单方法是将属性加载到符合特定格式的Archaius中：1&lt;clientName&gt;.&lt;nameSpace&gt;.&lt;propertyName&gt;=&lt;value&gt; 您可以在类路径上的文件中定义属性，也可以将其定义为系统属性。如果是使用前者，则应调用ConfigurationManager.loadPropertiesFromResources（）API来加载文件。 默认情况下，“ribbon”应为nameSpace。 如果没有为命名客户端指定属性，ClientFactory将使用默认配置属性值创建负载均衡器客户端，默认值在DefaultClientConfigImpl中指定。 如果某个属性缺少clientName，则会将其解释为适用于所有客户端的属性。 例如 1ribbon.ReadTimeout=1000 这将为所有客户端建立默认的ReadTimeout属性。 您还可以通过构造DefaultClientConfigImpl的实例以编程方式设置属性。通过如下步骤： 1.调用DefaultClientConfigImpl.getClientConfigWithDefaultValues（String clientName）以加载默认值，以及已在Archaius中使用Configuration定义的任何属性 2.通过调用DefaultClientConfigImpl.setProperty（）API设置所有所需的属性。 3.将此实例与客户端名称一起传递给正确的ClientFactory API。 如果希望在不同的名称空间中定义属性，例如“foo” 1myclient.foo.ReadTimeout=1000 您应该使用getClientConfigWithDefaultValues（String clientName，String nameSpace）构造函数 - 在本例中为getClientConfigWithDefaultValues（“myclient”，“foo”）- 在上面的第一步中。 3.2 .在ClientFactory中使用非默认属性名称空间如果要使用“ribbon”以外的属性名称空间，并使用ClientFactory API创建客户端或负载均衡器，有以下几种方法： 3.2.1 方法1扩展DefaultClientConfigImpl并重写方法getNameSpace（），例如， 123456public class MyClientConfig extends DefaultClientConfigImpl &#123; // ... public String getNameSpace() &#123; return \"foo\"; &#125;&#125; 假设您的所有属性都定义为myclient.foo。*，您可以使用以下ClientFactory API来创建客户端： 1MyClient client = (MyClient) ClientFactory.createNamedClient(\"myclient\", MyClientConfig.class); 3.2.2 方法2使用DefaultClientConfigImpl将默认名称空间更新为自定义命名空间，例如，我们的客户端名为“myclient”，其属性在名称空间“foo”中定义： 123DefaultClientConfigImpl clientConfig = new DefaultClientConfigImpl(\"foo\");clientConfig.loadProperites(\"myclient\");MyClient client = (MyClient) ClientFactory.registerClientFromProperties(\"myclient\", clientConfig); 3.3.使用负载均衡器支持实现您自己的客户端您需要扩展com.netflix.client.AbstractLoadBalancerAwareClient并实现一些方法。具体而言，应实现IClient.execute（）方法以执行协议特定的操作。 AbstractLoadBalancerAwareClient负责负载均衡器集成，重试逻辑和统计信息收集，这些统计信息用作负载均衡器算法和监控的输入。 客户端应用程序需要为其配置定义此属性 1&lt;clientName&gt;.&lt;nameSpace&gt;.ClientClassName=&lt;Your implementation class name&gt; 然后，客户端应用程序可以使用ClientFactory中的适当API获取客户端的实例 3.4 与Eureka整合Eureka提供服务发现功能，可将ribbon于eureka集成以提供动态服务器列表。要使用Eureka提供的服务列表，请按照下列步骤操作： 1.在您的依赖项中添加ribbon-eureka模块 2.（默认情况下已完成）为客户端启用负载均衡器，并将负载均衡器配置为DynamicServerListLoadBalancer或其子类。默认情况下这是已启用。 3.将ServerList配置为com.netflix.niws.loadbalancer.DiscoveryEnabledNIWSServerList 4.配置服务器刷新率。（可选，默认为30秒） 5.为客户端配置服务器的虚拟地址（“Vip Address”），并确保它与服务器的“Vip Address”匹配，用于向Eureka服务器注册。 demo 如下1234567myclient.ribbon.NIWSServerListClassName=com.netflix.niws.loadbalancer.DiscoveryEnabledNIWSServerList# refresh every minute myclient.ribbon.ServerListRefreshInterval=60000# movieservice 是一个注册在Eureka server注册中心的服务虚拟ip，myclient.ribbon.DeploymentContextBasedVipAddresses=movieservice 此外，您需要为Eureka客户端提供适当的配置文件。看到这里。 4.使用balancersribbon 提供软件与集群服务器的负载均衡通信，负载均衡提供如下基本功能 1.向通信客户端提供单个服务器的公共DNS名称或IP 2.根据具体的逻辑运行在服务器列表中 有些负载均衡器还提供了一下高级功能如下： 1.通过将客户端和服务器划分为多个区域（如数据中心中的机架）来建立客户端和服务器之间的关联，并支持同一区域中的服务器以减少延迟 2.保持服务器统计信息，避免服务器出现高延迟或频繁出现故障 3.保持区域统计并避免可能中断的区域 4.1.负载均衡器组件 rule - 用于确定从列表返回哪个服务器的逻辑组件 Ping - 在后台运行的组件，用于确保服务器的活跃性 ServerList - 服务列表，可以是静态的或动态的，如果是使用动态的(使用DynamicServerListLoadBalancer),后台线程将刷新并以特定间隔过滤列表 这些组件可以通过编程方式设置，也可以通过客户端的一些配置属性，并通过反射创建。这些是有相关属性名称（.. 在属性文件中添加前缀): 12345NFLoadBalancerClassNameNFLoadBalancerRuleClassNameNFLoadBalancerPingClassNameNIWSServerListClassNameNIWSServerListFilterClassName 通过Archaius更改属性，这些组件的行为通常可以在运行时更改 4.2. common rule4.2.1 RoundRobinRule此规则只是通过循环选择服务器。它通常用作默认规则或更高级规则的备选。 4.2.2 AvailabilityFilteringRule此规则将跳过被视为“电路跳闸”或具有高并发连接数的服务器。 默认情况下，如果RestClient最近三次无法与其建立连接，则实例会跳闸。一旦实例电路跳闸，它将在电路被认为再次关闭之前保持这种状态30秒。然而，如果它继续连接失败，它将再次“电路跳闸”并且它变为“电路闭合”的等待时间将指数地增加到连续故障的数量。 可以通过Archaius 设置以下属性ConfigurationManager： 12345678# 连续连接失败阈值使服务器处于电路跳闸状态，默认为3niws.loadbalancer.&lt;clientName&gt;.connectionFailureCountThreshold# 实例不可用状态的最大周期，默认：30niws.loadbalancer.&lt;clientName&gt;.circuitTripMaxTimeoutSeconds# 并发连接的阈值计数跳过服务器，默认为Integer.MAX_INT&lt;clientName&gt;.&lt;clientConfigNameSpace&gt;.ActiveConnectionsLimit 4.2.3 WeightedResponseTimeRule对于此规则，每个服务器根据其平均响应时间给予权重。响应时间越长，重量就越小。该规则随机选择服务器，其中可能性由服务器的权重决定。 要启用WeightedResponseTimeRule，请通过API使用负载均衡器进行设置，或者设置以下属性 1&lt;clientName&gt;.&lt;clientConfigNameSpace&gt;.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.WeightedResponseTimeRule 4.3.ServerList4.3.1 Adhoc 静态服务列表您始终可以使用BaseLoadBalancer或其子类与API一起设置静态服务器列表 BaseLoadBalancer.setServersList() 4.3.2 ConfigurationBasedServerList这是负载均衡器的默认ServerList实现。您可以使用Archaius ConfigurationManager将服务器列表设置为属性。例如1sample-client.ribbon.listOfServers=www.microsoft.com:80,www.yahoo.com:80,www.google.com:80 如果动态更改属性，则负载均衡器的服务器列表也将更改。 4.3.3 DiscoveryEnabledNIWSServerList此ServerList实现从Eureka客户端获取服务器列表。必须通过属性中的VipAddress标识服务器群集。例如123myClient.ribbon.NIWSServerListClassName=com.netflix.niws.loadbalancer.DiscoveryEnabledNIWSServerList # the server must register itself with Eureka server with VipAddress &quot;myservice&quot;myClient.ribbon.DeploymentContextBasedVipAddresses=myservice 4.4 ServerListFilterServerListFilter是用于DynamicServerListLoadBalancer过滤从ServerList实现返回的服务器的组件。功能区中有两个ServerListFilter实现： 4.4.1 ZoneAffinityServerListFilter筛选出与客户端不在同一区域中的服务器，除非客户端区域中没有可用的服务器。可以通过指定以下属性来启用此过滤器（假设客户端名称为“myclient”，客户端属性名称空间为“ribbon”）： 1myclient.ribbon.EnableZoneAffinity=true 4.4.2 ServerListSubsetFilter此筛选器确保客户端仅看到ServerList实现返回的整个服务器的固定子集。它还可以定期用新服务器替换可用性较差的子集中的服务器。要启用此过滤器，请指定以下属性 123456myClient.ribbon.NIWSServerListClassName=com.netflix.niws.loadbalancer.DiscoveryEnabledNIWSServerList # the server must register itself with Eureka server with VipAddress &quot;myservice&quot;myClient.ribbon.DeploymentContextBasedVipAddresses=myservicemyClient.ribbon.NIWSServerListFilterClassName=com.netflix.loadbalancer.ServerListSubsetFilter# only show client 5 servers. default is 20.myClient.ribbon.ServerListSubsetFilter.size=5 4.5 java doc ribbon-core ribbon-eureka ribbon-httpclient","categories":[{"name":"ribbon","slug":"ribbon","permalink":"http://blog.shagle.cn/categories/ribbon/"}],"tags":[{"name":"ribbon","slug":"ribbon","permalink":"http://blog.shagle.cn/tags/ribbon/"}]},{"title":"spring 导图","slug":"spring-map","date":"2018-12-22T13:23:03.000Z","updated":"2018-12-22T13:23:53.000Z","comments":true,"path":"2018/12/22/spring-map/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-map/","excerpt":"","text":"参见spring 导图","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spring 导图","slug":"spring-导图","permalink":"http://blog.shagle.cn/tags/spring-导图/"}]},{"title":"Java技术之Future、Callable和FutureTask原理解析","slug":"Java技术之Future、Callable和FutureTask原理解析","date":"2018-12-22T13:20:25.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/22/Java技术之Future、Callable和FutureTask原理解析/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java技术之Future、Callable和FutureTask原理解析/","excerpt":"Future表示一个任务的生命周期，并提供了方法来判断是否已经完成或取消，以及获取任务的结果和取消任务等。Future接口：","text":"Future表示一个任务的生命周期，并提供了方法来判断是否已经完成或取消，以及获取任务的结果和取消任务等。Future接口： 123456789101112public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 在Future接口中声明了5个方法，下面依次解释每个方法的作用： 1.cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。 2.isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。 3.isDone方法表示任务是否已经完成，若任务完成，则返回true； 4.get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； 5.get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 也就是说实际上Future提供了三种功能： 1.判断任务是否完成； 2.中断任务；*3.获取任务执行结果。 Future与Callable的关系与ExecutorService与Executor的关系对应。 Runnable和Callable描述的都是抽象的计算任务。这些任务通常是有生命周期的。Executor执行的任务有4个生命周期阶段：创建、提交、开始和完成。由于有些任务可能要执行很长时间，因此通常希望可以取消这些任务。在Executor框架中，已提交但尚未开始的任务可以取消，对于已经开始执行的任务，只有当它们响应中断时才能取消。 返回结果的任务Callable与Future Executor框架使用Runnable作为其基本的任务表示形式。Runnable是一种有很大局限的抽象，它不能返回一个值或抛出一个受检查的异常。Runnable接口： 123public interface Runnable &#123; public abstract void run();&#125; 由于run()方法返回值为void类型，所以在执行完任务之后无法返回任何结果。 许多任务实际上都是存在延迟的计算，对于这些任务，Callable是一种更好的抽象：它会返回一个值，并可能抛出一个异常。Callable接口： 123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 可以看到，这是一个泛型接口，call()函数返回的类型就是传递进来的V类型。 1. FutureTaskFuture只是一个接口，无法直接创建对象，因此有了FutureTask。我们先来看下FutureTask的实现：1public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; FutureTask类实现了RunnableFuture接口：123public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; RunnableFuture继承了Runnable和Future接口，而FutureTask实现了RunnableFuture接口。 FutureTask的继承关系和方法如图所示： FutureTask是一个可取消的异步计算，FutureTask 实现了Future的基本方法，提供start cancel 操作，可以查询计算是否已经完成，并且可以获取计算的结果。结果只可以在计算完成之后获取，get方法会阻塞当计算没有完成的时候，一旦计算已经完成， 那么计算就不能再次启动或是取消。 一个FutureTask 可以用来包装一个 Callable 或是一个Runnable对象。因为FurtureTask实现了Runnable方法，所以一个 FutureTask可以提交(submit)给一个Excutor执行(excution). 它同时实现了Callable, 所以也可以作为Future得到Callable的返回值。 FutureTask有两个很重要的属性分别是state和runner， FutureTask之所以支持canacel操作，也是因为这两个属性。其中state为枚举值： 123456789101112131415161718192021222324252627282930313233343536373839private volatile int state; // 注意volatile关键字/** * 在构建FutureTask时设置，同时也表示内部成员callable已成功赋值， * 一直到worker thread完成FutureTask中的run(); */private static final int NEW = 0;/** * woker thread在处理task时设定的中间状态，处于该状态时， * 说明worker thread正准备设置result. */private static final int COMPLETING = 1;/** * 当设置result结果完成后，FutureTask处于该状态，代表过程结果， * 该状态为最终状态final state,(正确完成的最终状态) */private static final int NORMAL = 2;/** * 同上，只不过task执行过程出现异常，此时结果设值为exception, * 也是final state */private static final int EXCEPTIONAL = 3;/** * final state, 表明task被cancel（task还没有执行就被cancel的状态）. */private static final int CANCELLED = 4;/** * 中间状态，task运行过程中被interrupt时，设置的中间状态 */private static final int INTERRUPTING = 5;/** * final state, 中断完毕的最终状态，几种情况，下面具体分析 */private static final int INTERRUPTED = 6; state初始化为NEW。只有在set, setException和cancel方法中state才可以转变为终态。在任务完成期间，state的值可能为COMPLETING或INTERRUPTING。state有四种可能的状态转换： 1.NEW -&gt; COMPLETING -&gt; NORMAL 2.NEW -&gt; COMPLETING -&gt; EXCEPTIONAL 3.NEW -&gt; CANCELLED 4.NEW -&gt; INTERRUPTING -&gt; INTERRUPTED 其他成员变量： 1234567891011121314151617 /** The underlying callable; nulled out after running */ private Callable&lt;V&gt; callable; // 具体run运行时会调用其方法call()，并获得结果，结果时置为null. /** The result to return or exception to throw from get() */// non-volatile, protected by state reads/writes //没必要为votaile,因为其是伴随state 进行读写，而state是FutureTask的主导因素。 /** The thread running the callable; CASed during run() */ private volatile Thread runner; //具体的worker thread. /** Treiber stack of waiting threads */ private volatile WaitNode waiters; //Treiber stack 并发stack数据结构，用于存放阻塞在该futuretask#get方法的线程。 注：Treiber算法可参见：Lock-Free 算法 下面分析下Task的状态变化，也就一个任务的生命周期：创建一个FutureTask首先调用构造方法： 1234public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable &#125; 此时将state设置为初始态NEW。这里注意Runnable是怎样转换为Callable的，看下this.callable = Executors.callable(runnable, result); 调用Executors.callable: 12345678910111213141516171819public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result);&#125;static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; &#123; final Runnable task; final T result; RunnableAdapter(Runnable task, T result) &#123; this.task = task; this.result = result; &#125; public T call() &#123; task.run(); return result; &#125;&#125; 其实就是通过Callable的call方法调用Runnable的run方法，把传入的 T result 作为Callable的返回结果； 当创建完一个Task通常会提交给Executors来执行，当然也可以使用Thread来执行，Thread的start()方法会调用Task的run()方法。看下FutureTask的run()方法的实现： 1234567891011121314151617181920212223242526272829303132public void run() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); &#125; if (ran) set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; 首先判断任务的状态，如果任务状态不是new，说明任务状态已经改变（说明他已经走了上面4种可能变化的一种，比如caller调用了cancel，此时状态为Interrupting, 也说明了上面的cancel方法，task没运行时，就interrupt, task得不到运行，总是返回）； 如果状态是new, 判断runner是否为null, 如果为null, 则把当前执行任务的线程赋值给runner，如果runner不为null, 说明已经有线程在执行，返回。此处使用cas来赋值worker thread是保证多个线程同时提交同一个FutureTask时，确保该FutureTask的run只被调用一次， 如果想运行多次，使用runAndReset()方法。 这里 12345678!UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())//语义相当于下面这句话if (this.runner == null )&#123; this.runner = Thread.currentThread();&#125; 使用compareAndSwap能够保证原子性。关于compareAndSwap的相关内容，可参看：http://huangyunbin.iteye.com/blog/1942369 接着开始执行任务，如果要执行的任务不为空，并且state为New就执行，可以看到这里调用了Callable的call方法。如果执行成功则set结果，如果出现异常则setException。最后把runner设为null。 接着看下set方法： 1234567protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion(); &#125;&#125; 如果现在的状态是NEW就把状态设置成COMPLETING，然后设置成NORMAL。这个执行流程的状态变化就是： NEW-&gt;COMPLETING-&gt;NORMAL。 最后执行finishCompletion()方法： 123456789101112131415161718192021222324private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; done(); `Callable` = null; // to reduce footprint &#125; finishCompletion()会解除所有阻塞的worker thread， 调用done()方法，将成员变量Callable设为null。这里使用了LockSupport类来解除线程阻塞，关于LockSupport，可参见：LockSupport的park和unpark的基本使用,以及对线程中断的响应性 接下来分析FutureTask非常重要的get方法: public V get() throws InterruptedException, ExecutionException { int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);} 首先判断FutureTask的状态是否为完成状态，如果是完成状态，说明已经执行过set或setException方法，返回report(s): 12345678private V report(int s) throws ExecutionException &#123; Object x = outcome; if (s == NORMAL) return (V)x; if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x);&#125; 可以看到，如果FutureTask的状态是NORMAL, 即正确执行了set方法，get方法直接返回处理的结果， 如果是取消状态，即执行了setException，则抛出CancellationException异常。 如果get时,FutureTask的状态为未完成状态，则调用awaitDone方法进行阻塞。awaitDone(): 123456789101112131415161718192021222324252627282930313233343536private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; LockSupport.parkNanos(this, nanos); &#125; else LockSupport.park(this); &#125;&#125; awaitDone方法可以看成是不断轮询查看FutureTask的状态。在get阻塞期间： 1.如果执行get的线程被中断，则移除FutureTask的所有阻塞队列中的线程（waiters）,并抛出中断异常； 2.如果FutureTask的状态转换为完成状态（正常完成或取消），则返回完成状态； 3.如果FutureTask的状态变为COMPLETING, 则说明正在set结果，此时让线程等一等； 4.如果FutureTask的状态为初始态NEW，则将当前线程加入到FutureTask的阻塞线程中去； 5.如果get方法没有设置超时时间，则阻塞当前调用get线程；如果设置了超时时间，则判断是否达到超时时间，如果到达，则移除FutureTask的所有阻塞列队中的线程，并返回此时FutureTask的状态，如果未到达时间，则在剩下的时间内继续阻塞当前线程。 原文参考：https://blog.csdn.net/codershamo/article/details/51901057 出自：https://blog.csdn.net/hacker_lees/article/details/81296388","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"Future","slug":"Future","permalink":"http://blog.shagle.cn/tags/Future/"},{"name":"Callable","slug":"Callable","permalink":"http://blog.shagle.cn/tags/Callable/"},{"name":"FutureTask","slug":"FutureTask","permalink":"http://blog.shagle.cn/tags/FutureTask/"}]},{"title":"Java技术之Semaphore的工作原理及实例","slug":"Java技术之Semaphore的工作原理及实例","date":"2018-12-22T13:18:46.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/22/Java技术之Semaphore的工作原理及实例/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java技术之Semaphore的工作原理及实例/","excerpt":"Semaphore是一种在多线程环境下使用的设施，该设施负责协调各个线程，以保证它们能够正确、合理的使用公共资源的设施，也是操作系统中用于控制进程同步互斥的量。Semaphore是一种计数信号量，用于管理一组资源，内部是基于AQS的共享模式。它相当于给线程规定一个量从而控制允许活动的线程数。","text":"Semaphore是一种在多线程环境下使用的设施，该设施负责协调各个线程，以保证它们能够正确、合理的使用公共资源的设施，也是操作系统中用于控制进程同步互斥的量。Semaphore是一种计数信号量，用于管理一组资源，内部是基于AQS的共享模式。它相当于给线程规定一个量从而控制允许活动的线程数。 1.工作原理以一个停车场是运作为例。为了简单起见，假设停车场只有三个车位，一开始三个车位都是空的。这时如果同时来了五辆车，看门人允许其中三辆不受阻碍的进入，然后放下车拦，剩下的车则必须在入口等待，此后来的车也都不得不在入口处等待。这时，有一辆车离开停车场，看门人得知后，打开车拦，放入一辆，如果又离开两辆，则又可以放入两辆，如此往复。这个停车系统中，每辆车就好比一个线程，看门人就好比一个信号量，看门人限制了可以活动的线程。假如里面依然是三个车位，但是看门人改变了规则，要求每次只能停两辆车，那么一开始进入两辆车，后面得等到有车离开才能有车进入，但是得保证最多停两辆车。对于Semaphore类而言，就如同一个看门人，限制了可活动的线程数。 1.1 Semaphore主要方法： Semaphore(int permits):构造方法，创建具有给定许可数的计数信号量并设置为非公平信号量。 Semaphore(int permits,boolean fair):构造方法，当fair等于true时，创建具有给定许可数的计数信号量并设置为公平信号量。 void acquire():从此信号量获取一个许可前线程将一直阻塞。相当于一辆车占了一个车位。 void acquire(int n):从此信号量获取给定数目许可，在提供这些许可前一直将线程阻塞。比如n=2，就相当于一辆车占了两个车位。 void release():释放一个许可，将其返回给信号量。就如同车开走返回一个车位。 void release(int n):释放n个许可。 int availablePermits()：当前可用的许可数。 2.实例讲解接下来举个例子，就是关于每个人的个人信息，那么一个人占用一个线程，并用Semphore类创建对象从而初始化信号量，控制可活动的线程数。具体代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package concurrent;import java.util.concurrent.Semaphore;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;import java.util.concurrent.LinkedBlockingQueue;public class SemaphoreDemo &#123; private static final Semaphore semaphore=new Semaphore(3); private static final ThreadPoolExecutor threadPool=new ThreadPoolExecutor(5,10,60,TimeUnit.SECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()); private static class InformationThread extends Thread&#123; private final String name; private final int age; public InformationThread(String name,int age) &#123; this.name=name; this.age=age; &#125; public void run() &#123; try &#123; semaphore.acquire(); System.out.println(Thread.currentThread().getName()+\":大家好，我是\"+name+\"我今年\"+age+\"岁当前时间为：\"+System.currentTimeMillis()); Thread.sleep(1000); System.out.println(name+\"要准备释放许可证了，当前时间为：\"+System.currentTimeMillis()); System.out.println(\"当前可使用的许可数为：\"+semaphore.availablePermits()); semaphore.release(); &#125; catch(InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; String[] name= &#123;\"李明\",\"王五\",\"张杰\",\"王强\",\"赵二\",\"李四\",\"张三\"&#125;; int[] age= &#123;26,27,33,45,19,23,41&#125;; for(int i=0;i&lt;7;i++) &#123; Thread t1=new InformationThread(name[i],age[i]); threadPool.execute(t1); &#125; &#125; &#125; 运行上述程序结果如下： 123456789101112131415161718192021pool-1-thread-3:大家好，我是张杰我今年33岁当前时间为：1520424000186pool-1-thread-1:大家好，我是李明我今年26岁当前时间为：1520424000186pool-1-thread-2:大家好，我是王五我今年27岁当前时间为：1520424000186张杰要准备释放许可证了，当前时间为：1520424001187李明要准备释放许可证了，当前时间为：1520424001187王五要准备释放许可证了，当前时间为：1520424001187当前可使用的许可数为：0当前可使用的许可数为：0当前可使用的许可数为：0pool-1-thread-4:大家好，我是王强我今年45岁当前时间为：1520424001187pool-1-thread-2:大家好，我是张三我今年41岁当前时间为：1520424001187pool-1-thread-1:大家好，我是李四我今年23岁当前时间为：1520424001187李四要准备释放许可证了，当前时间为：1520424002187王强要准备释放许可证了，当前时间为：1520424002187当前可使用的许可数为：0张三要准备释放许可证了，当前时间为：1520424002187pool-1-thread-5:大家好，我是赵二我今年19岁当前时间为：1520424002187当前可使用的许可数为：0当前可使用的许可数为：0赵二要准备释放许可证了，当前时间为：1520424003188当前可使用的许可数为：2 以上是非公平信号量，将建立Semaphore对象的语句改为如下语句： 1private static final Semaphore semaphore=new Semaphore(3,true); 运行程序：123456789101112131415161718192021pool-1-thread-2:大家好，我是王五我今年27岁当前时间为：1520424286454pool-1-thread-3:大家好，我是张杰我今年33岁当前时间为：1520424286454pool-1-thread-1:大家好，我是李明我今年26岁当前时间为：1520424286454pool-1-thread-1:李明要准备释放许可证了，当前时间为：1520424287455当前可使用的许可数为：0pool-1-thread-2:王五要准备释放许可证了，当前时间为：1520424287455pool-1-thread-3:张杰要准备释放许可证了，当前时间为：1520424287455当前可使用的许可数为：0当前可使用的许可数为：1pool-1-thread-1:大家好，我是李四我今年23岁当前时间为：1520424287455pool-1-thread-5:大家好，我是赵二我今年19岁当前时间为：1520424287455pool-1-thread-4:大家好，我是王强我今年45岁当前时间为：1520424287455pool-1-thread-4:王强要准备释放许可证了，当前时间为：1520424288456当前可使用的许可数为：0pool-1-thread-1:李四要准备释放许可证了，当前时间为：1520424288456pool-1-thread-3:大家好，我是张三我今年41岁当前时间为：1520424288456pool-1-thread-5:赵二要准备释放许可证了，当前时间为：1520424288456当前可使用的许可数为：0当前可使用的许可数为：0pool-1-thread-3:张三要准备释放许可证了，当前时间为：1520424289456当前可使用的许可数为：2 3.实现单例模式将创建信号量对象语句修改如下：1private static final Semaphore semaphore=new Semaphore(1); 运行程序，结果如下： 123456789101112131415161718192021pool-1-thread-1:大家好，我是李明我今年26岁当前时间为：1520424379699pool-1-thread-1:李明要准备释放许可证了，当前时间为：1520424380700当前可使用的许可数为：0pool-1-thread-2:大家好，我是王五我今年27岁当前时间为：1520424380700pool-1-thread-2:王五要准备释放许可证了，当前时间为：1520424381701当前可使用的许可数为：0pool-1-thread-3:大家好，我是张杰我今年33岁当前时间为：1520424381701pool-1-thread-3:张杰要准备释放许可证了，当前时间为：1520424382702当前可使用的许可数为：0pool-1-thread-4:大家好，我是王强我今年45岁当前时间为：1520424382702pool-1-thread-4:王强要准备释放许可证了，当前时间为：1520424383702当前可使用的许可数为：0pool-1-thread-5:大家好，我是赵二我今年19岁当前时间为：1520424383702pool-1-thread-5:赵二要准备释放许可证了，当前时间为：1520424384702当前可使用的许可数为：0pool-1-thread-1:大家好，我是李四我今年23岁当前时间为：1520424384702pool-1-thread-1:李四要准备释放许可证了，当前时间为：1520424385702当前可使用的许可数为：0pool-1-thread-2:大家好，我是张三我今年41岁当前时间为：1520424385702pool-1-thread-2:张三要准备释放许可证了，当前时间为：1520424386703当前可使用的许可数为：0 如上可知，如果将给定许可数设置为1，就如同一个单例模式，即单个停车位，只有一辆车进，然后这辆车出来后，下一辆车才能进。 4.总结Semaphore主要用于控制当前活动线程数目，就如同停车场系统一般，而Semaphore则相当于看守的人，用于控制总共允许停车的停车位的个数，而对于每辆车来说就如同一个线程，线程需要通过acquire()方法获取许可，而release()释放许可。如果许可数达到最大活动数，那么调用acquire()之后，便进入等待队列，等待已获得许可的线程释放许可，从而使得多线程能够合理的运行。 上面原文 5.源码解析Semaphore有两种模式，公平模式和非公平模式。公平模式就是调用acquire的顺序就是获取许可证的顺序，遵循FIFO( First Input First Output,简单说就是指先进先出)；而非公平模式是抢占式的，也就是有可能一个新的获取线程恰好在一个许可证释放时得到了这个许可证，而前面还有等待的线程。 5.1 构造方法Semaphore有两个构造方法，如下：1234567public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits);&#125; 从上面可以看到两个构造方法，都必须提供许可的数量，第二个构造方法可以指定是公平模式还是非公平模式，默认非公平模式。Semaphore内部基于AQS的共享模式，所以实现都委托给了Sync类。这里就看一下NonfairSync的构造方法： 123NonfairSync(int permits) &#123; super(permits);&#125; 可以看到直接调用了父类的构造方法，Sync的构造方法如下： 123Sync(int permits) &#123; setState(permits);&#125; 可以看到调用了setState方法，也就是说AQS中的资源就是许可证的数量。 5.2 获取许可先从获取一个许可看起，并且先看非公平模式下的实现。首先看acquire方法，acquire方法有几个重载，但主要是下面这个方法1234public void acquire(int permits) throws InterruptedException &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireSharedInterruptibly(permits);&#125; 从上面可以看到，调用了Sync的acquireSharedInterruptibly方法，该方法在父类AQS中，如下： 123456789public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; //如果线程被中断了，抛出异常 if (Thread.interrupted()) throw new InterruptedException(); //获取许可失败，将线程加入到等待队列中 if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125; AQS子类如果要使用共享模式的话，需要实现tryAcquireShared方法，下面看NonfairSync的该方法实现： 123protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires);&#125; 该方法调用了父类中的nonfairTyAcquireShared方法，如下： 123456789101112final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; //获取剩余许可数量 int available = getState(); //计算给完这次许可数量后的个数 int remaining = available - acquires; //如果许可不够或者可以将许可数量重置的话，返回 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125; 从上面可以看到，只有在许可不够时返回值才会小于0，其余返回的都是剩余许可数量，这也就解释了，一旦许可不够，后面的线程将会阻塞。看完了非公平的获取，再看下公平的获取，代码如下： 12345678910111213protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; //如果前面有线程再等待，直接返回-1 if (hasQueuedPredecessors()) return -1; //后面与非公平一样 int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125; 从上面可以看到，FairSync与NonFairSync的区别就在于会首先判断当前队列中有没有线程在等待，如果有，就老老实实进入到等待队列；而不像NonfairSync一样首先试一把，说不定就恰好获得了一个许可，这样就可以插队了。看完了获取许可后，再看一下释放许可。 5.3 释放许可释放许可也有几个重载方法，但都会调用下面这个带参数的方法， 1234public void release(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.releaseShared(permits);&#125; releaseShared方法在AQS中，如下： 12345678public final boolean releaseShared(int arg) &#123; //如果改变许可数量成功 if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; AQS子类实现共享模式的类需要实现tryReleaseShared类来判断是否释放成功，实现如下： 12345678910111213protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; //获取当前许可数量 int current = getState(); //计算回收后的数量 int next = current + releases; if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); //CAS改变许可数量成功，返回true if (compareAndSetState(current, next)) return true; &#125;&#125; 从上面可以看到，一旦CAS改变许可数量成功，那么就会调用doReleaseShared()方法释放阻塞的线程。 5.4 减小许可数量Semaphore还有减小许可数量的方法，该方法可以用于用于当资源用完不能再用时，这时就可以减小许可证。代码如下： 1234protected void reducePermits(int reduction) &#123; if (reduction &lt; 0) throw new IllegalArgumentException(); sync.reducePermits(reduction);&#125; 可以看到，委托给了Sync，Sync的reducePermits方法如下： 12345678910111213final void reducePermits(int reductions) &#123; for (;;) &#123; //得到当前剩余许可数量 int current = getState(); //得到减完之后的许可数量 int next = current - reductions; if (next &gt; current) // underflow throw new Error(\"Permit count underflow\"); //如果CAS改变成功 if (compareAndSetState(current, next)) return; &#125;&#125; 从上面可以看到，就是CAS改变AQS中的state变量，因为该变量代表许可证的数量。 5.5 获取剩余许可数量 Semaphore还可以一次将剩余的许可数量全部取走，该方法是drain方法，如下： 123public int drainPermits() &#123; return sync.drainPermits();&#125; Sync的实现如下： 1234567final int drainPermits() &#123; for (;;) &#123; int current = getState(); if (current == 0 || compareAndSetState(current, 0)) return current; &#125; &#125; 可以看到，就是CAS将许可数量置为0。 5.6 总结Semaphore是信号量，用于管理一组资源。其内部是基于AQS的共享模式，AQS的状态表示许可证的数量，在许可证数量不够时，线程将会被挂起；而一旦有一个线程释放一个资源，那么就有可能重新唤醒等待队列中的线程继续执行。 原文出自:https://blog.csdn.net/qq_19431333/article/details/70212663","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"Semaphore","slug":"Semaphore","permalink":"http://blog.shagle.cn/tags/Semaphore/"}]},{"title":"Java技术之AQS详解","slug":"Java技术之AQS详解","date":"2018-12-22T13:12:09.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/22/Java技术之AQS详解/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java技术之AQS详解/","excerpt":"Java并发包（JUC）中提供了很多并发工具，这其中，很多我们耳熟能详的并发工具，譬如ReentrangLock、Semaphore，它们的实现都用到了一个共同的基类–AbstractQueuedSynchronizer,简称AQS。AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。 本章我们就一起探究下这个神奇的东东，并对其实现原理进行剖析理解","text":"Java并发包（JUC）中提供了很多并发工具，这其中，很多我们耳熟能详的并发工具，譬如ReentrangLock、Semaphore，它们的实现都用到了一个共同的基类–AbstractQueuedSynchronizer,简称AQS。AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。 本章我们就一起探究下这个神奇的东东，并对其实现原理进行剖析理解 1. 基本实现原理AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。 1private volatile int state;//共享变量，使用volatile修饰保证线程可见性 volatile 状态信息通过procted类型的getState，setState，compareAndSetState进行操作,这三种操作均是原子操作，其中compareAndSetState的实现依赖于Unsafe的compareAndSwapInt()方法 AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch），组合式的如ReentrantReadWriteLock。总之，AQS为使用提供了底层支撑，如何组装实现，使用者可以自由发挥。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法： 同步器的设计是基于模板方法模式的，一般的使用方式是这样： 1.使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放） 2.将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。 这其实是模板方法模式的一个很经典的应用。 我们来看看AQS定义的这些可重写的方法： protected boolean tryAcquire(int arg) : 独占式获取同步状态，试着获取，成功返回true，反之为false protected boolean tryRelease(int arg) ：独占式释放同步状态，等待中的其他线程此时将有机会获取到同步状态； protected int tryAcquireShared(int arg) ：共享式获取同步状态，返回值大于等于0，代表获取成功；反之获取失败； protected boolean tryReleaseShared(int arg) ：共享式释放同步状态，成功为true，失败为false protected boolean isHeldExclusively() ： 是否在独占模式下被线程占用。 关于AQS的使用，我们来简单总结一下： 1.1 如何使用首先，我们需要去继承AbstractQueuedSynchronizer这个类，然后我们根据我们的需求去重写相应的方法，比如要实现一个独占锁，那就去重写tryAcquire，tryRelease方法，要实现共享锁，就去重写tryAcquireShared，tryReleaseShared；最后，在我们的组件中调用AQS中的模板方法就可以了，而这些模板方法是会调用到我们之前重写的那些方法的。也就是说，我们只需要很小的工作量就可以实现自己的同步组件，重写的那些方法，仅仅是一些简单的对于共享资源state的获取和释放操作，至于像是获取资源失败，线程需要阻塞之类的操作，自然是AQS帮我们完成了。 1.2 设计思想对于使用者来讲，我们无需关心获取资源失败，线程排队，线程阻塞/唤醒等一系列复杂的实现，这些都在AQS中为我们处理好了。我们只需要负责好自己的那个环节就好，也就是获取/释放共享资源state的姿势。很经典的模板方法设计模式的应用，AQS为我们定义好顶级逻辑的骨架，并提取出公用的线程入队列/出队列，阻塞/唤醒等一系列复杂逻辑的实现，将部分简单的可由使用者决定的操作逻辑延迟到子类中去实现即可。 2. 源码分析我们先来简单描述下AQS的基本实现，前面我们提到过，AQS维护一个共享资源state，通过内置的FIFO来完成获取资源线程的排队工作。（这个内置的同步队列称为”CLH”队列）。该队列由一个一个的Node结点组成，每个Node结点维护一个prev引用和next引用，分别指向自己的前驱和后继结点。AQS维护两个指针，分别指向队列头部head和尾部tail。 其实就是个双端双向链表。 当线程获取资源失败（比如tryAcquire时试图设置state状态失败），会被构造成一个结点加入CLH队列中，同时当前线程会被阻塞在队列中（通过LockSupport.park实现，其实是等待态）。当持有同步状态的线程释放同步状态时，会唤醒后继结点，然后此结点线程继续加入到对同步状态的争夺中。 2.1 Node结点Node结点是AbstractQueuedSynchronizer中的一个静态内部类，我们捡Node的几个重要属性来说一下1234567891011121314151617181920static final class Node &#123; /** waitStatus值，表示线程已被取消（等待超时或者被中断）*/ static final int CANCELLED = 1; /** waitStatus值，表示后继线程需要被唤醒（unpaking）*/ static final int SIGNAL = -1; /**waitStatus值，表示结点线程等待在condition上，当被signal后，会从等待队列转移到同步到队列中 */ /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; /** waitStatus值，表示下一次共享式同步状态会被无条件地传播下去 */ static final int PROPAGATE = -3; /** 等待状态，初始为0 */ volatile int waitStatus; /**当前结点的前驱结点 */ volatile Node prev; /** 当前结点的后继结点 */ volatile Node next; /** 与当前结点关联的排队中的线程 */ volatile Thread thread; /** ...... */&#125; 2.2 独占式2.2.1 获取同步状态–acquire()来看看acquire方法，lock方法一般会直接代理到acquire上12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 通过注释我们知道，acquire方法是一种互斥模式，且忽略中断。该方法至少执行一次tryAcquire(int)方法，如果tryAcquire(int)方法返回true，则acquire直接返回，否则当前线程需要进入队列进行排队。函数流程如下： a.首先，调用使用者重写的tryAcquire方法，若返回true，意味着获取同步状态成功，后面的逻辑不再执行；若返回false，也就是获取同步状态失败，进入b步骤； b.此时，获取同步状态失败，构造独占式同步结点，通过addWatiter将此结点添加到同步队列的尾部（此时可能会有多个线程结点试图加入同步队列尾部，需要以线程安全的方式添加）； c.acquireQueued()使线程在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 d.如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。 2.2.2 addWaiter为获取同步状态失败的线程，构造成一个Node结点，添加到同步队列尾部123456789101112131415private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode);//构造结点 //指向尾结点tail Node pred = tail; //如果尾结点不为空，CAS快速尝试在尾部添加，若CAS设置成功，返回；否则，eng。 if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 先cas快速设置，若失败，进入enq方法 将结点添加到同步队列尾部这个操作，同时可能会有多个线程尝试添加到尾部，是非线程安全的操作。 以上代码可以看出，使用了compareAndSetTail这个cas操作保证安全添加尾结点。 2.2.3 enq方法123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; //如果队列为空，创建结点，同时被head和tail引用 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123;//cas设置尾结点，不成功就一直重试 t.next = node; return t; &#125; &#125; &#125;&#125; enq内部是个死循环，通过CAS设置尾结点，不成功就一直重试。很经典的CAS自旋的用法，我们在之前关于原子类的源码分析中也提到过。这是一种乐观的并发策略。 最后，看下acquireQueued方法 2.2.4 acquireQueued12345678910111213141516171819202122final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123;//死循环 final Node p = node.predecessor();//找到当前结点的前驱结点 if (p == head &amp;&amp; tryAcquire(arg)) &#123;//如果前驱结点是头结点，才tryAcquire，其他结点是没有机会tryAcquire的。 setHead(node);//获取同步状态成功，将当前结点设置为头结点。 p.next = null; // 方便GC failed = false; return interrupted; &#125; // 如果没有获取到同步状态，通过shouldParkAfterFailedAcquire判断是否应该阻塞，parkAndCheckInterrupt用来阻塞线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; acquireQueued内部也是一个死循环，只有前驱结点是头结点的结点，也就是老二结点，才有机会去tryAcquire；若tryAcquire成功，表示获取同步状态成功，将此结点设置为头结点；若是非老二结点，或者tryAcquire失败，则进入shouldParkAfterFailedAcquire去判断判断当前线程是否应该阻塞，若可以，调用parkAndCheckInterrupt阻塞当前线程，直到被中断或者被前驱结点唤醒。若还不能休息，继续循环。 2.2.5 shouldParkAfterFailedAcquireshouldParkAfterFailedAcquire用来判断当前结点线程是否能休息 1234567891011121314151617private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //获取前驱结点的wait值 int ws = pred.waitStatus; if (ws == Node.SIGNAL)//若前驱结点的状态是SIGNAL，意味着当前结点可以被安全地park return true; if (ws &gt; 0) &#123; // ws&gt;0，只有CANCEL状态ws才大于0。若前驱结点处于CANCEL状态，也就是此结点线程已经无效，从后往前遍历，找到一个非CANCEL状态的结点，将自己设置为它的后继结点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 若前驱结点为其他状态，将其设置为SIGNAL状态 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 若shouldParkAfterFailedAcquire返回true，也就是当前结点的前驱结点为SIGNAL状态，则意味着当前结点可以放心休息，进入parking状态了。parkAncCheckInterrupt阻塞线程并处理中断。1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this);//使用LockSupport使线程进入阻塞状态 return Thread.interrupted();// 线程是否被中断过&#125; 至此，关于acquire的方法源码已经分析完毕，我们来简单总结下 a.首先tryAcquire获取同步状态，成功则直接返回；否则，进入下一环节； b.线程获取同步状态失败，就构造一个结点，加入同步队列中，这个过程要保证线程安全； c.加入队列中的结点线程进入自旋状态，若是老二结点（即前驱结点为头结点），才有机会尝试去获取同步状态；否则，当其前驱结点的状态为SIGNAL，线程便可安心休息，进入阻塞状态，直到被中断或者被前驱结点唤醒。 2.2.6 释放同步状态–release()当前线程执行完自己的逻辑之后，需要释放同步状态，来看看release方法的逻辑 123456789 public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123;//调用使用者重写的tryRelease方法，若成功，唤醒其后继结点，失败则返回false Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h);//唤醒后继结点 return true; &#125; return false;&#125; 2.2.7 unparkSuccessor:唤醒后继结点 123456789101112131415private void unparkSuccessor(Node node) &#123; //获取wait状态 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0);// 将等待状态waitStatus设置为初始值0 Node s = node.next;//后继结点 if (s == null || s.waitStatus &gt; 0) &#123;//若后继结点为空，或状态为CANCEL（已失效），则从后尾部往前遍历找到一个处于正常阻塞状态的结点 进行唤醒 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);//使用LockSupprot唤醒结点对应的线程&#125; release的同步状态相对简单，需要找到头结点的后继结点进行唤醒，若后继结点为空或处于CANCEL状态，从后向前遍历找寻一个正常的结点，唤醒其对应线程。 2.3 共享式共享式：共享式地获取同步状态。对于独占式同步组件来讲，同一时刻只有一个线程能获取到同步状态，其他线程都得去排队等待，期待重写的尝试获取同步状态的方法tryAcquire返回值为boolean，这很容易理解；对于共享式同步组件来讲，同一时刻可以有多个线程同时获取到同步状态，这也是“共享”的意义所在。其待重写的尝试获取同步状态的方法tryAcquireShared返回值为int。 123protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125; 1.当返回值大于0时，表示获取同步状态成功，同时还有剩余同步状态可供其他线程获取； 2.当返回值等于0时，表示获取同步状态成功，但没有可用同步状态了； 3.当返回值小于0时，表示获取同步状态失败。 2.3.1 获取同步状态–acquireShared 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0)//返回值小于0，获取同步状态失败，排队去；获取同步状态成功，直接返回去干自己的事儿。 doAcquireShared(arg);&#125; 2.3.2 doAcquireShared123456789101112131415161718192021222324252627private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED);//构造一个共享结点，添加到同步队列尾部。若队列初始为空，先添加一个无意义的傀儡结点，再将新节点添加到队列尾部。 boolean failed = true;//是否获取成功 try &#123; boolean interrupted = false;//线程parking过程中是否被中断过 for (;;) &#123;//死循环 final Node p = node.predecessor();//找到前驱结点 if (p == head) &#123;//头结点持有同步状态，只有前驱是头结点，才有机会尝试获取同步状态 int r = tryAcquireShared(arg);//尝试获取同步状态 if (r &gt;= 0) &#123;//r&gt;=0,获取成功 setHeadAndPropagate(node, r);//获取成功就将当前结点设置为头结点，若还有可用资源，传播下去，也就是继续唤醒后继结点 p.next = null; // 方便GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;//是否能安心进入parking状态 parkAndCheckInterrupt())//阻塞线程 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 大体逻辑与独占式的acquireQueued差距不大，只不过由于是共享式，会有多个线程同时获取到线程，也可能同时释放线程，空出很多同步状态，所以当排队中的老二获取到同步状态，如果还有可用资源，会继续传播下去。 123456789 private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 2.3.3 释放同步状态–releaseShared1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared();//释放同步状态 return true; &#125; return false;&#125; 2.3.4 doReleaseShared123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123;//死循环，共享模式，持有同步状态的线程可能有多个，采用循环CAS保证线程安全 Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h);//唤醒后继结点 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; if (h == head) break; &#125;&#125; 代码逻辑比较容易理解，需要注意的是，共享模式，释放同步状态也是多线程的，此处采用了CAS自旋来保证。 3.总结关于AQS的介绍及源码分析到此为止了。 AQS是JUC中很多同步组件的构建基础，简单来讲，它内部实现主要是状态变量state和一个FIFO队列来完成，同步队列的头结点是当前获取到同步状态的结点，获取同步状态state失败的线程，会被构造成一个结点（或共享式或独占式）加入到同步队列尾部（采用自旋CAS来保证此操作的线程安全），随后线程会阻塞；释放时唤醒头结点的后继结点，使其加入对同步状态的争夺中。 AQS为我们定义好了顶层的处理实现逻辑，我们在使用AQS构建符合我们需求的同步组件时，只需重写tryAcquire，tryAcquireShared，tryRelease，tryReleaseShared几个方法，来决定同步状态的释放和获取即可，至于背后复杂的线程排队，线程阻塞/唤醒，如何保证线程安全，都由AQS为我们完成了，这也是非常典型的模板方法的应用。AQS定义好顶级逻辑的骨架，并提取出公用的线程入队列/出队列，阻塞/唤醒等一系列复杂逻辑的实现，将部分简单的可由使用者决定的操作逻辑延迟到子类中去实现。 4. JUC AQS实现 Semaphore 信号 CountDownLatch ReentrantLock原文出自:https://www.cnblogs.com/chengxiao/p/7141160.html","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"AQS","slug":"AQS","permalink":"http://blog.shagle.cn/tags/AQS/"}]},{"title":"Java技术 interrupt(), interrupted(), isInterrupted()方法区别","slug":"Java技术之线程中断","date":"2018-12-22T13:10:18.000Z","updated":"2018-12-22T13:11:34.000Z","comments":true,"path":"2018/12/22/Java技术之线程中断/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java技术之线程中断/","excerpt":"","text":"1. interrupt()首先看看官方说明： interrupt（）方法 12345/*** 中断次线程。* 除非当前线程正在中断自身(始终允许)，否则checkAccess调用此线程的方法，这可能会导致SecurityException抛出该线程*/public void interrupt(); 其作用是中断此线程（此线程不一定是当前线程，而是指调用该方法的Thread实例所代表的线程），但实际上只是给线程设置一个中断标志，线程仍会继续运行。 2. interrupted（）方法1234567/*** 测试当前线程是否被中断，此方法清除线程的中断状态，换句话说，如果连续两次调用此方法，则第二次调用将返回false(除非当前线程在第一次调用已清除其中断状态之后且在第二次调用检查之前再次中断)* 线程中断被忽略，因为在中断时线程不活动将被此方法反映返回false* 返回：* true：如果当前线程已被中断；false：除此以外*/public static boolean interrupted() 作用是测试当前线程是否被中断(检查中断标志),返回一个boolean并清除中断状态，第二次在调用时中断状态已经被清除，将返回一个false 3. isInterrupted()方法1234567/*** 测试此线程是否已被中断，线程的中断状态不受此方法影响，线程中断被忽略，因为在中断时线程不活动将被此方法反应返回false。* 返回：* true：如果这个线程被中断了；false：除此以外* */public boolean isInterrupted() 作用是只测试此线程是否被中断 ，不清除中断状态。 4 测试说明下面我们进行测试说明： 定义一个MyThread类，继承Thread，如下： 12345678public class MyThread extends Thread &#123; @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(\"i=\"+(i+1)); &#125; &#125;&#125; 在main方法中测试： 12345678910public class Do &#123; public static void main(String[] args ) &#123; MyThread thread=new MyThread(); thread.start(); thread.interrupt(); System.out.println(\"第一次调用thread.isInterrupted()：\"+thread.isInterrupted()); System.out.println(\"第二次调用thread.isInterrupted()：\"+thread.isInterrupted()); System.out.println(\"thread是否存活：\"+thread.isAlive()); &#125;&#125; 输出结果如下：12345678910111213第一次调用thread.isInterrupted()：true第二次调用thread.isInterrupted()：:truethread是否存活：truei=1i=2i=3i=4i=5i=6i=7i=8i=9i=10 从结果可以看出调用interrupt（）方法后，线程仍在继续运行，并未停止，但已经给线程设置了中断标志，两个isInterrupted（）方法都会输出true，也说明isInterrupted（）方法并不会清除中断状态。 下面我们把代码修改一下，多加两行调用interrupted（）方法： 12345678910111213public class Do &#123; public static void main(String[] args ) &#123; MyThread thread=new MyThread(); thread.start(); thread.interrupt(); System.out.println(\"第一次调用thread.isInterrupted()：\"+thread.isInterrupted()); System.out.println(\"第二次调用thread.isInterrupted()：\"+thread.isInterrupted()); //测试interrupted（）函数 System.out.println(\"第一次调用thread.interrupted()：\"+thread.interrupted()); System.out.println(\"第二次调用thread.interrupted()：\"+thread.interrupted()); System.out.println(\"thread是否存活：\"+thread.isAlive()); &#125;&#125; 输出结果如下：123456789101112131415第一次调用thread.isInterrupted()：true第二次调用thread.isInterrupted()：:true第一次调用thread.interrupted()：false第二次调用thread.interrupted()：:falsethread是否存活：truei=1i=2i=3i=4i=5i=6i=7i=8i=9i=10 从输出结果看，可能会有疑惑，为什么后面两个interrupted方法输出的都是false，而不是预料中的一个true一个false？注意！！！这是一个坑！！！上面说到，interrupted（）方法测试的是当前线程是否被中断，当前线程！！！当前线程！！！这里当前线程是main线程，而thread.interrupt(）中断的是thread线程，这里的此线程就是thread线程。所以当前线程main从未被中断过，尽管interrupted（）方法是以thread.interrupted（）的形式被调用，但它检测的仍然是main线程而不是检测thread线程，所以thread.interrupted（）在这里相当于main.interrupted（）。对于这点，下面我们再修改进行测试。 Thread.currentThread()函数可以获取当前线程，下面代码中获取的是main线程 1234567891011public class Do &#123; public static void main(String[] args ) throws InterruptedException &#123; Thread.currentThread().interrupt(); System.out.println(\"第一次调用Thread.currentThread().interrupt()：\" +Thread.currentThread().isInterrupted()); System.out.println(\"第一次调用thread.interrupted()：\" +Thread.currentThread().interrupted()); System.out.println(\"第二次调用thread.interrupted()：\" +Thread.currentThread().interrupted()); &#125;&#125; 这里都是针对当前线程在操作，如果interrupted（）方法有检测中断并清除中断状态的作用，预料中的输出应该是true-true-false，实际输出如下： 123第一次调用Thread.currentThread().interrupt()：true第一次调用thread.interrupted()：true第二次调用thread.interrupted()：false 结果证明猜想是正确的。 若果想要是实现调用interrupt（）方法真正的终止线程，则可以在线程的run方法中做处理即可，比如直接跳出run（）方法使线程结束，视具体情况而定，下面是一个例子。 修改MyThread类： 123456789101112131415public class MyThread extends Thread &#123; @Override public void run() &#123; for (int i = 0; i &lt; 1000; i++) &#123; System.out.println(\"i=\"+(i+1)); if(this.isInterrupted())&#123; System.out.println(\"通过this.isInterrupted()检测到中断\"); System.out.println(\"第一个interrupted():\"+this.interrupted()); System.out.println(\"第二个interrupted():\"+this.interrupted()); break; &#125; &#125; System.out.println(\"因为检测到中断，所以跳出循环，线程到这里结束，因为后面没有内容了\"); &#125;&#125; 测试MyThread： 12345678910public class Do &#123; public static void main(String[] args ) throws InterruptedException &#123; MyThread myThread=new MyThread(); myThread.start(); myThread.interrupt(); //sleep等待一秒，等myThread运行完 Thread.currentThread().sleep(1000); System.out.println(\"myThread线程是否存活：\"+myThread.isAlive()); &#125;&#125; 结果： 123456i=1通过this.isInterrupted()检测到中断第一个interrupted():true第二个interrupted():false因为检测到中断，所以跳出循环，线程到这里结束，因为后面没有内容了myThread线程是否存活：false 最后总结，关于这三个方法，interrupt（）是给线程设置中断标志；interrupted（）是检测中断并清除中断状态；isInterrupted（）只检测中断。还有重要的一点就是interrupted（）作用于当前线程，interrupt（）和isInterrupted（）作用于此线程，即代码中调用此方法的实例所代表的线程。 原文：https://blog.csdn.net/qq_39682377/article/details/81449451","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"interrupt","slug":"interrupt","permalink":"http://blog.shagle.cn/tags/interrupt/"},{"name":"interrupted","slug":"interrupted","permalink":"http://blog.shagle.cn/tags/interrupted/"},{"name":"isInterrupted","slug":"isInterrupted","permalink":"http://blog.shagle.cn/tags/isInterrupted/"}]},{"title":"Java 技术之volatile","slug":"Java 技术之volatile","date":"2018-12-22T13:05:02.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/22/Java 技术之volatile/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java 技术之volatile/","excerpt":"volatile这个关键字可能很多朋友都听说过，或许也都用过。在Java 5之前，它是一个备受争议的关键字，因为在程序中使用它往往会导致出人意料的结果。在Java 5之后，volatile关键字才得以重获生机。 volatile关键字虽然从字面上理解起来比较简单，但是要用好不是一件容易的事情。由于volatile关键字是与Java的内存模型有关的，因此在讲述volatile关键之前，我们先来了解一下与内存模型相关的概念和知识，然后分析了volatile关键字的实现原理，最后给出了几个使用volatile关键字的场景。","text":"volatile这个关键字可能很多朋友都听说过，或许也都用过。在Java 5之前，它是一个备受争议的关键字，因为在程序中使用它往往会导致出人意料的结果。在Java 5之后，volatile关键字才得以重获生机。 volatile关键字虽然从字面上理解起来比较简单，但是要用好不是一件容易的事情。由于volatile关键字是与Java的内存模型有关的，因此在讲述volatile关键之前，我们先来了解一下与内存模型相关的概念和知识，然后分析了volatile关键字的实现原理，最后给出了几个使用volatile关键字的场景。 一.内存模型的相关概念大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。 也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码：1i = i + 1; 当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。 这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。 比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？ 可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。 最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。 也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。 为了解决缓存不一致性问题，通常来说有以下2种解决方法： 1）通过在总线加LOCK#锁的方式 2）通过缓存一致性协议 这2种方式都是硬件层面上提供的方式。 在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 二.并发编程中的三个概念在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们先看具体看一下这三个概念： 2.1.原子性原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 一个很经典的例子就是银行账户转账问题： 比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。 试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。 所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。 同样地反映到并发编程中会出现什么结果呢？ 举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？ 1i = 9; 假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。 那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。 2.2.可见性可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 举个简单的例子，看下面这段代码：123456//线程1执行的代码int i = 0;i = 10; //线程2执行的代码j = i; 假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。 此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10. 这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。 2.3.有序性有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码：1234int i = 0; boolean flag = false;i = 1; //语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。 下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。 但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子：1234int a = 10; //语句1int r = 2; //语句2a = a + 3; //语句3r = a*a; //语句4 这段代码有4个语句，那么可能的一个执行顺序是： 那么可不可能是这个执行顺序呢： 语句2 语句1 语句4 语句3 不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。 虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子： 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。 三.Java内存模型在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。 在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 举个简单的例子：在java中，执行下面这个语句：1i = 10; 执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。 那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？ 3.1.原子性在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i： 请分析以下哪些操作是原子性操作： 1234x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; //语句4 咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。 语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具备原子性。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。 不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 3.2.可见性对于可见性，Java提供了volatile关键字来保证可见性。 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 3.3.有序性在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 下面就来具体介绍下happens-before原则（先行发生原则）： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 这8条原则摘自《深入理解Java虚拟机》。 这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。 下面我们来解释一下前4条规则： 对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。 第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 第四条规则实际上就是体现happens-before原则具备传递性。 四.深入剖析volatile关键字在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们就进入主题。 4.1.volatile关键字的两层语义一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 2）禁止进行指令重排序。 先看一段代码，假如线程1先执行，线程2后执行： 12345678//线程1boolean stop = false;while(!stop)&#123; doSomething();&#125; //线程2stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是用volatile修饰之后就变得不一样了： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。 那么线程1读取到的就是最新的正确的值。 4.2.volatile保证原子性吗？从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？ 下面看一个例子： 1234567891011121314151617181920212223public class Test &#123; public `volatile` int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。 可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。 这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。 在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现： 假如某个时刻变量inc的值为10， 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，inc只增加了1。 解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。 把上面的代码改成以下任何一种都可以达到效果： 采用synchronized： 1234567891011121314151617181920212223public class Test &#123; public int inc = 0; public synchronized void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用Lock： 1234567891011121314151617181920212223242526272829public class Test &#123; public int inc = 0; Lock lock = new ReentrantLock(); public void increase() &#123; lock.lock(); try &#123; inc++; &#125; finally&#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用AtomicInteger： 1234567891011121314151617181920212223public class Test &#123; public AtomicInteger inc = new AtomicInteger(); public void increase() &#123; inc.getAndIncrement(); &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。 4.3.volatile能保证有序性吗？在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。 volatile关键字禁止指令重排序有两层意思： 1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子： 12345678//x、y为非`volatile`变量//flag为`volatile`变量 x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 那么我们回到前面举的一个例子： 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 4.4.volatile的原理和实现机制前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 五.使用volatile关键字的场景synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 1）对变量的写操作不依赖于当前值 2）该变量没有包含在具有其他变量的不变式中 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 下面列举几个Java中使用volatile的几个场景。 5.1.状态标记量123456789`volatile` boolean flag = false; while(!flag)&#123; doSomething();&#125; public void setFlag() &#123; flag = true;&#125; 12345678910`volatile` boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep()&#125;doSomethingwithconfig(context); 5.2.double check1234567891011121314151617class Singleton&#123; private `volatile` static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 至于为何需要这么写请参考： 《Java 中的双重检查（Double-Check）》http://blog.csdn.net/dl88250/article/details/5439024 和http://www.iteye.com/topic/652440 参考资料： 《Java编程思想》 《深入理解Java虚拟机》 http://jiangzhengjun.iteye.com/blog/652532 http://blog.sina.com.cn/s/blog_7bee8dd50101fu8n.html http://ifeve.com/`volatile`/ http://blog.csdn.net/ccit0519/article/details/11241403 http://blog.csdn.net/ns_code/article/details/17101369 http://www.cnblogs.com/kevinwu/archive/2012/05/02/2479464.html http://www.cppblog.com/elva/archive/2011/01/21/139019.html http://ifeve.com/`volatile`-array-visiblity/ http://www.bdqn.cn/news/201312/12579.shtml http://exploer.blog.51cto.com/7123589/1193399 http://www.cnblogs.com/Mainz/p/3556430.html 原文出处：http://www.cnblogs.com/dolphin0520/","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"volatile","slug":"volatile","permalink":"http://blog.shagle.cn/tags/volatile/"}]},{"title":"Java技术之CountDownLatch解析","slug":"Java技术之CountDownLatch解析","date":"2018-12-22T13:04:00.000Z","updated":"2018-12-22T13:04:32.000Z","comments":true,"path":"2018/12/22/Java技术之CountDownLatch解析/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java技术之CountDownLatch解析/","excerpt":"","text":"1. 入门 CountDownLatch是同步工具类之一，可以指定一个计数值，在并发环境下由线程进行减1操作，当计数值变为0之后，被await方法阻塞的线程将会唤醒，实现线程间的同步。 Java的concurrent包里面的CountDownLatch其实可以把它看作一个计数器，只不过这个计数器的操作是原子操作，同时只能有一个线程去操作这个计数器，也就是同时只能有一个线程去减这个计数器里面的值。 你可以向CountDownLatch对象设置一个初始的数字作为计数值，任何调用这个对象上的await()方法都会阻塞，直到这个计数器的计数值被其他的线程减为0为止。 CountDownLatch的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止。 举个例子，有三个工人在为老板干活，这个老板有一个习惯，就是当三个工人把一天的活都干完了的时候，他就来检查所有工人所干的活。记住这个条件：三个工人先全部干完活，老板才检查。所以在这里用Java代码设计两个类，Worker代表工人，Boss代表老板，具体的代码实现如下： Worker1234567891011121314151617181920212223242526public class Worker implements Runnable&#123; private CountDownLatch downLatch; private String name; public Worker(CountDownLatch downLatch, String name)&#123; this.downLatch = downLatch; this.name = name; &#125; public void run() &#123; this.doWork(); try&#123; TimeUnit.SECONDS.sleep(new Random().nextInt(10)); &#125;catch(InterruptedException ie)&#123; &#125; System.out.println(this.name + \"活干完了！\"); this.downLatch.countDown(); &#125; private void doWork()&#123; System.out.println(this.name + \"正在干活!\"); &#125; &#125; Boss123456789101112131415161718public class Boss implements Runnable &#123; private CountDownLatch downLatch; public Boss(CountDownLatch downLatch)&#123; this.downLatch = downLatch; &#125; public void run() &#123; System.out.println(\"老板正在等所有的工人干完活......\"); try &#123; this.downLatch.await(); &#125; catch (InterruptedException e) &#123; &#125; System.out.println(\"工人活都干完了，老板开始检查了！\"); &#125; &#125; app 12345678910111213141516171819202122public class CountDownLatchDemo &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newCachedThreadPool(); CountDownLatch latch = new CountDownLatch(3); Worker w1 = new Worker(latch,\"张三\"); Worker w2 = new Worker(latch,\"李四\"); Worker w3 = new Worker(latch,\"王二\"); Boss boss = new Boss(latch); executor.execute(w3); executor.execute(w2); executor.execute(w1); executor.execute(boss); executor.shutdown(); &#125; &#125; 当你运行CountDownLatchDemo这个对象的时候，你会发现是等所有的工人都干完了活，老板才来检查，下面是我本地机器上运行的一次结果，可以肯定的每次运行的结果可能与下面不一样，但老板检查永远是在后面的。 12345678王二正在干活! 李四正在干活! 老板正在等所有的工人干完活...... 张三正在干活! 张三活干完了！ 王二活干完了！ 李四活干完了！ 工人活都干完了，老板开始检查了！ 原文出自：https://zapldy.iteye.com/blog/746458 2. 源码分析2.1 构造器CountDownLatch和ReentrantLock一样，内部使用Sync继承AQS。构造函数很简单地传递计数值给Sync，并且设置了state。 123Sync(int count) &#123; setState(count);&#125; 上文已经介绍过AQS的state，这是一个由子类决定含义的“状态”。对于ReentrantLock来说，state是线程获取锁的次数；对于CountDownLatch来说，则表示计数值的大小。 2.2 阻塞线程接着来看await方法，直接调用了AQS的acquireSharedInterruptibly。 1234567891011public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125; 首先尝试获取共享锁，实现方式和独占锁类似，由CountDownLatch实现判断逻辑。123protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; 返回1代表获取成功，返回-1代表获取失败。如果获取失败，需要调用doAcquireSharedInterruptibly： 12345678910111213141516171819202122232425private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; doAcquireSharedInterruptibly的逻辑和独占功能的acquireQueued基本相同，阻塞线程的过程是一样的。不同之处： 1.创建的Node是定义成共享的（Node.SHARED）； 2.被唤醒后重新尝试获取锁，不只设置自己为head，还需要通知其他等待的线程。（重点看后文释放操作里的setHeadAndPropagate） 2.4 释放操作123public void countDown() &#123; sync.releaseShared(1);&#125; countDown操作实际就是释放锁的操作，每调用一次，计数值减少1：1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 同样是首先尝试释放锁，具体实现在CountDownLatch中：1234567891011protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; 死循环加上cas的方式保证state的减1操作，当计数值等于0，代表所有子线程都执行完毕，被await阻塞的线程可以唤醒了，下一步调用doReleaseShared：1234567891011121314151617181920private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; //1 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; //2 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 标记1里，头节点状态如果SIGNAL，则状态重置为0，并调用unparkSuccessor唤醒下个节点。标记2里，被唤醒的节点状态会重置成0，在下一次循环中被设置成PROPAGATE状态，代表状态要向后传播。123456789101112131415private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 在唤醒线程的操作里，分成三步： 处理当前节点：非CANCELLED状态重置为0； 寻找下个节点：如果是CANCELLED状态，说明节点中途溜了，从队列尾开始寻找排在最前还在等着的节点 唤醒：利用LockSupport.unpark唤醒下个节点里的线程。 线程是在doAcquireSharedInterruptibly里被阻塞的，唤醒后调用到setHeadAndPropagate。1234567891011private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; setHead设置头节点后，再判断一堆条件，取出下一个节点，如果也是共享类型，进行doReleaseShared释放操作。下个节点被唤醒后，重复上面的步骤，达到共享状态向后传播。要注意，await操作看着好像是独占操作，但它可以在多个线程中调用。当计数值等于0的时候，调用await的线程都需要知道，所以使用共享锁。 2.5.限定时间的await12345CountDownLatch的await方法还有个限定阻塞时间的版本.public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));&#125; 跟踪代码，最后来看doAcquireSharedNanos方法，和上文介绍的doAcquireShared逻辑基本一样，不同之处是加了time字眼的处理。123456789101112131415161718192021222324252627282930313233private boolean doAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return true; &#125; &#125; nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 进入方法时，算出能够执行多久的deadline，然后在循环中判断时间。注意到代码中间有句：123nanosTimeout &gt; spinForTimeoutThresholdstatic final long spinForTimeoutThreshold = 1000L; spinForTimeoutThreshold写死了1000ns，这就是所谓的自旋操作。当超时在1000ns内，让线程在循环中自旋，否则阻塞线程。 3.总结下面对上面说的三个辅助类进行一个总结： 1）CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同： CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行； 而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行； 另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。 2）Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。 原文出自：https://www.jianshu.com/p/7c7a5df5bda6?ref=myread","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[]},{"title":"HttpURLConnection","slug":"HttpURLConnection","date":"2018-12-22T13:02:41.000Z","updated":"2018-12-22T13:03:29.000Z","comments":true,"path":"2018/12/22/HttpURLConnection/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/HttpURLConnection/","excerpt":"","text":"1 代码出自feign client 默认实现1.1 Request &amp; Options123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * An immutable request to an http server. */public final class Request &#123; /** * No parameters can be null except &#123;@code body&#125; and &#123;@code charset&#125;. All parameters must be * effectively immutable, via safe copies, not mutating or otherwise. */ public static Request create(String method, String url, Map&lt;String, Collection&lt;String&gt;&gt; headers, byte[] body, Charset charset) &#123; return new Request(method, url, headers, body, charset); &#125; private final String method; private final String url; private final Map&lt;String, Collection&lt;String&gt;&gt; headers; private final byte[] body; private final Charset charset; Request(String method, String url, Map&lt;String, Collection&lt;String&gt;&gt; headers, byte[] body, Charset charset) &#123; this.method = checkNotNull(method, \"method of %s\", url); this.url = checkNotNull(url, \"url\"); this.headers = checkNotNull(headers, \"headers of %s %s\", method, url); this.body = body; // nullable this.charset = charset; // nullable &#125; //..... 忽略方法 /* Controls the per-request settings currently required to be implemented by all &#123;@link Client clients&#125; */ public static class Options &#123; private final int connectTimeoutMillis; private final int readTimeoutMillis; public Options(int connectTimeoutMillis, int readTimeoutMillis) &#123; this.connectTimeoutMillis = connectTimeoutMillis; this.readTimeoutMillis = readTimeoutMillis; &#125; public Options() &#123; this(10 * 1000, 60 * 1000); &#125; //..... 忽略方法 &#125;&#125; 1.2 feign default client123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140public static class Default implements Client &#123; public static final String CONTENT_ENCODING = \"Content-Encoding\"; public static final String ENCODING_GZIP = \"gzip\"; public static final String ENCODING_DEFLATE = \"deflate\"; public static final String CONTENT_LENGTH = \"Content-Length\"; public static final String RETRY_AFTER = \"Retry-After\"; public static final Charset UTF_8 = Charset.forName(\"UTF-8\"); public static final Charset ISO_8859_1 = Charset.forName(\"ISO-8859-1\"); private static final int BUF_SIZE = 0x800; // 2K chars (4K bytes) private final SSLSocketFactory sslContextFactory; //在握手期间，如果 URL 的主机名和服务器的标识主机名不匹配，则验证机制可以回调此接口的实现程序来确定是否应该允许此连接。 // 策略可以是基于证书的或依赖于其他验证方案。 private final HostnameVerifier hostnameVerifier; //此类是用于主机名验证的基接口。 /** * Null parameters imply platform defaults. */ public Default(SSLSocketFactory sslContextFactory, HostnameVerifier hostnameVerifier) &#123; this.sslContextFactory = sslContextFactory; this.hostnameVerifier = hostnameVerifier; &#125; @Override public Response execute(Request request, Options options) throws IOException &#123; HttpURLConnection connection = convertAndSend(request, options); return convertResponse(connection).toBuilder().request(request).build(); &#125; HttpURLConnection convertAndSend(Request request, Options options) throws IOException &#123; final HttpURLConnection connection = (HttpURLConnection) new URL(request.url()).openConnection(); if (connection instanceof HttpsURLConnection) &#123; HttpsURLConnection sslCon = (HttpsURLConnection) connection; if (sslContextFactory != null) &#123; sslCon.setSSLSocketFactory(sslContextFactory); &#125; if (hostnameVerifier != null) &#123; sslCon.setHostnameVerifier(hostnameVerifier); &#125; &#125; connection.setConnectTimeout(options.connectTimeoutMillis()); connection.setReadTimeout(options.readTimeoutMillis()); connection.setAllowUserInteraction(false); connection.setInstanceFollowRedirects(true); connection.setRequestMethod(request.method()); Collection&lt;String&gt; contentEncodingValues = request.headers().get(CONTENT_ENCODING); boolean gzipEncodedRequest = contentEncodingValues != null &amp;&amp; contentEncodingValues.contains(ENCODING_GZIP); boolean deflateEncodedRequest = contentEncodingValues != null &amp;&amp; contentEncodingValues.contains(ENCODING_DEFLATE); boolean hasAcceptHeader = false; Integer contentLength = null; for (String field : request.headers().keySet()) &#123; if (field.equalsIgnoreCase(\"Accept\")) &#123; hasAcceptHeader = true; &#125; for (String value : request.headers().get(field)) &#123; if (field.equals(CONTENT_LENGTH)) &#123; if (!gzipEncodedRequest &amp;&amp; !deflateEncodedRequest) &#123; contentLength = Integer.valueOf(value); connection.addRequestProperty(field, value); &#125; &#125; else &#123; connection.addRequestProperty(field, value); &#125; &#125; &#125; // Some servers choke on the default accept string. if (!hasAcceptHeader) &#123; connection.addRequestProperty(\"Accept\", \"*/*\"); &#125; if (request.body() != null) &#123; if (contentLength != null) &#123; connection.setFixedLengthStreamingMode(contentLength); &#125; else &#123; connection.setChunkedStreamingMode(8196); &#125; connection.setDoOutput(true); OutputStream out = connection.getOutputStream(); if (gzipEncodedRequest) &#123; out = new GZIPOutputStream(out); &#125; else if (deflateEncodedRequest) &#123; out = new DeflaterOutputStream(out); &#125; // new OutputStreamWriter(connection.getOutputStream(),\"utf-8\") ,如果参数乱码就用这句转换成你想要的编码方式 try &#123; out.write(request.body()); &#125; finally &#123; try &#123; out.close(); &#125; catch (IOException suppressed) &#123; // NOPMD &#125; &#125; &#125; return connection; &#125; Response convertResponse(HttpURLConnection connection) throws IOException &#123; int status = connection.getResponseCode(); String reason = connection.getResponseMessage(); if (status &lt; 0) &#123; throw new IOException(format(\"Invalid status(%s) executing %s %s\", status, connection.getRequestMethod(), connection.getURL())); &#125; Map&lt;String, Collection&lt;String&gt;&gt; headers = new LinkedHashMap&lt;String, Collection&lt;String&gt;&gt;(); for (Map.Entry&lt;String, List&lt;String&gt;&gt; field : connection.getHeaderFields().entrySet()) &#123; // response message if (field.getKey() != null) &#123; headers.put(field.getKey(), field.getValue()); &#125; &#125; Integer length = connection.getContentLength(); if (length == -1) &#123; length = null; &#125; InputStream stream; if (status &gt;= 400) &#123; stream = connection.getErrorStream(); &#125; else &#123; stream = connection.getInputStream(); &#125; // BufferedReader br = new BufferedReader(new InputStreamReader(stream,\"utf-8\"));,转成你想要的编码 return Response.builder() .status(status) .reason(reason) .headers(headers) .body(stream, length) .build(); &#125; &#125; 测试代码 12345public void testHttpURLConnection() &#123; Client client = new Client.Default(null, null); client.execute()&#125;","categories":[{"name":"HttpClient","slug":"HttpClient","permalink":"http://blog.shagle.cn/categories/HttpClient/"}],"tags":[{"name":"HttpURLConnection","slug":"HttpURLConnection","permalink":"http://blog.shagle.cn/tags/HttpURLConnection/"}]},{"title":"安全算法demo","slug":"security-demo","date":"2018-12-22T12:59:51.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/22/security-demo/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/security-demo/","excerpt":"一些常用的安全加密解码代码","text":"一些常用的安全加密解码代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419package com.bogle.nio;import sun.misc.BASE64Decoder;import sun.misc.BASE64Encoder;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.SecretKey;import javax.crypto.spec.SecretKeySpec;import java.io.IOException;import java.security.*;import java.security.spec.PKCS8EncodedKeySpec;import java.security.spec.X509EncodedKeySpec;/** * Created by lenovo on 2017/4/4. */public class Digest &#123; //--------------------------------------------------------------------------------数值摘要---------------------------------------------------------------------- /** * md5加密 * * @param content * @return * @throws Exception */ public static byte[] md5(String content) throws Exception &#123; MessageDigest md = MessageDigest.getInstance(\"MD5\"); byte[] bytes = md.digest(content.getBytes(\"utf8\")); return bytes; &#125; /** * sha1加密 * * @param content * @return * @throws Exception */ public static byte[] sha1(String content) throws Exception &#123; MessageDigest md = MessageDigest.getInstance(\"SHA-1\"); byte[] bytes = md.digest(content.getBytes(\"utf8\")); return bytes; &#125; /** * bytes 转十六进制 * * @param bytes * @return */ public static String bytes2Hex(byte[] bytes) &#123; StringBuilder hex = new StringBuilder(); for (int i = 0; i &lt; bytes.length; i++) &#123; byte b = bytes[i]; boolean negative = false;//是否为负数 if (b &lt; 0) negative = true; int inte = Math.abs(b); if (negative) inte = inte | 0x80;//负数会转成整数（最高位的符号变成数值计算），在转十六进制 String temp = Integer.toHexString(inte &amp; 0xFF); if (temp.length() == 1) &#123; hex.append(0); &#125; hex.append(temp.toLowerCase()); &#125; return hex.toString(); &#125; /** * 十六进制转bytes * * @param hex * @return */ public static byte[] hex2Bytes(String hex) &#123; byte[] bytes = new byte[hex.length() / 2]; for (int i = 0; i &lt; hex.length(); i = i + 2) &#123; String subStr = hex.substring(i, i + 2); boolean negative = false; //是否为负数 int inte = Integer.parseInt(subStr, 16); if (inte &gt; 127) negative = true; if (inte == 128) &#123; inte = -128; &#125; else if (negative) &#123; inte = 0 - (inte &amp; 0x7F); &#125; byte b = (byte) inte; bytes[i / 2] = b; &#125; return bytes; &#125; /** * byte转base64 * * @param bytes * @return */ public static String byte2base64(byte[] bytes) &#123; BASE64Encoder base64Encoder = new BASE64Encoder(); return base64Encoder.encode(bytes); &#125; /** * base64转bytes * * @param base64 * @return * @throws IOException */ public static byte[] base642byte(String base64) throws IOException &#123; BASE64Decoder base64Decoder = new BASE64Decoder(); return base64Decoder.decodeBuffer(base64); &#125; //--------------------------------------------------------------------------------对称加密---------------------------------------------------------------------- //////////////////////////////////////////////////////////DES加密解密///////////////////////////////////// /** * 生产DES密钥 * * @return * @throws Exception */ public static String getKeyDES() throws Exception &#123; KeyGenerator keyGen = KeyGenerator.getInstance(\"DES\"); keyGen.init(56); SecretKey key = keyGen.generateKey(); String base64Str = byte2base64(key.getEncoded()); return base64Str; &#125; public static void main(String[] args) throws Exception &#123; System.out.println(getKeyDES()); &#125; public static SecretKey loadKeyDES(String base64Key) throws Exception &#123; byte[] bytes = base642byte(base64Key); SecretKey key = new SecretKeySpec(bytes, \"DES\"); return key; &#125; /** * DES加密 * * @param source * @param key * @return * @throws Exception */ public static byte[] encryptDES(byte[] source, SecretKey key) throws Exception &#123; Cipher cipher = Cipher.getInstance(\"DES\"); cipher.init(Cipher.ENCRYPT_MODE, key); byte[] bytes = cipher.doFinal(source); return bytes; &#125; /** * DES解密 * * @param source * @param key * @return * @throws Exception */ public static byte[] decryptDES(byte[] source, SecretKey key) throws Exception &#123; Cipher cipher = Cipher.getInstance(\"DES\"); cipher.init(Cipher.DECRYPT_MODE, key); byte[] bytes = cipher.doFinal(source); return bytes; &#125; //////////////////////////////////////////////////////////AES加密解密///////////////////////////////////// /** * 生成AES密钥 * * @return * @throws Exception */ public static String genKeyAES() throws Exception &#123; KeyGenerator keyGen = KeyGenerator.getInstance(\"AES\"); keyGen.init(128); SecretKey key = keyGen.generateKey(); String base64Str = byte2base64(key.getEncoded()); return base64Str; &#125; public static SecretKey loadKeyAES(String base64Key) throws Exception &#123; byte[] bytes = base642byte(base64Key); SecretKey key = new SecretKeySpec(bytes, \"AES\"); return key; &#125; /** * AES加密 * * @param source * @param key * @return * @throws Exception */ public static byte[] encryptAES(byte[] source, SecretKey key) throws Exception &#123; Cipher cipher = Cipher.getInstance(\"AES\"); cipher.init(Cipher.ENCRYPT_MODE, key); byte[] bytes = cipher.doFinal(source); return bytes; &#125; /** * AES解密 * * @param source * @param key * @return * @throws Exception */ public static byte[] decryptAES(byte[] source, SecretKey key) throws Exception &#123; Cipher cipher = Cipher.getInstance(\"AES\"); cipher.init(Cipher.DECRYPT_MODE, key); byte[] bytes = cipher.doFinal(source); return bytes; &#125; //--------------------------------------------------------------------------------非对称加密---------------------------------------------------------------------- /** * 生成公钥和私钥 * * @return * @throws Exception */ public static KeyPair getKeyPair() throws Exception &#123; KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(\"RSA\"); keyPairGenerator.initialize(512); KeyPair keyPair = keyPairGenerator.generateKeyPair(); return keyPair; &#125; public static String getPublicKey(KeyPair keyPair) &#123; PublicKey publicKey = keyPair.getPublic(); byte[] bytes = publicKey.getEncoded(); return byte2base64(bytes); &#125; public static String getPrivateKey(KeyPair keyPair) &#123; PublicKey publicKey = keyPair.getPrivate() byte[] bytes = publicKey.getEncoded(); return byte2base64(bytes); &#125; /** * 将String类型的密钥转换为PublicKey * * @param pubStr * @return * @throws Exception */ public static PublicKey string2PublicKey(String pubStr) throws Exception &#123; byte[] keyBytes = base642byte(pubStr); X509EncodedKeySpec keySpec = new X509EncodedKeySpec(keyBytes); KeyFactory keyFactory = KeyFactory.getInstance(\"RSA\"); PublicKey publicKey = keyFactory.generatePublic(keySpec); return publicKey; &#125; /** * 将String类型的密钥转换为privateKey * * @param priStr * @return * @throws Exception */ public static PrivateKey string2PrivateKey(String priStr) throws Exception &#123; byte[] keyBytes = base642byte(priStr); PKCS8EncodedKeySpec keySpec = new PKCS8EncodedKeySpec(keyBytes); KeyFactory keyFactory = KeyFactory.getInstance(\"RSA\"); PrivateKey privateKey = keyFactory.generatePrivate(keySpec); return privateKey; &#125; /** * 使用公钥加密 * * @param content * @param publicKey * @return * @throws Exception */ public static byte[] publicEncrypt(byte[] content, PublicKey publicKey) throws Exception &#123; Cipher cipher = Cipher.getInstance(\"RSA\"); cipher.init(Cipher.ENCRYPT_MODE, publicKey); byte[] bytes = cipher.doFinal(content); return bytes; &#125; /** * 使用私钥解密 * * @param content * @param privateKey * @return * @throws Exception */ public static byte[] privateDecrypt(byte[] content, PrivateKey privateKey) throws Exception &#123; Cipher cipher = Cipher.getInstance(\"RSA\"); cipher.init(Cipher.DECRYPT_MODE, privateKey); byte[] bytes = cipher.doFinal(content); return bytes; &#125; //--------------------------------------------------------------------------------MD5withRSA---------------------------------------------------------------------- /** * MD5withRSA算法实现 * 签名 * * @param content * @param privateKey * @return * @throws Exception */ public static byte[] sign(byte[] content, PrivateKey privateKey) throws Exception &#123; MessageDigest md = MessageDigest.getInstance(\"MD5\"); byte[] bytes = md.digest(content); Cipher cipher = Cipher.getInstance(\"RSA\"); cipher.init(Cipher.ENCRYPT_MODE, privateKey); byte[] encryptBytes = cipher.doFinal(bytes); return encryptBytes; &#125; /** * 验证签名是否正确 * @param content 内容 * @param sign 签名 * @param publicKey 公钥 * @return * @throws Exception */ public static boolean verify(byte[] content, byte[] sign, PublicKey publicKey) throws Exception &#123; MessageDigest md = MessageDigest.getInstance(\"MD5\"); byte[] bytes = md.digest(content); Cipher cipher = Cipher.getInstance(\"RSA\"); cipher.init(Cipher.DECRYPT_MODE,publicKey); byte[] decryptBytes = cipher.doFinal(sign); return byte2base64(decryptBytes).equals(byte2base64(bytes)); &#125; //基于Signature API的使用 public static byte[] sign(byte[] content, PrivateKey privateKey) throws Exception &#123; Signature signature = Signature.getInstance(\"MD5withRSA\"); signature.initSign(privateKey); signature.update(content); return signature.sign(); &#125; public static boolean verify(byte[] content, byte[] sign, PublicKey publicKey) throws Exception &#123; Signature signature = Signature.getInstance(\"MD5withRSA\"); signature.initVerify(publicKey); signature.update(content); return signature.verify(sign); &#125; //--------------------------------------------------------------------------------SH1withRSA---------------------------------------------------------------------- /** * sh1签名 * @param content * @param privateKey * @return * @throws Exception */ public static byte[] sign(byte[] content, PrivateKey privateKey) throws Exception &#123; MessageDigest md = MessageDigest.getInstance(\"SHA1\"); byte[] bytes = md.digest(content); Cipher cipher = Cipher.getInstance(\"RSA\"); cipher.init(Cipher.ENCRYPT_MODE, privateKey); byte[] encryptBytes = cipher.doFinal(bytes); return encryptBytes; &#125; /** * 验证签名是否正确 * @param content 内容 * @param sign 签名 * @param publicKey 公钥 * @return * @throws Exception */ public static boolean verify(byte[] content, byte[] sign, PublicKey publicKey) throws Exception &#123; MessageDigest md = MessageDigest.getInstance(\"SHA1\"); byte[] bytes = md.digest(content); Cipher cipher = Cipher.getInstance(\"RSA\"); cipher.init(Cipher.DECRYPT_MODE,publicKey); byte[] decryptBytes = cipher.doFinal(sign); return byte2base64(decryptBytes).equals(byte2base64(bytes)); &#125; //基于Signature API的使用 public static byte[] sign(byte[] content, PrivateKey privateKey) throws Exception &#123; Signature signature = Signature.getInstance(\"SHA1withRSA\"); signature.initSign(privateKey); signature.update(content); return signature.sign(); &#125; public static boolean verify(byte[] content, byte[] sign, PublicKey publicKey) throws Exception &#123; Signature signature = Signature.getInstance(\"SHA1withRSA\"); signature.initVerify(publicKey); signature.update(content); return signature.verify(sign); &#125;&#125;","categories":[{"name":"security","slug":"security","permalink":"http://blog.shagle.cn/categories/security/"}],"tags":[{"name":"MD5加密","slug":"MD5加密","permalink":"http://blog.shagle.cn/tags/MD5加密/"},{"name":"sha1加密","slug":"sha1加密","permalink":"http://blog.shagle.cn/tags/sha1加密/"},{"name":"DES","slug":"DES","permalink":"http://blog.shagle.cn/tags/DES/"},{"name":"AES","slug":"AES","permalink":"http://blog.shagle.cn/tags/AES/"},{"name":"MD5withRSA","slug":"MD5withRSA","permalink":"http://blog.shagle.cn/tags/MD5withRSA/"},{"name":"公钥和私钥","slug":"公钥和私钥","permalink":"http://blog.shagle.cn/tags/公钥和私钥/"}]},{"title":"Java技术之FutureTask","slug":"Java技术之FutureTask","date":"2018-12-22T12:57:37.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/22/Java技术之FutureTask/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java技术之FutureTask/","excerpt":"在Java中一般通过继承Thread类或者实现Runnable接口这两种方式来创建多线程，但是这两种方式都有个缺陷，就是不能在执行完成后获取执行的结果，因此Java 1.5之后提供了Callable和Future接口，通过它们就可以在任务执行完毕之后得到任务的执行结果。","text":"在Java中一般通过继承Thread类或者实现Runnable接口这两种方式来创建多线程，但是这两种方式都有个缺陷，就是不能在执行完成后获取执行的结果，因此Java 1.5之后提供了Callable和Future接口，通过它们就可以在任务执行完毕之后得到任务的执行结果。 1.Callable接口123public interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; 可以看到Callable是个泛型接口，泛型V就是要call()方法返回的类型。Callable接口和Runnable接口很像，都可以被另外一个线程执行，但是正如前面所说的，Runnable不会返回数据也不能抛出异常。 2.Future接口Future接口代表异步计算的结果，通过Future接口提供的方法可以查看异步计算是否执行完成，或者等待执行结果并获取执行结果，同时还可以取消执行。 1234567public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; cancel():cancel()方法用来取消异步任务的执行。如果异步任务已经完成或者已经被取消，或者由于某些原因不能取消，则会返回false。如果任务还没有被执行，则会返回true并且异步任务不会被执行。如果任务已经开始执行了但是还没有执行完成，若mayInterruptIfRunning为true，则会立即中断执行任务的线程并返回true，若mayInterruptIfRunning为false，则会返回true且不会中断任务执行线程。 isCanceled():判断任务是否被取消，如果任务在结束(正常执行结束或者执行异常结束)前被取消则返回true，否则返回false。 isDone():判断任务是否已经完成，如果完成则返回true，否则返回false。需要注意的是：任务执行过程中发生异常、任务被取消也属于任务已完成，也会返回true。 get():获取任务执行结果，如果任务还没完成则会阻塞等待直到任务执行完成。如果任务被取消则会抛出CancellationException异常，如果任务执行过程发生异常则会抛出ExecutionException异常，如果阻塞等待过程中被中断则会抛出InterruptedException异常。 get(long timeout,Timeunit unit):带超时时间的get()版本，如果阻塞等待过程中超时则会抛出TimeoutException异常。 3.FutureTaskFuture只是一个接口，不能直接用来创建对象，FutureTask是Future的实现类。 FutureTask实现了RunnableFuture接口，则RunnableFuture接口继承了Runnable接口和Future接口，所以FutureTask既能当做一个Runnable直接被Thread执行，也能作为Future用来得到Callable的计算结果。 3.1.使用方式FutureTask一般配合ExecutorService来使用，也可以直接通过Thread来使用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class CallDemo &#123; // 1. 继承Callable接口,实现call()方法,泛型参数为要返回的类型 // 100累加 static class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println(\"Thread [\" + Thread.currentThread().getName() + \"] is running\"); int result = 0; for(int i = 0; i &lt; 100;++i) &#123; result += i; &#125; Thread.sleep(3000); return result; &#125; &#125; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; // 第一种方式:Future + ExecutorService Task task = new Task(); ExecutorService service = Executors.newCachedThreadPool(); Future&lt;Integer&gt; future = service.submit(task1); service.shutdown();//优雅关闭 // 第二种方式: FutureTask + ExecutorService ExecutorService service = Executors.newCachedThreadPool(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Task()); service.submit(futureTask); service.shutdown(); // 第三种方式:FutureTask + Thread // 新建FutureTask,需要一个实现了Callable接口的类的实例作为构造函数参数 FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Task()); // 新建Thread对象并启动 Thread thread = new Thread(futureTask); thread.setName(\"Task thread\"); thread.start(); //注释掉其他两种 留一种方式 try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Thread [\" + Thread.currentThread().getName() + \"] is running\"); // 调用isDone()判断任务是否结束 if(!futureTask.isDone()) &#123; System.out.println(\"Task is not done\"); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; int result = 0; try &#123; // 调用get()方法获取任务结果,如果任务没有执行完成则阻塞等待 result = futureTask.get(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(\"result is \" + result); &#125;&#125; 3.2.源码分析之构造函数FutureTask有两个构造函数，其中一个如下：123456public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125; 这个构造函数会把传入的Callable变量保存在this.callable字段中，该字段定义为private Callable callable;用来保存底层的调用，在被执行完成以后会指向null,接着会初始化state字段为NEW。 state字段用来保存FutureTask内部的任务执行状态，一共有7中状态，每种状态及其对应的值如下： 12345678private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;//大于这个值就是完成状态private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; 其中需要注意的是state是volatile类型的，也就是说只要有任何一个线程修改了这个变量，那么其他所有的线程都会知道最新的值。 NEW:表示是个新的任务或者还没被执行完的任务。这是初始状态。 COMPLETING:任务已经执行完成或者执行任务的时候发生异常，但是任务执行结果或者异常原因还没有保存到outcome字段(outcome字段用来保存任务执行结果，如果发生异常，则用来保存异常原因)的时候，状态会从NEW变更到COMPLETING。但是这个状态会时间会比较短，属于中间状态。 NORMAL:任务已经执行完成并且任务执行结果已经保存到outcome字段，状态会从COMPLETING转换到NORMAL。这是一个最终态。 EXCEPTIONAL:任务执行发生异常并且异常原因已经保存到outcome字段中后，状态会从COMPLETING转换到EXCEPTIONAL。这是一个最终态。 CANCELLED:任务还没开始执行或者已经开始执行但是还没有执行完成的时候，用户调用了cancel(false)方法取消任务且不中断任务执行线程，这个时候状态会从NEW转化为CANCELLED状态。这是一个最终态。 INTERRUPTING: 任务还没开始执行或者已经执行但是还没有执行完成的时候，用户调用了cancel(true)方法取消任务并且要中断任务执行线程但是还没有中断任务执行线程之前，状态会从NEW转化为INTERRUPTING。这是一个中间状态。 INTERRUPTED:调用interrupt()中断任务执行线程之后状态会从INTERRUPTING转换到INTERRUPTED。这是一个最终态。 ps：所有值大于COMPLETING的状态都表示任务已经执行完成(任务正常执行完成，任务执行异常或者任务被取消)。 各个状态之间的可能转换关系如下图所示: 另外一个构造函数如下： 1234567891011121314151617181920212223public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable&#125;public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result);&#125;static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; &#123; final Runnable task; final T result; RunnableAdapter(Runnable task, T result) &#123; this.task = task; this.result = result; &#125; public T call() &#123; task.run(); return result; &#125;&#125; 这个构造函数会把传入的Runnable封装成一个Callable对象保存在callable字段中，同时如果任务执行成功的话就会返回传入的result。这种情况下如果不需要返回值的话可以传入一个null。 在new了一个FutureTask对象之后，接下来就是在另一个线程中执行这个Task,无论是通过直接new一个Thread还是通过线程池，执行的都是run()方法，接下来就看看run()方法的实现。 3.2.源码分析之run方法run()方法实现如下: 1234567891011121314151617181920212223242526272829303132333435363738public void run() &#123; // 状态如果不是NEW，说明任务或者已经执行过，或者已经被取消，直接返回 // 状态如果是NEW，则尝试把当前执行线程保存在runner字段(runnerOffset)中，如果赋值失败则直接返回 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; // 执行任务 计算逻辑 result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; // 任务异常 setException(ex); &#125; if (ran) // 任务正常执行完毕 set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; // 如果任务被中断，执行中断处理 if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; run()方法首先会 1.判断当前任务的state是否等于NEW,如果不为NEW则说明任务或者已经执行过，或者已经被取消，直接返回。 2.如果状态为NEW则接着会通过unsafe类把任务执行线程引用CAS的保存在runner字段中，如果保存失败，则直接返回。 3.执行任务。 4.如果任务执行发生异常，则调用setException()方法保存异常信息。否则执行set()设置结果和状态值。 5.任务如果是被中断的，执行 handlePossibleCancellationInterrupt()处理状态和中断响应。 3.3源码分析之setException方法1234567protected void setException(Throwable t) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = t; UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state finishCompletion(); &#125;&#125; 在setException()方法中 1.首先会CAS的把当前的状态从NEW变更为COMPLETING(中间状态)状态。 2.把异常原因保存在outcome字段中，outcome字段用来保存任务执行结果或者异常原因。 3.CAS的把当前任务状态从COMPLETING变更为EXCEPTIONAL。这个状态转换对应着上图中的二。 4.调用finishCompletion()。 3.4.源码分析之set方法1234567protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion(); &#125;&#125; 1.首先会CAS的把当前的状态从NEW变更为COMPLETING状态。 2.把任务执行结果保存在outcome字段中。 3.CAS的把当前任务状态从COMPLETING变更为NORMAL。这个状态转换对应着上图中的一。 4.调用finishCompletion()。发起任务线程(threadpool)跟执行任务线程(main)通常情况下都不会是同一个线程，在任务执行线程执行任务的时候，任务发起线程可以查看任务执行状态、获取任务执行结果、取消任务等等操作，接下来分析下这些操作。 3.5.源码分析之get方法任务发起线程可以调用get()方法来获取任务执行结果，如果此时任务已经执行完毕则会直接返回任务结果，如果任务还没执行完毕，则调用方会阻塞直到任务执行结束返回结果为止。get()方法实现如下:123456public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125; 1.判断任务当前的state &lt;= COMPLETING是否成立。前面分析过，COMPLETING状态是任务是否执行完成的临界状态。 2.如果成立，表明任务还没有结束(这里的结束包括任务正常执行完毕，任务执行异常，任务被取消)，则会调用awaitDone()进行阻塞等待。 3.如果不成立表明任务已经结束，调用report()返回结果。 当调用get()获取任务结果但是任务还没执行完成的时候，调用线程会调用awaitDone()方法进行阻塞等待，该方法定义如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; // 计算等待截止时间 final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; // 1. 判断阻塞线程是否被中断,如果被中断则在等待队列中删除该节点并抛出InterruptedException异常 if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; // 2. 获取当前状态，如果状态大于COMPLETING // 说明任务已经结束(要么正常结束，要么异常结束，要么被取消) // 则把thread显示置空，并返回结果 int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; // 3. 如果状态处于中间状态COMPLETING // 表示任务已经结束但是任务执行线程还没来得及给outcome赋值 // 这个时候让出执行权让其他线程优先执行 else if (s == COMPLETING) // cannot time out yet Thread.yield(); // 4. 如果等待节点为空，则构造一个等待节点 else if (q == null) q = new WaitNode(); // 5. 如果还没有入队列，则把当前节点加入waiters首节点并替换原来waiters else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; // 如果需要等待特定时间，则先计算要等待的时间 // 如果已经超时，则删除对应节点并返回对应的状态 nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; // 6. 阻塞等待特定时间 LockSupport.parkNanos(this, nanos); &#125; else // 6. 阻塞等待直到被其他线程唤醒 LockSupport.park(this); &#125;&#125; awaitDone()中有个死循环，每一次循环都会： 1.判断调用get()的线程是否被其他线程中断，如果是的话则在等待队列中删除对应节点然后抛出InterruptedException异常。 2.获取任务当前状态，如果当前任务状态大于COMPLETING则表示任务执行完成，则把thread字段置null并返回结果。 3.如果任务处于COMPLETING状态，则表示任务已经处理完成(正常执行完成或者执行出现异常)，但是执行结果或者异常原因还没有保存到outcome字段中。这个时候调用线程让出执行权让其他线程优先执行。 4.如果等待节点为空，则构造一个等待节点WaitNode。 5.如果第四步中新建的节点还没如队列，则CAS的把该节点加入waiters队列的首节点。 6.阻塞等待。 假设当前state=NEW且waiters为NULL,也就是说还没有任何一个线程调用get()获取执行结果，这个时候有两个线程threadA和threadB先后调用get()来获取执行结果。再假设这两个线程在加入阻塞队列进行阻塞等待之前任务都没有执行完成且threadA和threadB都没有被中断的情况下(因为如果threadA和threadB在进行阻塞等待结果之前任务就执行完成或线程本身被中断的话，awaitDone()就执行结束返回了)，执行过程是这样的，以threadA为例: 1.第一轮for循环，执行的逻辑是q == null,所以这时候会新建一个节点q。第一轮循环结束。 2.第二轮for循环，执行的逻辑是!queue，这个时候会把第一轮循环中生成的节点的netx指针指向waiters，然后CAS的把节点q替换waiters。也就是把新生成的节点添加到waiters链表的首节点。如果替换成功，queued=true。第二轮循环结束。 3.第三轮for循环，进行阻塞等待。要么阻塞特定时间，要么一直阻塞知道被其他线程唤醒。 3.6.源码分析之cancel方法12345678910111213141516171819202122public boolean cancel(boolean mayInterruptIfRunning) &#123; // 1. 如果任务已经结束，则直接返回false 任务已经开始 if (state != NEW) return false; // 2. 如果需要中断任务执行线程 if (mayInterruptIfRunning) &#123; // 2.1. 把任务状态从NEW转化到INTERRUPTING if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, INTERRUPTING)) return false; Thread t = runner; // 2.2. 中断任务执行线程 if (t != null) t.interrupt(); // 2.3. 修改状态为INTERRUPTED UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); // final state &#125; // 3. 如果不需要中断任务执行线程，则直接把状态从NEW转化为CANCELLED else if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, CANCELLED)) return false; finishCompletion(); return true;&#125; 1.判断任务当前执行状态，如果任务状态不为NEW，则说明任务或者已经执行完成，或者执行异常，不能被取消，直接返回false表示执行失败。 2.判断需要中断任务执行线程，则 把任务状态从NEW转化到INTERRUPTING。这是个中间状态。 中断任务执行线程。 修改任务状态为INTERRUPTED。这个转换过程对应上图中的四。 3.如果不需要中断任务执行线程，直接把任务状态从NEW转化为CANCELLED。如果转化失败则返回false表示取消失败。这个转换过程对应上图中的四。 4.调用finishCompletion()。 3.7.源码分析之finishCompletion方法不管是任务执行异常还是任务正常执行完毕，或者取消任务，最后都会调用finishCompletion()方法 12345678910111213141516171819202122private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; done(); callable = null; // to reduce footprint&#125; 依次遍历waiters链表，唤醒节点中的线程，然后把callable置空。 被唤醒的线程会各自从awaitDone()方法中的LockSupport.park()阻塞中返回，然后会进行新一轮的循环。在新一轮的循环中会返回执行结果(或者更确切的说是返回任务的状态)。 3.8.源码分析之report()report()方法用在get()方法中，作用是把不同的任务状态映射成任务执行结果。 1234567891011private V report(int s) throws ExecutionException &#123; Object x = outcome; // 1. 任务正常执行完成，返回任务执行结果 if (s == NORMAL) return (V)x; // 2. 任务被取消，抛出CancellationException异常 if (s &gt;= CANCELLED) throw new CancellationException(); // 3. 其他状态，抛出执行异常ExecutionException throw new ExecutionException((Throwable)x);&#125; 如果任务处于NEW、COMPLETING和INTERRUPTING这三种状态的时候是执行不到report()方法的，所以没必要对这三种状态进行转换。 3.9.源码分析之get(long,TimeUnit) 带超时等待的获取任务结果，实现如下: 1234567891011public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; if (unit == null) throw new NullPointerException(); int s = state; if (s &lt;= COMPLETING &amp;&amp; // 如果awaitDone()超时返回之后任务还没结束，则抛出异常 (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); return report(s);&#125; 跟get()不同点在于get(long,TimeUnit)会在awaitDone()超时返回之后抛出TimeoutException异常。 3.10.源码分析之isCancelled()和isDone()这两个方法分别用来判断任务是否被取消和任务是否执行完成，实现都比较简单，代码如下: 1234567public boolean isCancelled() &#123; return state &gt;= CANCELLED;&#125;public boolean isDone() &#123; return state != NEW;&#125; 4.总结FutureTask的实现还是比较简单的，当用户实现Callable()接口定义好任务之后，把任务交给其他线程进行执行。FutureTask内部维护一个任务状态，任何操作都是围绕着这个状态进行，并随时更新任务状态。任务发起者调用get()获取执行结果的时候，如果任务还没有执行完毕，则会把自己放入阻塞队列中然后进行阻塞等待。当任务执行完成之后，任务执行线程会依次唤醒阻塞等待的线程。调用cancel()取消任务的时候也只是简单的修改任务状态，如果需要中断任务执行线程的话则调用Thread.interrupt()中断任务执行线程。 有个值得关注的问题就是当任务还在执行的时候用户调用cancel(true)方法能否真正让任务停止执行呢？ 当调用cancel(true)方法的时候，实际执行还是Thread.interrupt()方法，而interrupt()方法只是设置中断标志位，如果被中断的任务执行线程处于sleep()、wait()或者join()逻辑中则会抛出InterruptedException异常。因此结论是:cancel(true)并不一定能够停止正在执行的异步任务。 原文：https://www.cnblogs.com/wade-luffy/p/7073827.html","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"FutureTask","slug":"FutureTask","permalink":"http://blog.shagle.cn/tags/FutureTask/"}]},{"title":"kafka","slug":"kafka","date":"2018-12-22T12:54:20.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/22/kafka/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/kafka/","excerpt":"现代的互联网分布式系统，只要稍微大一些，就一定逃不开3类中间件：远程调用（RPC）框架、消息队列、数据库访问中间件。Kafka 是消息队列中间件的代表产品，用 Scala 语言实现，本文采用的是 Kafka_2.11 0.10.0.0 版本进行实验。","text":"现代的互联网分布式系统，只要稍微大一些，就一定逃不开3类中间件：远程调用（RPC）框架、消息队列、数据库访问中间件。Kafka 是消息队列中间件的代表产品，用 Scala 语言实现，本文采用的是 Kafka_2.11 0.10.0.0 版本进行实验。 1.基本概念首先，Kafka 中有一些基本的概念需要熟悉 1 2。 Topic，指消息的类别，每个消息都必须有； Producer，指消息的产生者，或者，消息的写端； Consumer，指消息的消费者，或者，消息的读端； Producer Group，指产生者组，组内的生产者产生同一类消息； Consumer Group，指消费者组，组内的消费者消费同一类消息； Broker，指消息服务器，Producer 产生的消息都是写到这里，Consumer 读消息也是从这里读； Zookeeper，是 Kafka 的注册中心，Broker 和 Consumer 之间的协调器，包含状态信息、配置信息和一些 Topic 的信息； Partition，指消息的水平分区，一个 Topic 可以有多个分区； Replica，指消息的副本，为了提高可用性，将消息副本保存在其他 Broker 上；特别说明，Broker 是指单个消息服务进程，一般情况下，Kafka 是集群运行的，Broker 只是集群中的一个服务进程，而非代指整个 Kafka 服务，可以简单将 Broker 理解成服务器（Server）。Kafka 引入的术语都比较常见，从字面上理解相对直观。Kafka 的大致结构图是这样， Kafka 是 Pull 模式的消息队列，即 Consumer 连到消息队列服务上，主动请求新消息，如果要做到实时性，需要采用长轮询，Kafka 在0.8的时候已经支持长轮询模式。上图中 Consumer 的连接箭头方向可能会让读者误以为是 Push 模式，特此注明。更多关于 Kafka 设计的文章可以参考官方文档，或者一些比较好的博客文章 1.1 关于顺序和分区Kafka 是一个力求保持消息顺序性的消息队列，但不是完全保证，其保证的是 Partition 级别的顺序性，如下图， 此图是 Topic 的分区 log 的示意图，可见，每个分区上的 log 都是一个有序的队列，所以，Kafka 是分区级别有序的。如果，某个 Topic 只有一个分区，那么这个 Topic 下的消息就都是有序的。 分区是为了提升消息处理的吞吐率而产生的，将一个 Topic 中的消息分成几份，分别给不同的 Broker 处理。如下图， 此图中有2个 Broker，Server 1 和 Server 2，每个 Broker 上有2个分区，总共4个分区，P0 ~ P3；有2个 Consumer Group，Consumer Group A 有2个 Consumer，Consumer Group B 有4个 Consumer。Kafka 的实现是，在稳定的情况下，维持固定的连接，每个 Consumer 稳定的消费其中某几个分区的消息，以上图举例，Consumer Group A 中的 C1 稳定消费 P0、P3，C2 稳定消费 P1、P2。这样的连接分配可能会导致消息消费的不均匀分布，但好处是比较容易保证顺序性。 维持完全的顺序性在分布式系统看来几乎是无意义的。因为，如果需要维持顺序性，那么就只能有一条线程阻塞的处理顺序消息，即，Producer -&gt; MQ -&gt; Consumer 必须线程上一一对应。这与分布式系统的初衷是相违背的。但是局部的有序性，是可以维持的。比如，有30000条消息，每3条之间有关联，1-&gt;2-&gt;3，4-&gt;5-&gt;6，……，但是全局范围来看，并不需要保证 1-&gt;4-&gt;7，可以 7-&gt;4-&gt;1 的顺序来执行，这样可以达到最大并行度10000，而这通常是现实中我们面对的情况。通常应用中，将有先后关系的消息发送到相同的分区上，即可解决大部分问题。 1.2. 关于副本副本是高可用 Kafka 集群的实现方式。假设集群中有3个 Broker，那么可以指定3个副本，这3个副本是对等的，对于某个 Topic 的分区来说，其中一个是 Leader，即主节点，另外2个副本是 Follower，即从节点，每个副本在一个 Broker 上。当 Leader 收到消息的时候，会将消息写一份到副本中，通常情况，只有 Leader 处于工作状态。在 Leader 发生故障宕机的时候，Follwer 会取代 Leader 继续传送消息，而不会发生消息丢失。Kafka 的副本是以分区为单位的，也就是说，即使是同一个 Topic，其不同分区的 Leader 节点也不同。甚至，Kafka 倾向于用不同的 Broker 来做分区的 Leader，因为这样能做到更好的负载均衡。 在副本间的消息同步，实际上是复制消息的 log，复制可以是同步复制，也可以是异步复制。同步复制是说，当 Leader 收到消息后，将消息写入从副本，只有在收到从副本写入成功的确认后才返回成功给 Producer；异步复制是说，Leader 将消息写入从副本，但是不等待从副本的成功确认，直接返回成功给 Producer。同步复制效率较低，但是消息不会丢；异步复制效率高，但是在 Broker 宕机的时候，可能会出现消息丢失。 1.3. 关于丢消息和重复收到消息任何一个 MQ 都需要处理丢消息和重复收到消息的，正常情况下，Kafka 可以保证：1. 不丢消息；2. 不重复发消息；3. 消息读且只读一次。当然这都是正常情况，极端情况，如 Broker 宕机，断电，这类情况下，Kafka 只能保证 1 或者 2，无法保证 3。 在有副本的情况下，Kafka 是可以保证消息不丢的，其前提是设置了同步复制，这也是 Kafka 的默认设置，但是可能出现重复发送消息，这个交给上层应用解决；在生产者中使用异步提交，可以保证不重复发送消息，但是有丢消息的可能，如果应用可以容忍，也可以接受。如果需要实现读且只读一次，就比较麻烦，需要更底层的 API. 2. Kafka 的工具和编程接口2.1. Kafka 的工具Kafka 提供的工具还是比较全的，bin/ 目录下的工具有以下一些，1234567bin/connect-distributed.sh bin/kafka-consumer-offset-checker.sh bin/kafka-replica-verification.sh bin/kafka-verifiable-producer.shbin/connect-standalone.sh bin/kafka-consumer-perf-test.sh bin/kafka-run-class.sh bin/zookeeper-security-migration.shbin/kafka-acls.sh bin/kafka-mirror-maker.sh bin/kafka-server-start.sh bin/zookeeper-server-start.shbin/kafka-configs.sh bin/kafka-preferred-replica-election.sh bin/kafka-server-stop.sh bin/zookeeper-server-stop.shbin/kafka-console-consumer.sh bin/kafka-producer-perf-test.sh bin/kafka-simple-consumer-shell.sh bin/zookeeper-shell.shbin/kafka-console-producer.sh bin/kafka-reassign-partitions.sh bin/kafka-topics.shbin/kafka-consumer-groups.sh bin/kafka-replay-log-producer.sh bin/kafka-verifiable-consumer.sh 我常用的命令有以下几个，1234567bin/kafka-server-start.sh -daemon config/server.properties &amp;bin/kafka-topics.sh --describe --zookeeper 192.168.232.23:2181 --topic topic1bin/kafka-topics.sh --list --zookeeper 192.168.232.23:2181bin/kafka-topics.sh --delete --zookeeper 192.168.232.23:2181 --topic topic1bin/kafka-topics.sh --create --zookeeper 192.168.232.23:2181 --replication-factor 3 --partitions 2 --topic topic1bin/kafka-console-consumer.sh --zookeeper 192.168.232.23:2181 --topic topic1 --from-beginningbin/kafka-console-producer.sh --broker-list 192.168.232.23:9092 --topic topic1 kafka-server-start.sh 是用于 Kafka 的 Broker 启动的，主要就一个参数 config/server.properties，该文件中的配置项待会再说.还有一个 -daemon 参数，这个是将 Kafka 放在后台用守护进程的方式运行，如果不加这个参数，Kafka 会在运行一段时间后自动退出，据说这个是 0.10.0.0 版本才有的问题。kafka-topics.sh 是用于管理 Topic 的工具，我主要用的 --describe、--list、--delete、--create 这4个功能，上述的例子基本是不言自明的，--replication-factor3、--partitions 2 这两个参数分别表示3个副本（含 Leader），和2个分区。kafka-console-consumer.sh 和 kafka-console-producer.sh 是生产者和消费者的简易终端工具，在调试的时候比较有用，我常用的是 kafka-console-consumer.sh。我没有用 Kafka 自带的 zookeeper，而是用的 zookeeper 官方的发布版本 3.4.8，端口是默认2181，与 Broker 在同一台机器上。 下面说一下 Broker 启动的配置文件 config/server.properties，我在默认配置的基础上，修改了以下一些，1234broker.id=0listeners=PLAINTEXT://192.168.232.23:9092log.dirs=/tmp/kafka-logsdelete.topic.enable=true broker.id 是 Kafka 集群中的 Broker ID，不可重复，我在多副本的实验中，将他们分别设置为0、1、2；listeners 是 Broker 监听的地址，默认是监听 localhost:9092，因为我不是单机实验，所以修改为本机局域网地址，当然，如果要监听所有地址的话，也可以设置为 0.0.0.0:9092，多副本实验中，将监听端口分别设置为 9092、9093、9094；log.dirs 是 Broker 的 log 的目录，多副本实验中，不同的 Broker 需要有不同的 log 目录；delete.topic.enable 设为 true 后，可以删除 Topic，并且连带 Topic 中的消息也一并删掉，否则，即使调用 kafka-topics.sh --delete 也无法删除 Topic，这是一个便利性的设置，对于开发环境可以，生产环境一定要设为 false（默认）。实验中发现， 如果有消费者在消费这个 Topic，那么也无法删除，还是比较安全的。 剩下的工具多数在文档中也有提到。如果看一下这些脚本的话，会发现多数脚本的写法都是一致的，先做一些参数的校验，最后运行 exec $base_dir/kafka-run-class.sh XXXXXXXXX &quot;$@&quot;，可见，这些工具都是使用运行 Java Class 的方式调用的。 2.2. Kafka 的 Java API在编程接口方面，官方提供了 Scala 和 Java 的接口，社区提供了更多的其他语言的接口，基本上，无论用什么语言开发，都能找到相应的 API。下面说一下 Java 的 API 接口。 生产者的 API 只有一种，相对比较简单，代码如下， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class SimpleProducerDemo &#123; public static void main(String[] args)&#123; Properties props = new Properties(); props.put(\"bootstrap.servers\", \"192.168.232.23:9092,192.168.232.23:9093,192.168.232.23:9094\"); props.put(\"zookeeper.connect\", \"192.168.232.23:2181\"); props.put(\"client.id\", \"DemoProducer\"); props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.IntegerSerializer\"); props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); KafkaProducer&lt;Integer, String&gt; producer = new KafkaProducer&lt;&gt;(props); String topic = \"topic1\"; Boolean isAsync = false; int messageNo = 1; while (true) &#123; String messageStr = \"Message_\" + String.format(\"%05d\",messageNo); long startTime = System.currentTimeMillis(); if (isAsync) &#123; // Send asynchronously producer.send(new ProducerRecord&lt;&gt;(topic, messageNo, messageStr), new DemoCallBack(startTime, messageNo, messageStr)); &#125; else &#123; // Send synchronously try &#123; producer.send(new ProducerRecord&lt;&gt;(topic, messageNo, messageStr)).get(); System.out.println(\"Sent message: (\" + messageNo + \", \" + messageStr + \")\"); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; Thread.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; ++messageNo; &#125; &#125;&#125;class DemoCallBack implements Callback &#123; private final long startTime; private final int key; private final String message; public DemoCallBack(long startTime, int key, String message) &#123; this.startTime = startTime; this.key = key; this.message = message; &#125; public void onCompletion(RecordMetadata metadata, Exception exception) &#123; long elapsedTime = System.currentTimeMillis() - startTime; if (metadata != null) &#123; System.out.println( \"Send message: (\" + String.format(\"%05d\",key) + \", \" + message + \") at offset \"+ metadata.offset() + \" to partition(\" + metadata.partition() + \") in \" + elapsedTime + \" ms\"); &#125; else &#123; exception.printStackTrace(); &#125; &#125;&#125; 上例中使用了同步和异步发送两种方式。在多副本的情况下，如果要指定同步复制还是异步复制，可以使用 acks 参数，详细参考官方文档 Producer Configs 部分的内容；在多分区的情况下，如果要指定发送到哪个分区，可以使用 partitioner.class 参数，其值是一个实现了 org.apache.kafka.clients.producer.Partitioner 接口的类，用于根据不同的消息指定分区6。消费者的 API 有几种，比较新的 API 如下，1234567891011121314151617181920public class SimpleConsumer &#123; public static void main(String[] args)&#123; Properties props = new Properties(); props.put(\"bootstrap.servers\", \"192.168.232.23:9092\"); props.put(\"group.id\", \"test\"); props.put(\"enable.auto.commit\", \"true\"); props.put(\"auto.commit.interval.ms\", \"1000\"); props.put(\"session.timeout.ms\", \"30000\"); props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.IntegerDeserializer\"); props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); KafkaConsumer&lt;Integer, String&gt; consumer = new KafkaConsumer&lt;&gt;(props); consumer.subscribe(Arrays.asList(\"topic1\", \"topic2\", \"topic3\")); while (true) &#123; ConsumerRecords&lt;Integer, String&gt; records = consumer.poll(100); for (ConsumerRecord&lt;Integer, String&gt; record : records) &#123; System.out.println(\"Received message: (\" + String.format(\"%05d\", record.key()) + \", \" + record.value() + \") at offset \" + record.offset()); &#125; &#125; &#125;&#125; 消费者还有旧的 API，比如 Consumer 和 SimpleConsumer API，这些都可以从 Kafka 代码的 kafka-example 中找到，上述的两个例子也是改写自 kafka-example。使用新旧 API 在功能上都能满足消息收发的需要，但新 API 只依赖 kafka-clients，打包出来的 jar 包会小很多，以我的测试，新 API 的消费者 jar 包大约有 2M 左右，而旧 API 的消费者 jar 包接近 16M。 其实，Kafka 也提供了按分区订阅，可以一次订阅多个分区 TopicPartition[]；也支持手动提交 offset，需要调用 consumer.commitSync。 Kafka 似乎没有公开 Topic 创建以及修改的 API（至少我没有找到），如果生产者向 Broker 写入的 Topic 是一个新 Topic，那么 Broker 会创建这个 Topic。创建的过程中会使用默认参数，例如，分区个数，会使用 Broker 配置中的 num.partitions 参数（默认1）；副本个数，会使用 default.replication.factor 参数。但是通常情况下，我们会需要创建自定义的 Topic，那官方的途径是使用 Kafka 的工具。也有一些非官方的途径 7，例如可以这样写，123456789101112String[] options = new String[]&#123; \"--create\", \"--zookeeper\", \"192.168.232.23:2181\", \"--partitions\", \"2\", \"--replication-factor\", \"3\", \"--topic\", \"topic1\"&#125;;TopicCommand.main(options); 但是这样写有一个问题，在执行完 TopicCommand.main(options); 之后，系统会自动退出，原因是执行完指令之后，会调用 System.exit(exitCode); 系统直接退出。这样当然不行，我的办法是，把相关的执行代码挖出来，写一个 TopicUtils 类，如下，123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116public class TopicUtils &#123; // from: http://blog.csdn.net/changong28/article/details/39325079 // from: http://www.cnblogs.com/davidwang456/p/4313784.html public static void createTopic()&#123; String[] options = new String[]&#123; \"--create\", \"--zookeeper\", KafkaProperties.ZOOKEEPER_URL, \"--partitions\", \"2\", \"--replication-factor\", \"3\", \"--topic\", KafkaProperties.TOPIC &#125;;// TopicCommand.main(options); oper(options); &#125; public static void listTopic()&#123; String[] options = new String[]&#123; \"--list\", \"--zookeeper\", KafkaProperties.ZOOKEEPER_URL &#125;;// TopicCommand.main(options); oper(options); &#125; public static void deleteTopic()&#123; String[] options = new String[]&#123; \"--delete\", \"--zookeeper\", KafkaProperties.ZOOKEEPER_URL, \"--topic\", KafkaProperties.TOPIC &#125;;// TopicCommand.main(options); oper(options); &#125; public static void describeTopic()&#123; String[] options = new String[]&#123; \"--describe\", \"--zookeeper\", KafkaProperties.ZOOKEEPER_URL, \"--topic\", KafkaProperties.TOPIC &#125;;// TopicCommand.main(options); oper(options); &#125; public static void main(String[] args)&#123; listTopic(); createTopic(); listTopic(); describeTopic(); deleteTopic(); try &#123; Thread.sleep(3*1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; listTopic(); &#125; /** copied &amp; modified from kafka.admin.TopicCommand$.main * * @param args */ public static void oper(String args[])&#123; try &#123; TopicCommand$ topicCommand$ = TopicCommand$.MODULE$; final TopicCommand.TopicCommandOptions opts = new TopicCommand.TopicCommandOptions(args); if(args.length == 0) &#123; throw kafka.utils.CommandLineUtils$.MODULE$.printUsageAndDie(opts.parser(), \"Create, delete, describe, or change a topic.\"); &#125; else &#123; int actions =0; OptionSpecBuilder[] optionSpecBuilders = &#123;opts.createOpt(), opts.listOpt(), opts.alterOpt(), opts.describeOpt(), opts.deleteOpt()&#125;; for (OptionSpecBuilder temp:optionSpecBuilders)&#123; if (opts.options().has(temp)) &#123; actions++; &#125; &#125; if(actions != 1) &#123; throw kafka.utils.CommandLineUtils$.MODULE$.printUsageAndDie(opts.parser(), \"Command must include exactly one action: --list, --describe, --create, --alter or --delete\"); &#125; else &#123; opts.checkArgs(); ZkUtils zkUtils = kafka.utils.ZkUtils$.MODULE$.apply((String)opts.options().valueOf(opts.zkConnectOpt()), 30000, 30000, JaasUtils.isZkSecurityEnabled()); byte exitCode = 0; try &#123; try &#123; if(opts.options().has(opts.createOpt())) &#123; topicCommand$.createTopic(zkUtils, opts); &#125; else if(opts.options().has(opts.alterOpt())) &#123; topicCommand$.alterTopic(zkUtils, opts); &#125; else if(opts.options().has(opts.listOpt())) &#123; topicCommand$.listTopics(zkUtils, opts); &#125; else if(opts.options().has(opts.describeOpt())) &#123; topicCommand$.describeTopic(zkUtils, opts); &#125; else if(opts.options().has(opts.deleteOpt())) &#123; topicCommand$.deleteTopic(zkUtils, opts); &#125; &#125; catch (final Throwable var12) &#123; scala.Predef$.MODULE$.println((new StringBuilder()).append(\"Error while executing topic command : \").append(var12.getMessage()).toString()); System.out.println(var12); exitCode = 1; return; &#125; &#125; finally &#123; zkUtils.close();// System.exit(exitCode); &#125; &#125; &#125; &#125; catch (Nothing$ nothing$) &#123; nothing$.printStackTrace(); &#125; &#125;&#125; 3. Kafka 副本和集群在生产环境中，Kafka 总是以“集群+分区”方式运行的，以保证可靠性和性能。下面是一个3副本的 Kafka 集群实例。 首先，需要启动3个 Kafka Broker，Broker 的配置文件分别如下， 123456789broker.id=0listeners=PLAINTEXT://192.168.232.23:9092log.dirs=/tmp/kafka-logsbroker.id=1listeners=PLAINTEXT://192.168.232.23:9093log.dirs=/tmp/kafka-logs-1broker.id=1listeners=PLAINTEXT://192.168.232.23:9094log.dirs=/tmp/kafka-logs-2 虽然每个 Broker 只配置了一个端口，实际上，Kafka 会多占用一个，可能是用来 Broker 之间的复制的。另外，3个 Broker 都配置了，12zookeeper.connect=localhost:2181delete.topic.enable=true 在同一个 Zookeeper 上的 Broker 会被归类到一个集群中。注意，这些配置中并没有指定哪一个 Broker 是主节点，哪些 Broker 是从节点，Kafka 采用的办法是从可选的 Broker 中，选出每个分区的 Leader。也就是说，对某个 Topic 来说，可能0节点是 Leader，另外一些 Topic，可能1节点是 Leader；甚至，如果 topic1 有2个分区的话，分区1的 Leader 是0节点，分区2的 Leader 是1节点。 这种对等的设计，对于故障恢复是十分有用的，在节点崩溃的时候，Kafka 会自动选举出可用的从节点，将其升级为主节点。在崩溃的节点恢复，加入集群之后，Kafka 又会将这个节点加入到可用节点，并自动选举出新的主节点。 实验如下，先新建一个3副本，2分区的 Topic，1bin/kafka-topics.sh --create --zookeeper 192.168.232.23:2181 --replication-factor 3 --partitions 2 --topic topic1 初始状况下，topic1 的状态如下，1234$ bin/kafka-topics.sh --describe --zookeeper 192.168.232.23:2181 --topic topic1Topic:topic1 PartitionCount:2 ReplicationFactor:3 Configs: Topic: topic1 Partition: 0 Leader: 0 Replicas: 0,1,2 Isr: 0,1,2 Topic: topic1 Partition: 1 Leader: 1 Replicas: 1,2,0 Isr: 1,2,0 对于上面的输出，即使没有文档，也可以看懂大概：topic1 有2个分区，Partition 0 和 Partition 1，Leader 分别在 Broker 0 和 1。Replicas 表示副本在哪些 Broker 上，Isr（In-Sync Replicas）表示处于同步状态中的 Broker，如果有 Broker 宕机了，那么 Replicas 不会变，但是 Isr 会仅显示没有宕机的 Broker，详见下面的实验。 然后分2个线程，运行之前写的 Producer 和 Consumer 的示例代码，Producer 采用异步发送，消息采用同步复制。在有消息传送的情况下，kill -9 停掉其中2个 Broker（Broker 0 和 Broker 1），模拟突然宕机。此时，topic1 状态如下，1234$ bin/kafka-topics.sh --describe --zookeeper 192.168.232.23:2181 --topic topic1Topic:topic1 PartitionCount:2 ReplicationFactor:3 Configs: Topic: topic1 Partition: 0 Leader: 2 Replicas: 0,1,2 Isr: 2 Topic: topic1 Partition: 1 Leader: 2 Replicas: 1,2,0 Isr: 2 可见，Kafka 已经选出了新的 Leader，消息传送没有中断。接着再启动被停掉的那两个 Broker，并查看 topic1 的状态，如下，12345678$ bin/kafka-topics.sh --describe --zookeeper 192.168.232.23:2181 --topic topic1Topic:topic1 PartitionCount:2 ReplicationFactor:3 Configs: Topic: topic1 Partition: 0 Leader: 2 Replicas: 0,1,2 Isr: 2,1,0 Topic: topic1 Partition: 1 Leader: 2 Replicas: 1,2,0 Isr: 2,1,0$ bin/kafka-topics.sh --describe --zookeeper 192.168.232.23:2181 --topic topic1Topic:topic1 PartitionCount:2 ReplicationFactor:3 Configs: Topic: topic1 Partition: 0 Leader: 2 Replicas: 0,1,2 Isr: 2,1,0 Topic: topic1 Partition: 1 Leader: 1 Replicas: 1,2,0 Isr: 2,1,0 可以发现， 有一个短暂的时间，topic1 的两个分区的 Leader 都是 Broker 2，但是在 Kafka 重新选举之后，分区1的 Leader 变为 Broker 1。说明 Kafka 倾向于用不同的 Broker 做分区的 Leader，这样更能达到负载均衡的效果。 再来看看 Producer 和 Consumer 的日志，下面这个片段是2个 Broker 宕机前后的日志，123456789101112131415161718192021222324252627282930313233343536373839404142......Send message: (00439, Message_00439) at offset 217 to partition(0) in 3 msReceived message: (00438, Message_00438) at offset 216Send message: (00440, Message_00440) at offset 218 to partition(0) in 5 msSend message: (00441, Message_00441) at offset 221 to partition(1) in 5 msReceived message: (00441, Message_00441) at offset 221Received message: (00439, Message_00439) at offset 217Send message: (00442, Message_00442) at offset 222 to partition(1) in 5 msSend message: (00443, Message_00443) at offset 219 to partition(0) in 3 msReceived message: (00440, Message_00440) at offset 218Received message: (00443, Message_00443) at offset 219org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.Received message: (00442, Message_00442) at offset 222Send message: (00452, Message_00452) at offset 223 to partition(1) in 7492 msSend message: (00454, Message_00454) at offset 224 to partition(1) in 7485 msSend message: (00455, Message_00455) at offset 225 to partition(1) in 7482 msSend message: (00458, Message_00458) at offset 226 to partition(1) in 7473 msSend message: (00460, Message_00460) at offset 227 to partition(1) in 7467 msSend message: (00461, Message_00461) at offset 228 to partition(1) in 7465 msSend message: (00462, Message_00462) at offset 229 to partition(1) in 7462 msSend message: (00463, Message_00463) at offset 230 to partition(1) in 7459 msSend message: (00464, Message_00464) at offset 231 to partition(1) in 7456 msSend message: (00465, Message_00465) at offset 232 to partition(1) in 7453 ms......Send message: (01103, Message_01103) at offset 543 to partition(1) in 5478 msReceived message: (00631, Message_00631) at offset 310Received message: (00633, Message_00633) at offset 311Send message: (00451, Message_00451) at offset 220 to partition(0) in 7525 msReceived message: (00634, Message_00634) at offset 312Send message: (00453, Message_00453) at offset 221 to partition(0) in 7518 msReceived message: (00639, Message_00639) at offset 313Send message: (00456, Message_00456) at offset 222 to partition(0) in 7509 msReceived message: (00641, Message_00641) at offset 314Send message: (00457, Message_00457) at offset 223 to partition(0) in 7506 msReceived message: (00643, Message_00643) at offset 315...... 出现错误的时候，Producer 抛出了 NetworkException 异常。其中有3589条 Received 日志，3583条 Send 日志，7条 NetworkException 异常日志，发送消息的最大序号是3590，接收消息的最大序号是3589，有以下几个值得注意的地方， 1.宕机之前，消息的接收并不是顺序的，这是因为 topic1 有2个分区，Kafka 只保证分区上的有序； 2.宕机之后，出现了长段的发送日志而没有接收日志，说明 Kafka 此时正在选举，选举的过程会阻塞消费者； 3.从接收消息的条数和序号来看，所有的消息都收到了，没有丢（没有收到3590的消息可能是因为强制退出 client 进程的原因），发送的过程的7个异常应该只是虚警，7条异常对应序号444~450，3583条 Send 消息再加上这7条，与总消息3590条一致；从这个实验中，可以看到，虽然 Kafka 不保证消息重复发送，但是却在尽量保证没有消息被重复发送，可能我的实验场景还不够极端，没有做出消息重复的情况。 如之前所说，如果要保持完全顺序性，需要使用单分区；如果要避免抛出 NetworkException 异常，就使用 Producer 同步发送。下面，我们重做上面的例子，不同之处是使用单分区和 Producer 同步发送，截取一段 Broker 宕机时的日志如下， 12345678910111213141516......Sent message: (118, Message_00118)Received message: (00118, Message_00118) at offset 117Received message: (00119, Message_00119) at offset 118Sent message: (119, Message_00119)Sent message: (120, Message_00120)Received message: (00120, Message_00120) at offset 119Sent message: (121, Message_00121)Received message: (00121, Message_00121) at offset 120Sent message: (122, Message_00122)Sent message: (123, Message_00123)Sent message: (124, Message_00124)Sent message: (125, Message_00125)Sent message: (126, Message_00126)Sent message: (127, Message_00127)...... 可见，由于采用同步发送，Broker 宕机并没有造成抛出异常，另外，由于使用单分区，顺序性也得到了保证，全局没有出现乱序的情况。 综上，是否使用多分区更多的是对顺序性的要求，而使用 Producer 同步发送还是异步发送，更多是出于重复消息的考虑，如果异步发送抛出异常，在保证不丢消息的前提下，势必要重发消息，这就会导致收到重复消息。多分区和 Producer 异步发送，会带来性能的提升，但是也会引入非顺序性，重复消息等问题，如何取舍要看应用的需求。 4. Kafka 最佳实践Kafka 在一些应用场景中，有一些前人总结的最佳实践 8 9。对最佳实践，我的看法是，对于自己比较熟悉，有把握的部分，可以按自己的步骤进行；对一些自己不清楚的领域，可以借鉴其中的一些内容，至少不会错的特别厉害。有文章10说，Kafka 在分区比较多的时候，相应时间会变长，这个现象值得在实践中注意。 5. 后记在 Kafka 与 RocketMQ 的对比中，RocketMQ 的一个核心功能就是可以支持同步刷盘，此时，即使突然断电，也可以保证消息不丢；而 Kafka 采用的是异步刷盘，即使返回写入成功，也只是写入缓冲区成功，并非已经持久化。因此，如果出现断电或 kill -9 的情况，Kafka 内存中的消息可能丢失。另外，同步刷盘的效率是比较低下的，一般生产中估计也不会使用，可以用优雅关闭的方式来关闭进程。如果不考虑这些极端情况的话，Kafka 基本是一个很可靠的消息中间件。 http://kafka.apache.org/documentation.html↩ http://www.jianshu.com/p/453c6e7ff81c↩ http://www.infoq.com/cn/author/%E9%83%AD%E4%BF%8A#文章↩ http://developer.51cto.com/art/201501/464491.htm↩ https://segmentfault.com/q/1010000004292925↩ http://www.cnblogs.com/gnivor/p/5318319.html↩ http://www.cnblogs.com/davidwang456/p/4313784.html↩ http://www.jianshu.com/p/8689901720fd↩ http://zqhxuyuan.github.io/2016/05/26/2016-05-13-Kafka-Book-Sample/↩ http://www.confluent.io/blog/how-to-choose-the-number-of-topicspartitions-in-a-kafka-cluster/↩ 原文出处：Valleylord","categories":[{"name":"MQ","slug":"MQ","permalink":"http://blog.shagle.cn/categories/MQ/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://blog.shagle.cn/tags/kafka/"}]},{"title":"Java技术之ReentrantLock的实现原理","slug":"Java技术之ReentrantLock的实现原理","date":"2018-12-22T12:52:35.000Z","updated":"2019-02-26T10:14:11.000Z","comments":true,"path":"2018/12/22/Java技术之ReentrantLock的实现原理/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/Java技术之ReentrantLock的实现原理/","excerpt":"ReentrantLock是Java并发包中提供的一个可重入的互斥锁。ReentrantLock和synchronized在基本用法，行为语义上都是类似的，同样都具有可重入性。只不过相比原生的synchronized，ReentrantLock增加了一些高级的扩展功能，比如它可以实现公平锁，同时也可以绑定多个Conditon。","text":"ReentrantLock是Java并发包中提供的一个可重入的互斥锁。ReentrantLock和synchronized在基本用法，行为语义上都是类似的，同样都具有可重入性。只不过相比原生的synchronized，ReentrantLock增加了一些高级的扩展功能，比如它可以实现公平锁，同时也可以绑定多个Conditon。 1. 可重入性/公平锁/非公平锁1.1 可重入性所谓的可重入性，就是可以支持一个线程对锁的重复获取，原生的synchronized就具有可重入性，一个用synchronized修饰的递归方法，当线程在执行期间，它是可以反复获取到锁的，而不会出现自己把自己锁死的情况。ReentrantLock也是如此，在调用lock()方法时，已经获取到锁的线程，能够再次调用lock()方法获取锁而不被阻塞。那么有可重入锁，就有不可重入锁，我们在之前文章中自定义的一个Mutex锁就是个不可重入锁，不过使用场景极少而已。 1.2 公平锁/非公平锁所谓公平锁,顾名思义，意指锁的获取策略相对公平，当多个线程在获取同一个锁时，必须按照锁的申请时间来依次获得锁，排排队，不能插队；非公平锁则不同，当锁被释放时，等待中的线程均有机会获得锁。synchronized是非公平锁，ReentrantLock默认也是非公平的，但是可以通过带boolean参数的构造方法指定使用公平锁，但非公平锁的性能一般要优于公平锁。 synchronized是Java原生的互斥同步锁，使用方便，对于synchronized修饰的方法或同步块，无需再显式释放锁。synchronized底层是通过monitorenter和monitorexit两个字节码指令来实现加锁解锁操作的。而ReentrantLock做为API层面的互斥锁，需要显式地去加锁解锁。 12345678910111213class X &#123; private final ReentrantLock lock = new ReentrantLock(); // ... public void m() &#123; lock.lock(); // 加锁 try &#123; // ... 函数主题 &#125; finally &#123; lock.unlock() //解锁 &#125; &#125; &#125; 2. 源码分析接下来我们从源码角度来看看ReentrantLock的实现原理，它是如何保证可重入性，又是如何实现公平锁的。 ReentrantLock是基于AQS的，AQS是Java并发包中众多同步组件的构建基础，它通过一个int类型的状态变量state和一个FIFO队列来完成共享资源的获取，线程的排队等待等。AQS是个底层框架，采用模板方法模式，它定义了通用的较为复杂的逻辑骨架，比如线程的排队，阻塞，唤醒等，将这些复杂但实质通用的部分抽取出来，这些都是需要构建同步组件的使用者无需关心的，使用者仅需重写一些简单的指定的方法即可（其实就是对于共享变量state的一些简单的获取释放的操作）。 上面简单介绍了下AQS，详细内容可参考本人的另一篇文章《Java技术之AQS详解》，此处就不再赘述了。先来看常用的几个方法，我们从上往下推。 2.1 无参构造器（默认为非公平锁）123public ReentrantLock() &#123; sync = new NonfairSync();//默认是非公平的&#125; sync是ReentrantLock内部实现的一个同步组件，它是ReentrantLock的一个静态内部类，继承于AQS，后面我们再分析。 2.2 带布尔值的构造器（是否公平）123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();//fair为true，公平锁；反之，非公平锁&#125; 看到了吧，此处可以指定是否采用公平锁，FailSync和NonFailSync亦为ReentrantLock的静态内部类，都继承于Sync。 再来看看几个我们常用到的方法 2.3 lock()123public void lock() &#123; sync.lock();//代理到Sync的lock方法上&#125; Sync的lock方法是抽象的，实际的lock会代理到FairSync或是NonFairSync上（根据用户的选择来决定，公平锁还是非公平锁） 2.4 lockInterruptibly()如果当前线程未被中断，则获取锁定，如果已经被中断则出现异常。 123public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);//代理到sync的相应方法上，同lock方法的区别是此方法响应中断&#125; 此方法响应中断，当线程在阻塞中的时候，若被中断，会抛出InterruptedException异常 2.5 tryLock()仅在调用时锁定未被另一个线程保持的情况下，才获取该锁定。 123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);//代理到sync的相应方法上&#125; tryLock，尝试获取锁，成功则直接返回true，不成功也不耽搁时间，立即返回false。 2.6 unlock()123public void unlock() &#123; sync.release(1);//释放锁&#125; 释放锁，调用sync的release方法，其实是AQS的release逻辑。 2.7 newCondition()获取一个conditon，ReentrantLock支持多个Condition123public Condition newCondition() &#123; return sync.newCondition();&#125; 其他方法就不再赘述了，若想继续了解可去API中查看。功能和notify/wait 功能类似，实现等待通知，但是Condition可以实现部分通知功能 2.8 方法getHoldCount（）、getQueueLength（）和getWaitQueueLength（） 方法int getHoldCount（）的作用是查询当前线程保持此锁定的个数，也就是调用lock（）方法的次数。 方法int getQueueLength（）的作用是返回正等待获取此锁定的线程估计数，比如有5个线程，1个线程首先执行await（）方法，那么在调用getQueueLength（）方法后返回值是4，说明有4个线程同时在等待lock的释放。 方法int getWaitQueueLength（Condition condition）的作用是返回等待与此锁定相关的给定条件Condition的线程估计数，比如有5个线程，每个线程都执行了同一个condition对象的await（）方法，则调用getWaitQueueLength（Condition condition）方法时返回的int值是5。 2.9 方法hasQueuedThread（）、hasQueuedThreads（）和hasWaiters（） 方法boolean hasQueuedThread（Thread thread）的作用是查询指定的线程是否正在等待获取此锁定。 方法boolean hasWaiters（Condition condition）的作用是查询是否有线程正在等待与此锁定有关的condition条件。 2.10 方法isFair（）、isHeldByCurrentThread（）和isLocked（） 方法boolean isFair（）的作用是判断是不是公平锁。 方法boolean isHeldByCurrentThread（）的作用是查询当前线程是否保持此锁定。 2.11 方法awaitUninterruptibly（）的使用 无视中断请求，直到被唤醒。 2.12 方法awaitUntil（）的使用 在等待时间到达前，可以被其他线程提前唤醒 3. 小结其实从上面这写方法的介绍，我们都能大概梳理出ReentrantLock的处理逻辑，其内部定义了三个重要的静态内部类，Sync，NonFairSync，FairSync。Sync作为ReentrantLock中公用的同步组件，继承了AQS（要利用AQS复杂的顶层逻辑嘛，线程排队，阻塞，唤醒等等）；NonFairSync和FairSync则都继承Sync，调用Sync的公用逻辑，然后再在各自内部完成自己特定的逻辑（公平或非公平）。 接下来，关于如何实现重入性，如何实现公平性，就得去看这几个静态内部类了 4. NonFairSync（非公平可重入锁）12345678910111213static final class NonfairSync extends Sync &#123;//继承Sync private static final long serialVersionUID = 7316153563782823691L; /** 获取锁 */ final void lock() &#123; if (compareAndSetState(0, 1))//CAS设置state状态，若原值是0，将其置为1 setExclusiveOwnerThread(Thread.currentThread());//将当前线程标记为已持有锁 else acquire(1);//若设置失败，调用AQS的acquire方法，acquire又会调用我们下面重写的tryAcquire方法。这里说的调用失败有两种情况：1当前没有线程获取到资源，state为0，但是将state由0设置为1的时候，其他线程抢占资源，将state修改了，导致了CAS失败；2 state原本就不为0，也就是已经有线程获取到资源了，有可能是别的线程获取到资源，也有可能是当前线程获取的，这时线程又重复去获取，所以去tryAcquire中的nonfairTryAcquire我们应该就能看到可重入的实现逻辑了。 &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);//调用Sync中的方法 &#125;&#125; 4.1 nonfairTryAcquire()123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread();//获取当前线程 int c = getState();//获取当前state值 if (c == 0) &#123;//若state为0，意味着没有线程获取到资源，CAS将state设置为1，并将当前线程标记我获取到排他锁的线程，返回true if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;//若state不为0，但是持有锁的线程是当前线程 int nextc = c + acquires;//state累加1 if (nextc &lt; 0) // int类型溢出了 throw new Error(\"Maximum lock count exceeded\"); setState(nextc);//设置state，此时state大于1，代表着一个线程多次获锁，state的值即是线程重入的次数 return true;//返回true，获取锁成功 &#125; return false;//获取锁失败了&#125; 简单总结下流程： 1.先获取state值，若为0，意味着此时没有线程获取到资源，CAS将其设置为1，设置成功则代表获取到排他锁了； 2.若state大于0，肯定有线程已经抢占到资源了，此时再去判断是否就是自己抢占的，是的话，state累加，返回true，重入成功，state的值即是线程重入的次数； 3.其他情况，则获取锁失败。 来看看可重入公平锁的处理逻辑 5. FairSync123456789101112131415161718192021222324252627static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1);//直接调用AQS的模板方法acquire，acquire会调用下面我们重写的这个tryAcquire &#125; protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread();//获取当前线程 int c = getState();//获取state值 if (c == 0) &#123;//若state为0，意味着当前没有线程获取到资源，那就可以直接获取资源了吗？NO!这不就跟之前的非公平锁的逻辑一样了嘛。看下面的逻辑 if (!hasQueuedPredecessors() &amp;&amp;//判断在时间顺序上，是否有申请锁排在自己之前的线程，若没有，才能去获取，CAS设置state，并标记当前线程为持有排他锁的线程；反之，不能获取！这即是公平的处理方式。 compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;//重入的处理逻辑，与上文一致，不再赘述 int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125;&#125; 可以看到，公平锁的大致逻辑与非公平锁是一致的，不同的地方在于有了!hasQueuedPredecessors()这个判断逻辑，即便state为0，也不能贸然直接去获取，要先去看有没有还在排队的线程，若没有，才能尝试去获取，做后面的处理。反之，返回false，获取失败。 看看这个判断是否有排队中线程的逻辑 5.1 hasQueuedPredecessors()1234567public final boolean hasQueuedPredecessors() &#123; Node t = tail; // 尾结点 Node h = head;//头结点 Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());//判断是否有排在自己之前的线程&#125; 需要注意的是，这个判断是否有排在自己之前的线程的逻辑稍微有些绕，我们来梳理下，由代码得知，有两种情况会返回true，我们将此逻辑分解一下（注意：返回true意味着有其他线程申请锁比自己早，需要放弃抢占） 1.h !=t &amp;&amp; (s = h.next) == null，这个逻辑成立的一种可能是head指向头结点，tail此时还为null。考虑这种情况：当其他某个线程去获取锁失败，需构造一个结点加入同步队列中（假设此时同步队列为空），在添加的时候，需要先创建一个无意义傀儡头结点（在AQS的enq方法中，这是个自旋CAS操作），有可能在将head指向此傀儡结点完毕之后，还未将tail指向此结点。很明显，此线程时间上优于当前线程，所以，返回true，表示有等待中的线程且比自己来的还早。 2.h != t &amp;&amp; (s = h.next) != null &amp;&amp; s.thread != Thread.currentThread()。同步队列中已经有若干排队线程且当前线程不是队列的老二结点，此种情况会返回true。假如没有s.thread !=Thread.currentThread()这个判断的话，会怎么样呢？若当前线程已经在同步队列中是老二结点（头结点此时是个无意义的傀儡结点),此时持有锁的线程释放了资源，唤醒老二结点线程，老二结点线程重新tryAcquire（此逻辑在AQS中的acquireQueued方法中），又会调用到hasQueuedPredecessors，不加s.thread !=Thread.currentThread()这个判断的话，返回值就为true，导致tryAcquire失败。 最后，来看看ReentrantLock的tryRelease，定义在Sync中 12345678910111213 protected final boolean tryRelease(int releases) &#123; int c = getState() - releases;//减去1个资源 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //若state值为0，表示当前线程已完全释放干净，返回true，上层的AQS会意识到资源已空出。若不为0，则表示线程还占有资源，只不过将此次重入的资源的释放了而已，返回false。 if (c == 0) &#123; free = true;// setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 6. 总结ReentrantLock是一种可重入的，可实现公平性的互斥锁，它的设计基于AQS框架，可重入和公平性的实现逻辑都不难理解，每重入一次，state就加1，当然在释放的时候，也得一层一层释放。至于公平性，在尝试获取锁的时候多了一个判断：是否有比自己申请早的线程在同步队列中等待，若有，去等待；若没有，才允许去抢占。 原文出处： http://www.cnblogs.com/chengxiao/ 参考：https://www.javadoop.com/post/reentrant-read-write-lockhttps://www.jianshu.com/p/6923c126e762http://www.cnblogs.com/leesf456/p/5419132.htmlhttp://www.linkedkeeper.com/1118.html","categories":[{"name":"Java技术","slug":"Java技术","permalink":"http://blog.shagle.cn/categories/Java技术/"}],"tags":[{"name":"ReentrantLock","slug":"ReentrantLock","permalink":"http://blog.shagle.cn/tags/ReentrantLock/"}]},{"title":"spring aop","slug":"spring-aop","date":"2018-12-22T12:50:41.000Z","updated":"2018-12-22T12:51:48.000Z","comments":true,"path":"2018/12/22/spring-aop/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-aop/","excerpt":"","text":"1. 目录 Spring中Bean的生命周期 注册BeanPostProcessor BeanFactory.getBean()（注册Bean） createBean() resolveBeforeInstantiation InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation() BeanPostProcessor.postProcessAfterInitialization() 这里调用postProcessAfterInitialization 有啥用？？ doCreateBean() 创建bean createBeanInstance 创建实例 populateBean 设置Bean属性 InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation initializeBean 初始化方法 处理BeanNameAware、BeanClassLoaderAware、BeanFactoryAware applyBeanPostProcessorsBeforeInitialization invokeInitMethods applyBeanPostProcessorsAfterInitialization getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) registerBeanPostProcessors ApplicationContextAware 在哪被调用？ 多个BeanPostProcessor，先注册的会不会对后面注册的BeanPostProcessor起作用？ InstantiationAwareBeanPostProcessor应用——AOP 创建AOP @EnableAspectJAutoProxy AnnotationAwareAspectJAutoProxyCreator InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation 创建目标对象 InstantiationAwareBeanPostProcessor.postProcessAfterInitialization(initializeBean()中的) wrapIfNecessary()包装Bean 什么时候注册的增强器？？ AspectJPointcutAdvisor 是干什么的？？ 执行AOP目标方法 获取拦截器链 递归调用拦截器 总结 2. 流程图代码流程可参见 spirng 流程图 3. spring中bean生命周期 Spring作为一个优秀的框架，拥有良好的可扩展性。Spring对对象的可扩展性主要就是依靠InstantiationAwareBeanPostProcessor和BeanPostProcessor来实现的。 * InstantiationAwareBeanPostProcessor 主要是作用于实例化阶段。 * BeanPostProcessor 主要作用与 初始化阶段。 12345public AnnotationConfigApplicationContext(Class&lt;?&gt;... annotatedClasses) &#123; this(); register(annotatedClasses); refresh();&#125; applicationContext构造方法中调用refresh()方法 refresh() 方法中这里主要关心两个方法 registerBeanPostProcessors(beanFactory); 注册BeanPostProcessor finishBeanFactoryInitialization(beanFactory); 注册余下的Singletions Bean 4. 注册BeanPostProcessor1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374//BeanPostProcessor按优先级分为PriorityOrdered，Ordered和其他的，对他们分别进行操作。public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; //取所有BeanPostProcessor。 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // Register BeanPostProcessorChecker that logs an info message when // a bean is created during BeanPostProcessor instantiation, i.e. when // a bean is not eligible for getting processed by all BeanPostProcessors. int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // Separate between BeanPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;String&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;String&gt;(); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; //注册或创建`BeanPostProcessor` BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, register the BeanPostProcessors that implement PriorityOrdered. sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // Next, register the BeanPostProcessors that implement Ordered. List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); for (String ppName : orderedPostProcessorNames) &#123; //注册或创建`BeanPostProcessor` BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // Now, register all regular BeanPostProcessors. List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); for (String ppName : nonOrderedPostProcessorNames) &#123; //注册或创建`BeanPostProcessor` BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; // 注册未实现Ordered接口的BeanPostProcessor 对象 registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // Finally, re-register all internal BeanPostProcessors. sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); // Re-register post-processor for detecting inner beans as ApplicationListeners, // moving it to the end of the processor chain (for picking up proxies etc). beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext)); &#125; BeanPostProcessor按优先级分为PriorityOrdered，Ordered和其他的，对他们分别进行操作。 先beanFactory.getBean进性实例化， 再使用sortPostProcessors() 进行排序， 最后registerBeanPostProcessors()进行注册。 4.1 BeanFactory.getBean()（注册Bean）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = transformedBeanName(name); Object bean; //缓存 先getSingleton()从缓存中获取Bean，如果没有则创建。 // Eagerly check singleton cache for manually registered singletons. Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // Fail if we're already creating this bean instance: // We're assumably within a circular reference. //判断循环引用,抛异常 if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // Check if bean definition exists in this factory. BeanFactory parentBeanFactory = getParentBeanFactory(); // this.beanDefinitionMap.containsKey(beanName); 就是判断有没有BeanDefinition if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) &#123; return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); &#125; else if (args != null) &#123; // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; if (!typeCheckOnly) &#123; markBeanAsCreated(beanName); &#125; try &#123; final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. // 获取bean的依赖，实例化bean前先实例化依赖。 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); &#125; registerDependentBean(dep, beanName); try &#123; getBean(dep); &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex); &#125; &#125; &#125; //创建实例 // Create bean instance. if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &#125; try &#123; Object scopedInstance = scope.get(beanName, () -&gt; &#123; beforePrototypeCreation(beanName); try &#123; // 创建bean return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; &#125; &#125; &#125; // Check if required type matches the type of the actual bean instance. if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; return convertedBean; &#125; &#125; return (T) bean;&#125; 先getSingleton()从缓存中获取Bean，如果没有则创建。 创建过程先检查有无循环依赖，有则抛出异常。 实例化bean前先实例化所依赖的对象。 4.1.1 createBean()12345678910111213141516171819202122232425262728293031323334353637383940@Overrideprotected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // Prepare method overrides. try &#123; mbdToUse.prepareMethodOverrides(); &#125;... try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // 处理InstantiationAwareBeanPostProcessor Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125;... try &#123; //创建对象 Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) &#123; logger.debug(\"Finished creating instance of bean '\" + beanName + \"'\"); &#125; return beanInstance; &#125; ...&#125; resolveBeforeInstantiation() 在doCreateBean() 之前调用，使用InstantiationAwareBeanPostProcessor，在Bean被创建之前处理。 4.1.1.1 resolveBeforeInstantiation123456789101112131415161718protected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) &#123; Object bean = null; if (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) &#123; // Make sure bean class is actually resolved at this point. if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; Class&lt;?&gt; targetType = determineTargetType(beanName, mbd); if (targetType != null) &#123; // 调用InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation() bean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName); if (bean != null) &#123; bean = applyBeanPostProcessorsAfterInitialization(bean, beanName); &#125; &#125; &#125; mbd.beforeInstantiationResolved = (bean != null); &#125; return bean;&#125; 4.1.1.1.1 InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation()12345678910111213protected Object applyBeanPostProcessorsBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 执行所有InstantiationAwareBeanPostProcessor的postProcessBeforeInstantiation Object result = ibp.postProcessBeforeInstantiation(beanClass, beanName); if (result != null) &#123; return result; &#125; &#125; &#125; return null;&#125;","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"aop","slug":"aop","permalink":"http://blog.shagle.cn/tags/aop/"}]},{"title":"spring @Profile注解","slug":"spring-Profile","date":"2018-12-22T12:46:41.000Z","updated":"2018-12-22T12:49:52.000Z","comments":true,"path":"2018/12/22/spring-Profile/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-Profile/","excerpt":"","text":"14 @Profile 根据不同环境初始化bean我们知道实际工作中一般都会有本地开发环境（一般开发环境都等同于dev环境），uat测试环境（test），生产（pro）环境，不同的环境都需要读取不同环境的配置。本篇博客就讨论实际工作中springboot多环境配置管理。 比如我不同的环境定义了不同环境的配置文件 开发环境，application.properties：1spring.redis.host=192.168.1.111 测试环境，application-test.properties：1spring.redis.host=172.168.1.121 生产环境，application-pro.properties：1spring.redis.host=10.10.1.121 启动类： 12345678@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context =SpringApplication.run(Application.class,args); String redishost = context.getEnvironment().getProperty(\"spring.redis.host\"); System.out.println(redishost); &#125;&#125; 启动打印： 我们发现默认读的配置文件是application.properties,那么我们要去读取开发或者生产环境的配置文件呢？有多种方式， 14.1 第一种，比如在application.properties中配置属性：12spring.redis.host=192.168.1.111spring.profiles.active=test 发现已经读取到测试环境的配置。 14.2 第二种方式，启动项目的时候指定参数idea配置页面，exclipse同理。 14.3 第三种，也可以在代码里配置，硬编码（不推荐）12345678910@SpringBootApplicationpublic class Application2 &#123; public static void main(String[] args) &#123; SpringApplication springApplication = new SpringApplication(Application.class); `springApplication.setAdditionalProfiles(\"test\");` ConfigurableApplicationContext context =springApplication.run(args); String redishost =context.getEnvironment().getProperty(\"spring.redis.host\"); System.out.println(redishost); &#125;&#125; 14.4 第四种打包环境，打包时指定1java -jar springboot-profile2-1.0-SNAPSHOT.jar --spring.profiles.active=pro 当然上面都可以指定多个profile文件，实际开发中很少这么做。定义开发的application.properties 12spring.redis.host=192.168.1.111spring.profiles.active=test,pro 测试环境的application-test.properties:12spring.redis.host=172.168.1.121spring.redis.database=0 生产中的application-pro.properties12spring.redis.host=10.10.1.121spring.redis.password=323dsds32e3 123456789101112@SpringBootApplicationpublic class Application3 &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context =SpringApplication.run(Application3.class,args); String redishost = context.getEnvironment().getProperty(\"spring.redis.host\"); String redisdatabase = context.getEnvironment().getProperty(\"spring.redis.database\"); String redispassword = context.getEnvironment().getProperty(\"spring.redis.password\"); System.out.println(redishost); System.out.println(redisdatabase); System.out.println(redispassword); &#125;&#125; 发现即读到测试的配置又读到生产的配置，测试，生产都有的配置取后配置的，比如我这边配置的1spring.profiles.active=test,pro 测试，生产都有spring.redis.host的配置，但是系统读到的是生产的配置。 根据不同的环境初始化不同的bean 14.5 定义一个普通的配置类MyConfig，代码如下：123456789101112131415161718192021@Configurationpublic class MyConfig &#123; @Bean public Runnable createDevRunnable()&#123; System.out.println(\"========dev========\"); return () -&gt; &#123;&#125;; &#125; @Bean public Runnable createTestRunnable()&#123; System.out.println(\"========test========\"); return () -&gt; &#123;&#125;; &#125; @Bean public Runnable createProRunnable()&#123; System.out.println(\"========pro========\"); return () -&gt; &#123;&#125;; &#125;&#125; 启动执行类 1234567@SpringBootApplicationpublic class Application4 &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context =SpringApplication.run(Application4.class,args); System.out.println(context.getBeansOfType(Runnable.class)); &#125;&#125; 发现三个类都初始化了， 需求这样，不同的环境初始化不同环境的bean，使用 @Profile注解，配置类修改如下： 123456789101112131415161718192021222324@Configurationpublic class MyConfig &#123; @Bean @Profile(\"dev\") public Runnable createDevRunnable()&#123; System.out.println(\"========dev========\"); return () -&gt; &#123;&#125;; &#125; @Bean @Profile(\"test\") public Runnable createTestRunnable()&#123; System.out.println(\"========test========\"); return () -&gt; &#123;&#125;; &#125; @Bean @Profile(\"pro\") public Runnable createProRunnable()&#123; System.out.println(\"========pro========\"); return () -&gt; &#123;&#125;; &#125;&#125; 注意：@Profile也可以修饰类，和修饰方法一致，这边就不多做过多解释了 本文转自：简书 - 二月_春风","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spirng Profile","slug":"spirng-Profile","permalink":"http://blog.shagle.cn/tags/spirng-Profile/"}]},{"title":"spring Aware接口","slug":"spring-Aware","date":"2018-12-22T12:45:36.000Z","updated":"2018-12-22T12:46:15.000Z","comments":true,"path":"2018/12/22/spring-Aware/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-Aware/","excerpt":"","text":"14 Aware 实现分析通过前面深入理解spring生命周期与BeanPostProcessor的实现原理分析，我们知道Aware的实现是通过BeanPostProcessor实现的，我们以ApplicationContextAware做分析,实现接口是使用ApplicationContextAwareProcessor接口完成Aware注入，代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172class ApplicationContextAwareProcessor implements BeanPostProcessor &#123; private final ConfigurableApplicationContext applicationContext; private final StringValueResolver embeddedValueResolver; /** * Create a new ApplicationContextAwareProcessor for the given context. */ public ApplicationContextAwareProcessor(ConfigurableApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; this.embeddedValueResolver = new EmbeddedValueResolver(applicationContext.getBeanFactory()); &#125; @Override public Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException &#123; AccessControlContext acc = null; if (System.getSecurityManager() != null &amp;&amp; (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) &#123; acc = this.applicationContext.getBeanFactory().getAccessControlContext(); &#125; if (acc != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareInterfaces(bean); return null; &#125; &#125;, acc); &#125; else &#123; invokeAwareInterfaces(bean); &#125; return bean; &#125; private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof EmbeddedValueResolverAware) &#123; ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); &#125; if (bean instanceof ResourceLoaderAware) &#123; ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); &#125; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; if (bean instanceof MessageSourceAware) &#123; ((MessageSourceAware) bean).setMessageSource(this.applicationContext); &#125; if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125; &#125; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) &#123; return bean; &#125;&#125; 在上述代码invokeAwareInterfaces中我们可以看的，每一个初始化的bean 是否实现其中的Aware接口，并回调注入参数属性，类似函数回调方式 要想实现自己的组件，我们也可以安装spring的实现方式，提供一个BeanPostProcessor接口，并在初始化时判断bean是否实现自定义的Aware接口，如果实现时，通过回调方式调用接口方法 Aware常用的实现类 ApplicationContextAware 自动注入IOC容器 ApplicationEventPublisherAware 注入事件派发器 BeanClassLoaderAware 类加载器 BeanFactoryAware Bean工厂 BeanNameAware Bean名字 EmbeddedValueResolverAware Embedded值解析器 EnvironmentAware 环境 ImportAware 导入相关的 LoadTimeWeaverAware 导入相关的 MessageSourceAware 国际化 NotificationPublisherAware 发送通知的支持 ResourceLoaderAware 资源加载器","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spring Aware","slug":"spring-Aware","permalink":"http://blog.shagle.cn/tags/spring-Aware/"}]},{"title":"spring @Autowired，@Qualifier和@Primary注解","slug":"spring-自动装配","date":"2018-12-22T12:43:11.000Z","updated":"2018-12-22T12:44:40.000Z","comments":true,"path":"2018/12/22/spring-自动装配/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-自动装配/","excerpt":"","text":"14 @Autowired，@Qualifier和@Primary注解1，@Autowired注解的使用 继续上文深入理解spring注解之@ComponentScan注解中的例子，现在我们需要在UserService中调用UserDao相关操作，那我们可以在UserService中增加如下代码：12345678910111213import com.zhang.dao.UserDao;@Servicepublic class UserService &#123; @Autowired private UserDao userDao; /** * 增加一个tostring方法 方便测试 */ @Override public String toString() &#123; return \"UserService [userDao=\" + userDao + \"]\"; &#125;&#125; 测试代码如下：123AnnotationConfigApplicationContext applicationContext2 = new AnnotationConfigApplicationContext(MainScanConfig.class);UserService object = (UserService) applicationContext2.getBean(\"userService\");System.out.println(\"实例bean为 === \"+object); 运行结果如下：1实例bean为 === UserService [userDao=com.zhang.dao.UserDao@51b279c9] 根据运行结果我们可以发现userDao已经成功注入到UserService中了 假设现在业务中有一种情况是UserDao是第三方提供的服务，我们也不能保证其是否可以成功加入到spring容器中，那我们也不能因为UserDao没能成功注入到spring容器而使我们整个UserService服务都不能使用，那这边我们就来演示一下这种情况，如下我们注释掉UserDao的@Repository注解：1234import org.springframework.stereotype.Repository;//@Repositorypublic class UserDao &#123;&#125; 这个时候你再启动测试类会报如下错误：1234567891011121314151617警告: Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userService': Unsatisfied dependency expressed through field 'userDao'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.zhang.dao.UserDao' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: &#123;@org.springframework.beans.factory.annotation.Autowired(required=true)&#125;Exception in thread \"main\" org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'userService': Unsatisfied dependency expressed through field 'userDao'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.zhang.dao.UserDao' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: &#123;@org.springframework.beans.factory.annotation.Autowired(required=true)&#125; at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:588) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:366) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1268) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:312) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:761) at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:867) at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) at org.springframework.context.annotation.AnnotationConfigApplicationContext.&lt;init&gt;(AnnotationConfigApplicationContext.java:84) at com.zhang.ApplicationTest.main(ApplicationTest.java:31) 其实很简单这个时候我们只需要在@Autowired注解中加上如下属性：12@Autowired(required=false)private UserDao userDao; 再次运行测试类你会发现错误已经消失只是这个时候userDao是null如下：1实例bean为 === UserService [userDao=null] 2，@Qualifier注解的使用 把UserDao代码修改为如下：12345678910111213141516171819202122232425import org.springframework.stereotype.Repository;@Repositorypublic class UserDao &#123; // 给一个默认值 private Integer version = 0; /** * 增加tostring方便测试 */ @Override public String toString() &#123; return \"UserDao [version=\" + version + \"]\"; &#125; /** * @return the version */ public Integer getVersion() &#123; return version; &#125; /** * @param version the version to set */ public void setVersion(Integer version) &#123; this.version = version; &#125;&#125; 同时在配置类中增加一个@Bean的UserDao配置如下：123456@Bean(value = \"userDao2\")public UserDao getUserDao()&#123; UserDao userDao = new UserDao(); userDao.setVersion(2); return userDao;&#125; 运行测试类结果如下：1234567实例bean为 === UserService [userDao=UserDao [version=0]]``` 我们可以发现这个时候用的是默认的扫描到的UserDao，这个时候我们把UserService中注入的UserDao改成如下：```java@Autowired(required=false)private UserDao userDao2; 继续运行测试类结果如下：1实例bean为 === UserService [userDao=UserDao [version=2]] 从以上运行结果我们可以发现如果有多个同类型的bean默认是根据对应的bean名称注入的，那如果这个时候我们不想使用spring默认的注入方式而是希望根据自己业务需要指定固定的bean，那就是@Qualifier注解表现的时候了如下：123@Qualifier(value=\"userDao\")@Autowired(required=false)private UserDao userDao2; 这个时候不管你UserDao定义什么名字永远只会注入userDao这个bean了 3，@Primary注解的使用 不管是因为洁癖还是什么也好可能有些同学不是特别喜欢使用@Qualifier注解，那么没关系，spring还为我们提供了另外一个注解@Primary同样可以实现以上功能 假设现在我们UserService中注入的UserDao是userDao2，这么这个时候我们可以在配置类中的UserDao上增加@Primary注解如下： 1234567@Primary@Bean(value = \"userDao2\")public UserDao getUserDao()&#123; UserDao userDao = new UserDao(); userDao.setVersion(2); return userDao;&#125; 这个时候运行测试类你会发现UserService注入的就是userDao2了 注意：这个时候UserService中的UserDao就不能再加@Qualifier对应的注解了 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spring Autowired","slug":"spring-Autowired","permalink":"http://blog.shagle.cn/tags/spring-Autowired/"},{"name":"spring Qualifier","slug":"spring-Qualifier","permalink":"http://blog.shagle.cn/tags/spring-Qualifier/"},{"name":"spring Primary","slug":"spring-Primary","permalink":"http://blog.shagle.cn/tags/spring-Primary/"}]},{"title":"spring @PropertySource原理","slug":"spring-PropertySource原理","date":"2018-12-22T12:37:55.000Z","updated":"2018-12-22T12:41:42.000Z","comments":true,"path":"2018/12/22/spring-PropertySource原理/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-PropertySource原理/","excerpt":"","text":"13 深入理解spring注解@PropertySource的实现原理首先让我们一起看下@PropertySource的源码如下： 1234567891011121314151617181920212223242526272829@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Repeatable(PropertySources.class)public @interface PropertySource &#123; /** * 资源的名称 */ String name() default \"\"; /** * 资源文件路径，可以是数据多个文件地址 * 可以是classpath地址如： * \"classpath:/com/myco/app.properties\" * 也可以是对应的文件系统地址如： * \"file:/path/to/file\" */ String[] value(); /** * 是否忽略文件资源是否存在，默认是false,也就是说配置不存在的文件地址spring启动将会报错 */ boolean ignoreResourceNotFound() default false; /** * 这个没什么好说的了就是对应的字符编码了，默认是空值，如果配置文件中有中文应该设置为utf-8 */ String encoding() default \"\"; /** * 关键的元素了 读取对应资源文件的工厂类了 默认的是PropertySourceFactory */ Class&lt;? extends PropertySourceFactory&gt; factory() default PropertySourceFactory.class;&#125; 注意看上面代码中的注释，之前文章有演示过读取classpath中的配置文件，这边演示一下如何读取系统目录中文件如下： 12@PropertySource(value=&#123;\"classpath:/user2.properties\",\"file:/d://user2.properties\"&#125;,encoding=\"utf-8\",ignoreResourceNotFound=true) user2.properties的配置文件如下: 12u.name2=王五u.age2=25 增加一个user1对象如下: 12345678910/*** 用户名 */@Value(\"$&#123;u.name2&#125;\")private String userName;/*** 年龄*/@Value(\"$&#123;u.age2&#125;\")private Integer age; 运行测试如下： 12实例1 === User [userName=李四, age=29]实例2 === User [userName=王五, age=25] 从上我们可以发现@PropertySource注解的地址可以是以下两种： 1 classpath路径：”classpath:/com/myco/app.properties” 2 文件对应路径：”file:/path/to/file” 接下来我们来详细的介绍@PropertySource注解底层是如何解析这些配置文件，这个就必须得PropertySourceFactory的具体实现源码了 进入PropertySourceFactory中你会发现它是一个接口代码如下： 12345678910public interface PropertySourceFactory &#123; /** * Create a &#123;@link PropertySource&#125; that wraps the given resource. * @param name the name of the property source * @param resource the resource (potentially encoded) to wrap * @return the new &#123;@link PropertySource&#125; (never &#123;@code null&#125;) * @throws IOException if resource resolution failed */ PropertySource&lt;?&gt; createPropertySource(String name, EncodedResource resource) throws IOException;&#125; 里边只有一个createPropertySource方法，进入其中的实现类中如下：123456public class DefaultPropertySourceFactory implements PropertySourceFactory &#123; @Override public PropertySource&lt;?&gt; createPropertySource(String name, EncodedResource resource) throws IOException &#123; return (name != null ? new ResourcePropertySource(name, resource) : new ResourcePropertySource(resource)); &#125;&#125; 注意，重要的类ResourcePropertySource出现了，进去可以看到两个主要的构造方法如下： 1234567891011121314151617/** * Create a PropertySource having the given name based on Properties * loaded from the given encoded resource. */ public ResourcePropertySource(String name, EncodedResource resource) throws IOException &#123; super(name, PropertiesLoaderUtils.loadProperties(resource)); this.resourceName = getNameForResource(resource.getResource()); &#125; /** * Create a PropertySource based on Properties loaded from the given resource. * The name of the PropertySource will be generated based on the * &#123;@link Resource#getDescription() description&#125; of the given resource. */ public ResourcePropertySource(EncodedResource resource) throws IOException &#123; super(getNameForResource(resource.getResource()), PropertiesLoaderUtils.loadProperties(resource)); this.resourceName = null; &#125; 在构造方法中你可以发现加载资源的地方PropertiesLoaderUtils.loadProperties(resource)，一路进去你可以返现如下代码： 12345678910111213141516171819202122static void fillProperties(Properties props, EncodedResource resource, PropertiesPersister persister) throws IOException &#123; InputStream stream = null; Reader reader = null; try &#123; String filename = resource.getResource().getFilename(); // 加载xml文件 if (filename != null &amp;&amp; filename.endsWith(XML_FILE_EXTENSION)) &#123; stream = resource.getInputStream(); persister.loadFromXml(props, stream); &#125; // 判断是否有需要对应的字符编码设置 有的话处理对应的InputStream else if (resource.requiresReader()) &#123; reader = resource.getReader(); persister.load(props, reader); &#125; else &#123; stream = resource.getInputStream(); persister.load(props, stream); &#125; &#125;&#125; 怎么样，是不是可以发现@PropertySource不仅可以解析properties的文件同样也可以解析xml文件，下边我们一起来演示一下解析xml的例子吧 首先新增一个user2.xml如下： 123456&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"&gt; &lt;properties&gt; &lt;entry key=\"u.name3\"&gt;王二小&lt;/entry&gt; &lt;entry key=\"u.age3\"&gt;22&lt;/entry&gt; &lt;/properties&gt; 配置类增加配置如下： 1@PropertySource(value=&#123;\"classpath:/user.properties\",\"classpath:/user2.xml\",\"file:/d://user2.properties\"&#125;,encoding=\"utf-8\",ignoreResourceNotFound=false) 测试运行结果如下：12实例1 === User [userName=李四, age=29]实例2 === User [userName=王二小, age=22] 好了，到目前为止我们不仅学会了@PropertySource注解的使用，而且了解到了其底层的具体实现，做到知其然知其所以然，以及了解了其默认的资源解析器PropertySourceFactory，并且你也可以继承PropertySourceFactory实现自定义的解析器，感兴趣的同学可以自己去实现一个自定义解析类 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spring PropertySource原理","slug":"spring-PropertySource原理","permalink":"http://blog.shagle.cn/tags/spring-PropertySource原理/"}]},{"title":"spring @PropertySource注解","slug":"spring-PropertySource","date":"2018-12-22T12:34:43.000Z","updated":"2018-12-22T12:41:42.000Z","comments":true,"path":"2018/12/22/spring-PropertySource/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-PropertySource/","excerpt":"","text":"12 spring注解之@PropertySource注解上一篇文章跟大家简单介绍了@value注解的使用，没有查看的同学可以点击查看学会spring注解之@value注解，今天将给大家介绍另外一个可以方便@value注解使用的@PropertySource注解，废话不多说直接上代码吧 首先在src/main/resources目录下新增一个user.properties配置文件如下： 12u.name=lisiu.age=29 然后在主配置文件类上增加@PropertySource注解如下： 1@PropertySource(value=&#123;\"classpath:/user.properties\"&#125;) 最后把user对象中的代码从： 12345678910/*** 用户名*/@Value(\"张三\")private String userName;/*** 年龄*/@Value(\"26\")private Integer age; 改成： 12345678910/*** 用户名*/@Value(\"$&#123;u.name&#125;\")private String userName;/*** 年龄*/@Value(\"$&#123;u.age&#125;\")private Integer age; 怎么样现在@Value注解结合@PropertySource注解使用，项目中需要动态配置的参数是不是都可以抽取到对应的配置文件中 好了，今天的一分钟就到这了，家里领导又在说天天就知道敲代码都不陪她聊天了，接下来的一篇文章会详细的介绍@PropertySource的使用以及其底层实现原理，大家尽情期待…. 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spring PropertySource注解","slug":"spring-PropertySource注解","permalink":"http://blog.shagle.cn/tags/spring-PropertySource注解/"}]},{"title":"spring @Value注解","slug":"spring-Value","date":"2018-12-22T12:30:13.000Z","updated":"2018-12-22T12:41:57.000Z","comments":true,"path":"2018/12/22/spring-Value/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-Value/","excerpt":"","text":"11 spring注解之@value注解11.1 xml配置属性方式简单介绍一下@value注解的使用，在讲@value注解使用前，先让我们一起来看看原先xml方式是怎么注入属性参数的 首先在xml中定义一个bean如下：把对应的参数以property中value的形式注入 12345&lt;!-- 定义一个id为user的bean对象 --&gt;&lt;bean id=\"user\" class=\"com.zhang.bean.User\"&gt; &lt;property name=\"age\" value=\"26\"&gt;&lt;/property&gt; &lt;property name=\"userName\" value=\"zhangsan\"&gt;&lt;/property&gt;&lt;/bean&gt; 测试代码如下： 12345678@Testpublic void testXmlValue() &#123; // 使用ClassPathXmlApplicationContext获取spring容器ApplicationContext ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"beans.xml\"); // 根据bean id获取bean对象 User bean = (User) applicationContext.getBean(\"user\"); System.out.println(bean);&#125; 运行结果如下：可以发现已经获取到xml中配置的属性了 [userName1234567891011121314151617## 11.2 @Value配置属性方式接下来我们来看看用`@value`注解要怎么实现，首先在User对象的属性中增加`@value`注解如下：```javapublic class User &#123; /** * 用户名 */ @Value(&quot;张三&quot;) private String userName; /** * 年龄 */ @Value(&quot;26&quot;) private Integer age;&#125; 配置类如下： 1234567891011@Configurationpublic class MainConfig &#123; /** * 定义一个bean对象 * @return */ @Bean public User getUser()&#123; return new User(); &#125;&#125; 测试类如下： 123456public void testValue() &#123; AnnotationConfigApplicationContext applicationContext2 = new AnnotationConfigApplicationContext(MainConfig.class); User bean = applicationContext2.getBean(User.class); System.out.println(\"实例1 === \"+bean); applicationContext2.close();&#125; 怎么样发现我们同样获取到了对应的值，有人可能会觉得这样配置并不是特别方便，甚至觉得这样比较麻烦，那下边我们一起来看下@value几种数值填充方式 基本数值的填充 这个上面演示的就是 基于SpEl表达式#{} 如上文中年龄也可以这样#{28-2} 基于配置文件${配置文件中参数名} 基于配置文件是我们最常用的也是最方便的一种，将会在下一节中讲@PropertySource注解的时候给大家演示，敬请期待… 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spring value注解","slug":"spring-value注解","permalink":"http://blog.shagle.cn/tags/spring-value注解/"}]},{"title":"spring BeanPostProcessor原理","slug":"spring-BeanPostProcessor原理","date":"2018-12-22T12:28:34.000Z","updated":"2018-12-22T12:42:34.000Z","comments":true,"path":"2018/12/22/spring-BeanPostProcessor原理/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-BeanPostProcessor原理/","excerpt":"","text":"10 深入理解spring生命周期与BeanPostProcessor的实现原理新建一个User1对象如下：1234567891011121314151617181920212223/** * 定义一个实现InitializingBean DisposableBean的bean * * @author * @date 2018年5月4日 */public class User1 implements InitializingBean,DisposableBean&#123; public User1()&#123; System.out.println(\"实例化User1的构造方法......\"); &#125; public void destroy() throws Exception &#123; System.out.println(\"调用实现DisposableBean的destroy方法....\"); &#125; public void afterPropertiesSet() throws Exception &#123; System.out.println(\"调用实现InitializingBean的afterPropertiesSet方法......\"); &#125; public void initUser()&#123; System.out.println(\"执行initMethod方法.....\"); &#125; public void destroyUser()&#123; System.out.println(\"执行destroyMethod方法......\"); &#125;&#125; 新建一个MyBeanPostProcessor实现BeanPostProcessor如下：1234567891011121314151617181920/** * 定义一个前置后置处理器 * * @author * @date 2018年5月6日 */public class MyBeanPostProcessor implements BeanPostProcessor &#123; public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; // 这边只做简单打印 原样返回bean System.out.println(\"postProcessBeforeInitialization====\"+beanName); return bean; &#125; public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; // 这边只做简单打印 原样返回bean System.out.println(\"postProcessAfterInitialization====\"+beanName); return bean; &#125;&#125; 主配置文件如下：1234567891011121314151617/** * 定义一个注解配置文件 必须要加上@Configuration注解 * * @author * @date 2018年4月30日 */@Configurationpublic class MainConfig &#123; @Bean(initMethod=\"initUser\",destroyMethod=\"destroyUser\") public User1 getUser1()&#123; return new User1(); &#125; @Bean public MyBeanPostProcessor getMyBeanPostProcessor()&#123; return new MyBeanPostProcessor(); &#125;&#125; 测试代码如下：12345public static void main(String[] args) &#123; // 使用AnnotationConfigApplicationContext获取spring容器ApplicationContext2 AnnotationConfigApplicationContext applicationContext2 = new AnnotationConfigApplicationContext(MainConfig.class); applicationContext2.close();&#125; 运行结果如下： 1234567实例化User1的构造方法......postProcessBeforeInitialization====getUser1调用实现InitializingBean的afterPropertiesSet方法......执行initMethod方法.....postProcessAfterInitialization====getUser1调用实现DisposableBean的destroy方法....执行destroyMethod方法...... 从结果中可以看出他们之前执行的顺序如下：注意其中的位置序号下边文章会用到 1，首先执行bean的构造方法, 2，BeanPostProcessor的postProcessBeforeInitialization方法 3，InitializingBean的afterPropertiesSet方法 4，@Bean注解的initMethod方法 5，BeanPostProcessor的postProcessAfterInitialization方法 6，DisposableBean的destroy方法 7，@Bean注解的destroyMethod方法 接下来我们再来看看spring底层的实现，首先进入程序的启动类AnnotationConfigApplicationContext方法如下：12345public AnnotationConfigApplicationContext(Class&lt;?&gt;... annotatedClasses) &#123; this(); register(annotatedClasses); refresh();&#125; 里边有两个方法一个是register注册对应的java配置类和另一个是refresh方法，我们重点来看这个refresh方法如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // 实例化所有的不是延迟加载（延迟加载的只有在使用的时候才会实例化）的bean实例 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 接下来我们重点来看下finishBeanFactoryInitialization实例化bean的方法，进去之后我们发现最后有一个preInstantiateSingletons方法如下： 1234567891011121314151617181920212223242526272829303132333435protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // Initialize conversion service for this context. if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; // Register a default embedded value resolver if no bean post-processor // (such as a PropertyPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(new StringValueResolver() &#123; @Override public String resolveStringValue(String strVal) &#123; return getEnvironment().resolvePlaceholders(strVal); &#125; &#125;); &#125; // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early. String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // Allow for caching all bean definition metadata, not expecting further changes. beanFactory.freezeConfiguration(); // Instantiate all remaining (non-lazy-init) singletons. beanFactory.preInstantiateSingletons(); &#125; 继续查看preInstantiateSingletons对应实现如下： 123456789101112131415161718192021222324252627282930313233343536@Override public void preInstantiateSingletons() throws BeansException &#123; // Iterate over a copy to allow for init methods which in turn register new bean definitions. // While this may not be part of the regular factory bootstrap, it does otherwise work fine. List&lt;String&gt; beanNames = new ArrayList&lt;String&gt;(this.beanDefinitionNames); // 循环所有的bean实例化 for (String beanName : beanNames) &#123; RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; if (isFactoryBean(beanName)) &#123; final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) getBean(FACTORY_BEAN_PREFIX + beanName); boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged(new PrivilegedAction&lt;Boolean&gt;() &#123; @Override public Boolean run() &#123; return ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit(); &#125; &#125;, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; // 获取bean方法 getBean(beanName); &#125; &#125; else &#123; getBean(beanName); &#125; &#125; &#125; // 省略部分代码&#125; 我们发现里边的关键方法getBean如下：1234@Overridepublic Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false);&#125; 继续跟进去如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = transformedBeanName(name); Object bean; // 检查缓存中是否已经存在了bean实例. Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); &#125; else &#123; logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); &#125; &#125; bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125;else &#123; // 省略部分代码。。。。。 try &#123; // 省略部分代码。。。。。 // 判断bean是否配置的是单实例 if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125;// bean配置的是多实例 else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123;// 既不是单实例也不是多实例的逻辑 // 省略部分代码。。。。。 &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // 省略部分代码。。。。。 return (T) bean; &#125; 接下来重点看一下其中创建bean的方法createBean如下：12345678910protected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123; RootBeanDefinition mbdToUse = mbd; // 省略部分代码 // 重点注意doCreateBean方法 Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) &#123; logger.debug(\"Finished creating instance of bean '\" + beanName + \"'\"); &#125; return beanInstance;&#125; 继续跟进可以看到doCreateBean方法如下：123456789101112131415161718192021222324252627282930313233protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; // 省略部分代码 // Initialize the bean instance. Object exposedObject = bean; try &#123; // 设置bean 属性 populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) &#123; exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Initialization of bean failed\", ex); &#125; &#125; // 省略部分代码...... // Register bean as disposable. // 注意这个地方 下面讲销毁的时候说讲到 try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Invalid destruction signature\", ex); &#125; return exposedObject;&#125; 可以发现其中有一个initializeBean方法如下：123456789101112131415161718192021222324protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; // 省略部分代码。。。。 Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; // 重点来了BeanPostProcessor的postProcessBeforeInitialization方法执行的地方 // 这也是为什么他执行所有的初始化之前的原因了 位置2 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; // 初始化bean invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; // BeanPostProcessor的PostProcessorsAfterInitialization方法执行的地方 // 初始化完成之后执行BeanPostProcessor的postProcessorsAfterInitialization 位置5 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 到这BeanPostProcessor的实现已经很清晰了吧，BeanPostProcessor的postProcessBeforeInitialization（方法位置2）和BeanPostProcessor的postProcessAfterInitialization（方法位置5）的执行位置我们搞清楚了，那上面的位置3和位置4又是怎么执行的呢，让我们继续到invokeInitMethods里边看看如下： 1234567891011121314151617181920212223242526272829303132333435protected void invokeInitMethods(String beanName, final Object bean, RootBeanDefinition mbd) throws Throwable &#123; boolean isInitializingBean = (bean instanceof InitializingBean); if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\"); &#125; if (System.getSecurityManager() != null) &#123; try &#123; AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Object&gt;() &#123; @Override public Object run() throws Exception &#123; ((InitializingBean) bean).afterPropertiesSet(); return null; &#125; &#125;, getAccessControlContext()); &#125; catch (PrivilegedActionException pae) &#123; throw pae.getException(); &#125; &#125; else &#123; // 位置3的 InitializingBean的afterPropertiesSet方法 ((InitializingBean) bean).afterPropertiesSet(); &#125; &#125; if (mbd != null) &#123; // 位置4的 @Bean注解的initMethod方法 String initMethodName = mbd.getInitMethodName(); if (initMethodName != null &amp;&amp; !(isInitializingBean &amp;&amp; \"afterPropertiesSet\".equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) &#123; invokeCustomInitMethod(beanName, bean, mbd); &#125; &#125;&#125; 聪明的你应该一眼就能看到位置3，以及位置4的执行顺序了吧 好了初始化的逻辑部分搞清楚了，接下来我们一起来看看销毁的流程，销毁开始于applicationContext.close();方法，点进去看如下：12345678910111213141516@Overridepublic void close() &#123; synchronized (this.startupShutdownMonitor) &#123; doClose(); // If we registered a JVM shutdown hook, we don't need it anymore now: // We've already explicitly closed the context. if (this.shutdownHook != null) &#123; try &#123; Runtime.getRuntime().removeShutdownHook(this.shutdownHook); &#125; catch (IllegalStateException ex) &#123; // ignore - VM is already shutting down &#125; &#125; &#125;&#125; 看到其中有一个doClose继续跟进去看会发现有一个destroyBeans方法，再进去直到找到destroySingletons方法如下：12345678public void destroySingletons() &#123; // 省略部分代码 // 循环所有的disposableBean执行对应的destroy方法 for (int i = disposableBeanNames.length - 1; i &gt;= 0; i--) &#123; destroySingleton(disposableBeanNames[i]); &#125; // 省略部分代码&#125; 在继续从destroySingleton方法进去可以找到destroyBean方法如下：12345678910111213protected void destroyBean(String beanName, DisposableBean bean) &#123; // 省略部分代码 // 重点的地方到了 执行DisposableBean 中的destroy 也就是位置6 中对应的打印 if (bean != null) &#123; try &#123; bean.destroy(); &#125; catch (Throwable ex) &#123; logger.error(\"Destroy method on bean with name '\" + beanName + \"' threw an exception\", ex); &#125; &#125; // 省略部分代码&#125; 到这里我们已经完成了90%的原理分析了，这个时候细心的你一定会发现那位置7中的@Bean注解中配置的destroyMethod是在什么时候调用的呢，好像上面都没有讲到，要想知道destroyMethod的调用让我们回到上面讲bean初始化中的doCreateBean方法中其中有一个registerDisposableBeanIfNecessary方法进去看如下： 12345678910111213141516171819202122protected void registerDisposableBeanIfNecessary(String beanName, Object bean, RootBeanDefinition mbd) &#123; AccessControlContext acc = (System.getSecurityManager() != null ? getAccessControlContext() : null); if (!mbd.isPrototype() &amp;&amp; requiresDestruction(bean, mbd)) &#123; if (mbd.isSingleton()) &#123; // Register a DisposableBean implementation that performs all destruction // work for the given bean: DestructionAwareBeanPostProcessors, // DisposableBean interface, custom destroy method. registerDisposableBean(beanName, new DisposableBeanAdapter(bean, beanName, mbd, getBeanPostProcessors(), acc)); &#125; else &#123; // A bean with a custom scope... Scope scope = this.scopes.get(mbd.getScope()); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + mbd.getScope() + \"'\"); &#125; // 关键代码 scope.registerDestructionCallback(beanName, new DisposableBeanAdapter(bean, beanName, mbd, getBeanPostProcessors(), acc)); &#125; &#125;&#125; 继续进去到DisposableBeanAdapter类如下：12345678910111213141516171819202122232425262728293031323334public DisposableBeanAdapter(Object bean, String beanName, RootBeanDefinition beanDefinition, List&lt;BeanPostProcessor&gt; postProcessors, AccessControlContext acc) &#123; Assert.notNull(bean, \"Disposable bean must not be null\"); this.bean = bean; this.beanName = beanName; this.invokeDisposableBean = (this.bean instanceof DisposableBean &amp;&amp; !beanDefinition.isExternallyManagedDestroyMethod(\"destroy\")); this.nonPublicAccessAllowed = beanDefinition.isNonPublicAccessAllowed(); this.acc = acc; String destroyMethodName = inferDestroyMethodIfNecessary(bean, beanDefinition); if (destroyMethodName != null &amp;&amp; !(this.invokeDisposableBean &amp;&amp; \"destroy\".equals(destroyMethodName)) &amp;&amp; !beanDefinition.isExternallyManagedDestroyMethod(destroyMethodName)) &#123; this.destroyMethodName = destroyMethodName; this.destroyMethod = determineDestroyMethod(); if (this.destroyMethod == null) &#123; if (beanDefinition.isEnforceDestroyMethod()) &#123; throw new BeanDefinitionValidationException(\"Couldn't find a destroy method named '\" + destroyMethodName + \"' on bean with name '\" + beanName + \"'\"); &#125; &#125; else &#123; Class&lt;?&gt;[] paramTypes = this.destroyMethod.getParameterTypes(); if (paramTypes.length &gt; 1) &#123; throw new BeanDefinitionValidationException(\"Method '\" + destroyMethodName + \"' of bean '\" + beanName + \"' has more than one parameter - not supported as destroy method\"); &#125; else if (paramTypes.length == 1 &amp;&amp; boolean.class != paramTypes[0]) &#123; throw new BeanDefinitionValidationException(\"Method '\" + destroyMethodName + \"' of bean '\" + beanName + \"' has a non-boolean parameter - not supported as destroy method\"); &#125; &#125; &#125; this.beanPostProcessors = filterPostProcessors(postProcessors, bean); &#125; 怎么样，到现在是不是就很清晰了，位置7的打印其实也是DisposableBean方法中打印出来的，@bean注解的destroyMethod其实是在初始化的时候转换成DisposableBean的实现放入到了disposableBeans中 Spring中Bean的生命周期流程图如下 总结：查看BeanPostProcessor的子类，发现spring大部分功能都是通过BeanPostProcessor来实现，比如，属性注入，*Aware组件，@Autowired注解，生命周期注解(PostConstruct,PreDestroy)等功能都是通过BeanPostProcessor完成 BeanPostProcessor子类 1.AutowiredAnnotationBeanPostProcessor：完成@Autowired注入 2.ApplicationContextAwareProcessor: 完成Aware接口注入 3.AsyncAnnotationBeanPostProcessor: 完成@Async 异步功能 ….. 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[]},{"title":"spring BeanPostProcessor","slug":"spring-BeanPostProcessor","date":"2018-12-22T12:25:44.000Z","updated":"2018-12-22T12:42:34.000Z","comments":true,"path":"2018/12/22/spring-BeanPostProcessor/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-BeanPostProcessor/","excerpt":"","text":"9 spring-bean的统一前后置处理器BeanPostProcessor下面给大家介绍第4种方式，基于实现BeanPostProcessor接口的方式，为啥没放在之前文章中一起介绍，是因为实现BeanPostProcessor的方式是bean的统一前置后置处理而不是基于某一个bean， 定义一个前置后置处理器MyBeanPostProcessor如下： 1234567891011121314151617181920/** * 定义一个前置后置处理器 * * @author * @date 2018年5月6日 */public class MyBeanPostProcessor implements BeanPostProcessor &#123; public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; // 这边只做简单打印 原样返回bean System.out.println(\"postProcessBeforeInitialization====\"+beanName); return bean; &#125; public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; // 这边只做简单打印 原样返回bean System.out.println(\"postProcessAfterInitialization====\"+beanName); return bean; &#125;&#125; 配置类中增加配置如下：1234@Beanpublic MyBeanPostProcessor getMyBeanPostProcessor()&#123; return new MyBeanPostProcessor();&#125; 运行测试结果如下： 123456postProcessBeforeInitialization====org.springframework.context.event.internalEventListenerProcessorpostProcessAfterInitialization====org.springframework.context.event.internalEventListenerProcessorpostProcessBeforeInitialization====org.springframework.context.event.internalEventListenerFactorypostProcessAfterInitialization====org.springframework.context.event.internalEventListenerFactorypostProcessBeforeInitialization====user1postProcessAfterInitialization====user1 下面简单说一下的使用场景： 1，可以解析bean中的一些注解转化为需要的属性 2，注入处理一些统一的属性，而不用在每个bean中注入 3，甚至可以做一些日志打印时间等 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"BeanPostProcessor","slug":"BeanPostProcessor","permalink":"http://blog.shagle.cn/tags/BeanPostProcessor/"}]},{"title":"spring bean生命周期之初始化和销毁的三种方式","slug":"spring-bean生命周期之初始化和销毁的三种方式","date":"2018-12-22T12:23:20.000Z","updated":"2019-01-10T08:36:54.000Z","comments":true,"path":"2018/12/22/spring-bean生命周期之初始化和销毁的三种方式/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-bean生命周期之初始化和销毁的三种方式/","excerpt":"","text":"1 spring-bean生命周期之初始化和销毁的三种方式spring-bean生命周期之初始化和销毁的三种方式 注解bean之指定init-method/destroy-method 实现InitializingBean/DisposableBean接口 @PostConstruct和@PreDestroy注解 1.1，注解bean之指定init-method/destroy-method这种方式其实在之前的一篇文章深入理解spring注解之@Bean注解就有介绍过，这边再简单演示如下： 配置类中增加一个bean如下： 123456789/** * 定义一个bean对象 * @return */ @Bean(value=\"user0\",initMethod=\"initUser\",destroyMethod=\"destroyUser\") public User getUser()&#123; System.out.println(\"创建user实例\"); return new User(\"张三\",26); &#125; User中增加两个方法如下： 123456public void initUser()&#123; System.out.println(\"初始化用户bean之前执行\");&#125;public void destroyUser()&#123; System.out.println(\"bean销毁之后执行\");&#125; 1.2，实现InitializingBean/DisposableBean接口定义一个bean实现InitializingBean/DisposableBean接口如下： 1234567891011121314151617/** * 定义一个实现InitializingBean DisposableBean的bean * * @author * @date 2018年5月4日 */public class User1 implements InitializingBean,DisposableBean&#123; public User1()&#123; System.out.println(\"实例化bean\"); &#125; public void destroy() throws Exception &#123; System.out.println(\"bean销毁之后执行\"); &#125; public void afterPropertiesSet() throws Exception &#123; System.out.println(\"初始化用户bean之前执行\"); &#125;&#125; 配置类中增加配置如下： 1234@Beanpublic User1 getUser1()&#123; return new User1();&#125; 1.3，@PostConstruct和@PreDestroy注解定义一个bean对象User3增加两个方法如下： 12345678910111213141516171819/** * 定义一个bean User3 * * @author * @date 2018年5月4日 */public class User3 &#123; public User3()&#123; System.out.println(\"实例化bean\"); &#125; @PostConstruct public void initUser()&#123; System.out.println(\"初始化用户bean之前执行\"); &#125; @PreDestroy public void destroyUser()&#123; System.out.println(\"bean销毁之前执行\"); &#125;&#125; 配置类中增加配置如下： 1234@Beanpublic User3 getUser3()&#123; return new User3();&#125; 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spring-生命周期","slug":"spring-生命周期","permalink":"http://blog.shagle.cn/tags/spring-生命周期/"}]},{"title":"spring FactoryBean","slug":"spring-factory-bean","date":"2018-12-22T12:21:10.000Z","updated":"2018-12-22T12:41:42.000Z","comments":true,"path":"2018/12/22/spring-factory-bean/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-factory-bean/","excerpt":"","text":"7 spring之FactoryBeanFactoryBean从名字来看以bean结尾那应该就是一个bean吧，没错它确实是一个bean，不同于普通Bean的是：它是实现了FactoryBean&lt;T&gt;接口的Bean，根据该Bean的ID从BeanFactory中获取的实际上是FactoryBean的getObject()返回的 对象，而不是FactoryBean本身，如果要获取FactoryBean对象，请在id前面加一个&amp;符号来获取 7.1. FactoryBean使用演示首先咱们一起来看下FactoryBean的源代码如下： 123456789101112131415161718public interface FactoryBean&lt;T&gt; &#123; /** * 获取bean对应的实例对象 * @return * @throws Exception */ T getObject() throws Exception; /** * 获取factoryBean获取到的实例类型 * @return */ Class&lt;?&gt; getObjectType(); /** * factoryBean创建的实例是否是单实例 * @return */ boolean isSingleton();&#125; 下面我们通过FactoryBean来创建一个图形Circular的bean，代码如下： 1234567891011121314151617181920/** * 创建一个自定义的spring的FactoryBean * * @author * @date 2018年5月2日 */public class MyFactoryBean implements FactoryBean&lt;Circular&gt;&#123; public Circular getObject() throws Exception &#123; return new Circular(); &#125; public Class&lt;?&gt; getObjectType() &#123; return Circular.class; &#125; /** * 是否是单实例的，可以通过改变返回值测试效果 */ public boolean isSingleton() &#123; return true; &#125;&#125; 再在MainConfig主配置中增加一个bean如下： 1234@Beanpublic MyFactoryBean getMyFactoryBean()&#123; return new MyFactoryBean();&#125; 测试代码如下： 12345678@Testpublic void testFactoryBean() &#123; AnnotationConfigApplicationContext applicationContext2 = new AnnotationConfigApplicationContext(MainConfig.class); Object object = applicationContext2.getBean(\"getMyFactoryBean\"); System.out.println(\"实例bean为 === \"+object); Object object2 = applicationContext2.getBean(\"&amp;getMyFactoryBean\"); System.out.println(\"实例bean为 === \"+object2);&#125; 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"FactoryBean","slug":"FactoryBean","permalink":"http://blog.shagle.cn/tags/FactoryBean/"}]},{"title":"spring @Import","slug":"spring-Import","date":"2018-12-22T12:11:15.000Z","updated":"2018-12-22T12:41:42.000Z","comments":true,"path":"2018/12/22/spring-Import/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-Import/","excerpt":"","text":"6. @Import-给容器中快速导入一个组件通过导入的方式实现把实例加入springIOC容器中 6.1 @Import的三种使用方式通过查看@Import源码可以发现@Import注解只能注解在类上，以及唯一的参数value上可以配置3种类型的值Configuration，ImportSelector，ImportBeanDefinitionRegistrar，源码如下： 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Import &#123; /** * &#123;@link Configuration&#125;, &#123;@link ImportSelector&#125;, &#123;@link ImportBeanDefinitionRegistrar&#125; * or regular component classes to import. */ Class&lt;?&gt;[] value();&#125; 接下来就分别来看看三种方式具体使用： 6.1.1 基于Configuration也就是直接填对应的class数组在bean目录下新增两个类Square和Circular如下：1234567891011121314151617/** * 定义一个圆形 * * @author * @date 2018年5月1日 */public class Circular &#123;&#125;/** * 定义一个正方形 * * @author * @date 2018年5月1日 */public class Square &#123;&#125; MainConfig注解配置中增加@Import注解如下： 123@Import(&#123;Square.class,Circular.class&#125;)@Configurationpublic class MainConfig 测试如下 12345678@Testpublic void testImport() &#123; AnnotationConfigApplicationContext applicationContext2 = new AnnotationConfigApplicationContext(MainConfig.class); String[] beanNames = applicationContext2.getBeanDefinitionNames(); for(int i=0;i&lt;beanNames.length;i++)&#123; System.out.println(\"bean名称为===\"+beanNames[i]); &#125;&#125; 6.1.2 基于自定义ImportSelector的使用定义一个MyImportSelector如下： 1234567891011/** * 定义一个我自己的ImportSelector * * @author * @date 2018年5月1日 */public class MyImportSelector implements ImportSelector&#123; public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; return new String[]&#123;\"com.zhang.bean.Triangle\"&#125;; &#125;&#125; MainConfig注解配置修改如下：1@Import(&#123;Square.class,Circular.class,MyImportSelector.class&#125;) 6.1.3 基于ImportBeanDefinitionRegistrar的使用新建一个ImportBeanDefinitionRegistrar如下： 12345678910111213141516/** * 定义一个自定的ImportBeanDefinitionRegistrar * * @author * @date 2018年5月1日 */public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar&#123; public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; // new一个RootBeanDefinition RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Rectangle.class); // 注册一个名字叫rectangle的bean registry.registerBeanDefinition(\"rectangle\", rootBeanDefinition); &#125;&#125; 修改MainConfig注解配置如下：1@Import(&#123;Square.class,Circular.class,MyImportSelector.class,MyImportBeanDefinitionRegistrar.class&#125;) 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spring Import注解","slug":"spring-Import注解","permalink":"http://blog.shagle.cn/tags/spring-Import注解/"}]},{"title":"springcloud feign","slug":"springcloud-feign","date":"2018-12-22T12:08:08.000Z","updated":"2019-01-09T06:54:27.000Z","comments":true,"path":"2018/12/22/springcloud-feign/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/springcloud-feign/","excerpt":"","text":"1. 简介feign是一个声明式的HTTP客户端，spring-cloud-openfeign将feign集成到spring boot中，在接口上通过注解声明Rest协议，将http调用转换为接口方法的调用，使得客户端调用http服务更加简单。 当前spring cloud最新稳定版本是Edgware，feign在其集成的spring-cloud-netflix 1.4.0.RELEASE版本中。 spring cloud下一个版本是Finchley，将会单独集成spring-cloud-openfeign 2. demo我们来看个简单的例子。源代码链接：https://github.com/along101/spring-boot-test/tree/master/feign-test 2.1 服务端代码使用spring boot编写一个简单的Rest服务 1234567@RestController public class HelloController implements HelloService &#123; @Override public String hello(@RequestParam(\"name\") String name) &#123; return \"Hello \" + name; &#125; &#125; 接口代码：12345@RequestMapping(\"/test\") public interface HelloService &#123; @RequestMapping(value = \"/hello1\", method = RequestMethod.GET) String hello(@RequestParam(\"name\") String name); &#125; 代码很简单，通过springMVC注解在接口HelloService上声明Rest服务，HelloController被@RestController注解声明为一个Rest服务。 启动spring boot 就可通过浏览器访问http://localhost:8080/test/hello1?name=ppdai得到返回Hello ppdai。 2.2 客户端代码客户端pom中需要加入spring-cloud-starter-feign的依赖 123456789101112131415161718&lt;dependencies&gt; ... &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Camden.SR7&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 在客户端中新建一个HelloClient接口继承服务端HelloService接口：12345//在spring boot配置文件中配置remote.hello.service.host=http://localhost:8080 @FeignClient(value = \"HELLO-SERVICE\", url = \"$&#123;remote.hello.service.host&#125;\") public interface HelloClient extends HelloService &#123; &#125; HelloClient接口上注解@FeignClient，声明为Feign的客户端，参数url指定服务端地址。在spring boot启动类上增加注解@EnableFeignClients 1234567@SpringBootApplication @EnableFeignClients public class FeignClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(FeignClientApplication.class, args); &#125; &#125; 注意，HelloClient接口需要在启动类package或者子package之下。编写测试类测试：123456789101112@RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = FeignClientApplication.class) public class HelloClientTest &#123; @Autowired private HelloClient helloClient; @Test public void testClient() throws Exception &#123; String result = helloClient.hello(\"ppdai\"); System.out.println(result); &#125; &#125; 启动服务端后，运行该测试类，在控制台会打印出Hello ppdai 3. 原理分析看到客户端测试类中，我们只用了一行代码，就能完成对远程Rest服务的调用，相当的简单。为什么这么神奇，这几段代码是如何做到的呢？ 3.1 @EnableFeignClients 注解声明客户端接口入口是启动类上的注解@EnableFeignClients，源代码：12345678910111213141516@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented @Import(FeignClientsRegistrar.class) public @interface EnableFeignClients &#123; //basePackages的别名 String[] value() default &#123;&#125;; //声明基础包，spring boot启动后，会扫描该包下被@FeignClient注解的接口 String[] basePackages() default &#123;&#125;; //声明基础包的类，通过该类声明基础包 Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;; //默认配置类 Class&lt;?&gt;[] defaultConfiguration() default &#123;&#125;; //直接声明的客户端接口类 Class&lt;?&gt;[] clients() default &#123;&#125;; &#125; @EnableFeignClients的参数声明客户端接口的位置和默认的配置类。 3.1.1 @FeignClient注解，将接口声明为Feign客户端12345678910111213141516171819202122@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface FeignClient &#123; @AliasFor(\"name\") String value() default \"\"; //名称，对应与eureka上注册的应用名 @AliasFor(\"value\") String name() default \"\"; //生成spring bean的qualifier String qualifier() default \"\"; //http服务的url String url() default \"\"; boolean decode404() default false; //配置类，这里设置的配置类是Spring Configuration，将会在FeignContext中创建内部声明的Bean，用于不同的客户端进行隔离 Class&lt;?&gt;[] configuration() default &#123;&#125;; //声明hystrix调用失败后的方法 Class&lt;?&gt; fallback() default void.class; Class&lt;?&gt; fallbackFactory() default void.class; String path() default \"\"; &#125; 3.2 FeignClientsRegistrar 注册客户端“FeignClientsRegistrar 注册客户端”)FeignClientsRegistrar 注册客户端 @EnableFeignClients注解上被注解了@Import(FeignClientsRegistrar.class)，@Import注解的作用是将指定的类作为Bean注入到Spring Context中，我们再来看被引入的FeignClientsRegistrar123456789101112class FeignClientsRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware, BeanClassLoaderAware &#123;。。。 @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; registerDefaultConfiguration(metadata, registry); registerFeignClients(metadata, registry); &#125;。。。&#125; FeignClientsRegistrar类实现了3个接口: 接口ResourceLoaderAware用于注入ResourceLoader 接口BeanClassLoaderAware用于注入ClassLoader 接口ImportBeanDefinitionRegistrar用于动态向Spring Context中注册bean ImportBeanDefinitionRegistrar接口方法registerBeanDefinitions有两个参数 AnnotationMetadata 包含被@Import注解类的信息 这里 @Import注解在@EnableFeignClients上，@EnableFeignClients注解在spring boot启动类上，AnnotationMetadata拿到的是spring boot启动类的相关信息 BeanDefinitionRegistry bean定义注册中心 3.3 registerDefaultConfiguration方法，注册默认配置registerDefaultConfiguration方法代码： 12345678910111213141516171819private void registerDefaultConfiguration(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; //获取@EnableFeignClients注解参数 Map&lt;String, Object&gt; defaultAttrs = metadata .getAnnotationAttributes(EnableFeignClients.class.getName(), true); //如果参数中包含defaultConfiguration if (defaultAttrs != null &amp;&amp; defaultAttrs.containsKey(\"defaultConfiguration\")) &#123; String name; if (metadata.hasEnclosingClass()) &#123; name = \"default.\" + metadata.getEnclosingClassName(); &#125; else &#123; name = \"default.\" + metadata.getClassName(); &#125; //注册客户端的配置Bean registerClientConfiguration(registry, name, defaultAttrs.get(\"defaultConfiguration\")); &#125;&#125; 取出@EnableFeignClients注解参数defaultConfiguration，注册到spring Context中。registerClientConfiguration方法代码如下： 1234567891011121314private void registerClientConfiguration(BeanDefinitionRegistry registry, Object name, Object configuration) &#123; // 创建一个BeanDefinitionBuilder，注册bean的类为FeignClientSpecification BeanDefinitionBuilder builder = BeanDefinitionBuilder .genericBeanDefinition(FeignClientSpecification.class); //增加构造函数参数 builder.addConstructorArgValue(name); builder.addConstructorArgValue(configuration); //调用BeanDefinitionRegistry.registerBeanDefinition方法动态注册Bean registry.registerBeanDefinition( name + \".\" + FeignClientSpecification.class.getSimpleName(), builder.getBeanDefinition());&#125; 这里使用spring 动态注册bean的方式，注册了一个FeignClientSpecification的bean。 3.4 FeignClientSpecification 客户端定义一个简单的pojo，继承了NamedContextFactory.Specification，两个属性String name 和 Class&lt;?&gt;[] configuration，用于FeignContext命名空间独立配置，后面会用到。12345678910@Data @AllArgsConstructor @NoArgsConstructor class FeignClientSpecification implements NamedContextFactory.Specification &#123; private String name; private Class&lt;?&gt;[] configuration; &#125; 3.5 registerFeignClients方法，注册feign客户端1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public void registerFeignClients(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; //生成一个scanner，扫描注定包下的类 ClassPathScanningCandidateComponentProvider scanner = getScanner(); scanner.setResourceLoader(this.resourceLoader); Set&lt;String&gt; basePackages; Map&lt;String, Object&gt; attrs = metadata .getAnnotationAttributes(EnableFeignClients.class.getName()); //包含@FeignClient注解的过滤器 AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter( FeignClient.class); final Class&lt;?&gt;[] clients = attrs == null ? null : (Class&lt;?&gt;[]) attrs.get(\"clients\"); if (clients == null || clients.length == 0) &#123; //@EnableFeignClients没有声明clients，获取basePackages，设置过滤器 scanner.addIncludeFilter(annotationTypeFilter); basePackages = getBasePackages(metadata); &#125; else &#123; //@EnableFeignClients声明了clients final Set&lt;String&gt; clientClasses = new HashSet&lt;&gt;(); basePackages = new HashSet&lt;&gt;(); //basePackages为声明的clients所在的包 for (Class&lt;?&gt; clazz : clients) &#123; basePackages.add(ClassUtils.getPackageName(clazz)); clientClasses.add(clazz.getCanonicalName()); &#125; //增加过滤器，只包含声明的clients AbstractClassTestingTypeFilter filter = new AbstractClassTestingTypeFilter() &#123; @Override protected boolean match(ClassMetadata metadata) &#123; String cleaned = metadata.getClassName().replaceAll(\"\\\\$\", \".\"); return clientClasses.contains(cleaned); &#125; &#125;; scanner.addIncludeFilter( new AllTypeFilter(Arrays.asList(filter, annotationTypeFilter))); &#125; //遍历basePackages for (String basePackage : basePackages) &#123; //扫描包，根据过滤器找到候选的Bean Set&lt;BeanDefinition&gt; candidateComponents = scanner .findCandidateComponents(basePackage); // 遍历候选的bean for (BeanDefinition candidateComponent : candidateComponents) &#123; if (candidateComponent instanceof AnnotatedBeanDefinition) &#123; // 校验注解是否是注解在接口上 AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent; AnnotationMetadata annotationMetadata = beanDefinition.getMetadata(); Assert.isTrue(annotationMetadata.isInterface(), \"@FeignClient can only be specified on an interface\"); // 获取注解属性 Map&lt;String, Object&gt; attributes = annotationMetadata .getAnnotationAttributes( FeignClient.class.getCanonicalName()); String name = getClientName(attributes); //注册客户端配置 registerClientConfiguration(registry, name, attributes.get(\"configuration\")); //注册客户端 registerFeignClient(registry, annotationMetadata, attributes); &#125; &#125; &#125;&#125; 这个方法主要逻辑是扫描注解声明的客户端，调用registerFeignClient方法注册到registry中。这里是一个典型的spring动态注册bean的例子，可以参考这段代码在spring中轻松的实现类路径下class扫描，动态注册bean到spring中。想了解spring类的扫描机制，可以断点到ClassPathScanningCandidateComponentProvider.findCandidateComponents方法中，一步步调试。 3.6 registerFeignClient方法，注册单个客户feign端12345678910111213141516171819202122232425262728293031private void registerFeignClient(BeanDefinitionRegistry registry, AnnotationMetadata annotationMetadata, Map&lt;String, Object&gt; attributes) &#123; String className = annotationMetadata.getClassName(); //构建一个FeignClientFactoryBean的bean工厂定义 BeanDefinitionBuilder definition = BeanDefinitionBuilder .genericBeanDefinition(FeignClientFactoryBean.class); validate(attributes); //根据@FeignClient注解的参数，设置属性 definition.addPropertyValue(\"url\", getUrl(attributes)); definition.addPropertyValue(\"path\", getPath(attributes)); String name = getName(attributes); definition.addPropertyValue(\"name\", name); definition.addPropertyValue(\"type\", className); definition.addPropertyValue(\"decode404\", attributes.get(\"decode404\")); definition.addPropertyValue(\"fallback\", attributes.get(\"fallback\")); definition.addPropertyValue(\"fallbackFactory\", attributes.get(\"fallbackFactory\")); definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); String alias = name + \"FeignClient\"; AbstractBeanDefinition beanDefinition = definition.getBeanDefinition(); beanDefinition.setPrimary(true); //设置qualifier String qualifier = getQualifier(attributes); if (StringUtils.hasText(qualifier)) &#123; alias = qualifier; &#125; //注册，这里为了简写，新建一个BeanDefinitionHolder，调用BeanDefinitionReaderUtils静态方法注册 BeanDefinitionHolder holder = new BeanDefinitionHolder(beanDefinition, className, new String[] &#123; alias &#125;); BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry);&#125; registerFeignClient方法主要是将FeignClientFactoryBean工厂Bean注册到registry中，spring初始化后，会调用FeignClientFactoryBean的getObject方法创建bean注册到spring context中。 3.7 FeignClientFactoryBean 创建feign客户端的工厂1234567891011121314151617181920@Data@EqualsAndHashCode(callSuper = false)class FeignClientFactoryBean implements FactoryBean&lt;Object&gt;, InitializingBean, ApplicationContextAware &#123; //feign客户端接口类 private Class&lt;?&gt; type; private String name; private String url; private String path; private boolean decode404; private ApplicationContext applicationContext; //hystrix集成，调用失败的执行方法 private Class&lt;?&gt; fallback = void.class; //同上 private Class&lt;?&gt; fallbackFactory = void.class;。。。&#125; FeignClientFactoryBean实现了FactoryBean接口，是一个工厂bean 3.7.1 FeignClientFactoryBean.getObject方法12345678910111213141516171819202122232425262728293031323334353637383940414243@Overridepublic Object getObject() throws Exception &#123; //FeignContext在FeignAutoConfiguration中自动注册，FeignContext用于客户端配置类独立注册，后面具体分析 FeignContext context = applicationContext.getBean(FeignContext.class); //创建Feign.Builder Feign.Builder builder = feign(context); //如果@FeignClient注解没有设置url参数 if (!StringUtils.hasText(this.url)) &#123; String url; //url为@FeignClient注解的name参数 if (!this.name.startsWith(\"http\")) &#123; url = \"http://\" + this.name; &#125; else &#123; url = this.name; &#125; //加上path url += cleanPath(); //返回loadBlance客户端，也就是ribbon+eureka的客户端 return loadBalance(builder, context, new HardCodedTarget&lt;&gt;(this.type, this.name, url)); &#125; //@FeignClient设置了url参数，不做负载均衡 if (StringUtils.hasText(this.url) &amp;&amp; !this.url.startsWith(\"http\")) &#123; this.url = \"http://\" + this.url; &#125; //加上path String url = this.url + cleanPath(); //从FeignContext中获取client Client client = getOptional(context, Client.class); if (client != null) &#123; if (client instanceof LoadBalancerFeignClient) &#123; // 有url参数，不做负载均衡，但是客户端是ribbon，或者实际的客户端 client = ((LoadBalancerFeignClient)client).getDelegate(); &#125; builder.client(client); &#125; //从FeignContext中获取Targeter Targeter targeter = get(context, Targeter.class); //生成客户端代理 return targeter.target(this, builder, context, new HardCodedTarget&lt;&gt;( this.type, this.name, url));&#125; 这段代码有个比较重要的逻辑，如果在@FeignClient注解中设置了url参数，就不走Ribbon，直接url调用，否则通过Ribbon调用，实现客户端负载均衡。 可以看到，生成Feign客户端所需要的各种配置对象，都是通过FeignContex中获取的。 3.7.2 FeignContext 隔离配置在@FeignClient注解参数configuration，指定的类是Spring的Configuration Bean，里面方法上加@Bean注解实现Bean的注入，可以指定feign客户端的各种配置，包括Encoder/Decoder/Contract/Feign.Builder等。不同的客户端指定不同配置类，就需要对配置类进行隔离，FeignContext就是用于隔离配置的。 123456public class FeignContext extends NamedContextFactory&lt;FeignClientSpecification&gt; &#123; public FeignContext() &#123; super(FeignClientsConfiguration.class, \"feign\", \"feign.client.name\"); &#125;&#125; FeignContext继承NamedContextFactory，空参数构造函数指定FeignClientsConfiguration类为默认配置。NamedContextFactory实现接口ApplicationContextAware，注入ApplicationContextAware作为parent：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public abstract class NamedContextFactory&lt;C extends NamedContextFactory.Specification&gt; implements DisposableBean, ApplicationContextAware &#123; //命名空间对应的Spring Context private Map&lt;String, AnnotationConfigApplicationContext&gt; contexts = new ConcurrentHashMap&lt;&gt;(); //不同命名空间的定义 private Map&lt;String, C&gt; configurations = new ConcurrentHashMap&lt;&gt;(); //父ApplicationContext，通过ApplicationContextAware接口注入 private ApplicationContext parent; //默认配置类 private Class&lt;?&gt; defaultConfigType; private final String propertySourceName; private final String propertyName;。。。 //设置配置，在FeignAutoConfiguration中将Spring Context中的所有FeignClientSpecification设置进来，如果@EnableFeignClients有设置参数defaultConfiguration也会加进来，前面已经分析在registerDefaultConfiguration方法中注册的FeignClientSpecification Bean public void setConfigurations(List&lt;C&gt; configurations) &#123; for (C client : configurations) &#123; this.configurations.put(client.getName(), client); &#125; &#125; //获取指定命名空间的ApplicationContext，先从缓存中获取，没有就创建 protected AnnotationConfigApplicationContext getContext(String name) &#123; if (!this.contexts.containsKey(name)) &#123; synchronized (this.contexts) &#123; if (!this.contexts.containsKey(name)) &#123; this.contexts.put(name, createContext(name)); &#125; &#125; &#125; return this.contexts.get(name); &#125; //创建ApplicationContext protected AnnotationConfigApplicationContext createContext(String name) &#123; //新建AnnotationConfigApplicationContext AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); //根据name在configurations找到所有的配置类，注册到context总 if (this.configurations.containsKey(name)) &#123; for (Class&lt;?&gt; configuration : this.configurations.get(name) .getConfiguration()) &#123; context.register(configuration); &#125; &#125; //将default.开头的默认默认也注册到Context中 for (Map.Entry&lt;String, C&gt; entry : this.configurations.entrySet()) &#123; if (entry.getKey().startsWith(\"default.\")) &#123; for (Class&lt;?&gt; configuration : entry.getValue().getConfiguration()) &#123; context.register(configuration); &#125; &#125; &#125; //注册一些需要的bean context.register(PropertyPlaceholderAutoConfiguration.class, this.defaultConfigType); context.getEnvironment().getPropertySources().addFirst(new MapPropertySource( this.propertySourceName, Collections.&lt;String, Object&gt; singletonMap(this.propertyName, name))); if (this.parent != null) &#123; // 设置parent context.setParent(this.parent); &#125; //刷新，完成bean生成 context.refresh(); return context; &#125; //从命名空间中获取指定类型的Bean public &lt;T&gt; T getInstance(String name, Class&lt;T&gt; type) &#123; AnnotationConfigApplicationContext context = getContext(name); if (BeanFactoryUtils.beanNamesForTypeIncludingAncestors(context, type).length &gt; 0) &#123; return context.getBean(type); &#125; return null; &#125; //从命名空间中获取指定类型的Bean public &lt;T&gt; Map&lt;String, T&gt; getInstances(String name, Class&lt;T&gt; type) &#123; AnnotationConfigApplicationContext context = getContext(name); if (BeanFactoryUtils.beanNamesForTypeIncludingAncestors(context, type).length &gt; 0) &#123; return BeanFactoryUtils.beansOfTypeIncludingAncestors(context, type); &#125; return null; &#125;&#125; 关键的方法是createContext，为每个命名空间独立创建ApplicationContext，设置parent为外部传入的Context，这样就可以共用外部的Context中的Bean，又有各种独立的配置Bean，熟悉springMVC的同学应该知道，springMVC中创建的WebApplicatonContext里面也有个parent，原理跟这个类似。 从FeignContext中获取Bean，需要传入命名空间，根据命名空间找到缓存中的ApplicationContext，先从自己注册的Bean中获取bean，没有获取到再从到parent中获取。 3.7.3 创建Feign.Builder了解了FeignContext的原理，我们再来看feign最重要的构建类创建过程 12345678910111213141516171819202122232425262728293031323334protected Feign.Builder feign(FeignContext context) &#123; 。。。 //从FeignContext中获取注册的Feign.Builder bean，设置Encoder/Decoder/Contract Feign.Builder builder = get(context, Feign.Builder.class) .logger(logger) .encoder(get(context, Encoder.class)) .decoder(get(context, Decoder.class)) .contract(get(context, Contract.class)); 。。。 //设置feign其他参数，都从FeignContext中获取 Retryer retryer = getOptional(context, Retryer.class); if (retryer != null) &#123; builder.retryer(retryer); &#125; ErrorDecoder errorDecoder = getOptional(context, ErrorDecoder.class); if (errorDecoder != null) &#123; builder.errorDecoder(errorDecoder); &#125; Request.Options options = getOptional(context, Request.Options.class); if (options != null) &#123; builder.options(options); &#125; Map&lt;String, RequestInterceptor&gt; requestInterceptors = context.getInstances( this.name, RequestInterceptor.class); if (requestInterceptors != null) &#123; builder.requestInterceptors(requestInterceptors.values()); &#125; if (decode404) &#123; builder.decode404(); &#125; return builder;&#125; 这里设置了Feign.Builder所必须的参数Encoder/Decoder/Contract，其他参数都是可选的。这三个必须的参数从哪里来的呢？答案是在FeignContext的构造器中，传入了默认的配置FeignClientsConfiguration，这个配置类里面初始化了这三个参数。 3.7.4 FeignClientsConfiguration 客户端默认配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@Configurationpublic class FeignClientsConfiguration &#123; //注入springMVC的HttpMessageConverters @Autowired private ObjectFactory&lt;HttpMessageConverters&gt; messageConverters; //注解参数处理器，处理SpringMVC注解，生成http元数据 @Autowired(required = false) private List&lt;AnnotatedParameterProcessor&gt; parameterProcessors = new ArrayList&lt;&gt;();。。。 //Decoder bean，默认通过HttpMessageConverters进行处理 @Bean @ConditionalOnMissingBean public Decoder feignDecoder() &#123; return new ResponseEntityDecoder(new SpringDecoder(this.messageConverters)); &#125; //Encoder bean，默认通过HttpMessageConverters进行处理 @Bean @ConditionalOnMissingBean public Encoder feignEncoder() &#123; return new SpringEncoder(this.messageConverters); &#125; //Contract bean，通过SpringMvcContract进行处理接口 @Bean @ConditionalOnMissingBean public Contract feignContract(ConversionService feignConversionService) &#123; return new SpringMvcContract(this.parameterProcessors, feignConversionService); &#125; //hystrix自动注入 @Configuration @ConditionalOnClass(&#123; HystrixCommand.class, HystrixFeign.class &#125;) protected static class HystrixFeignConfiguration &#123; //HystrixFeign的builder，全局关掉Hystrix配置feign.hystrix.enabled=false @Bean @Scope(\"prototype\") @ConditionalOnMissingBean @ConditionalOnProperty(name = \"feign.hystrix.enabled\", matchIfMissing = true) public Feign.Builder feignHystrixBuilder() &#123; return HystrixFeign.builder(); &#125; &#125; //默认不重试 @Bean @ConditionalOnMissingBean public Retryer feignRetryer() &#123; return Retryer.NEVER_RETRY; &#125; //默认的builder @Bean @Scope(\"prototype\") @ConditionalOnMissingBean public Feign.Builder feignBuilder(Retryer retryer) &#123; return Feign.builder().retryer(retryer); &#125;。。。&#125; 可以看到，feign需要的decoder/enoder通过适配器共用springMVC中的HttpMessageConverters引入。 feign有自己的注解体系，这里通过SpringMvcContract适配了springMVC的注解体系。 3.7.5 SpringMvcContract 适配feign注解体系SpringMvcContract继承了feign的类Contract.BaseContract，作用是解析接口方法上的注解和方法参数，生成MethodMetadata用于接口方法调用过程中组装http请求。123456789101112131415161718192021222324252627public class SpringMvcContract extends Contract.BaseContract implements ResourceLoaderAware &#123;。。。 //处理Class上的注解 @Override protected void processAnnotationOnClass(MethodMetadata data, Class&lt;?&gt; clz) &#123; 。。。 &#125; //处理方法 @Override public MethodMetadata parseAndValidateMetadata(Class&lt;?&gt; targetType, Method method) &#123; 。。。 &#125; //处理方法上的注解 @Override protected void processAnnotationOnMethod(MethodMetadata data, Annotation methodAnnotation, Method method) &#123; 。。。 &#125; //处理参数上的注解 @Override protected boolean processAnnotationsOnParameter(MethodMetadata data, Annotation[] annotations, int paramIndex) &#123; 。。。 &#125;&#125; 几个覆盖方法分别是处理类上的注解，处理方法，处理方法上的注解，处理方法参数注解，最终生成完整的MethodMetadata。feign自己提供的Contract和扩展javax.ws.rx的Contract原理都是类似的。 3.7.6 Targeter 生成接口动态代理Feign.Builder生成后，就要用Target生成feign客户端的动态代理，这里FeignClientFactoryBean中使用Targeter，Targeter有两个实现类，分别是HystrixTargeter和DefaultTargeter，DefaultTargeter很简单，直接调用HardCodedTarget生成动态代理，HystrixTargeter源码如下：123456789101112131415161718192021222324class HystrixTargeter implements Targeter &#123; @Override public &lt;T&gt; T target(FeignClientFactoryBean factory, Feign.Builder feign, FeignContext context, Target.HardCodedTarget&lt;T&gt; target) &#123; //如果不是HystrixFeign.Builder，直接调用target生成代理 if (!(feign instanceof feign.hystrix.HystrixFeign.Builder)) &#123; return feign.target(target); &#125; //找到fallback或者fallbackFactory，设置到hystrix中 feign.hystrix.HystrixFeign.Builder builder = (feign.hystrix.HystrixFeign.Builder) feign; Class&lt;?&gt; fallback = factory.getFallback(); if (fallback != void.class) &#123; return targetWithFallback(factory.getName(), context, target, builder, fallback); &#125; Class&lt;?&gt; fallbackFactory = factory.getFallbackFactory(); if (fallbackFactory != void.class) &#123; return targetWithFallbackFactory(factory.getName(), context, target, builder, fallbackFactory); &#125; return feign.target(target); &#125; 。。。&#125; 到这里，接口的动态代理就生成了，然后回到FeignClientFactoryBean工厂bean中，会将动态代理注入到SpringContext，在使用的地方，就可以通过@Autowire方式注入了。 3.8 loadBalance方法，客户端负载均衡如果@FeignClient注解中没有配置url参数，将会通过loadBalance方法生成Ribbon的动态代理：1234567891011 protected &lt;T&gt; T loadBalance(Feign.Builder builder, FeignContext context, HardCodedTarget&lt;T&gt; target) &#123; //这里获取到的Client是LoadBalancerFeignClient Client client = getOptional(context, Client.class); if (client != null) &#123; builder.client(client); Targeter targeter = get(context, Targeter.class); return targeter.target(this, builder, context, target); &#125;。。。 &#125; LoadBalancerFeignClient在FeignRibbonClientAutoConfiguration中自动配置的Bean 3.8.1 LoadBalancerFeignClient 负载均衡客户端12345678910111213141516171819202122public class LoadBalancerFeignClient implements Client &#123;。。。 @Override public Response execute(Request request, Request.Options options) throws IOException &#123; try &#123; //获取URI URI asUri = URI.create(request.url()); //获取客户端的名称 String clientName = asUri.getHost(); URI uriWithoutHost = cleanUrl(request.url(), clientName); //创建RibbonRequest FeignLoadBalancer.RibbonRequest ribbonRequest = new FeignLoadBalancer.RibbonRequest( this.delegate, request, uriWithoutHost); //配置 IClientConfig requestConfig = getClientConfig(options, clientName); //获取FeignLoadBalancer，发请求，转换Response return lbClient(clientName).executeWithLoadBalancer(ribbonRequest, requestConfig).toResponse(); &#125; catch (ClientException e) &#123; 。。。 &#125; &#125; 代码逻辑也比较简单，就是是配到Ribbon客户端上调用。Ribbon的相关使用和原理就不在本文中描述。 4. 总结feign本身是一款优秀的开源组件，spring cloud feign又非常巧妙的将feign集成到spring boot中。本文通过对spring cloud feign源代码的解读，详细的分析了feign集成到spring boot中的原理，使我们更加全面的了解到feign的使用。 spring cloud feign也是一个很好的学习spring boot的例子，从中我们可以学习到： spring boot注解声明注入bean spring类扫描机制 spring接口动态注册bean spring命名空间隔离ApplicationContext 本文转载：拍拍贷基础框架团队博客","categories":[{"name":"HttpClient","slug":"HttpClient","permalink":"http://blog.shagle.cn/categories/HttpClient/"}],"tags":[{"name":"feign","slug":"feign","permalink":"http://blog.shagle.cn/tags/feign/"},{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/tags/spring/"}]},{"title":"feign","slug":"feign","date":"2018-12-22T12:02:30.000Z","updated":"2019-01-09T06:49:04.000Z","comments":true,"path":"2018/12/22/feign/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/feign/","excerpt":"Feign是一款java的Restful客户端组件，Feign使得 Java HTTP 客户端编写更方便。Feign 灵感来源于Retrofit, JAXRS-2.0和WebSocket。feign在github上有近3K个star，是一款相当优秀的开源组件，虽然相比Retrofit的近30K个star，逊色了太多，但是spring cloud集成了feign，使得feign在java生态中比Retrofit使用的更加广泛。","text":"Feign是一款java的Restful客户端组件，Feign使得 Java HTTP 客户端编写更方便。Feign 灵感来源于Retrofit, JAXRS-2.0和WebSocket。feign在github上有近3K个star，是一款相当优秀的开源组件，虽然相比Retrofit的近30K个star，逊色了太多，但是spring cloud集成了feign，使得feign在java生态中比Retrofit使用的更加广泛。 1.feign介绍feign的基本原理是在接口方法上加注解，定义rest请求，构造出接口的动态代理对象，然后通过调用接口方法就可以发送http请求，并且自动解析http响应为方法返回值，极大的简化了客户端调用rest api的代码。官网的示例如下： 123456789101112131415161718192021interface GitHub &#123; @RequestLine(\"GET /repos/&#123;owner&#125;/&#123;repo&#125;/contributors\") List&lt;Contributor&gt; contributors(@Param(\"owner\") String owner, @Param(\"repo\") String repo);&#125;static class Contributor &#123; String login; int contributions;&#125;public static void main(String... args) &#123; GitHub github = Feign.builder() .decoder(new GsonDecoder()) .target(GitHub.class, \"https://api.github.com\"); // Fetch and print a list of the contributors to this library. List&lt;Contributor&gt; contributors = github.contributors(\"OpenFeign\", \"feign\"); for (Contributor contributor : contributors) &#123; System.out.println(contributor.login + \" (\" + contributor.contributions + \")\"); &#125;&#125; feign使用教程请参考官网https://github.com/OpenFeign/feign/ 本文主要是对feign源码进行分析，根据源码来理解feign的设计架构和内部实现技术。 2.Feign.build构建接口动态代理我们先来看看接口的动态代理是如何构建出来的，下图是主要接口和类的类图： 从上文中的示例可以看到，构建的接口动态代理对象是通过Feign.builder()生成Feign.Builder的构造者对象，然后设置相关的参数，再调用target方法构造的。Feign.Builder的参数包括： 123456789101112131415161718192021222324252627//拦截器，组装完RequestTemplate，发请求之前的拦截处理RequestTemplate private final List&lt;RequestInterceptor&gt; requestInterceptors = new ArrayList&lt;RequestInterceptor&gt;();//日志级别 private Logger.Level logLevel = Logger.Level.NONE;//契约模型，默认为Contract.Default，用户创建MethodMetadata，用spring cloud就是扩展这个实现springMVC注解 private Contract contract = new Contract.Default();//客户端，默认为Client.Default，可以扩展ApacheHttpClient，OKHttpClient，RibbonClient等 private Client client = new Client.Default(null, null);//重试设置，默认不设置 private Retryer retryer = new Retryer.Default();//日志，可以接入Slf4j private Logger logger = new NoOpLogger();//编码器，用于body的编码 private Encoder encoder = new Encoder.Default();//解码器，用户response的解码 private Decoder decoder = new Decoder.Default();//用@QueryMap注解的参数编码器 private QueryMapEncoder queryMapEncoder = new QueryMapEncoder.Default();//请求错误解码器 private ErrorDecoder errorDecoder = new ErrorDecoder.Default();//参数配置，主要是超时时间之类的 private Options options = new Options();//动态代理工厂 private InvocationHandlerFactory invocationHandlerFactory = new InvocationHandlerFactory.Default();//是否decode404 private boolean decode404; private boolean closeAfterDecode = true; 这块是一个典型的构造者模式，target方法内部先调用build方法新建一个ReflectFeign对象，然后调用ReflectFeign的newInstance方法创建动态代理，代码如下： 123456789101112131415161718192021 //默认使用HardCodedTarget public &lt;T&gt; T target(Class&lt;T&gt; apiType, String url) &#123; return target(new HardCodedTarget&lt;T&gt;(apiType, url)); &#125; public &lt;T&gt; T target(Target&lt;T&gt; target) &#123; return build().newInstance(target); &#125; public Feign build() &#123; SynchronousMethodHandler.Factory synchronousMethodHandlerFactory = new SynchronousMethodHandler.Factory(client, retryer, requestInterceptors, logger, logLevel, decode404, closeAfterDecode); ParseHandlersByName handlersByName = new ParseHandlersByName(contract, options, encoder, decoder, queryMapEncoder, errorDecoder, synchronousMethodHandlerFactory); //handlersByName将所有参数进行封装，并提供解析接口方法的逻辑 //invocationHandlerFactory是Builder的属性，默认值是InvocationHandlerFactory.Default,用创建java动态代理的InvocationHandler实现 return new ReflectiveFeign(handlersByName, invocationHandlerFactory, queryMapEncoder); &#125;&#125; ReflectiveFeign构造函数有三个参数： ParseHandlersByName 将builder所有参数进行封装，并提供解析接口方法的逻辑 InvocationHandlerFactory java动态代理的InvocationHandler的工厂类，默认值是InvocationHandlerFactory.Default QueryMapEncoder 接口参数注解@QueryMap时，参数的编码器 ReflectiveFeign.newInstance方法创建接口动态代理对象： 12345678910111213141516171819202122232425262728public &lt;T&gt; T newInstance(Target&lt;T&gt; target) &#123; //targetToHandlersByName是构造器传入的ParseHandlersByName对象，根据target对象生成MethodHandler映射 Map&lt;String, MethodHandler&gt; nameToHandler = targetToHandlersByName.apply(target); Map&lt;Method, MethodHandler&gt; methodToHandler = new LinkedHashMap&lt;Method, MethodHandler&gt;(); List&lt;DefaultMethodHandler&gt; defaultMethodHandlers = new LinkedList&lt;DefaultMethodHandler&gt;(); //遍历接口所有方法，构建Method-&gt;MethodHandler的映射 for (Method method : target.type().getMethods()) &#123; if (method.getDeclaringClass() == Object.class) &#123; continue; &#125; else if(Util.isDefault(method)) &#123; //接口default方法的Handler，这类方法直接调用 DefaultMethodHandler handler = new DefaultMethodHandler(method); defaultMethodHandlers.add(handler); methodToHandler.put(method, handler); &#125; else &#123; methodToHandler.put(method, nameToHandler.get(Feign.configKey(target.type(), method))); &#125; &#125; //这里factory是构造其中传入的，创建InvocationHandler InvocationHandler handler = factory.create(target, methodToHandler); //java的动态代理 T proxy = (T) Proxy.newProxyInstance(target.type().getClassLoader(), new Class&lt;?&gt;[]&#123;target.type()&#125;, handler); //将default方法直接绑定到动态代理上 for(DefaultMethodHandler defaultMethodHandler : defaultMethodHandlers) &#123; defaultMethodHandler.bindTo(proxy); &#125; return proxy;&#125; 这段代码主要的逻辑是： 1.创建MethodHandler的映射，这里创建的是实现类SynchronousMethodHandler 2.通过InvocationHandlerFatory创建InvocationHandler 3.绑定接口的default方法，通过DefaultMethodHandler绑定 类图中已经画出，SynchronousMethodHandler和DefaultMethodHandler实现了InvocationHandlerFactory.MethodHandler接口，动态代理对象调用方法时，如果是default方法，会直接调用接口方法，因为这里将接口的default方法绑定到动态代理对象上了，其他方法根据方法签名找到SynchronousMethodHandler对象，调用其invoke方法。 3.创建MethodHandler方法处理器SynchronousMethodHandler是feign组件的核心，接口方法调用转换为http请求和解析http响应都是通过SynchronousMethodHandler来执行的，相关类图如下： 创建MethodHandler实现类SynchronousMethodHandler的代码： 1234567891011121314151617181920212223242526public Map&lt;String, MethodHandler&gt; apply(Target key) &#123; //通过contract解析接口方法，生成MethodMetadata列表，默认的contract解析Feign自定义的http注解 List&lt;MethodMetadata&gt; metadata = contract.parseAndValidatateMetadata(key.type()); Map&lt;String, MethodHandler&gt; result = new LinkedHashMap&lt;String, MethodHandler&gt;(); for (MethodMetadata md : metadata) &#123; //BuildTemplateByResolvingArgs实现RequestTemplate.Factory，RequestTemplate的工厂 BuildTemplateByResolvingArgs buildTemplate; //根据方法元数据，使用不同的RequestTemplate的工厂 if (!md.formParams().isEmpty() &amp;&amp; md.template().bodyTemplate() == null) &#123; //如果有formParam，并且bodyTemplate不为空，请求体为x-www-form-urlencoded格式 //将会解析form参数，填充到bodyTemplate中 buildTemplate = new BuildFormEncodedTemplateFromArgs(md, encoder, queryMapEncoder); &#125; else if (md.bodyIndex() != null) &#123; //如果包含请求体，将会用encoder编码请求体对象 buildTemplate = new BuildEncodedTemplateFromArgs(md, encoder, queryMapEncoder); &#125; else &#123; //默认的RequestTemplate的工厂，没有请求体，不需要编码器 buildTemplate = new BuildTemplateByResolvingArgs(md, queryMapEncoder); &#125; //使用工厂SynchronousMethodHandler.Factory创建SynchronousMethodHandler result.put(md.configKey(), factory.create(key, md, buildTemplate, options, decoder, errorDecoder)); &#125; return result;&#125; 这段代码的逻辑是： 1.通过Contract解析接口方法，生成MethodMetadata，默认的Contract解析Feign自定义的http注解 2.根据MethodMetadata方法元数据生成特定的RequestTemplate的工厂 3.使用SynchronousMethodHandler.Factory工厂创建SynchronousMethodHandler 这里有两个工厂不要搞混淆了，SynchronousMethodHandler工厂和RequestTemplate工厂，SynchronousMethodHandler的属性包含RequestTemplate工厂 4.Contract解析接口方法生成MethodMetadatafeign默认的解析器是Contract.Default继承了Contract.BaseContract，解析生成MethodMetadata方法入口： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165@Overridepublic List&lt;MethodMetadata&gt; parseAndValidatateMetadata(Class&lt;?&gt; targetType) &#123; 。。。 Map&lt;String, MethodMetadata&gt; result = new LinkedHashMap&lt;String, MethodMetadata&gt;(); for (Method method : targetType.getMethods()) &#123; 。。。 MethodMetadata metadata = parseAndValidateMetadata(targetType, method); 。。。 result.put(metadata.configKey(), metadata); &#125; return new ArrayList&lt;MethodMetadata&gt;(result.values());&#125;protected MethodMetadata parseAndValidateMetadata(Class&lt;?&gt; targetType, Method method) &#123; MethodMetadata data = new MethodMetadata(); data.returnType(Types.resolve(targetType, targetType, method.getGenericReturnType())); data.configKey(Feign.configKey(targetType, method)); if(targetType.getInterfaces().length == 1) &#123; processAnnotationOnClass(data, targetType.getInterfaces()[0]); &#125; //处理Class上的注解 processAnnotationOnClass(data, targetType); for (Annotation methodAnnotation : method.getAnnotations()) &#123; //处理方法注解 processAnnotationOnMethod(data, methodAnnotation, method); &#125; 。。。 Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); Type[] genericParameterTypes = method.getGenericParameterTypes(); //方法参数注解 Annotation[][] parameterAnnotations = method.getParameterAnnotations(); int count = parameterAnnotations.length; for (int i = 0; i &lt; count; i++) &#123; boolean isHttpAnnotation = false; if (parameterAnnotations[i] != null) &#123; isHttpAnnotation = processAnnotationsOnParameter(data, parameterAnnotations[i], i); &#125; if (parameterTypes[i] == URI.class) &#123; //参数类型是URI，后面构造http请求时，使用该URI data.urlIndex(i); &#125; else if (!isHttpAnnotation) &#123; //如果没有被http注解，就是body参数 。。。 data.bodyIndex(i); data.bodyType(Types.resolve(targetType, targetType, genericParameterTypes[i])); &#125; &#125; if (data.headerMapIndex() != null) &#123; //@HeaderMap注解的参数必须是Map，key类型必须是String checkMapString(\"HeaderMap\", parameterTypes[data.headerMapIndex()], genericParameterTypes[data.headerMapIndex()]); &#125; if (data.queryMapIndex() != null) &#123; if (Map.class.isAssignableFrom(parameterTypes[data.queryMapIndex()])) &#123; //@QueryMap注解的参数如果是Map，key类型必须是String checkMapKeys(\"QueryMap\", genericParameterTypes[data.queryMapIndex()]); &#125; &#125; return data;&#125;protected void processAnnotationOnClass(MethodMetadata data, Class&lt;?&gt; targetType) &#123; if (targetType.isAnnotationPresent(Headers.class)) &#123; //被Headers注解 String[] headersOnType = targetType.getAnnotation(Headers.class).value(); 。。。 //header解析成map，加到MethodMetadata中 Map&lt;String, Collection&lt;String&gt;&gt; headers = toMap(headersOnType); headers.putAll(data.template().headers()); data.template().headers(null); // to clear data.template().headers(headers); &#125;&#125;protected void processAnnotationOnMethod(MethodMetadata data, Annotation methodAnnotation, Method method) &#123; Class&lt;? extends Annotation&gt; annotationType = methodAnnotation.annotationType(); if (annotationType == RequestLine.class) &#123; //@RequestLine注解 String requestLine = RequestLine.class.cast(methodAnnotation).value(); 。。。 if (requestLine.indexOf(' ') == -1) &#123; 。。。 data.template().method(requestLine); return; &#125; //http请求方法 data.template().method(requestLine.substring(0, requestLine.indexOf(' '))); if (requestLine.indexOf(' ') == requestLine.lastIndexOf(' ')) &#123; // no HTTP version is ok data.template().append(requestLine.substring(requestLine.indexOf(' ') + 1)); &#125; else &#123; // skip HTTP version data.template().append( requestLine.substring(requestLine.indexOf(' ') + 1, requestLine.lastIndexOf(' '))); &#125; //将'%2F'反转为'/' data.template().decodeSlash(RequestLine.class.cast(methodAnnotation).decodeSlash()); //参数集合格式化方式，默认使用key=value0&amp;key=value1 data.template().collectionFormat(RequestLine.class.cast(methodAnnotation).collectionFormat()); &#125; else if (annotationType == Body.class) &#123; //@Body注解 String body = Body.class.cast(methodAnnotation).value(); 。。。 if (body.indexOf('&#123;') == -1) &#123; //body中不存在&#123;，直接传入body data.template().body(body); &#125; else &#123; //body中存在&#123;，就是bodyTemplate方式 data.template().bodyTemplate(body); &#125; &#125; else if (annotationType == Headers.class) &#123; //@Header注解 String[] headersOnMethod = Headers.class.cast(methodAnnotation).value(); 。。。 data.template().headers(toMap(headersOnMethod)); &#125;&#125;//处理参数上的注解protected boolean processAnnotationsOnParameter(MethodMetadata data, Annotation[] annotations, int paramIndex) &#123; boolean isHttpAnnotation = false; for (Annotation annotation : annotations) &#123; Class&lt;? extends Annotation&gt; annotationType = annotation.annotationType(); if (annotationType == Param.class) &#123; //@Param注解 Param paramAnnotation = (Param) annotation; String name = paramAnnotation.value(); 。。。 //增加到MethodMetadata中 nameParam(data, name, paramIndex); //@Param注解的expander参数，定义参数的解释器，默认是ToStringExpander，调用参数的toString方法 Class&lt;? extends Param.Expander&gt; expander = paramAnnotation.expander(); if (expander != Param.ToStringExpander.class) &#123; data.indexToExpanderClass().put(paramIndex, expander); &#125; //参数是否已经urlEncoded，如果没有，会使用urlEncoded方式编码 data.indexToEncoded().put(paramIndex, paramAnnotation.encoded()); isHttpAnnotation = true; String varName = '&#123;' + name + '&#125;'; if (!data.template().url().contains(varName) &amp;&amp; !searchMapValuesContainsSubstring(data.template().queries(), varName) &amp;&amp; !searchMapValuesContainsSubstring(data.template().headers(), varName)) &#123; //如果参数不在path里面，不在query里面，不在header里面，就设置到formParam中 data.formParams().add(name); &#125; &#125; else if (annotationType == QueryMap.class) &#123; //@QueryMap注解，注解参数对象时，将该参数转换为http请求参数格式发送 。。。 data.queryMapIndex(paramIndex); data.queryMapEncoded(QueryMap.class.cast(annotation).encoded()); isHttpAnnotation = true; &#125; else if (annotationType == HeaderMap.class) &#123; //@HeaderMap注解，注解一个Map类型的参数，放入http header中发送 。。。 data.headerMapIndex(paramIndex); isHttpAnnotation = true; &#125; &#125; return isHttpAnnotation;&#125; 代码稍微有点多，但是逻辑很清晰，先处理类上的注解，再处理方法上注解，最后处理方法参数注解，把所有注解的情况都处理到就可以了。 生成的MethodMetadata的结构如下： 1234567891011121314151617181920212223242526272829public final class MethodMetadata implements Serializable &#123; //标识方法的key，接口名加方法签名：GitHub#contributors(String,String) private String configKey;//方法返回值类型 private transient Type returnType;//uri参数的位置，方法中可以写个uri参数，发请求时直接使用这个参数 private Integer urlIndex;//body参数的位置，只能有一个未注解的参数为body，否则报错 private Integer bodyIndex;//headerMap参数的位置 private Integer headerMapIndex;//@QueryMap注解参数位置 private Integer queryMapIndex;//@QueryMap注解里面encode参数，是否已经urlEncode编码过了 private boolean queryMapEncoded;//body的类型 private transient Type bodyType;//RequestTemplate 原型 private RequestTemplate template = new RequestTemplate();//form请求参数 private List&lt;String&gt; formParams = new ArrayList&lt;String&gt;();//方法参数位置和名称的map private Map&lt;Integer, Collection&lt;String&gt;&gt; indexToName ;//@Param中注解的expander方法，可以指定解析参数类 private Map&lt;Integer, Class&lt;? extends Expander&gt;&gt; indexToExpanderClass ;//参数是否被urlEncode编码过了，@Param中encoded方法 private Map&lt;Integer, Boolean&gt; indexToEncoded ;//自定义的Expander private transient Map&lt;Integer, Expander&gt; indexToExpander; Contract也是feign的一个扩展点，一个优秀组件的架构通常是具有很强的扩展性，feign的架构本身很简单，设计的扩展点也很简单方便，所以受到spring的青睐，将其集成到spring cloud中。spring cloud就是通过Contract的扩展，实现使用springMVC的注解接入feign。feign自己还实现了使用jaxrs注解接入feign。 5.初始化总结上文已经完成了feign初始化结构为动态代理的整个过程，简单的捋一遍： 初始化Feign.Builder传入参数，构造ReflectiveFeign ReflectiveFeign通过内部类ParseHandlersByName的Contract属性，解析接口生成MethodMetadata ParseHandlersByName根据MethodMetadata生成RequestTemplate工厂 ParseHandlersByName创建SynchronousMethodHandler，传入MethodMetadata、RequestTemplate工厂和Feign.Builder相关参数 ReflectiveFeign创建FeignInvocationHandler，传入参数SynchronousMethodHandler，绑定DefaultMethodHandler ReflectiveFeign根据FeignInvocationHandler创建Proxy 关键的几个类是： ReflectiveFeign 初始化入口 FeignInvocationHandler 实现动态代理的InvocHandler SynchronousMethodHandler 方法处理器，方法调用处理器 MethodMetadata 方法元数据 6.接口调用为方便理解，分析完feign源码后，我将feign执行过程分成三层，如下图： 三层分别为： 代理层 动态代理调用层 转换层 方法转http请求，解码http响应 网络层 http请求发送 java动态代理接口方法调用，会调用到InvocaHandler的invoke方法，feign里面实现类是FeignInvocationHandler，invoke代码如下： 123456private final Map&lt;Method, MethodHandler&gt; dispatch;public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; 。。。 return dispatch.get(method).invoke(args);&#125; 根据方法找到MethodHandler，除接口的default方法外，找到的是SynchronousMethodHandler对象，然后调用SynchronousMethodHandlerd.invoke方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public Object invoke(Object[] argv) throws Throwable &#123; //buildTemplateFromArgs是RequestTemplate工程对象，根据方法参数创建RequestTemplate RequestTemplate template = buildTemplateFromArgs.create(argv); //重试设置 Retryer retryer = this.retryer.clone(); while (true) &#123; try &#123; //执行和解码 return executeAndDecode(template); &#125; catch (RetryableException e) &#123; retryer.continueOrPropagate(e); 。。。 continue; &#125; &#125;&#125;Object executeAndDecode(RequestTemplate template) throws Throwable &#123; //RequestTemplate转换为Request Request request = targetRequest(template) 。。。 Response response; long start = System.nanoTime(); try &#123; response = client.execute(request, options); response.toBuilder().request(request).build(); &#125; catch (IOException e) &#123; 。。。 throw errorExecuting(request, e); &#125; long elapsedTime = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start); boolean shouldClose = true; try &#123; 。。。 if (Response.class == metadata.returnType()) &#123; //如果接口方法返回的是Response类 if (response.body() == null) &#123; //body为空，直接返回 return response; &#125; if (response.body().length() == null || response.body().length() &gt; MAX_RESPONSE_BUFFER_SIZE) &#123; //body不为空，且length&gt;最大缓存值，返回response，但是不能关闭response shouldClose = false; return response; &#125; // 读取body字节数组，返回response byte[] bodyData = Util.toByteArray(response.body().asInputStream()); return response.toBuilder().body(bodyData).build(); &#125; if (response.status() &gt;= 200 &amp;&amp; response.status() &lt; 300) &#123; //响应成功 if (void.class == metadata.returnType()) &#123; //接口返回void return null; &#125; else &#123; //解码response，直接调用decoder解码 Object result = decode(response); shouldClose = closeAfterDecode; return result; &#125; &#125; else if (decode404 &amp;&amp; response.status() == 404 &amp;&amp; void.class != metadata.returnType()) &#123; //404解析 Object result = decode(response); shouldClose = closeAfterDecode; return result; &#125; else &#123; //其他返回码，使用errorDecoder解析，抛出异常 throw errorDecoder.decode(metadata.configKey(), response); &#125; &#125; catch (IOException e) &#123; throw errorReading(request, response, e); &#125; finally &#123; //是否需要关闭response，根据Feign.Builder 参数设置是否要关闭流 if (shouldClose) &#123; ensureClosed(response.body()); &#125; &#125;&#125; 过程比较简单，生成RquestTemplate -&gt; 转换为Request -&gt; client发请求 -&gt; Decoder解析Response RquestTemplate构建过程先看看RequestTemplate的结构： 12345678910111213141516171819private static final long serialVersionUID = 1L;//请求参数 ?后面的name=value private final Map&lt;String, Collection&lt;String&gt;&gt; queries ;//请求头 private final Map&lt;String, Collection&lt;String&gt;&gt; headers ;//请求方法 GET/POST等 private String method;//请求路径 private StringBuilder url = new StringBuilder();//字符集 private transient Charset charset;//请求体 private byte[] body;//@Body(\"%7B\\\"user_name\\\": \\\"&#123;user_name&#125;\\\", \\\"password\\\": \\\"&#123;password&#125;\\\"%7D\")注解的模板 private String bodyTemplate;//是否decode削减，将\"%2F\"反转为\"/\" private boolean decodeSlash = true;//集合格式化，分隔符 private CollectionFormat collectionFormat = CollectionFormat.EXPLODED; 在SynchronousMethodHandler.invoke方法中生成RequestTemplate 12//buildTemplateFromArgs是RequestTemplate.Factory实现类RequestTemplate template = buildTemplateFromArgs.create(argv); RequestTemplate.Factory有三个实现类： BuildTemplateByResolvingArgs RequestTemplate工厂 BuildEncodedTemplateFromArgs BuildTemplateByResolvingArgs的子类 重载resolve方法，解析form表单请求 BuildFormEncodedTemplateFromArgs BuildTemplateByResolvingArgs的子类，重载resolve方法，解析body请求 BuildTemplateByResolvingArgs创建RequestTemplate的create方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293//BuildTemplateByResolvingArgs实现RequestTemplate.Factory的方法public RequestTemplate create(Object[] argv) &#123; RequestTemplate mutable = new RequestTemplate(metadata.template()); if (metadata.urlIndex() != null) &#123; //插入接口方法参数中的URI int urlIndex = metadata.urlIndex(); mutable.insert(0, String.valueOf(argv[urlIndex])); &#125; Map&lt;String, Object&gt; varBuilder = new LinkedHashMap&lt;String, Object&gt;(); //方法参数位置和请求定义的参数名称的map for (Entry&lt;Integer, Collection&lt;String&gt;&gt; entry : metadata.indexToName().entrySet()) &#123; //将方法参数值和定义的请求参数进行映射，varBuilder int i = entry.getKey(); Object value = argv[entry.getKey()]; if (value != null) &#123; // Null values are skipped. if (indexToExpander.containsKey(i)) &#123; value = expandElements(indexToExpander.get(i), value); &#125; for (String name : entry.getValue()) &#123; varBuilder.put(name, value); &#125; &#125; &#125; //解析RequestTemplate RequestTemplate template = resolve(argv, mutable, varBuilder); //解析queryMap，这块代码有些奇怪，为什么单独把queryMap放在这里解析，而不是在resolve方法中，或者在RequestTemplate中 if (metadata.queryMapIndex() != null) &#123; // add query map parameters after initial resolve so that they take // precedence over any predefined values Object value = argv[metadata.queryMapIndex()]; Map&lt;String, Object&gt; queryMap = toQueryMap(value); template = addQueryMapQueryParameters(queryMap, template); &#125; //解析headerMap定义的参数 if (metadata.headerMapIndex() != null) &#123; template = addHeaderMapHeaders((Map&lt;String, Object&gt;) argv[metadata.headerMapIndex()], template); &#125; return template;&#125;//BuildTemplateByResolvingArgsprotected RequestTemplate resolve(Object[] argv, RequestTemplate mutable, Map&lt;String, Object&gt; variables) &#123; // 根据需要进行urlEncode参数 Map&lt;String, Boolean&gt; variableToEncoded = new LinkedHashMap&lt;String, Boolean&gt;(); for (Entry&lt;Integer, Boolean&gt; entry : metadata.indexToEncoded().entrySet()) &#123; Collection&lt;String&gt; names = metadata.indexToName().get(entry.getKey()); for (String name : names) &#123; variableToEncoded.put(name, entry.getValue()); &#125; &#125; //解析参数 return mutable.resolve(variables, variableToEncoded);&#125;//BuildEncodedTemplateFromArgsprotected RequestTemplate resolve(Object[] argv, RequestTemplate mutable, Map&lt;String, Object&gt; variables) &#123; Object body = argv[metadata.bodyIndex()]; checkArgument(body != null, \"Body parameter %s was null\", metadata.bodyIndex()); try &#123; //编码并设置RequestTemplate的body encoder.encode(body, metadata.bodyType(), mutable); &#125; catch (EncodeException e) &#123; throw e; &#125; catch (RuntimeException e) &#123; throw new EncodeException(e.getMessage(), e); &#125; return super.resolve(argv, mutable, variables);&#125;//BuildFormEncodedTemplateFromArgsprotected RequestTemplate resolve(Object[] argv, RequestTemplate mutable, Map&lt;String, Object&gt; variables) &#123; //构造form参数，为HashMap Map&lt;String, Object&gt; formVariables = new LinkedHashMap&lt;String, Object&gt;(); for (Entry&lt;String, Object&gt; entry : variables.entrySet()) &#123; if (metadata.formParams().contains(entry.getKey())) &#123; formVariables.put(entry.getKey(), entry.getValue()); &#125; &#125; try &#123; //编码并设置RequestTemplate的body， encoder.encode(formVariables, Encoder.MAP_STRING_WILDCARD, mutable); &#125; catch (EncodeException e) &#123; throw e; &#125; catch (RuntimeException e) &#123; throw new EncodeException(e.getMessage(), e); &#125; //调用父类的resolve return super.resolve(argv, mutable, variables);&#125; RequestTemplate解析参数的方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980//RequestTemplate解析参数的方法public RequestTemplate resolve(Map&lt;String, ?&gt; variables) &#123; StringBuilder uri = new StringBuilder(); /* create a new template form this one, but explicitly */ RequestTemplate resolved = RequestTemplate.from(this); if (this.uriTemplate == null) &#123; /* create a new uri template using the default root */ this.uriTemplate = UriTemplate.create(\"\", !this.decodeSlash, this.charset); &#125; uri.append(this.uriTemplate.expand(variables)); /* * for simplicity, combine the queries into the uri and use the resulting uri to seed the * resolved template. */ if (!this.queries.isEmpty()) &#123; /* * since we only want to keep resolved query values, reset any queries on the resolved copy */ resolved.queries(Collections.emptyMap()); StringBuilder query = new StringBuilder(); Iterator&lt;QueryTemplate&gt; queryTemplates = this.queries.values().iterator(); while (queryTemplates.hasNext()) &#123; QueryTemplate queryTemplate = queryTemplates.next(); String queryExpanded = queryTemplate.expand(variables); if (Util.isNotBlank(queryExpanded)) &#123; query.append(queryTemplate.expand(variables)); if (queryTemplates.hasNext()) &#123; query.append(\"&amp;\"); &#125; &#125; &#125; String queryString = query.toString(); if (!queryString.isEmpty()) &#123; Matcher queryMatcher = QUERY_STRING_PATTERN.matcher(uri); if (queryMatcher.find()) &#123; /* the uri already has a query, so any additional queries should be appended */ uri.append(\"&amp;\"); &#125; else &#123; uri.append(\"?\"); &#125; uri.append(queryString); &#125; &#125; /* add the uri to result */ resolved.uri(uri.toString()); /* headers */ if (!this.headers.isEmpty()) &#123; /* * same as the query string, we only want to keep resolved values, so clear the header map on * the resolved instance */ resolved.headers(Collections.emptyMap()); for (HeaderTemplate headerTemplate : this.headers.values()) &#123; /* resolve the header */ String header = headerTemplate.expand(variables); if (!header.isEmpty()) &#123; /* split off the header values and add it to the resolved template */ String headerValues = header.substring(header.indexOf(\" \") + 1); if (!headerValues.isEmpty()) &#123; resolved.header(headerTemplate.getName(), headerValues); &#125; &#125; &#125; &#125; resolved.body(this.body.expand(variables)); /* mark the new template resolved */ resolved.resolved = true; return resolved; &#125; 8.RquestTemplate转换Request先来看看Request的结构，完整的http请求信息的定义： 12345private final String method;private final String url;private final Map&lt;String, Collection&lt;String&gt;&gt; headers;private final byte[] body;private final Charset charset; SynchronousMethodHandler的targetRequest方法将RequestTemplate转换为Request12345678Request targetRequest(RequestTemplate template) &#123; //先应用所用拦截器，拦截器是在Feign.Builder中传入的，拦截器可以修改RequestTemplate信息 for (RequestInterceptor interceptor : requestInterceptors) &#123; interceptor.apply(template); &#125; //调用Target的apply方法，默认Target是HardCodedTarget return target.apply(new RequestTemplate(template));&#125; 这块先应用所有拦截器，然后target的apply方法。拦截器和target都是扩展点，拦截器可以在构造好RequestTemplate后和发请求前修改请求信息，target默认使用HardCodedTarget直接发请求，feign还提供了LoadBalancingTarget，适配Ribbon来发请求，实现客户端的负载均衡。 创建过程： 12345678910111213141516171819202122232425262728 //HardCodedTarget的apply方法 public Request apply(RequestTemplate input) &#123; if (input.url().indexOf(\"http\") != 0) &#123; input.insert(0, url()); &#125; //调用RequestTemplate的request方法 return input.request(); &#125; //RequestTemplate的request方法public Request request() &#123; //安全拷贝所有header Map&lt;String, Collection&lt;String&gt;&gt; safeCopy = new LinkedHashMap&lt;String, Collection&lt;String&gt;&gt;(); safeCopy.putAll(headers); //调用Request的create静态方法 return Request.create( method, url + queryLine(), Collections.unmodifiableMap(safeCopy), body, charset );&#125;//Request的create方法 public static Request create(String method, String url, Map&lt;String, Collection&lt;String&gt;&gt; headers, byte[] body, Charset charset) &#123; //new 对象 return new Request(method, url, headers, body, charset); &#125; 从代码上可以看到，RequestTemplate基本上直接转为Request，没有做什么逻辑操作。对比下LoadBalancingTarget： 12345678910111213public Request apply(RequestTemplate input) &#123; //选取一个Server，lb是Ribbon的AbstractLoadBalancer类 Server currentServer = lb.chooseServer(null); //生成url String url = format(\"%s://%s%s\", scheme, currentServer.getHostPort(), path); input.insert(0, url); try &#123; //生成Request return input.request(); &#125; finally &#123; lb.getLoadBalancerStats().incrementNumRequests(currentServer); &#125;&#125; 可以看到，非常简单的几行代码，只要修改请求的url就能实现客户端负载均衡。 9.http请求发送SynchronousMethodHandler中构造好Request后，直接调用client的execute方法发送请求： 1response = client.execute(request, options); client是一个Client接口，默认实现类是Client.Default，使用java api中的HttpURLConnection发送http请求。feign还实现了： ApacheHttpClient OkHttpClient RibbonClient 使用RibbonClient跟使用LoadBalancingTarget作用都是实现客户端负载均衡，RibbonClient实现稍微复杂些。 10.接口调用过程总结我们再将接口调用过程捋一遍： 接口的动态代理Proxy调用接口方法会执行的FeignInvocationHandler FeignInvocationHandler通过方法签名在属性Map&lt;Method, MethodHandler&gt; dispatch中找到SynchronousMethodHandler，调用invoke方法 SynchronousMethodHandler的invoke方法根据传入的方法参数，通过自身属性工厂对象RequestTemplate.Factory创建RequestTemplate，工厂里面会用根据需要进行Encode SynchronousMethodHandler遍历自身属性RequestInterceptor列表，对RequestTemplate进行改造 SynchronousMethodHandler调用自身Target属性的apply方法，将RequestTemplate转换为Request对象 SynchronousMethodHandler调用自身Client的execute方法，传入Request对象 Client将Request转换为http请求，发送后将http响应转换为Response对象 SynchronousMethodHandler调用Decoder的方法对Response对象解码后返回 返回的对象最后返回到Proxy 时序图如下： 11.feign扩展点总结前文分析源代码时，已经提到了feign的扩展点，最后我们再将feign的主要扩展点进行总结一下： Contract 契约Contract的作用是解析接口方法，生成Rest定义。feign默认使用自己的定义的注解，还提供了 JAXRSContract javax.ws.rs注解接口实现 SpringContract是spring cloud提供SpringMVC注解实现方式。 InvocationHandler 动态代理handler通过InvocationHandlerFactory注入到Feign.Builder中，feign提供了Hystrix的扩展，实现Hystrix接入 Encoder 请求body编码器feign已经提供扩展包含： 默认编码器，只能处理String和byte[] json编码器GsonEncoder、JacksonEncoder XML编码器JAXBEncoder Decoder http响应解码器最基本的有： json解码器 GsonDecoder、JacksonDecoder XML解码器 JAXBDecoder Stream流解码器 StreamDecoder Target 请求转换器feign提供的实现有： HardCodedTarget 默认Target，不做任何处理。 LoadBalancingTarget 使用Ribbon进行客户端路由 Client 发送http请求的客户端feign提供的Client实现有： Client.Default 默认实现，使用java api的HttpClientConnection发送http请求 ApacheHttpClient 使用apache的Http客户端发送请求 OkHttpClient 使用OKHttp客户端发送请求 RibbonClient 使用Ribbon进行客户端路由 RequestInterceptor 请求拦截器调用客户端发请求前，修改RequestTemplate，比如为所有请求添加Header就可以用拦截器实现。 Retryer 重试策略默认的策略是Retryer.Default，包含3个参数：间隔、最大间隔和重试次数，第一次失败重试前会sleep输入的间隔时间的，后面每次重试sleep时间是前一次的1.5倍，超过最大时间或者最大重试次数就失败 本文转载：拍拍贷基础框架团队博客","categories":[{"name":"HttpClient","slug":"HttpClient","permalink":"http://blog.shagle.cn/categories/HttpClient/"}],"tags":[{"name":"feign","slug":"feign","permalink":"http://blog.shagle.cn/tags/feign/"}]},{"title":"spring @Conditional","slug":"spring-Conditional","date":"2018-12-22T12:00:53.000Z","updated":"2018-12-22T12:41:42.000Z","comments":true,"path":"2018/12/22/spring-Conditional/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-Conditional/","excerpt":"","text":"5. @Conditional-按照条件注册bean5.1 配置类12345678910111213141516171819202122//类中组件统一设置。满足当前条件，这个类中配置的所有bean注册都能生效；@Conditional(&#123;WindowsCondition.class&#125;)@Configurationpublic class MainConfig2 &#123; /** * @Conditional(&#123;Condition&#125;) ： 按照一定的条件进行判断，满足条件给容器中注册bean * * 如果系统是windows，给容器中注册(\"bill\") * 如果是linux系统，给容器中注册(\"linus\") */ @Conditional(&#123;WindowsCondition.class&#125;) @Bean(\"bill\") public Person person01()&#123; return new Person(\"Bill Gates\",62); &#125; @Conditional(LinuxCondition.class) @Bean(\"linus\") public Person person02()&#123; return new Person(\"linus\", 48); &#125;&#125; 5.2 条件112345678910111213141516171819202122232425262728293031//判断是否linux系统public class LinuxCondition implements Condition &#123; /** * ConditionContext：判断条件能使用的上下文（环境） * AnnotatedTypeMetadata：注释信息 */ @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; // TODO是否linux系统 //1、能获取到ioc使用的beanfactory ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); //2、获取类加载器 ClassLoader classLoader = context.getClassLoader(); //3、获取当前环境信息 Environment environment = context.getEnvironment(); //4、获取到bean定义的注册类 BeanDefinitionRegistry registry = context.getRegistry(); String property = environment.getProperty(\"os.name\"); //可以判断容器中的bean注册情况，也可以给容器中注册bean boolean definition = registry.containsBeanDefinition(\"person\"); if(property.contains(\"linux\"))&#123; return true; &#125; return false; &#125;&#125; 5.3 条件21234567891011121314//判断是否windows系统public class WindowsCondition implements Condition &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; Environment environment = context.getEnvironment(); String property = environment.getProperty(\"os.name\"); if(property.contains(\"Windows\"))&#123; return true; &#125; return false; &#125;&#125; @ConditionalOnBean（仅仅在当前上下文中存在某个对象时，才会实例化一个Bean） @ConditionalOnClass（某个class位于类路径上，才会实例化一个Bean） @ConditionalOnExpression（当表达式为true的时候，才会实例化一个Bean） @ConditionalOnMissingBean（仅仅在当前上下文中不存在某个对象时，才会实例化一个Bean） @ConditionalOnMissingClass（某个class类路径上不存在的时候，才会实例化一个Bean） @ConditionalOnNotWebApplication（不是web应用） 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"Conditional","slug":"Conditional","permalink":"http://blog.shagle.cn/tags/Conditional/"}]},{"title":"spring @Lazy","slug":"spring-Lazy-bean","date":"2018-12-22T12:00:53.000Z","updated":"2018-12-22T12:41:42.000Z","comments":true,"path":"2018/12/22/spring-Lazy-bean/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-Lazy-bean/","excerpt":"","text":"4. @Lazy-bean懒加载当使用@Scope注解的singleton属性时，bean的实例会在IOC容器创建的时候被加载，但是如果在创建bean的时候加上@lazy注解，则bean的实例会在第一次使用的时候被创建。 123456789 @Lazy @Scope(value = ConfigurableBeanFactory.SCOPE_SINGLETON)//singleton @Bean(name = \"person\") public Person person()&#123; Person person = new Person(); person.setName(\"lqf\"); person.setEmail(\"lqf@163.com\"); return person;&#125;","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"Lazy-bean注解","slug":"Lazy-bean注解","permalink":"http://blog.shagle.cn/tags/Lazy-bean注解/"}]},{"title":"spring @Scope","slug":"spring-Scope","date":"2018-12-22T11:59:53.000Z","updated":"2018-12-22T12:41:42.000Z","comments":true,"path":"2018/12/22/spring-Scope/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-Scope/","excerpt":"","text":"3. @Scope@Scope注解是springIoc容器中的一个作用域，在 Spring IoC 容器中具有以下几种作用域：基本作用域 singleton（全局有且仅有一个实例）、 prototype(每次获取Bean的时候会有一个新的实例)， Web 作用域 reqeust：表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP request内有效 session：作用域表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP session内有效 globalsession：作用域类似于标准的HTTP Session作用域，不过它仅仅在基于portlet的web应用中才有意义","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spring Scope注解","slug":"spring-Scope注解","permalink":"http://blog.shagle.cn/tags/spring-Scope注解/"}]},{"title":"spring @ComponentScan","slug":"spring-ComponentScan","date":"2018-12-22T10:45:22.000Z","updated":"2018-12-22T12:41:42.000Z","comments":true,"path":"2018/12/22/spring-ComponentScan/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-ComponentScan/","excerpt":"","text":"2. @ComponentScan 扫描bean注册到spring中123456789101112131415161718@Configuration@ComponentScanpublic class MainConfig &#123; &#125;public class MainTest &#123; @Test public void testConfig() &#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取容器中所有的bean名字 String[] names =applicationContext.getBeanDefinitionNames(); System.out.println(names); &#125;&#125; @ComponentScan 源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Repeatable(ComponentScans.class)public @interface ComponentScan &#123; /** * 对应的包扫描路径 可以是单个路径，也可以是扫描的路径数组 * @return */ @AliasFor(\"basePackages\") String[] value() default &#123;&#125;; /** * 和value一样是对应的包扫描路径 可以是单个路径，也可以是扫描的路径数组 * @return */ @AliasFor(\"value\") String[] basePackages() default &#123;&#125;; /** * 指定具体的扫描的类 * @return */ Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;; /** * 对应的bean名称的生成器 默认的是BeanNameGenerator * @return */ Class&lt;? extends BeanNameGenerator&gt; nameGenerator() default BeanNameGenerator.class; /** * 处理检测到的bean的scope范围 */ Class&lt;? extends ScopeMetadataResolver&gt; scopeResolver() default AnnotationScopeMetadataResolver.class; /** * 是否为检测到的组件生成代理 * Indicates whether proxies should be generated for detected components, which may be * necessary when using scopes in a proxy-style fashion. * &lt;p&gt;The default is defer to the default behavior of the component scanner used to * execute the actual scan. * &lt;p&gt;Note that setting this attribute overrides any value set for &#123;@link #scopeResolver&#125;. * @see ClassPathBeanDefinitionScanner#setScopedProxyMode(ScopedProxyMode) */ ScopedProxyMode scopedProxy() default ScopedProxyMode.DEFAULT; /** * 控制符合组件检测条件的类文件 默认是包扫描下的 **/*.class * @return */ String resourcePattern() default ClassPathScanningCandidateComponentProvider.DEFAULT_RESOURCE_PATTERN; /** * 是否对带有@Component @Repository @Service @Controller注解的类开启检测,默认是开启的 * @return */ boolean useDefaultFilters() default true; /** * 指定某些定义Filter满足条件的组件 FilterType有5种类型如： * ANNOTATION, 注解类型 默认 ASSIGNABLE_TYPE,指定固定类 ASPECTJ， ASPECTJ类型 REGEX,正则表达式 CUSTOM,自定义类型 * @return */ Filter[] includeFilters() default &#123;&#125;; /** * 排除某些过来器扫描到的类 * @return */ Filter[] excludeFilters() default &#123;&#125;; /** * 扫描到的类是都开启懒加载 ，默认是不开启的 * @return */ boolean lazyInit() default false;&#125; 扫码自定义过滤器，将className包含Service的类，注入容器 123456789101112131415161718192021222324/** * 自定义过滤 * * @author * @date 2018年5月12日 */public class MyTypeFilter implements TypeFilter &#123; public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; //获取当前类注解信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); //获取当前正在扫描类信息 ClassMetadata classMetadata = metadataReader.getClassMetadata(); //获取当前类路径 Resource resource = metadataReader.getResource(); String className = classMetadata.getClassName(); System.out.println(\"---&gt;\"+className); // 检测名字包含Service的bean if(className.contains(\"Service\"))&#123; return true; &#125; return false; &#125;&#125; 主配置如下 12345678@ComponentScan(value=\"com.zhang\",useDefaultFilters=true, includeFilters=&#123; @Filter(type=FilterType.ANNOTATION,classes=&#123;Controller.class&#125;), @Filter(type=FilterType.CUSTOM,classes=&#123;MyTypeFilter.class&#125;) &#125;)@Configurationpublic class MainScanConfig &#123;&#125; 好了includeFilters参数就演示到这，另外一个参数excludeFilters和includeFilters用户一摸一样，只是他是过滤出不加入spring容器中， 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"ComponentScan","slug":"ComponentScan","permalink":"http://blog.shagle.cn/tags/ComponentScan/"}]},{"title":"spring @Configuration","slug":"spring-Configuration","date":"2018-12-22T10:39:30.000Z","updated":"2018-12-22T12:41:42.000Z","comments":true,"path":"2018/12/22/spring-Configuration/","link":"","permalink":"http://blog.shagle.cn/2018/12/22/spring-Configuration/","excerpt":"","text":"1. @Configuration 配置类123456789101112131415161718@Configurationpublic class MainConfig &#123; @Bean public Person person() &#123; return new Person(); &#125;&#125;public class MainTest &#123; @Test public void testConfig() &#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); Person person = applicationContext.getBean(Person.class); &#125;&#125; 本文大部分转自：51CTO博客-知了123","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.shagle.cn/categories/spring/"}],"tags":[{"name":"spring Configuration注解","slug":"spring-Configuration注解","permalink":"http://blog.shagle.cn/tags/spring-Configuration注解/"}]}]}